"use strict";(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[70649],{70649:e=>{e.exports=JSON.parse('{"01-ai/yi-1.5-34b-chat":{"description":"Zero Um, o mais recente modelo de ajuste fino de c\xf3digo aberto, com 34 bilh\xf5es de par\xe2metros, suporta m\xfaltiplos cen\xe1rios de di\xe1logo, com dados de treinamento de alta qualidade, alinhados \xe0s prefer\xeancias humanas."},"01-ai/yi-1.5-9b-chat":{"description":"Zero Um, o mais recente modelo de ajuste fino de c\xf3digo aberto, com 9 bilh\xf5es de par\xe2metros, suporta m\xfaltiplos cen\xe1rios de di\xe1logo, com dados de treinamento de alta qualidade, alinhados \xe0s prefer\xeancias humanas."},"360/deepseek-r1":{"description":"【Vers\xe3o implantada 360】DeepSeek-R1 utilizou amplamente t\xe9cnicas de aprendizado por refor\xe7o na fase de p\xf3s-treinamento, melhorando significativamente a capacidade de infer\xeancia do modelo com apenas poucos dados rotulados. Em tarefas de matem\xe1tica, c\xf3digo e racioc\xednio em linguagem natural, seu desempenho \xe9 compar\xe1vel \xe0 vers\xe3o oficial OpenAI o1."},"360gpt-pro":{"description":"360GPT Pro, como um membro importante da s\xe9rie de modelos de IA da 360, atende a diversas aplica\xe7\xf5es de linguagem natural com sua capacidade eficiente de processamento de texto, suportando compreens\xe3o de longos textos e di\xe1logos em m\xfaltiplas rodadas."},"360gpt-pro-trans":{"description":"Modelo dedicado \xe0 tradu\xe7\xe3o, otimizado com ajuste fino profundo, com resultados de tradu\xe7\xe3o l\xedderes."},"360gpt-turbo":{"description":"360GPT Turbo oferece poderosas capacidades de computa\xe7\xe3o e di\xe1logo, com excelente compreens\xe3o sem\xe2ntica e efici\xeancia de gera\xe7\xe3o, sendo a solu\xe7\xe3o ideal de assistente inteligente para empresas e desenvolvedores."},"360gpt-turbo-responsibility-8k":{"description":"360GPT Turbo Responsibility 8K enfatiza seguran\xe7a sem\xe2ntica e responsabilidade, projetado especificamente para cen\xe1rios de aplica\xe7\xe3o com altas exig\xeancias de seguran\xe7a de conte\xfado, garantindo precis\xe3o e robustez na experi\xeancia do usu\xe1rio."},"360gpt2-o1":{"description":"O 360gpt2-o1 utiliza busca em \xe1rvore para construir cadeias de pensamento e introduz um mecanismo de reflex\xe3o, sendo treinado com aprendizado por refor\xe7o, o modelo possui a capacidade de auto-reflex\xe3o e corre\xe7\xe3o de erros."},"360gpt2-pro":{"description":"360GPT2 Pro \xe9 um modelo avan\xe7ado de processamento de linguagem natural lan\xe7ado pela 360, com excelente capacidade de gera\xe7\xe3o e compreens\xe3o de texto, destacando-se especialmente na gera\xe7\xe3o e cria\xe7\xe3o de conte\xfado, capaz de lidar com tarefas complexas de convers\xe3o de linguagem e interpreta\xe7\xe3o de pap\xe9is."},"360zhinao2-o1":{"description":"O 360zhinao2-o1 utiliza busca em \xe1rvore para construir cadeias de pensamento e introduz um mecanismo de reflex\xe3o, utilizando aprendizado por refor\xe7o para treinar, permitindo que o modelo tenha a capacidade de auto-reflex\xe3o e corre\xe7\xe3o de erros."},"4.0Ultra":{"description":"Spark4.0 Ultra \xe9 a vers\xe3o mais poderosa da s\xe9rie de grandes modelos Xinghuo, que, ao atualizar a conex\xe3o de busca online, melhora a capacidade de compreens\xe3o e resumo de conte\xfado textual. \xc9 uma solu\xe7\xe3o abrangente para aumentar a produtividade no trabalho e responder com precis\xe3o \xe0s demandas, sendo um produto inteligente l\xedder na ind\xfastria."},"AnimeSharp":{"description":"AnimeSharp (tamb\xe9m conhecido como “4x‑AnimeSharp”) \xe9 um modelo de super-resolu\xe7\xe3o open source desenvolvido por Kim2091 baseado na arquitetura ESRGAN, focado em amplia\xe7\xe3o e nitidez de imagens no estilo anime. Renomeado em fevereiro de 2022 a partir de “4x-TextSharpV1”, originalmente tamb\xe9m aplic\xe1vel a imagens de texto, mas com desempenho significativamente otimizado para conte\xfado de anime."},"Baichuan2-Turbo":{"description":"Utiliza tecnologia de busca aprimorada para conectar completamente o grande modelo com conhecimento de dom\xednio e conhecimento da web. Suporta upload de v\xe1rios documentos, como PDF e Word, e entrada de URLs, garantindo acesso a informa\xe7\xf5es de forma r\xe1pida e abrangente, com resultados precisos e profissionais."},"Baichuan3-Turbo":{"description":"Otimizado para cen\xe1rios de alta frequ\xeancia empresarial, com melhorias significativas de desempenho e excelente custo-benef\xedcio. Em compara\xe7\xe3o com o modelo Baichuan2, a cria\xe7\xe3o de conte\xfado aumentou em 20%, a resposta a perguntas de conhecimento em 17% e a capacidade de interpreta\xe7\xe3o de pap\xe9is em 40%. O desempenho geral \xe9 superior ao do GPT-3.5."},"Baichuan3-Turbo-128k":{"description":"Possui uma janela de contexto ultra longa de 128K, otimizada para cen\xe1rios de alta frequ\xeancia empresarial, com melhorias significativas de desempenho e excelente custo-benef\xedcio. Em compara\xe7\xe3o com o modelo Baichuan2, a cria\xe7\xe3o de conte\xfado aumentou em 20%, a resposta a perguntas de conhecimento em 17% e a capacidade de interpreta\xe7\xe3o de pap\xe9is em 40%. O desempenho geral \xe9 superior ao do GPT-3.5."},"Baichuan4":{"description":"O modelo \xe9 o melhor do pa\xeds, superando modelos estrangeiros em tarefas em chin\xeas, como enciclop\xe9dias, textos longos e cria\xe7\xe3o de conte\xfado. Tamb\xe9m possui capacidades multimodais l\xedderes na ind\xfastria, com desempenho excepcional em v\xe1rias avalia\xe7\xf5es de refer\xeancia."},"Baichuan4-Air":{"description":"Modelo com a melhor capacidade do pa\xeds, superando modelos estrangeiros em tarefas em chin\xeas como enciclop\xe9dia, textos longos e cria\xe7\xe3o de conte\xfado. Tamb\xe9m possui capacidades multimodais l\xedderes da ind\xfastria, com excelente desempenho em v\xe1rias avalia\xe7\xf5es de refer\xeancia."},"Baichuan4-Turbo":{"description":"Modelo com a melhor capacidade do pa\xeds, superando modelos estrangeiros em tarefas em chin\xeas como enciclop\xe9dia, textos longos e cria\xe7\xe3o de conte\xfado. Tamb\xe9m possui capacidades multimodais l\xedderes da ind\xfastria, com excelente desempenho em v\xe1rias avalia\xe7\xf5es de refer\xeancia."},"ByteDance-Seed/Seed-OSS-36B-Instruct":{"description":"Seed-OSS \xe9 uma s\xe9rie de grandes modelos de linguagem de c\xf3digo aberto desenvolvidos pela equipe Seed da ByteDance, projetados para processamento poderoso de contexto longo, racioc\xednio, agentes inteligentes e capacidades gerais. O Seed-OSS-36B-Instruct desta s\xe9rie \xe9 um modelo ajustado por instru\xe7\xf5es com 36 bilh\xf5es de par\xe2metros, que suporta nativamente comprimentos de contexto ultra longos, permitindo processar grandes volumes de documentos ou bases de c\xf3digo complexas de uma s\xf3 vez. Este modelo \xe9 especialmente otimizado para tarefas de racioc\xednio, gera\xe7\xe3o de c\xf3digo e agentes (como uso de ferramentas), mantendo um equil\xedbrio e desempenho geral excelentes. Uma caracter\xedstica marcante deste modelo \xe9 a fun\xe7\xe3o \\"Or\xe7amento de Pensamento\\" (Thinking Budget), que permite aos usu\xe1rios ajustar flexivelmente o comprimento do racioc\xednio conforme necess\xe1rio, melhorando efetivamente a efici\xeancia do racioc\xednio em aplica\xe7\xf5es pr\xe1ticas."},"DeepSeek-R1":{"description":"LLM eficiente de ponta, especializado em racioc\xednio, matem\xe1tica e programa\xe7\xe3o."},"DeepSeek-R1-Distill-Llama-70B":{"description":"DeepSeek R1 — o modelo maior e mais inteligente do conjunto DeepSeek — foi destilado para a arquitetura Llama 70B. Com base em testes de benchmark e avalia\xe7\xf5es humanas, este modelo \xe9 mais inteligente do que o Llama 70B original, destacando-se especialmente em tarefas que exigem precis\xe3o matem\xe1tica e factual."},"DeepSeek-R1-Distill-Qwen-1.5B":{"description":"Modelo de destila\xe7\xe3o DeepSeek-R1 baseado no Qwen2.5-Math-1.5B, otimizado para desempenho de infer\xeancia atrav\xe9s de aprendizado por refor\xe7o e dados de inicializa\xe7\xe3o fria, modelo de c\xf3digo aberto que redefine os padr\xf5es de m\xfaltiplas tarefas."},"DeepSeek-R1-Distill-Qwen-14B":{"description":"Modelo de destila\xe7\xe3o DeepSeek-R1 baseado no Qwen2.5-14B, otimizado para desempenho de infer\xeancia atrav\xe9s de aprendizado por refor\xe7o e dados de inicializa\xe7\xe3o fria, modelo de c\xf3digo aberto que redefine os padr\xf5es de m\xfaltiplas tarefas."},"DeepSeek-R1-Distill-Qwen-32B":{"description":"A s\xe9rie DeepSeek-R1 otimiza o desempenho de infer\xeancia atrav\xe9s de aprendizado por refor\xe7o e dados de inicializa\xe7\xe3o fria, modelo de c\xf3digo aberto que redefine os padr\xf5es de m\xfaltiplas tarefas, superando o n\xedvel do OpenAI-o1-mini."},"DeepSeek-R1-Distill-Qwen-7B":{"description":"Modelo de destila\xe7\xe3o DeepSeek-R1 baseado no Qwen2.5-Math-7B, otimizado para desempenho de infer\xeancia atrav\xe9s de aprendizado por refor\xe7o e dados de inicializa\xe7\xe3o fria, modelo de c\xf3digo aberto que redefine os padr\xf5es de m\xfaltiplas tarefas."},"DeepSeek-V3":{"description":"DeepSeek-V3 \xe9 um modelo MoE desenvolvido internamente pela DeepSeek. Os resultados de v\xe1rias avalia\xe7\xf5es do DeepSeek-V3 superaram outros modelos de c\xf3digo aberto, como Qwen2.5-72B e Llama-3.1-405B, e seu desempenho \xe9 compar\xe1vel aos melhores modelos fechados do mundo, como GPT-4o e Claude-3.5-Sonnet."},"DeepSeek-V3-1":{"description":"DeepSeek V3.1: modelo de infer\xeancia de pr\xf3xima gera\xe7\xe3o, aprimorado para racioc\xednio complexo e pensamento em cadeia, ideal para tarefas que exigem an\xe1lise profunda."},"DeepSeek-V3-Fast":{"description":"Fornecedor do modelo: plataforma sophnet. DeepSeek V3 Fast \xe9 a vers\xe3o de alta velocidade e alto TPS do DeepSeek V3 0324, totalmente n\xe3o quantificada, com capacidades aprimoradas de c\xf3digo e matem\xe1tica, respondendo de forma mais r\xe1pida!"},"DeepSeek-V3.1":{"description":"DeepSeek-V3.1 - modo sem pensamento; DeepSeek-V3.1 \xe9 um novo modelo h\xedbrido de racioc\xednio lan\xe7ado pela DeepSeek, suportando dois modos de racioc\xednio: com e sem pensamento, com efici\xeancia de pensamento superior ao DeepSeek-R1-0528. Otimizado p\xf3s-treinamento, o uso de ferramentas por agentes e o desempenho em tarefas de agentes foram significativamente aprimorados."},"DeepSeek-V3.1-Fast":{"description":"DeepSeek V3.1 Fast \xe9 a vers\xe3o de alta TPS e alta velocidade do DeepSeek V3.1. Modo h\xedbrido de pensamento: atrav\xe9s da altera\xe7\xe3o do template de chat, um \xfanico modelo pode suportar simultaneamente os modos com e sem pensamento. Chamadas de ferramentas mais inteligentes: com otimiza\xe7\xe3o p\xf3s-treinamento, o desempenho do modelo no uso de ferramentas e em tarefas de agentes foi significativamente melhorado."},"DeepSeek-V3.1-Think":{"description":"DeepSeek-V3.1 - modo com pensamento; DeepSeek-V3.1 \xe9 um novo modelo h\xedbrido de racioc\xednio lan\xe7ado pela DeepSeek, suportando dois modos de racioc\xednio: com e sem pensamento, com efici\xeancia de pensamento superior ao DeepSeek-R1-0528. Otimizado p\xf3s-treinamento, o uso de ferramentas por agentes e o desempenho em tarefas de agentes foram significativamente aprimorados."},"DeepSeek-V3.2-Exp":{"description":"DeepSeek V3.2 \xe9 o mais recente modelo universal lan\xe7ado pela DeepSeek, suportando uma arquitetura de infer\xeancia h\xedbrida e possuindo capacidades de agente mais avan\xe7adas."},"DeepSeek-V3.2-Exp-Think":{"description":"Modo de pensamento do DeepSeek V3.2. Antes de fornecer a resposta final, o modelo gera uma cadeia de racioc\xednio para melhorar a precis\xe3o da resposta."},"Doubao-lite-128k":{"description":"Doubao-lite oferece velocidade de resposta extrema e melhor custo-benef\xedcio, proporcionando op\xe7\xf5es mais flex\xedveis para diferentes cen\xe1rios dos clientes. Suporta infer\xeancia e fine-tuning com janela de contexto de 128k."},"Doubao-lite-32k":{"description":"Doubao-lite oferece velocidade de resposta extrema e melhor custo-benef\xedcio, proporcionando op\xe7\xf5es mais flex\xedveis para diferentes cen\xe1rios dos clientes. Suporta infer\xeancia e fine-tuning com janela de contexto de 32k."},"Doubao-lite-4k":{"description":"Doubao-lite oferece velocidade de resposta extrema e melhor custo-benef\xedcio, proporcionando op\xe7\xf5es mais flex\xedveis para diferentes cen\xe1rios dos clientes. Suporta infer\xeancia e fine-tuning com janela de contexto de 4k."},"Doubao-pro-128k":{"description":"Modelo principal com melhor desempenho, adequado para tarefas complexas, apresentando \xf3timos resultados em perguntas de refer\xeancia, resumos, cria\xe7\xe3o, classifica\xe7\xe3o de texto, interpreta\xe7\xe3o de pap\xe9is e outros cen\xe1rios. Suporta infer\xeancia e fine-tuning com janela de contexto de 128k."},"Doubao-pro-32k":{"description":"Modelo principal com melhor desempenho, adequado para tarefas complexas, apresentando \xf3timos resultados em perguntas de refer\xeancia, resumos, cria\xe7\xe3o, classifica\xe7\xe3o de texto, interpreta\xe7\xe3o de pap\xe9is e outros cen\xe1rios. Suporta infer\xeancia e fine-tuning com janela de contexto de 32k."},"Doubao-pro-4k":{"description":"Modelo principal com melhor desempenho, adequado para tarefas complexas, apresentando \xf3timos resultados em perguntas de refer\xeancia, resumos, cria\xe7\xe3o, classifica\xe7\xe3o de texto, interpreta\xe7\xe3o de pap\xe9is e outros cen\xe1rios. Suporta infer\xeancia e fine-tuning com janela de contexto de 4k."},"DreamO":{"description":"DreamO \xe9 um modelo open source de gera\xe7\xe3o de imagens customizadas desenvolvido em parceria pela ByteDance e pela Universidade de Pequim, projetado para suportar gera\xe7\xe3o multitarefa de imagens atrav\xe9s de uma arquitetura unificada. Utiliza um m\xe9todo eficiente de modelagem combinada para gerar imagens altamente consistentes e personalizadas com base em m\xfaltiplas condi\xe7\xf5es especificadas pelo usu\xe1rio, como identidade, sujeito, estilo e fundo."},"ERNIE-3.5-128K":{"description":"Modelo de linguagem de grande escala desenvolvido pela Baidu, cobrindo uma vasta quantidade de dados em chin\xeas e ingl\xeas, com poderosas capacidades gerais, capaz de atender \xe0 maioria das demandas de perguntas e respostas em di\xe1logos, gera\xe7\xe3o de conte\xfado e aplica\xe7\xf5es de plugins; suporta integra\xe7\xe3o autom\xe1tica com o plugin de busca da Baidu, garantindo a atualidade das informa\xe7\xf5es nas respostas."},"ERNIE-3.5-8K":{"description":"Modelo de linguagem de grande escala desenvolvido pela Baidu, cobrindo uma vasta quantidade de dados em chin\xeas e ingl\xeas, com poderosas capacidades gerais, capaz de atender \xe0 maioria das demandas de perguntas e respostas em di\xe1logos, gera\xe7\xe3o de conte\xfado e aplica\xe7\xf5es de plugins; suporta integra\xe7\xe3o autom\xe1tica com o plugin de busca da Baidu, garantindo a atualidade das informa\xe7\xf5es nas respostas."},"ERNIE-3.5-8K-Preview":{"description":"Modelo de linguagem de grande escala desenvolvido pela Baidu, cobrindo uma vasta quantidade de dados em chin\xeas e ingl\xeas, com poderosas capacidades gerais, capaz de atender \xe0 maioria das demandas de perguntas e respostas em di\xe1logos, gera\xe7\xe3o de conte\xfado e aplica\xe7\xf5es de plugins; suporta integra\xe7\xe3o autom\xe1tica com o plugin de busca da Baidu, garantindo a atualidade das informa\xe7\xf5es nas respostas."},"ERNIE-4.0-8K-Latest":{"description":"Modelo de linguagem ultra grande escala desenvolvido pela Baidu, que em compara\xe7\xe3o com o ERNIE 3.5, apresenta uma atualiza\xe7\xe3o completa nas capacidades do modelo, amplamente aplic\xe1vel em cen\xe1rios de tarefas complexas em diversas \xe1reas; suporta integra\xe7\xe3o autom\xe1tica com o plugin de busca da Baidu, garantindo a atualidade das informa\xe7\xf5es de perguntas e respostas."},"ERNIE-4.0-8K-Preview":{"description":"Modelo de linguagem ultra grande escala desenvolvido pela Baidu, que em compara\xe7\xe3o com o ERNIE 3.5, apresenta uma atualiza\xe7\xe3o completa nas capacidades do modelo, amplamente aplic\xe1vel em cen\xe1rios de tarefas complexas em diversas \xe1reas; suporta integra\xe7\xe3o autom\xe1tica com o plugin de busca da Baidu, garantindo a atualidade das informa\xe7\xf5es de perguntas e respostas."},"ERNIE-4.0-Turbo-8K-Latest":{"description":"Modelo de linguagem de \xfaltima gera\xe7\xe3o desenvolvido pela Baidu, com desempenho excepcional em uma ampla gama de cen\xe1rios de tarefas complexas; suporta integra\xe7\xe3o autom\xe1tica com plugins de busca da Baidu, garantindo a relev\xe2ncia da informa\xe7\xe3o nas respostas. Supera o desempenho do ERNIE 4.0."},"ERNIE-4.0-Turbo-8K-Preview":{"description":"Modelo de linguagem ultra grande escala desenvolvido pela Baidu, com desempenho excepcional em resultados gerais, amplamente aplic\xe1vel em cen\xe1rios de tarefas complexas em diversas \xe1reas; suporta integra\xe7\xe3o autom\xe1tica com o plugin de busca da Baidu, garantindo a atualidade das informa\xe7\xf5es de perguntas e respostas. Em compara\xe7\xe3o com o ERNIE 4.0, apresenta desempenho superior."},"ERNIE-Character-8K":{"description":"Modelo de linguagem vertical desenvolvido pela Baidu, adequado para aplica\xe7\xf5es como NPCs em jogos, di\xe1logos de atendimento ao cliente e interpreta\xe7\xe3o de personagens em di\xe1logos, com estilos de personagem mais distintos e consistentes, maior capacidade de seguir instru\xe7\xf5es e desempenho de infer\xeancia superior."},"ERNIE-Lite-Pro-128K":{"description":"Modelo de linguagem leve desenvolvido pela Baidu, que combina excelente desempenho do modelo com efici\xeancia de infer\xeancia, apresentando resultados superiores ao ERNIE Lite, adequado para uso em infer\xeancia com placas de acelera\xe7\xe3o de IA de baixo poder computacional."},"ERNIE-Speed-128K":{"description":"Modelo de linguagem de alto desempenho desenvolvido pela Baidu, lan\xe7ado em 2024, com capacidades gerais excepcionais, adequado como modelo base para ajuste fino, melhorando o tratamento de problemas em cen\xe1rios espec\xedficos, enquanto mant\xe9m excelente desempenho de infer\xeancia."},"ERNIE-Speed-Pro-128K":{"description":"Modelo de linguagem de alto desempenho desenvolvido pela Baidu, lan\xe7ado em 2024, com capacidades gerais excepcionais, apresentando resultados superiores ao ERNIE Speed, adequado como modelo base para ajuste fino, melhorando o tratamento de problemas em cen\xe1rios espec\xedficos, enquanto mant\xe9m excelente desempenho de infer\xeancia."},"FLUX-1.1-pro":{"description":"FLUX.1.1 Pro"},"FLUX.1-Kontext-dev":{"description":"FLUX.1-Kontext-dev \xe9 um modelo multimodal de gera\xe7\xe3o e edi\xe7\xe3o de imagens desenvolvido pela Black Forest Labs, baseado na arquitetura Rectified Flow Transformer, com 12 bilh\xf5es de par\xe2metros, focado em gerar, reconstruir, aprimorar ou editar imagens sob condi\xe7\xf5es contextuais fornecidas. Combina as vantagens da gera\xe7\xe3o controlada de modelos de difus\xe3o com a capacidade de modelagem contextual dos Transformers, suportando sa\xedda de imagens de alta qualidade e aplic\xe1vel a tarefas como restaura\xe7\xe3o, preenchimento e reconstru\xe7\xe3o visual de cenas."},"FLUX.1-Kontext-pro":{"description":"FLUX.1 Kontext [pro]"},"FLUX.1-dev":{"description":"FLUX.1-dev \xe9 um modelo multimodal de linguagem open source desenvolvido pela Black Forest Labs, otimizado para tarefas de texto e imagem, integrando capacidades de compreens\xe3o e gera\xe7\xe3o de imagens e texto. Baseado em avan\xe7ados modelos de linguagem como Mistral-7B, utiliza codificadores visuais cuidadosamente projetados e ajuste fino em m\xfaltiplas etapas para alcan\xe7ar processamento colaborativo de texto e imagem e racioc\xednio complexo."},"Gryphe/MythoMax-L2-13b":{"description":"MythoMax-L2 (13B) \xe9 um modelo inovador, adequado para aplica\xe7\xf5es em m\xfaltiplas \xe1reas e tarefas complexas."},"HelloMeme":{"description":"HelloMeme \xe9 uma ferramenta de IA que gera automaticamente memes, GIFs ou v\xeddeos curtos a partir de imagens ou a\xe7\xf5es fornecidas por voc\xea. N\xe3o requer habilidades de desenho ou programa\xe7\xe3o; basta fornecer imagens de refer\xeancia, e ela cria conte\xfados visualmente atraentes, divertidos e com estilo consistente."},"HiDream-I1-Full":{"description":"HiDream-E1-Full \xe9 um grande modelo open source de edi\xe7\xe3o multimodal de imagens lan\xe7ado pela HiDream.ai, baseado na avan\xe7ada arquitetura Diffusion Transformer e integrado com forte capacidade de compreens\xe3o lingu\xedstica (incorporando LLaMA 3.1-8B-Instruct). Suporta gera\xe7\xe3o de imagens, transfer\xeancia de estilo, edi\xe7\xe3o local e repintura de conte\xfado via comandos em linguagem natural, com excelente compreens\xe3o e execu\xe7\xe3o texto-imagem."},"HunyuanDiT-v1.2-Diffusers-Distilled":{"description":"hunyuandit-v1.2-distilled \xe9 um modelo leve de gera\xe7\xe3o de imagens a partir de texto, otimizado por destila\xe7\xe3o para gerar imagens de alta qualidade rapidamente, especialmente adequado para ambientes com recursos limitados e tarefas de gera\xe7\xe3o em tempo real."},"InstantCharacter":{"description":"InstantCharacter \xe9 um modelo de gera\xe7\xe3o personalizada de personagens lan\xe7ado pela equipe de IA da Tencent em 2025, que n\xe3o requer ajuste fino (tuning-free), visando gerar personagens consistentes e de alta fidelidade em m\xfaltiplos cen\xe1rios. Suporta modelagem de personagens a partir de uma \xfanica imagem de refer\xeancia e permite transferir esses personagens para diversos estilos, a\xe7\xf5es e fundos de forma flex\xedvel."},"InternVL2-8B":{"description":"InternVL2-8B \xe9 um poderoso modelo de linguagem visual, que suporta processamento multimodal de imagens e textos, capaz de identificar com precis\xe3o o conte\xfado da imagem e gerar descri\xe7\xf5es ou respostas relevantes."},"InternVL2.5-26B":{"description":"InternVL2.5-26B \xe9 um poderoso modelo de linguagem visual, que suporta processamento multimodal de imagens e textos, capaz de identificar com precis\xe3o o conte\xfado da imagem e gerar descri\xe7\xf5es ou respostas relevantes."},"Kolors":{"description":"Kolors \xe9 um modelo de gera\xe7\xe3o de imagens a partir de texto desenvolvido pela equipe Kolors da Kuaishou. Treinado com bilh\xf5es de par\xe2metros, apresenta vantagens significativas em qualidade visual, compreens\xe3o sem\xe2ntica do chin\xeas e renderiza\xe7\xe3o de texto."},"Kwai-Kolors/Kolors":{"description":"Kolors \xe9 um modelo de gera\xe7\xe3o de imagens a partir de texto em larga escala baseado em difus\xe3o latente, desenvolvido pela equipe Kolors da Kuaishou. Treinado com bilh\xf5es de pares texto-imagem, destaca-se na qualidade visual, precis\xe3o sem\xe2ntica complexa e renderiza\xe7\xe3o de caracteres em chin\xeas e ingl\xeas. Suporta entrada em chin\xeas e ingl\xeas, com desempenho excepcional na compreens\xe3o e gera\xe7\xe3o de conte\xfados espec\xedficos em chin\xeas."},"Kwaipilot/KAT-Dev":{"description":"KAT-Dev (32B) \xe9 um modelo de c\xf3digo aberto com 32 bilh\xf5es de par\xe2metros, projetado especialmente para tarefas de engenharia de software. No benchmark SWE-Bench Verified, alcan\xe7ou uma taxa de resolu\xe7\xe3o de 62,4%, classificando-se em quinto lugar entre todos os modelos de c\xf3digo aberto de diferentes tamanhos. O modelo foi otimizado por meio de v\xe1rias etapas, incluindo treinamento intermedi\xe1rio, ajuste supervisionado (SFT) e aprendizado por refor\xe7o (RL), com o objetivo de oferecer suporte robusto para tarefas complexas de programa\xe7\xe3o, como autocompletar c\xf3digo, corre\xe7\xe3o de bugs e revis\xe3o de c\xf3digo."},"Llama-3.2-11B-Vision-Instruct":{"description":"Capacidade de racioc\xednio de imagem excepcional em imagens de alta resolu\xe7\xe3o, adequada para aplica\xe7\xf5es de compreens\xe3o visual."},"Llama-3.2-90B-Vision-Instruct\\t":{"description":"Capacidade avan\xe7ada de racioc\xednio de imagem para aplica\xe7\xf5es de agentes de compreens\xe3o visual."},"Meta-Llama-3-3-70B-Instruct":{"description":"Llama 3.3 70B: modelo Transformer vers\xe1til, adequado para tarefas de di\xe1logo e gera\xe7\xe3o."},"Meta-Llama-3.1-405B-Instruct":{"description":"Modelo de texto ajustado para instru\xe7\xf5es Llama 3.1, otimizado para casos de uso de di\xe1logos multil\xedngues, apresentando desempenho superior em muitos modelos de chat de c\xf3digo aberto e fechados em benchmarks da ind\xfastria."},"Meta-Llama-3.1-70B-Instruct":{"description":"Modelo de texto ajustado para instru\xe7\xf5es Llama 3.1, otimizado para casos de uso de di\xe1logos multil\xedngues, apresentando desempenho superior em muitos modelos de chat de c\xf3digo aberto e fechados em benchmarks da ind\xfastria."},"Meta-Llama-3.1-8B-Instruct":{"description":"Modelo de texto ajustado para instru\xe7\xf5es Llama 3.1, otimizado para casos de uso de di\xe1logos multil\xedngues, apresentando desempenho superior em muitos modelos de chat de c\xf3digo aberto e fechados em benchmarks da ind\xfastria."},"Meta-Llama-3.2-1B-Instruct":{"description":"Modelo de linguagem pequeno de ponta, com compreens\xe3o de linguagem, excelente capacidade de racioc\xednio e gera\xe7\xe3o de texto."},"Meta-Llama-3.2-3B-Instruct":{"description":"Modelo de linguagem pequeno de ponta, com compreens\xe3o de linguagem, excelente capacidade de racioc\xednio e gera\xe7\xe3o de texto."},"Meta-Llama-3.3-70B-Instruct":{"description":"Llama 3.3 \xe9 o modelo de linguagem de c\xf3digo aberto multil\xedngue mais avan\xe7ado da s\xe9rie Llama, oferecendo desempenho compar\xe1vel ao modelo de 405B a um custo extremamente baixo. Baseado na estrutura Transformer, e aprimorado por meio de ajuste fino supervisionado (SFT) e aprendizado por refor\xe7o com feedback humano (RLHF) para aumentar a utilidade e a seguran\xe7a. Sua vers\xe3o ajustada para instru\xe7\xf5es \xe9 otimizada para di\xe1logos multil\xedngues, superando muitos modelos de chat de c\xf3digo aberto e fechados em v\xe1rios benchmarks da ind\xfastria. A data limite de conhecimento \xe9 dezembro de 2023."},"Meta-Llama-4-Maverick-17B-128E-Instruct-FP8":{"description":"Llama 4 Maverick: modelo de grande escala baseado em Mixture-of-Experts, oferecendo uma estrat\xe9gia eficiente de ativa\xe7\xe3o de especialistas para desempenho superior em infer\xeancia."},"MiniMax-M1":{"description":"Novo modelo de infer\xeancia desenvolvido internamente. L\xedder global: 80 mil cadeias de racioc\xednio x 1 milh\xe3o de entradas, com desempenho compar\xe1vel aos melhores modelos internacionais."},"MiniMax-M2":{"description":"Projetado especialmente para codifica\xe7\xe3o eficiente e fluxos de trabalho com agentes."},"MiniMax-Text-01":{"description":"Na s\xe9rie de modelos MiniMax-01, fizemos inova\xe7\xf5es ousadas: pela primeira vez, implementamos em larga escala um mecanismo de aten\xe7\xe3o linear, tornando a arquitetura Transformer tradicional n\xe3o mais a \xfanica op\xe7\xe3o. Este modelo possui um total de 456 bilh\xf5es de par\xe2metros, com 45,9 bilh\xf5es ativados em uma \xfanica vez. O desempenho geral do modelo \xe9 compar\xe1vel aos melhores modelos internacionais, enquanto lida eficientemente com contextos de at\xe9 4 milh\xf5es de tokens, 32 vezes mais que o GPT-4o e 20 vezes mais que o Claude-3.5-Sonnet."},"MiniMaxAI/MiniMax-M1-80k":{"description":"MiniMax-M1 \xe9 um modelo de infer\xeancia de aten\xe7\xe3o mista em grande escala com pesos abertos, possuindo 456 bilh\xf5es de par\xe2metros, com cerca de 45,9 bilh\xf5es de par\xe2metros ativados por token. O modelo suporta nativamente contextos ultra longos de 1 milh\xe3o de tokens e, gra\xe7as ao mecanismo de aten\xe7\xe3o rel\xe2mpago, economiza 75% do custo computacional em opera\xe7\xf5es de ponto flutuante em tarefas de gera\xe7\xe3o com 100 mil tokens, em compara\xe7\xe3o com o DeepSeek R1. Al\xe9m disso, MiniMax-M1 utiliza a arquitetura MoE (Mistura de Especialistas), combinando o algoritmo CISPO e um design eficiente de aten\xe7\xe3o mista para treinamento refor\xe7ado, alcan\xe7ando desempenho l\xedder na ind\xfastria em infer\xeancia de entradas longas e cen\xe1rios reais de engenharia de software."},"MiniMaxAI/MiniMax-M2":{"description":"O MiniMax-M2 redefine a efici\xeancia para agentes inteligentes. \xc9 um modelo MoE compacto, r\xe1pido e econ\xf4mico, com 230 bilh\xf5es de par\xe2metros totais e 10 bilh\xf5es de par\xe2metros ativos, projetado para oferecer desempenho de ponta em tarefas de codifica\xe7\xe3o e agentes, mantendo uma intelig\xeancia geral robusta. Com apenas 10 bilh\xf5es de par\xe2metros ativos, o MiniMax-M2 oferece desempenho compar\xe1vel a modelos de grande escala, tornando-se a escolha ideal para aplica\xe7\xf5es de alta efici\xeancia."},"Moonshot-Kimi-K2-Instruct":{"description":"Com 1 trilh\xe3o de par\xe2metros totais e 32 bilh\xf5es de par\xe2metros ativados, este modelo n\xe3o reflexivo alcan\xe7a n\xedveis de ponta em conhecimento avan\xe7ado, matem\xe1tica e codifica\xe7\xe3o, sendo especialmente apto para tarefas gerais de agentes. Otimizado para tarefas de agentes, n\xe3o apenas responde perguntas, mas tamb\xe9m pode agir. Ideal para conversas improvisadas, experi\xeancias gerais de chat e agentes, funcionando como um modelo reflexivo sem necessidade de longos processos de pensamento."},"NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO":{"description":"Nous Hermes 2 - Mixtral 8x7B-DPO (46.7B) \xe9 um modelo de instru\xe7\xe3o de alta precis\xe3o, adequado para c\xe1lculos complexos."},"OmniConsistency":{"description":"OmniConsistency melhora a consist\xeancia de estilo e a capacidade de generaliza\xe7\xe3o em tarefas de imagem para imagem (Image-to-Image) ao introduzir grandes Diffusion Transformers (DiTs) e dados estilizados pareados, evitando a degrada\xe7\xe3o do estilo."},"Phi-3-medium-128k-instruct":{"description":"Mesmo modelo Phi-3-medium, mas com um tamanho de contexto maior para RAG ou prompting de poucos exemplos."},"Phi-3-medium-4k-instruct":{"description":"Um modelo de 14B par\xe2metros, que apresenta melhor qualidade do que o Phi-3-mini, com foco em dados densos de racioc\xednio de alta qualidade."},"Phi-3-mini-128k-instruct":{"description":"Mesmo modelo Phi-3-mini, mas com um tamanho de contexto maior para RAG ou prompting de poucos exemplos."},"Phi-3-mini-4k-instruct":{"description":"O menor membro da fam\xedlia Phi-3. Otimizado tanto para qualidade quanto para baixa lat\xeancia."},"Phi-3-small-128k-instruct":{"description":"Mesmo modelo Phi-3-small, mas com um tamanho de contexto maior para RAG ou prompting de poucos exemplos."},"Phi-3-small-8k-instruct":{"description":"Um modelo de 7B par\xe2metros, que apresenta melhor qualidade do que o Phi-3-mini, com foco em dados densos de racioc\xednio de alta qualidade."},"Phi-3.5-mini-instruct":{"description":"Vers\xe3o atualizada do modelo Phi-3-mini."},"Phi-3.5-vision-instrust":{"description":"Vers\xe3o atualizada do modelo Phi-3-vision."},"Pro/Qwen/Qwen2-7B-Instruct":{"description":"Qwen2-7B-Instruct \xe9 um modelo de linguagem de grande escala com ajuste fino para instru\xe7\xf5es na s\xe9rie Qwen2, com um tamanho de par\xe2metro de 7B. Este modelo \xe9 baseado na arquitetura Transformer, utilizando fun\xe7\xf5es de ativa\xe7\xe3o SwiGLU, vi\xe9s de aten\xe7\xe3o QKV e aten\xe7\xe3o de consulta em grupo. Ele \xe9 capaz de lidar com entradas em larga escala. O modelo se destaca em compreens\xe3o de linguagem, gera\xe7\xe3o, capacidade multil\xedngue, codifica\xe7\xe3o, matem\xe1tica e racioc\xednio em v\xe1rios benchmarks, superando a maioria dos modelos de c\xf3digo aberto e demonstrando competitividade compar\xe1vel a modelos propriet\xe1rios em algumas tarefas. O Qwen2-7B-Instruct superou o Qwen1.5-7B-Chat em v\xe1rias avalia\xe7\xf5es, mostrando melhorias significativas de desempenho."},"Pro/Qwen/Qwen2.5-7B-Instruct":{"description":"Qwen2.5-7B-Instruct \xe9 um dos mais recentes modelos de linguagem de grande escala lan\xe7ados pela Alibaba Cloud. Este modelo de 7B apresenta melhorias significativas em \xe1reas como codifica\xe7\xe3o e matem\xe1tica. O modelo tamb\xe9m oferece suporte multil\xedngue, abrangendo mais de 29 idiomas, incluindo chin\xeas e ingl\xeas. O modelo teve melhorias significativas em seguir instru\xe7\xf5es, entender dados estruturados e gerar sa\xeddas estruturadas (especialmente JSON)."},"Pro/Qwen/Qwen2.5-Coder-7B-Instruct":{"description":"Qwen2.5-Coder-7B-Instruct \xe9 a vers\xe3o mais recente da s\xe9rie de modelos de linguagem de grande escala espec\xedficos para c\xf3digo lan\xe7ada pela Alibaba Cloud. Este modelo, baseado no Qwen2.5, foi treinado com 55 trilh\xf5es de tokens, melhorando significativamente a capacidade de gera\xe7\xe3o, racioc\xednio e corre\xe7\xe3o de c\xf3digo. Ele n\xe3o apenas aprimora a capacidade de codifica\xe7\xe3o, mas tamb\xe9m mant\xe9m as vantagens em matem\xe1tica e habilidades gerais. O modelo fornece uma base mais abrangente para aplica\xe7\xf5es pr\xe1ticas, como agentes de c\xf3digo."},"Pro/Qwen/Qwen2.5-VL-7B-Instruct":{"description":"Qwen2.5-VL \xe9 o novo membro da s\xe9rie Qwen, com capacidades avan\xe7adas de compreens\xe3o visual. Ele pode analisar textos, gr\xe1ficos e layouts em imagens, compreender v\xeddeos longos e capturar eventos. Capaz de realizar racioc\xednios, manipular ferramentas, suporta localiza\xe7\xe3o de objetos em m\xfaltiplos formatos e gera\xe7\xe3o de sa\xeddas estruturadas. Otimiza a compreens\xe3o de v\xeddeos atrav\xe9s de treinamento com resolu\xe7\xe3o din\xe2mica e taxa de quadros, al\xe9m de melhorar a efici\xeancia do codificador visual."},"Pro/THUDM/GLM-4.1V-9B-Thinking":{"description":"GLM-4.1V-9B-Thinking \xe9 um modelo de linguagem visual (VLM) de c\xf3digo aberto lan\xe7ado em conjunto pela Zhipu AI e pelo Laborat\xf3rio KEG da Universidade de Tsinghua, projetado para lidar com tarefas cognitivas multimodais complexas. Este modelo \xe9 baseado no modelo base GLM-4-9B-0414 e melhora significativamente sua capacidade e estabilidade de racioc\xednio multimodal ao introduzir o mecanismo de racioc\xednio \\"Chain-of-Thought\\" (Cadeia de Pensamento) e adotar estrat\xe9gias de aprendizado por refor\xe7o."},"Pro/THUDM/glm-4-9b-chat":{"description":"GLM-4-9B-Chat \xe9 a vers\xe3o de c\xf3digo aberto da s\xe9rie de modelos pr\xe9-treinados GLM-4 lan\xe7ada pela Zhipu AI. Este modelo se destaca em sem\xe2ntica, matem\xe1tica, racioc\xednio, c\xf3digo e conhecimento. Al\xe9m de suportar di\xe1logos de m\xfaltiplas rodadas, o GLM-4-9B-Chat tamb\xe9m possui recursos avan\xe7ados como navega\xe7\xe3o na web, execu\xe7\xe3o de c\xf3digo, chamadas de ferramentas personalizadas (Function Call) e racioc\xednio de longo texto. O modelo suporta 26 idiomas, incluindo chin\xeas, ingl\xeas, japon\xeas, coreano e alem\xe3o. Em v\xe1rios benchmarks, o GLM-4-9B-Chat demonstrou desempenho excepcional, como AlignBench-v2, MT-Bench, MMLU e C-Eval. O modelo suporta um comprimento de contexto m\xe1ximo de 128K, adequado para pesquisa acad\xeamica e aplica\xe7\xf5es comerciais."},"Pro/deepseek-ai/DeepSeek-R1":{"description":"DeepSeek-R1 \xe9 um modelo de infer\xeancia impulsionado por aprendizado por refor\xe7o (RL), que resolve problemas de repetitividade e legibilidade no modelo. Antes do RL, o DeepSeek-R1 introduziu dados de inicializa\xe7\xe3o a frio, otimizando ainda mais o desempenho de infer\xeancia. Ele se compara ao OpenAI-o1 em tarefas matem\xe1ticas, de c\xf3digo e de infer\xeancia, e melhora o desempenho geral por meio de m\xe9todos de treinamento cuidadosamente projetados."},"Pro/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B":{"description":"DeepSeek-R1-Distill-Qwen-7B \xe9 um modelo obtido por destila\xe7\xe3o de conhecimento baseado no Qwen2.5-Math-7B. Este modelo foi refinado usando 800 mil amostras selecionadas geradas pelo DeepSeek-R1, demonstrando excelente capacidade de racioc\xednio. Apresenta desempenho destacado em diversos benchmarks, alcan\xe7ando 92,8% de precis\xe3o no MATH-500, 55,5% de taxa de aprova\xe7\xe3o no AIME 2024 e uma pontua\xe7\xe3o de 1189 no CodeForces, mostrando forte compet\xeancia em matem\xe1tica e programa\xe7\xe3o para um modelo de escala 7B."},"Pro/deepseek-ai/DeepSeek-V3":{"description":"DeepSeek-V3 \xe9 um modelo de linguagem com 671 bilh\xf5es de par\xe2metros, utilizando uma arquitetura de especialistas mistos (MoE) com aten\xe7\xe3o potencial de m\xfaltiplas cabe\xe7as (MLA) e uma estrat\xe9gia de balanceamento de carga sem perda auxiliar, otimizando a efici\xeancia de infer\xeancia e treinamento. Pr\xe9-treinado em 14,8 trilh\xf5es de tokens de alta qualidade, e ajustado por supervis\xe3o e aprendizado por refor\xe7o, o DeepSeek-V3 supera outros modelos de c\xf3digo aberto, aproximando-se de modelos fechados l\xedderes."},"Pro/deepseek-ai/DeepSeek-V3.1-Terminus":{"description":"DeepSeek-V3.1-Terminus \xe9 uma vers\xe3o atualizada do modelo V3.1 lan\xe7ado pela DeepSeek, posicionada como um modelo de linguagem grande com agentes h\xedbridos. Esta atualiza\xe7\xe3o mant\xe9m as capacidades originais do modelo, focando na corre\xe7\xe3o de problemas reportados pelos usu\xe1rios e na melhoria da estabilidade. Houve uma melhoria significativa na consist\xeancia lingu\xedstica, reduzindo o uso misto de chin\xeas e ingl\xeas e a ocorr\xeancia de caracteres an\xf4malos. O modelo integra o “Modo de Pensamento” e o “Modo N\xe3o-Pensamento”, permitindo que os usu\xe1rios alternem flexivelmente entre eles via templates de chat para diferentes tarefas. Como uma otimiza\xe7\xe3o importante, o V3.1-Terminus aprimora o desempenho dos agentes de c\xf3digo e de busca, tornando-os mais confi\xe1veis na chamada de ferramentas e na execu\xe7\xe3o de tarefas complexas em m\xfaltiplas etapas."},"Pro/deepseek-ai/DeepSeek-V3.2-Exp":{"description":"DeepSeek-V3.2-Exp \xe9 a vers\xe3o experimental V3.2 lan\xe7ada pela DeepSeek, representando uma etapa intermedi\xe1ria rumo \xe0 pr\xf3xima gera\xe7\xe3o de arquitetura. Baseando-se no V3.1-Terminus, ela introduz o mecanismo de Aten\xe7\xe3o Esparsa DeepSeek (DeepSeek Sparse Attention, DSA) para melhorar a efici\xeancia de treinamento e infer\xeancia em contextos longos. Foi especialmente otimizada para chamadas de ferramentas, compreens\xe3o de documentos extensos e racioc\xednio em m\xfaltiplas etapas. A V3.2-Exp serve como uma ponte entre pesquisa e aplica\xe7\xe3o comercial, ideal para usu\xe1rios que buscam maior efici\xeancia de racioc\xednio em cen\xe1rios com or\xe7amentos de contexto elevados."},"Pro/moonshotai/Kimi-K2-Instruct-0905":{"description":"Kimi K2-Instruct-0905 \xe9 a vers\xe3o mais recente e poderosa do Kimi K2. Trata-se de um modelo de linguagem de especialistas mistos (MoE) de ponta, com um total de 1 trilh\xe3o de par\xe2metros e 32 bilh\xf5es de par\xe2metros ativados. As principais caracter\xedsticas deste modelo incluem: intelig\xeancia aprimorada para codifica\xe7\xe3o de agentes, demonstrando melhorias significativas em testes de refer\xeancia p\xfablicos e em tarefas reais de codifica\xe7\xe3o de agentes; experi\xeancia de codifica\xe7\xe3o front-end melhorada, com avan\xe7os tanto na est\xe9tica quanto na funcionalidade da programa\xe7\xe3o front-end."},"QwQ-32B-Preview":{"description":"O QwQ-32B-Preview \xe9 um modelo de processamento de linguagem natural inovador, capaz de lidar eficientemente com tarefas complexas de gera\xe7\xe3o de di\xe1logos e compreens\xe3o de contexto."},"Qwen/QVQ-72B-Preview":{"description":"QVQ-72B-Preview \xe9 um modelo de pesquisa desenvolvido pela equipe Qwen, focado em capacidades de racioc\xednio visual, apresentando vantagens \xfanicas na compreens\xe3o de cen\xe1rios complexos e na resolu\xe7\xe3o de problemas matem\xe1ticos relacionados \xe0 vis\xe3o."},"Qwen/QwQ-32B":{"description":"QwQ \xe9 o modelo de infer\xeancia da s\xe9rie Qwen. Em compara\xe7\xe3o com modelos tradicionais de ajuste de instru\xe7\xf5es, o QwQ possui habilidades de racioc\xednio e infer\xeancia, permitindo um desempenho significativamente melhorado em tarefas de downstream, especialmente na resolu\xe7\xe3o de problemas dif\xedceis. O QwQ-32B \xe9 um modelo de infer\xeancia de m\xe9dio porte, capaz de obter um desempenho competitivo em compara\xe7\xe3o com modelos de infer\xeancia de ponta, como DeepSeek-R1 e o1-mini. Este modelo utiliza tecnologias como RoPE, SwiGLU, RMSNorm e vi\xe9s de aten\xe7\xe3o QKV, apresentando uma estrutura de rede de 64 camadas e 40 cabe\xe7as de aten\xe7\xe3o Q (sendo KV 8 no GQA)."},"Qwen/QwQ-32B-Preview":{"description":"QwQ-32B-Preview \xe9 o mais recente modelo de pesquisa experimental da Qwen, focado em melhorar a capacidade de racioc\xednio da IA. Ao explorar mecanismos complexos como mistura de linguagem e racioc\xednio recursivo, suas principais vantagens incluem forte capacidade de an\xe1lise de racioc\xednio, habilidades matem\xe1ticas e de programa\xe7\xe3o. Ao mesmo tempo, existem quest\xf5es de troca de linguagem, ciclos de racioc\xednio, considera\xe7\xf5es de seguran\xe7a e diferen\xe7as em outras capacidades."},"Qwen/Qwen-Image":{"description":"Qwen-Image \xe9 um modelo base de gera\xe7\xe3o de imagens desenvolvido pela equipe Tongyi Qianwen da Alibaba, com 20 bilh\xf5es de par\xe2metros. O modelo apresenta avan\xe7os significativos na renderiza\xe7\xe3o de texto complexa e na edi\xe7\xe3o precisa de imagens, sendo especialmente eficaz na gera\xe7\xe3o de imagens com textos em chin\xeas e ingl\xeas de alta fidelidade. O Qwen-Image \xe9 capaz de lidar com layouts de m\xfaltiplas linhas e textos em n\xedvel de par\xe1grafo, mantendo a coer\xeancia tipogr\xe1fica e a harmonia contextual durante a gera\xe7\xe3o de imagens. Al\xe9m de sua not\xe1vel capacidade de renderiza\xe7\xe3o de texto, o modelo suporta uma ampla gama de estilos art\xedsticos — desde fotografias realistas at\xe9 est\xe9ticas de anime — adaptando-se com flexibilidade a diversas necessidades criativas. Ele tamb\xe9m possui poderosas capacidades de edi\xe7\xe3o e compreens\xe3o de imagens, incluindo transfer\xeancia de estilo, adi\xe7\xe3o e remo\xe7\xe3o de objetos, aprimoramento de detalhes, edi\xe7\xe3o de texto e at\xe9 manipula\xe7\xe3o de poses humanas, com o objetivo de se tornar um modelo base abrangente para cria\xe7\xe3o e processamento visual inteligente que integra linguagem, layout e imagem."},"Qwen/Qwen-Image-Edit-2509":{"description":"Qwen-Image-Edit-2509 \xe9 a vers\xe3o mais recente de edi\xe7\xe3o de imagens do Qwen-Image, lan\xe7ada pela equipe Tongyi Qianwen da Alibaba. Este modelo foi treinado com base no Qwen-Image de 20B par\xe2metros, expandindo com sucesso sua capacidade \xfanica de renderiza\xe7\xe3o de texto para o campo da edi\xe7\xe3o de imagens, permitindo edi\xe7\xf5es precisas de textos contidos nas imagens. O Qwen-Image-Edit adota uma arquitetura inovadora que envia a imagem de entrada simultaneamente para o Qwen2.5-VL (para controle sem\xe2ntico visual) e para o VAE Encoder (para controle da apar\xeancia visual), oferecendo assim capacidades de edi\xe7\xe3o tanto sem\xe2nticas quanto visuais. Isso significa que ele n\xe3o apenas suporta edi\xe7\xf5es locais de apar\xeancia, como adi\xe7\xe3o, remo\xe7\xe3o ou modifica\xe7\xe3o de elementos, mas tamb\xe9m edi\xe7\xf5es sem\xe2nticas visuais avan\xe7adas que exigem consist\xeancia de significado, como cria\xe7\xe3o de IPs e transfer\xeancia de estilo. O modelo demonstrou desempenho de ponta (SOTA) em diversos benchmarks p\xfablicos, tornando-se uma poderosa base para edi\xe7\xe3o de imagens."},"Qwen/Qwen2-72B-Instruct":{"description":"Qwen2 \xe9 um modelo de linguagem universal avan\xe7ado, suportando diversos tipos de instru\xe7\xf5es."},"Qwen/Qwen2-7B-Instruct":{"description":"Qwen2-72B-Instruct \xe9 um modelo de linguagem de grande escala com ajuste fino para instru\xe7\xf5es na s\xe9rie Qwen2, com um tamanho de par\xe2metro de 72B. Este modelo \xe9 baseado na arquitetura Transformer, utilizando fun\xe7\xf5es de ativa\xe7\xe3o SwiGLU, vi\xe9s de aten\xe7\xe3o QKV e aten\xe7\xe3o de consulta em grupo. Ele \xe9 capaz de lidar com entradas em larga escala. O modelo se destaca em compreens\xe3o de linguagem, gera\xe7\xe3o, capacidade multil\xedngue, codifica\xe7\xe3o, matem\xe1tica e racioc\xednio em v\xe1rios benchmarks, superando a maioria dos modelos de c\xf3digo aberto e demonstrando competitividade compar\xe1vel a modelos propriet\xe1rios em algumas tarefas."},"Qwen/Qwen2-VL-72B-Instruct":{"description":"Qwen2-VL \xe9 a vers\xe3o mais recente do modelo Qwen-VL, alcan\xe7ando desempenho de ponta em testes de compreens\xe3o visual."},"Qwen/Qwen2.5-14B-Instruct":{"description":"Qwen2.5 \xe9 uma nova s\xe9rie de modelos de linguagem em larga escala, projetada para otimizar o processamento de tarefas instrucionais."},"Qwen/Qwen2.5-32B-Instruct":{"description":"Qwen2.5 \xe9 uma nova s\xe9rie de modelos de linguagem em larga escala, projetada para otimizar o processamento de tarefas instrucionais."},"Qwen/Qwen2.5-72B-Instruct":{"description":"Modelo de linguagem de grande escala desenvolvido pela equipe Qianwen da Alibaba Cloud."},"Qwen/Qwen2.5-72B-Instruct-128K":{"description":"Qwen2.5 \xe9 uma nova s\xe9rie de grandes modelos de linguagem, com capacidades de compreens\xe3o e gera\xe7\xe3o aprimoradas."},"Qwen/Qwen2.5-72B-Instruct-Turbo":{"description":"Qwen2.5 \xe9 uma nova s\xe9rie de grandes modelos de linguagem, projetada para otimizar o processamento de tarefas instrucionais."},"Qwen/Qwen2.5-7B-Instruct":{"description":"Qwen2.5 \xe9 uma nova s\xe9rie de modelos de linguagem em larga escala, projetada para otimizar o processamento de tarefas instrucionais."},"Qwen/Qwen2.5-7B-Instruct-Turbo":{"description":"Qwen2.5 \xe9 uma nova s\xe9rie de grandes modelos de linguagem, projetada para otimizar o processamento de tarefas instrucionais."},"Qwen/Qwen2.5-Coder-32B-Instruct":{"description":"Qwen2.5-Coder foca na escrita de c\xf3digo."},"Qwen/Qwen2.5-Coder-7B-Instruct":{"description":"Qwen2.5-Coder-7B-Instruct \xe9 a vers\xe3o mais recente da s\xe9rie de modelos de linguagem de grande escala espec\xedficos para c\xf3digo lan\xe7ada pela Alibaba Cloud. Este modelo, baseado no Qwen2.5, foi treinado com 55 trilh\xf5es de tokens, melhorando significativamente a capacidade de gera\xe7\xe3o, racioc\xednio e corre\xe7\xe3o de c\xf3digo. Ele n\xe3o apenas aprimora a capacidade de codifica\xe7\xe3o, mas tamb\xe9m mant\xe9m as vantagens em matem\xe1tica e habilidades gerais. O modelo fornece uma base mais abrangente para aplica\xe7\xf5es pr\xe1ticas, como agentes de c\xf3digo."},"Qwen/Qwen2.5-VL-32B-Instruct":{"description":"Qwen2.5-VL-32B-Instruct \xe9 um modelo multimodal de grande escala desenvolvido pela equipe Tongyi Qianwen, parte da s\xe9rie Qwen2.5-VL. Este modelo n\xe3o apenas domina o reconhecimento de objetos comuns, mas tamb\xe9m pode analisar textos, gr\xe1ficos, \xedcones, diagramas e layouts em imagens. Ele funciona como um agente visual inteligente, capaz de raciocinar e manipular ferramentas dinamicamente, com habilidades para operar computadores e smartphones. Al\xe9m disso, o modelo pode localizar objetos em imagens com precis\xe3o e gerar sa\xeddas estruturadas para documentos como faturas e tabelas. Em compara\xe7\xe3o com a vers\xe3o anterior Qwen2-VL, esta vers\xe3o apresenta melhorias significativas em habilidades matem\xe1ticas e de resolu\xe7\xe3o de problemas atrav\xe9s de aprendizado por refor\xe7o, com um estilo de resposta mais alinhado \xe0s prefer\xeancias humanas."},"Qwen/Qwen2.5-VL-72B-Instruct":{"description":"Qwen2.5-VL \xe9 o modelo de linguagem visual da s\xe9rie Qwen2.5. Este modelo apresenta melhorias significativas em v\xe1rios aspectos: possui capacidade aprimorada de compreens\xe3o visual, podendo reconhecer objetos comuns, analisar textos, gr\xe1ficos e layouts; atua como um agente visual capaz de raciocinar e orientar dinamicamente o uso de ferramentas; suporta a compreens\xe3o de v\xeddeos longos com mais de 1 hora de dura\xe7\xe3o, capturando eventos-chave; pode localizar objetos em imagens com precis\xe3o atrav\xe9s da gera\xe7\xe3o de caixas delimitadoras ou pontos; suporta a gera\xe7\xe3o de sa\xeddas estruturadas, sendo especialmente \xfatil para dados digitalizados como faturas e tabelas."},"Qwen/Qwen3-14B":{"description":"O Qwen3 \xe9 um novo modelo de grande escala da Tongyi Qianwen com capacidades significativamente aprimoradas, alcan\xe7ando n\xedveis l\xedderes da ind\xfastria em racioc\xednio, tarefas gerais, agentes e multilinguismo, e suporta a altern\xe2ncia de modos de pensamento."},"Qwen/Qwen3-235B-A22B":{"description":"O Qwen3 \xe9 um novo modelo de grande escala da Tongyi Qianwen com capacidades significativamente aprimoradas, alcan\xe7ando n\xedveis l\xedderes da ind\xfastria em racioc\xednio, tarefas gerais, agentes e multilinguismo, e suporta a altern\xe2ncia de modos de pensamento."},"Qwen/Qwen3-235B-A22B-Instruct-2507":{"description":"Qwen3-235B-A22B-Instruct-2507 \xe9 um modelo de linguagem grande h\xedbrido especialista (MoE) flagship da s\xe9rie Qwen3, desenvolvido pela equipe Tongyi Qianwen da Alibaba Cloud. Com 235 bilh\xf5es de par\xe2metros totais e 22 bilh\xf5es ativados por infer\xeancia, \xe9 uma vers\xe3o atualizada do modo n\xe3o reflexivo Qwen3-235B-A22B, focada em melhorias significativas em seguimento de instru\xe7\xf5es, racioc\xednio l\xf3gico, compreens\xe3o textual, matem\xe1tica, ci\xeancia, programa\xe7\xe3o e uso de ferramentas. Al\xe9m disso, amplia a cobertura de conhecimento multil\xedngue e alinha melhor as prefer\xeancias do usu\xe1rio em tarefas subjetivas e abertas para gerar textos mais \xfateis e de alta qualidade."},"Qwen/Qwen3-235B-A22B-Thinking-2507":{"description":"Qwen3-235B-A22B-Thinking-2507 \xe9 um modelo de linguagem grande da s\xe9rie Qwen3, desenvolvido pela equipe Tongyi Qianwen da Alibaba, focado em tarefas complexas de racioc\xednio avan\xe7ado. Baseado em arquitetura MoE, possui 235 bilh\xf5es de par\xe2metros totais, ativando cerca de 22 bilh\xf5es por token, equilibrando alta performance e efici\xeancia computacional. Como modelo dedicado ao “pensamento”, apresenta melhorias not\xe1veis em racioc\xednio l\xf3gico, matem\xe1tica, ci\xeancia, programa\xe7\xe3o e benchmarks acad\xeamicos, alcan\xe7ando o topo entre modelos open source reflexivos. Tamb\xe9m aprimora capacidades gerais como seguimento de instru\xe7\xf5es, uso de ferramentas e gera\xe7\xe3o de texto, com suporte nativo para contexto longo de 256K tokens, ideal para cen\xe1rios que exigem racioc\xednio profundo e processamento de documentos extensos."},"Qwen/Qwen3-30B-A3B":{"description":"O Qwen3 \xe9 um novo modelo de grande escala da Tongyi Qianwen com capacidades significativamente aprimoradas, alcan\xe7ando n\xedveis l\xedderes da ind\xfastria em racioc\xednio, tarefas gerais, agentes e multilinguismo, e suporta a altern\xe2ncia de modos de pensamento."},"Qwen/Qwen3-30B-A3B-Instruct-2507":{"description":"Qwen3-30B-A3B-Instruct-2507 \xe9 uma vers\xe3o atualizada do Qwen3-30B-A3B no modo n\xe3o reflexivo. Este \xe9 um modelo de especialista misto (MoE) com um total de 30,5 bilh\xf5es de par\xe2metros e 3,3 bilh\xf5es de par\xe2metros ativados. O modelo apresenta melhorias significativas em v\xe1rios aspectos, incluindo um aumento not\xe1vel na capacidade de seguir instru\xe7\xf5es, racioc\xednio l\xf3gico, compreens\xe3o de texto, matem\xe1tica, ci\xeancias, codifica\xe7\xe3o e uso de ferramentas. Al\xe9m disso, alcan\xe7a avan\xe7os substanciais na cobertura de conhecimento em m\xfaltiplos idiomas e melhor alinhamento com as prefer\xeancias dos usu\xe1rios em tarefas subjetivas e abertas, permitindo gerar respostas mais \xfateis e textos de maior qualidade. A capacidade de compreens\xe3o de textos longos tamb\xe9m foi ampliada para 256K. Este modelo suporta apenas o modo n\xe3o reflexivo e n\xe3o gera tags `<think></think>` em sua sa\xedda."},"Qwen/Qwen3-30B-A3B-Thinking-2507":{"description":"Qwen3-30B-A3B-Thinking-2507 \xe9 o mais recente modelo de racioc\xednio da s\xe9rie Qwen3, lan\xe7ado pela equipe Tongyi Qianwen da Alibaba. Como um modelo Mixture-of-Experts (MoE) com um total de 30,5 bilh\xf5es de par\xe2metros e 3,3 bilh\xf5es de par\xe2metros de ativa\xe7\xe3o, ele foca em aprimorar a capacidade de lidar com tarefas complexas. O modelo apresenta melhorias de desempenho significativas em benchmarks acad\xeamicos de racioc\xednio l\xf3gico, matem\xe1tica, ci\xeancias, programa\xe7\xe3o e outras tarefas que exigem conhecimento especializado humano. Al\xe9m disso, suas capacidades gerais — como cumprimento de instru\xe7\xf5es, uso de ferramentas, gera\xe7\xe3o de texto e alinhamento com prefer\xeancias humanas — tamb\xe9m foram significativamente aprimoradas. O modelo oferece suporte nativo \xe0 compreens\xe3o de contexto longo de 256K tokens e pode ser expandido at\xe9 1 milh\xe3o de tokens. Esta vers\xe3o foi projetada especificamente para o \'modo de pensamento\', visando resolver tarefas altamente complexas por meio de um racioc\xednio passo a passo detalhado, e suas capacidades como agente (Agent) tamb\xe9m se destacam."},"Qwen/Qwen3-32B":{"description":"O Qwen3 \xe9 um novo modelo de grande escala da Tongyi Qianwen com capacidades significativamente aprimoradas, alcan\xe7ando n\xedveis l\xedderes da ind\xfastria em racioc\xednio, tarefas gerais, agentes e multilinguismo, e suporta a altern\xe2ncia de modos de pensamento."},"Qwen/Qwen3-8B":{"description":"O Qwen3 \xe9 um novo modelo de grande escala da Tongyi Qianwen com capacidades significativamente aprimoradas, alcan\xe7ando n\xedveis l\xedderes da ind\xfastria em racioc\xednio, tarefas gerais, agentes e multilinguismo, e suporta a altern\xe2ncia de modos de pensamento."},"Qwen/Qwen3-Coder-30B-A3B-Instruct":{"description":"Qwen3-Coder-30B-A3B-Instruct \xe9 um modelo de c\xf3digo da s\xe9rie Qwen3 desenvolvido pela equipe Tongyi Qianwen da Alibaba. Como um modelo enxuto e otimizado, ele mant\xe9m alto desempenho e efici\xeancia, ao mesmo tempo em que se concentra em aprimorar a capacidade de processamento de c\xf3digo. Esse modelo demonstra vantagens de desempenho not\xe1veis entre modelos de c\xf3digo aberto em tarefas complexas, como programa\xe7\xe3o agente (Agentic Coding), automa\xe7\xe3o de opera\xe7\xf5es de navegador e chamadas de ferramentas. Ele suporta nativamente contexto longo de 256K tokens e pode ser expandido at\xe9 1M tokens, permitindo um entendimento e processamento mais aprofundados em n\xedvel de reposit\xf3rio de c\xf3digo. Al\xe9m disso, o modelo oferece forte suporte a codifica\xe7\xe3o por agentes em plataformas como Qwen Code e CLINE, e foi projetado com um formato dedicado para chamadas de fun\xe7\xe3o."},"Qwen/Qwen3-Coder-480B-A35B-Instruct":{"description":"Qwen3-Coder-480B-A35B-Instruct \xe9 o modelo de c\xf3digo com maior capacidade agentic (de atua\xe7\xe3o aut\xf4noma) publicado pela Alibaba at\xe9 o momento. \xc9 um modelo de especialistas mistos (MoE) com 480 bilh\xf5es de par\xe2metros totais e 35 bilh\xf5es de par\xe2metros ativados, que alcan\xe7a um equil\xedbrio entre efici\xeancia e desempenho. O modelo oferece suporte nativo a um comprimento de contexto de 256K (aproximadamente 260 mil) tokens e pode ser estendido at\xe9 1 milh\xe3o de tokens por meio de m\xe9todos de extrapola\xe7\xe3o como YaRN, permitindo lidar com grandes bases de c\xf3digo e tarefas de programa\xe7\xe3o complexas. O Qwen3-Coder foi projetado para fluxos de trabalho de codifica\xe7\xe3o baseados em agentes: al\xe9m de gerar c\xf3digo, ele pode interagir de forma aut\xf4noma com ferramentas e ambientes de desenvolvimento para resolver problemas de programa\xe7\xe3o complexos. Em diversos benchmarks de tarefas de codifica\xe7\xe3o e de agentes, este modelo alcan\xe7ou desempenho de ponta entre os modelos de c\xf3digo aberto, compar\xe1vel a modelos l\xedderes como o Claude Sonnet 4."},"Qwen/Qwen3-Next-80B-A3B-Instruct":{"description":"Qwen3-Next-80B-A3B-Instruct \xe9 o modelo base de pr\xf3xima gera\xe7\xe3o lan\xe7ado pela equipe Tongyi Qianwen da Alibaba. Baseado na nova arquitetura Qwen3-Next, visa alcan\xe7ar efici\xeancia m\xe1xima em treinamento e infer\xeancia. O modelo adota um mecanismo inovador de aten\xe7\xe3o h\xedbrida (Gated DeltaNet e Gated Attention), uma estrutura de especialistas mistos altamente esparsos (MoE) e v\xe1rias otimiza\xe7\xf5es para estabilidade no treinamento. Como um modelo esparso com 80 bilh\xf5es de par\xe2metros totais, ativa apenas cerca de 3 bilh\xf5es de par\xe2metros durante a infer\xeancia, reduzindo significativamente o custo computacional. Em tarefas de contexto longo com mais de 32 mil tokens, sua taxa de infer\xeancia \xe9 mais de 10 vezes superior ao modelo Qwen3-32B. Esta vers\xe3o \xe9 ajustada por instru\xe7\xe3o para tarefas gerais e n\xe3o suporta o modo de cadeia de pensamento (Thinking). Em desempenho, \xe9 compar\xe1vel ao modelo principal Tongyi Qianwen Qwen3-235B em alguns benchmarks, destacando-se especialmente em tarefas de contexto ultra longo."},"Qwen/Qwen3-Next-80B-A3B-Thinking":{"description":"Qwen3-Next-80B-A3B-Thinking \xe9 o modelo base de pr\xf3xima gera\xe7\xe3o lan\xe7ado pela equipe Tongyi Qianwen da Alibaba, projetado para tarefas complexas de racioc\xednio. Baseado na inovadora arquitetura Qwen3-Next, que integra mecanismos h\xedbridos de aten\xe7\xe3o (Gated DeltaNet e Gated Attention) e uma estrutura de especialistas mistos altamente esparsos (MoE), busca m\xe1xima efici\xeancia em treinamento e infer\xeancia. Como um modelo esparso com 80 bilh\xf5es de par\xe2metros totais, ativa apenas cerca de 3 bilh\xf5es durante a infer\xeancia, reduzindo significativamente o custo computacional. Em tarefas de contexto longo com mais de 32 mil tokens, sua taxa de infer\xeancia \xe9 mais de 10 vezes superior ao modelo Qwen3-32B. Esta vers\xe3o “Thinking” \xe9 otimizada para executar tarefas complexas de m\xfaltiplas etapas, como provas matem\xe1ticas, s\xedntese de c\xf3digo, an\xe1lise l\xf3gica e planejamento, e por padr\xe3o produz o processo de racioc\xednio em forma estruturada de “cadeia de pensamento”. Em desempenho, supera modelos mais custosos como o Qwen3-32B-Thinking e tamb\xe9m apresenta melhor desempenho que o Gemini-2.5-Flash-Thinking em v\xe1rios benchmarks."},"Qwen/Qwen3-Omni-30B-A3B-Captioner":{"description":"O Qwen3-Omni-30B-A3B-Captioner \xe9 um modelo de linguagem visual (VLM) da s\xe9rie Qwen3, desenvolvido pela equipe Tongyi Qianwen da Alibaba. Ele \xe9 especializado na gera\xe7\xe3o de descri\xe7\xf5es de imagens de alta qualidade, detalhadas e precisas. Baseado em uma arquitetura de especialistas mistos (MoE) com 30 bilh\xf5es de par\xe2metros totais, o modelo \xe9 capaz de compreender profundamente o conte\xfado visual e transform\xe1-lo em descri\xe7\xf5es textuais naturais e fluentes. Apresenta desempenho excepcional em captura de detalhes, compreens\xe3o de cen\xe1rios, reconhecimento de objetos e racioc\xednio relacional, sendo ideal para aplica\xe7\xf5es que exigem entendimento visual preciso e gera\xe7\xe3o de descri\xe7\xf5es."},"Qwen/Qwen3-Omni-30B-A3B-Instruct":{"description":"O Qwen3-Omni-30B-A3B-Instruct \xe9 um modelo da nova s\xe9rie Qwen3 da equipe Tongyi Qianwen da Alibaba. Com 30 bilh\xf5es de par\xe2metros totais e 3 bilh\xf5es de par\xe2metros ativos, este modelo de especialistas mistos (MoE) oferece alto desempenho com menor custo de infer\xeancia. Treinado com dados de alta qualidade, multiorigem e multil\xedngues, possui forte capacidade geral e suporta entrada multimodal, incluindo texto, imagem, \xe1udio e v\xeddeo, sendo capaz de compreender e gerar conte\xfado entre diferentes modalidades."},"Qwen/Qwen3-Omni-30B-A3B-Thinking":{"description":"O Qwen3-Omni-30B-A3B-Thinking \xe9 o componente central \\"pensador\\" (Thinker) do modelo multimodal Qwen3-Omni. Ele \xe9 respons\xe1vel por processar entradas multimodais, como texto, \xe1udio, imagem e v\xeddeo, realizando racioc\xednios complexos em cadeia. Atuando como o c\xe9rebro da infer\xeancia, o modelo unifica todas as entradas em um espa\xe7o de representa\xe7\xe3o comum, permitindo compreens\xe3o profunda e racioc\xednio complexo entre modalidades. Baseado em uma arquitetura de especialistas mistos (MoE), possui 30 bilh\xf5es de par\xe2metros totais e 3 bilh\xf5es de par\xe2metros ativos, otimizando a efici\xeancia computacional sem comprometer a capacidade de racioc\xednio."},"Qwen/Qwen3-VL-235B-A22B-Instruct":{"description":"Qwen3-VL-235B-A22B-Instruct \xe9 um modelo de ajuste fino baseado em instru\xe7\xf5es da s\xe9rie Qwen3-VL, com arquitetura de especialistas mistos (MoE), oferecendo capacidades excepcionais de compreens\xe3o e gera\xe7\xe3o multimodal. Suporta nativamente contexto de at\xe9 256K tokens, sendo adequado para servi\xe7os multimodais de produ\xe7\xe3o com alta concorr\xeancia."},"Qwen/Qwen3-VL-235B-A22B-Thinking":{"description":"Qwen3-VL-235B-A22B-Thinking \xe9 a vers\xe3o principal da s\xe9rie Qwen3-VL voltada para racioc\xednio, com otimiza\xe7\xf5es espec\xedficas para infer\xeancia multimodal complexa, racioc\xednio com contexto longo e intera\xe7\xf5es com agentes inteligentes. \xc9 ideal para cen\xe1rios corporativos que exigem racioc\xednio profundo e interpreta\xe7\xe3o visual avan\xe7ada."},"Qwen/Qwen3-VL-30B-A3B-Instruct":{"description":"Qwen3-VL-30B-A3B-Instruct \xe9 a vers\xe3o ajustada por instru\xe7\xf5es da s\xe9rie Qwen3-VL, com fortes capacidades de compreens\xe3o e gera\xe7\xe3o visuo-lingu\xedstica. Suporta nativamente contexto de at\xe9 256K tokens, sendo ideal para di\xe1logos multimodais e tarefas de gera\xe7\xe3o condicionada por imagem."},"Qwen/Qwen3-VL-30B-A3B-Thinking":{"description":"Qwen3-VL-30B-A3B-Thinking \xe9 a vers\xe3o aprimorada para racioc\xednio da s\xe9rie Qwen3-VL, otimizada para tarefas de infer\xeancia multimodal, convers\xe3o de imagem para c\xf3digo e compreens\xe3o visual complexa. Suporta contexto de at\xe9 256K tokens e possui capacidades avan\xe7adas de racioc\xednio encadeado."},"Qwen/Qwen3-VL-32B-Instruct":{"description":"O Qwen3-VL-32B-Instruct \xe9 um modelo de linguagem visual desenvolvido pela equipe Tongyi Qianwen da Alibaba, que alcan\xe7ou desempenho SOTA em diversos benchmarks de linguagem visual. Suporta entrada de imagens em alta resolu\xe7\xe3o com milh\xf5es de pixels e possui capacidades robustas de compreens\xe3o visual geral, OCR multil\xedngue, localiza\xe7\xe3o visual de alta precis\xe3o e di\xe1logo visual. Como parte da s\xe9rie Qwen3, este modelo \xe9 capaz de lidar com tarefas multimodais complexas e oferece funcionalidades avan\xe7adas como chamada de ferramentas e continua\xe7\xe3o de prefixos."},"Qwen/Qwen3-VL-32B-Thinking":{"description":"O Qwen3-VL-32B-Thinking \xe9 uma vers\xe3o otimizada do modelo de linguagem visual da equipe Tongyi Qianwen da Alibaba, voltada para tarefas complexas de racioc\xednio visual. Com um modo de \\"pensamento\\" embutido, o modelo \xe9 capaz de gerar etapas intermedi\xe1rias de racioc\xednio antes de responder, melhorando significativamente seu desempenho em tarefas que exigem l\xf3gica em m\xfaltiplas etapas, planejamento e racioc\xednio complexo. Suporta imagens em alta resolu\xe7\xe3o com milh\xf5es de pixels, possui forte compreens\xe3o visual geral, OCR multil\xedngue, localiza\xe7\xe3o visual precisa e di\xe1logo visual, al\xe9m de funcionalidades como chamada de ferramentas e continua\xe7\xe3o de prefixos."},"Qwen/Qwen3-VL-8B-Instruct":{"description":"Qwen3-VL-8B-Instruct \xe9 um modelo de linguagem visual da s\xe9rie Qwen3, desenvolvido com base no Qwen3-8B-Instruct e treinado com grandes volumes de dados multimodais. Ele \xe9 especializado em compreens\xe3o visual geral, di\xe1logos centrados em imagens e reconhecimento multil\xedngue de texto em imagens. \xc9 ideal para tarefas como perguntas e respostas visuais, descri\xe7\xe3o de imagens, seguimento de instru\xe7\xf5es multimodais e chamadas de ferramentas."},"Qwen/Qwen3-VL-8B-Thinking":{"description":"Qwen3-VL-8B-Thinking \xe9 a vers\xe3o de racioc\xednio visual da s\xe9rie Qwen3, otimizada para tarefas complexas de racioc\xednio em m\xfaltiplas etapas. Por padr\xe3o, o modelo gera uma cadeia de pensamento antes de responder, a fim de melhorar a precis\xe3o do racioc\xednio. \xc9 adequado para cen\xe1rios que exigem racioc\xednio visual profundo, como perguntas e respostas visuais complexas, revis\xe3o de conte\xfado de imagens e an\xe1lises detalhadas."},"Qwen2-72B-Instruct":{"description":"Qwen2 \xe9 a mais recente s\xe9rie do modelo Qwen, suportando 128k de contexto. Em compara\xe7\xe3o com os melhores modelos de c\xf3digo aberto atuais, o Qwen2-72B supera significativamente os modelos l\xedderes em v\xe1rias capacidades, incluindo compreens\xe3o de linguagem natural, conhecimento, c\xf3digo, matem\xe1tica e multilinguismo."},"Qwen2-7B-Instruct":{"description":"Qwen2 \xe9 a mais recente s\xe9rie do modelo Qwen, capaz de superar modelos de c\xf3digo aberto de tamanho equivalente e at\xe9 mesmo modelos de maior escala. O Qwen2 7B obteve vantagens significativas em v\xe1rias avalia\xe7\xf5es, especialmente em compreens\xe3o de c\xf3digo e chin\xeas."},"Qwen2-VL-72B":{"description":"O Qwen2-VL-72B \xe9 um poderoso modelo de linguagem visual, que suporta processamento multimodal de imagens e texto, capaz de reconhecer com precis\xe3o o conte\xfado das imagens e gerar descri\xe7\xf5es ou respostas relacionadas."},"Qwen2.5-14B-Instruct":{"description":"Qwen2.5-14B-Instruct \xe9 um grande modelo de linguagem com 14 bilh\xf5es de par\xe2metros, com desempenho excelente, otimizado para cen\xe1rios em chin\xeas e multil\xedngues, suportando aplica\xe7\xf5es como perguntas e respostas inteligentes e gera\xe7\xe3o de conte\xfado."},"Qwen2.5-32B-Instruct":{"description":"Qwen2.5-32B-Instruct \xe9 um grande modelo de linguagem com 32 bilh\xf5es de par\xe2metros, com desempenho equilibrado, otimizado para cen\xe1rios em chin\xeas e multil\xedngues, suportando aplica\xe7\xf5es como perguntas e respostas inteligentes e gera\xe7\xe3o de conte\xfado."},"Qwen2.5-72B-Instruct":{"description":"Qwen2.5-72B-Instruct suporta 16k de contexto, gerando textos longos com mais de 8K. Suporta chamadas de fun\xe7\xe3o e intera\xe7\xe3o sem costura com sistemas externos, aumentando significativamente a flexibilidade e escalabilidade. O conhecimento do modelo aumentou consideravelmente, e suas habilidades em codifica\xe7\xe3o e matem\xe1tica melhoraram muito, com suporte a mais de 29 idiomas."},"Qwen2.5-7B-Instruct":{"description":"Qwen2.5-7B-Instruct \xe9 um grande modelo de linguagem com 7 bilh\xf5es de par\xe2metros, que suporta chamadas de fun\xe7\xe3o e intera\xe7\xe3o sem costura com sistemas externos, aumentando significativamente a flexibilidade e escalabilidade. Otimizado para cen\xe1rios em chin\xeas e multil\xedngues, suporta aplica\xe7\xf5es como perguntas e respostas inteligentes e gera\xe7\xe3o de conte\xfado."},"Qwen2.5-Coder-14B-Instruct":{"description":"O Qwen2.5-Coder-14B-Instruct \xe9 um modelo de instru\xe7\xe3o de programa\xe7\xe3o baseado em pr\xe9-treinamento em larga escala, com forte capacidade de compreens\xe3o e gera\xe7\xe3o de c\xf3digo, capaz de lidar eficientemente com diversas tarefas de programa\xe7\xe3o, especialmente adequado para escrita inteligente de c\xf3digo, gera\xe7\xe3o de scripts automatizados e resolu\xe7\xe3o de problemas de programa\xe7\xe3o."},"Qwen2.5-Coder-32B-Instruct":{"description":"Qwen2.5-Coder-32B-Instruct \xe9 um grande modelo de linguagem projetado para gera\xe7\xe3o de c\xf3digo, compreens\xe3o de c\xf3digo e cen\xe1rios de desenvolvimento eficiente, com uma escala de 32 bilh\xf5es de par\xe2metros, atendendo a diversas necessidades de programa\xe7\xe3o."},"Qwen3-235B":{"description":"Qwen3-235B-A22B, modelo MoE (especialista misto), introduz o “modo de racioc\xednio h\xedbrido”, permitindo aos usu\xe1rios alternar perfeitamente entre os modos “reflexivo” e “n\xe3o reflexivo”. Suporta compreens\xe3o e racioc\xednio em 119 idiomas e dialetos, al\xe9m de possuir forte capacidade de chamada de ferramentas. Em testes de benchmark abrangentes, incluindo habilidades gerais, c\xf3digo, matem\xe1tica, multilinguismo, conhecimento e racioc\xednio, compete com os principais grandes modelos do mercado, como DeepSeek R1, OpenAI o1, o3-mini, Grok 3 e Google Gemini 2.5 Pro."},"Qwen3-235B-A22B-Instruct-2507-FP8":{"description":"Qwen3 235B A22B Instruct 2507: modelo otimizado para racioc\xednio avan\xe7ado e instru\xe7\xf5es de di\xe1logo, com arquitetura h\xedbrida de especialistas para manter efici\xeancia em infer\xeancia com grande n\xfamero de par\xe2metros."},"Qwen3-32B":{"description":"Qwen3-32B, modelo denso (Dense Model), introduz o “modo de racioc\xednio h\xedbrido”, permitindo aos usu\xe1rios alternar perfeitamente entre os modos “reflexivo” e “n\xe3o reflexivo”. Gra\xe7as a melhorias na arquitetura do modelo, aumento dos dados de treinamento e m\xe9todos de treinamento mais eficazes, seu desempenho geral \xe9 compar\xe1vel ao do Qwen2.5-72B."},"SenseChat":{"description":"Modelo da vers\xe3o b\xe1sica (V4), com comprimento de contexto de 4K, com capacidades gerais poderosas."},"SenseChat-128K":{"description":"Modelo da vers\xe3o b\xe1sica (V4), com comprimento de contexto de 128K, se destaca em tarefas de compreens\xe3o e gera\xe7\xe3o de textos longos."},"SenseChat-32K":{"description":"Modelo da vers\xe3o b\xe1sica (V4), com comprimento de contexto de 32K, aplic\xe1vel de forma flex\xedvel em diversos cen\xe1rios."},"SenseChat-5":{"description":"Modelo da vers\xe3o mais recente (V5.5), com comprimento de contexto de 128K, com capacidades significativamente aprimoradas em racioc\xednio matem\xe1tico, di\xe1logos em ingl\xeas, seguimento de instru\xe7\xf5es e compreens\xe3o de textos longos, rivalizando com o GPT-4o."},"SenseChat-5-1202":{"description":"Baseado na vers\xe3o mais recente V5.5, apresenta melhorias significativas em v\xe1rias dimens\xf5es, incluindo habilidades b\xe1sicas em chin\xeas e ingl\xeas, conversa\xe7\xe3o, conhecimento cient\xedfico, conhecimento human\xedstico, escrita, l\xf3gica matem\xe1tica e controle de contagem de palavras."},"SenseChat-5-Cantonese":{"description":"Comprimento de contexto de 32K, superando o GPT-4 na compreens\xe3o de di\xe1logos em canton\xeas, competindo com o GPT-4 Turbo em v\xe1rias \xe1reas, incluindo conhecimento, racioc\xednio, matem\xe1tica e programa\xe7\xe3o."},"SenseChat-5-beta":{"description":"Desempenho superior em alguns aspectos em rela\xe7\xe3o ao SenseCat-5-1202"},"SenseChat-Character":{"description":"Modelo padr\xe3o, com comprimento de contexto de 8K, alta velocidade de resposta."},"SenseChat-Character-Pro":{"description":"Modelo avan\xe7ado, com comprimento de contexto de 32K, com capacidades amplamente aprimoradas, suportando di\xe1logos em chin\xeas e ingl\xeas."},"SenseChat-Turbo":{"description":"Adequado para perguntas r\xe1pidas e cen\xe1rios de ajuste fino do modelo."},"SenseChat-Turbo-1202":{"description":"\xc9 a vers\xe3o mais recente do modelo leve, alcan\xe7ando mais de 90% da capacidade do modelo completo, reduzindo significativamente o custo de infer\xeancia."},"SenseChat-Vision":{"description":"Modelo da vers\xe3o mais recente (V5.5), suporta entrada de m\xfaltiplas imagens, otimizando completamente as capacidades b\xe1sicas do modelo, com grandes melhorias em reconhecimento de atributos de objetos, rela\xe7\xf5es espaciais, reconhecimento de eventos, compreens\xe3o de cen\xe1rios, reconhecimento de emo\xe7\xf5es, racioc\xednio l\xf3gico e compreens\xe3o e gera\xe7\xe3o de texto."},"SenseNova-V6-5-Pro":{"description":"Com atualiza\xe7\xf5es abrangentes em dados multimodais, lingu\xedsticos e de racioc\xednio, al\xe9m da otimiza\xe7\xe3o das estrat\xe9gias de treinamento, o novo modelo alcan\xe7a melhorias significativas em racioc\xednio multimodal e capacidade de seguir instru\xe7\xf5es generalizadas. Suporta janelas de contexto de at\xe9 128k e apresenta desempenho excepcional em tarefas especializadas como OCR e reconhecimento de IPs culturais e tur\xedsticos."},"SenseNova-V6-5-Turbo":{"description":"Com atualiza\xe7\xf5es abrangentes em dados multimodais, lingu\xedsticos e de racioc\xednio, al\xe9m da otimiza\xe7\xe3o das estrat\xe9gias de treinamento, o novo modelo alcan\xe7a melhorias significativas em racioc\xednio multimodal e capacidade de seguir instru\xe7\xf5es generalizadas. Suporta janelas de contexto de at\xe9 128k e apresenta desempenho excepcional em tarefas especializadas como OCR e reconhecimento de IPs culturais e tur\xedsticos."},"SenseNova-V6-Pro":{"description":"Realizar a unifica\xe7\xe3o nativa de capacidades de imagem, texto e v\xeddeo, superando as limita\xe7\xf5es tradicionais da multimodalidade discreta, conquistando o t\xedtulo duplo nas avalia\xe7\xf5es OpenCompass e SuperCLUE."},"SenseNova-V6-Reasoner":{"description":"Equilibrar racioc\xednio visual e lingu\xedstico profundo, realizando um pensamento lento e uma infer\xeancia profunda, apresentando um processo completo de cadeia de pensamento."},"SenseNova-V6-Turbo":{"description":"Realizar a unifica\xe7\xe3o nativa de capacidades de imagem, texto e v\xeddeo, superando as limita\xe7\xf5es tradicionais da multimodalidade discreta, liderando amplamente em dimens\xf5es centrais como capacidades b\xe1sicas multimodais e lingu\xedsticas, combinando rigor acad\xeamico e pr\xe1tico, e alcan\xe7ando repetidamente o n\xedvel da primeira divis\xe3o em v\xe1rias avalia\xe7\xf5es nacionais e internacionais."},"Skylark2-lite-8k":{"description":"Modelo de segunda gera\xe7\xe3o Skylark, o modelo Skylark2-lite possui alta velocidade de resposta, adequado para cen\xe1rios que exigem alta capacidade de resposta, sens\xedveis ao custo e com baixa exig\xeancia de precis\xe3o do modelo, com uma janela de contexto de 8k."},"Skylark2-pro-32k":{"description":"Modelo de segunda gera\xe7\xe3o Skylark, a vers\xe3o Skylark2-pro possui alta precis\xe3o, adequada para cen\xe1rios de gera\xe7\xe3o de texto mais complexos, como gera\xe7\xe3o de textos em campos especializados, cria\xe7\xe3o de romances e tradu\xe7\xf5es de alta qualidade, com uma janela de contexto de 32k."},"Skylark2-pro-4k":{"description":"Modelo de segunda gera\xe7\xe3o Skylark, o modelo Skylark2-pro possui alta precis\xe3o, adequado para cen\xe1rios de gera\xe7\xe3o de texto mais complexos, como gera\xe7\xe3o de textos em campos especializados, cria\xe7\xe3o de romances e tradu\xe7\xf5es de alta qualidade, com uma janela de contexto de 4k."},"Skylark2-pro-character-4k":{"description":"Modelo de segunda gera\xe7\xe3o Skylark, o modelo Skylark2-pro-character possui excelentes habilidades de interpreta\xe7\xe3o de pap\xe9is e chat, especializado em interpretar diferentes pap\xe9is com base nas solicita\xe7\xf5es do usu\xe1rio e engajar em conversas, apresentando um estilo de personagem distinto e um conte\xfado de di\xe1logo natural e flu\xeddo, adequado para construir chatbots, assistentes virtuais e atendimento ao cliente online, com alta velocidade de resposta."},"Skylark2-pro-turbo-8k":{"description":"Modelo de segunda gera\xe7\xe3o Skylark, o Skylark2-pro-turbo-8k proporciona racioc\xednio mais r\xe1pido e menor custo, com uma janela de contexto de 8k."},"THUDM/GLM-4-32B-0414":{"description":"GLM-4-32B-0414 \xe9 a nova gera\xe7\xe3o de modelo de c\xf3digo aberto da s\xe9rie GLM, com 32 bilh\xf5es de par\xe2metros. O desempenho deste modelo \xe9 compar\xe1vel ao da s\xe9rie GPT da OpenAI e da s\xe9rie V3/R1 da DeepSeek."},"THUDM/GLM-4-9B-0414":{"description":"GLM-4-9B-0414 \xe9 um modelo compacto da s\xe9rie GLM, com 9 bilh\xf5es de par\xe2metros. Este modelo herda as caracter\xedsticas t\xe9cnicas da s\xe9rie GLM-4-32B, mas oferece uma op\xe7\xe3o de implanta\xe7\xe3o mais leve. Apesar de seu tamanho menor, o GLM-4-9B-0414 ainda demonstra habilidades excepcionais em tarefas de gera\xe7\xe3o de c\xf3digo, design de p\xe1ginas da web, gera\xe7\xe3o de gr\xe1ficos SVG e reda\xe7\xe3o baseada em pesquisa."},"THUDM/GLM-4.1V-9B-Thinking":{"description":"GLM-4.1V-9B-Thinking \xe9 um modelo de linguagem visual (VLM) de c\xf3digo aberto lan\xe7ado em conjunto pela Zhipu AI e pelo Laborat\xf3rio KEG da Universidade de Tsinghua, projetado para lidar com tarefas cognitivas multimodais complexas. Este modelo \xe9 baseado no modelo base GLM-4-9B-0414 e melhora significativamente sua capacidade e estabilidade de racioc\xednio multimodal ao introduzir o mecanismo de racioc\xednio \\"Chain-of-Thought\\" (Cadeia de Pensamento) e adotar estrat\xe9gias de aprendizado por refor\xe7o."},"THUDM/GLM-Z1-32B-0414":{"description":"GLM-Z1-32B-0414 \xe9 um modelo de infer\xeancia com capacidade de pensamento profundo. Este modelo \xe9 baseado no GLM-4-32B-0414, desenvolvido atrav\xe9s de inicializa\xe7\xe3o a frio e aprendizado por refor\xe7o expandido, e foi treinado adicionalmente em tarefas de matem\xe1tica, c\xf3digo e l\xf3gica. Em compara\xe7\xe3o com o modelo base, o GLM-Z1-32B-0414 melhorou significativamente suas habilidades matem\xe1ticas e capacidade de resolver tarefas complexas."},"THUDM/GLM-Z1-9B-0414":{"description":"GLM-Z1-9B-0414 \xe9 um modelo compacto da s\xe9rie GLM, com apenas 9 bilh\xf5es de par\xe2metros, mas mantendo a tradi\xe7\xe3o de c\xf3digo aberto enquanto exibe habilidades impressionantes. Apesar de seu tamanho menor, este modelo ainda se destaca em racioc\xednio matem\xe1tico e tarefas gerais, com desempenho geral em n\xedvel de lideran\xe7a entre modelos de c\xf3digo aberto de tamanho semelhante."},"THUDM/GLM-Z1-Rumination-32B-0414":{"description":"GLM-Z1-Rumination-32B-0414 \xe9 um modelo de infer\xeancia profunda com capacidade de reflex\xe3o (compar\xe1vel ao Deep Research da OpenAI). Diferente dos modelos t\xedpicos de pensamento profundo, o modelo de reflex\xe3o utiliza um tempo mais longo de pensamento profundo para resolver problemas mais abertos e complexos."},"THUDM/glm-4-9b-chat":{"description":"GLM-4 9B \xe9 uma vers\xe3o de c\xf3digo aberto, oferecendo uma experi\xeancia de di\xe1logo otimizada para aplica\xe7\xf5es de conversa."},"Tongyi-Zhiwen/QwenLong-L1-32B":{"description":"QwenLong-L1-32B \xe9 o primeiro modelo de racioc\xednio de grande escala com contexto longo treinado por aprendizado por refor\xe7o (LRM), otimizado para tarefas de racioc\xednio em textos longos. O modelo utiliza um framework de aprendizado por refor\xe7o com expans\xe3o progressiva de contexto, permitindo uma transi\xe7\xe3o est\xe1vel de contextos curtos para longos. Em sete benchmarks de perguntas e respostas com documentos de contexto longo, QwenLong-L1-32B supera modelos l\xedderes como OpenAI-o3-mini e Qwen3-235B-A22B, com desempenho compar\xe1vel ao Claude-3.7-Sonnet-Thinking. \xc9 especialmente eficaz em racioc\xednio matem\xe1tico, l\xf3gico e racioc\xednio de m\xfaltiplos saltos."},"Yi-34B-Chat":{"description":"Yi-1.5-34B, mantendo as excelentes habilidades lingu\xedsticas do modelo original, aumentou significativamente suas capacidades de l\xf3gica matem\xe1tica e codifica\xe7\xe3o atrav\xe9s de treinamento incremental com 500 bilh\xf5es de tokens de alta qualidade."},"abab5.5-chat":{"description":"Voltado para cen\xe1rios de produtividade, suportando o processamento de tarefas complexas e gera\xe7\xe3o de texto eficiente, adequado para aplica\xe7\xf5es em \xe1reas profissionais."},"abab5.5s-chat":{"description":"Projetado para cen\xe1rios de di\xe1logo de personagens em chin\xeas, oferecendo capacidade de gera\xe7\xe3o de di\xe1logos de alta qualidade em chin\xeas, adequado para v\xe1rias aplica\xe7\xf5es."},"abab6.5g-chat":{"description":"Projetado para di\xe1logos de personagens multil\xedngues, suportando gera\xe7\xe3o de di\xe1logos de alta qualidade em ingl\xeas e v\xe1rias outras l\xednguas."},"abab6.5s-chat":{"description":"Adequado para uma ampla gama de tarefas de processamento de linguagem natural, incluindo gera\xe7\xe3o de texto, sistemas de di\xe1logo, etc."},"abab6.5t-chat":{"description":"Otimizado para cen\xe1rios de di\xe1logo de personagens em chin\xeas, oferecendo capacidade de gera\xe7\xe3o de di\xe1logos fluentes e que respeitam os h\xe1bitos de express\xe3o em chin\xeas."},"accounts/fireworks/models/deepseek-r1":{"description":"DeepSeek-R1 \xe9 um modelo de linguagem grande de \xfaltima gera\xe7\xe3o, otimizado com aprendizado por refor\xe7o e dados de inicializa\xe7\xe3o a frio, apresentando desempenho excepcional em racioc\xednio, matem\xe1tica e programa\xe7\xe3o."},"accounts/fireworks/models/deepseek-v3":{"description":"Modelo de linguagem poderoso da Deepseek, baseado em Mixture-of-Experts (MoE), com um total de 671B de par\xe2metros, ativando 37B de par\xe2metros por token."},"accounts/fireworks/models/llama-v3-70b-instruct":{"description":"O modelo Llama 3 70B Instruct \xe9 otimizado para di\xe1logos multil\xedngues e compreens\xe3o de linguagem natural, superando a maioria dos modelos concorrentes."},"accounts/fireworks/models/llama-v3-8b-instruct":{"description":"O modelo Llama 3 8B Instruct \xe9 otimizado para di\xe1logos e tarefas multil\xedngues, apresentando desempenho excepcional e efici\xeancia."},"accounts/fireworks/models/llama-v3-8b-instruct-hf":{"description":"O modelo Llama 3 8B Instruct (vers\xe3o HF) \xe9 consistente com os resultados da implementa\xe7\xe3o oficial, apresentando alta consist\xeancia e compatibilidade entre plataformas."},"accounts/fireworks/models/llama-v3p1-405b-instruct":{"description":"O modelo Llama 3.1 405B Instruct possui par\xe2metros em escala extremamente grande, adequado para seguimento de instru\xe7\xf5es em tarefas complexas e cen\xe1rios de alta carga."},"accounts/fireworks/models/llama-v3p1-70b-instruct":{"description":"O modelo Llama 3.1 70B Instruct oferece excelente compreens\xe3o e gera\xe7\xe3o de linguagem natural, sendo a escolha ideal para tarefas de di\xe1logo e an\xe1lise."},"accounts/fireworks/models/llama-v3p1-8b-instruct":{"description":"O modelo Llama 3.1 8B Instruct \xe9 otimizado para di\xe1logos multil\xedngues, superando a maioria dos modelos de c\xf3digo aberto e fechado em benchmarks do setor."},"accounts/fireworks/models/llama-v3p2-11b-vision-instruct":{"description":"Modelo de racioc\xednio visual de 11B par\xe2metros da Meta, otimizado para reconhecimento visual, racioc\xednio visual, descri\xe7\xe3o de imagens e resposta a perguntas gerais sobre imagens. Este modelo \xe9 capaz de entender dados visuais, como gr\xe1ficos e diagramas, e preencher a lacuna entre vis\xe3o e linguagem gerando descri\xe7\xf5es textuais dos detalhes das imagens."},"accounts/fireworks/models/llama-v3p2-3b-instruct":{"description":"O modelo de instru\xe7\xe3o Llama 3.2 3B \xe9 um modelo multil\xedngue leve lan\xe7ado pela Meta. Este modelo visa aumentar a efici\xeancia, oferecendo melhorias significativas em lat\xeancia e custo em compara\xe7\xe3o com modelos maiores. Exemplos de uso incluem consultas, reescrita de prompts e aux\xedlio na reda\xe7\xe3o."},"accounts/fireworks/models/llama-v3p2-90b-vision-instruct":{"description":"Modelo de racioc\xednio visual de 90B par\xe2metros da Meta, otimizado para reconhecimento visual, racioc\xednio visual, descri\xe7\xe3o de imagens e resposta a perguntas gerais sobre imagens. Este modelo \xe9 capaz de entender dados visuais, como gr\xe1ficos e diagramas, e preencher a lacuna entre vis\xe3o e linguagem gerando descri\xe7\xf5es textuais dos detalhes das imagens."},"accounts/fireworks/models/llama-v3p3-70b-instruct":{"description":"Llama 3.3 70B Instruct \xe9 a vers\xe3o atualizada de dezembro do Llama 3.1 70B. Este modelo foi aprimorado com base no Llama 3.1 70B (lan\xe7ado em julho de 2024), melhorando a chamada de ferramentas, suporte a textos multil\xedngues, habilidades matem\xe1ticas e de programa\xe7\xe3o. O modelo alcan\xe7ou n\xedveis de lideran\xe7a da ind\xfastria em racioc\xednio, matem\xe1tica e seguimento de instru\xe7\xf5es, e \xe9 capaz de oferecer desempenho semelhante ao 3.1 405B, ao mesmo tempo em que apresenta vantagens significativas em velocidade e custo."},"accounts/fireworks/models/mistral-small-24b-instruct-2501":{"description":"Modelo com 24B de par\xe2metros, com capacidades de ponta compar\xe1veis a modelos maiores."},"accounts/fireworks/models/mixtral-8x22b-instruct":{"description":"O modelo Mixtral MoE 8x22B Instruct, com par\xe2metros em grande escala e arquitetura de m\xfaltiplos especialistas, suporta o processamento eficiente de tarefas complexas."},"accounts/fireworks/models/mixtral-8x7b-instruct":{"description":"O modelo Mixtral MoE 8x7B Instruct, com uma arquitetura de m\xfaltiplos especialistas, oferece seguimento e execu\xe7\xe3o de instru\xe7\xf5es de forma eficiente."},"accounts/fireworks/models/mythomax-l2-13b":{"description":"O modelo MythoMax L2 13B combina novas t\xe9cnicas de fus\xe3o, sendo especializado em narrativas e interpreta\xe7\xe3o de personagens."},"accounts/fireworks/models/phi-3-vision-128k-instruct":{"description":"O modelo Phi 3 Vision Instruct \xe9 um modelo multimodal leve, capaz de processar informa\xe7\xf5es visuais e textuais complexas, com forte capacidade de racioc\xednio."},"accounts/fireworks/models/qwen-qwq-32b-preview":{"description":"O modelo QwQ \xe9 um modelo de pesquisa experimental desenvolvido pela equipe Qwen, focado em aprimorar a capacidade de racioc\xednio da IA."},"accounts/fireworks/models/qwen2-vl-72b-instruct":{"description":"A vers\xe3o 72B do modelo Qwen-VL \xe9 o resultado da mais recente itera\xe7\xe3o da Alibaba, representando quase um ano de inova\xe7\xf5es."},"accounts/fireworks/models/qwen2p5-72b-instruct":{"description":"Qwen2.5 \xe9 uma s\xe9rie de modelos de linguagem com apenas decodificadores, desenvolvida pela equipe Qwen da Alibaba Cloud. Estes modelos t\xeam tamanhos variados, incluindo 0.5B, 1.5B, 3B, 7B, 14B, 32B e 72B, com variantes base (base) e de instru\xe7\xe3o (instruct)."},"accounts/fireworks/models/qwen2p5-coder-32b-instruct":{"description":"Qwen2.5 Coder 32B Instruct \xe9 a vers\xe3o mais recente da s\xe9rie de modelos de linguagem de grande escala espec\xedficos para c\xf3digo lan\xe7ada pela Alibaba Cloud. Este modelo, baseado no Qwen2.5, foi treinado com 55 trilh\xf5es de tokens, melhorando significativamente a capacidade de gera\xe7\xe3o, racioc\xednio e corre\xe7\xe3o de c\xf3digo. Ele n\xe3o apenas aprimora a capacidade de codifica\xe7\xe3o, mas tamb\xe9m mant\xe9m as vantagens em matem\xe1tica e habilidades gerais. O modelo fornece uma base mais abrangente para aplica\xe7\xf5es pr\xe1ticas, como agentes de c\xf3digo."},"accounts/yi-01-ai/models/yi-large":{"description":"O modelo Yi-Large oferece excelente capacidade de processamento multil\xedngue, adequado para diversas tarefas de gera\xe7\xe3o e compreens\xe3o de linguagem."},"ai21-jamba-1.5-large":{"description":"Um modelo multil\xedngue com 398B de par\xe2metros (94B ativos), oferecendo uma janela de contexto longa de 256K, chamada de fun\xe7\xe3o, sa\xedda estruturada e gera\xe7\xe3o fundamentada."},"ai21-jamba-1.5-mini":{"description":"Um modelo multil\xedngue com 52B de par\xe2metros (12B ativos), oferecendo uma janela de contexto longa de 256K, chamada de fun\xe7\xe3o, sa\xedda estruturada e gera\xe7\xe3o fundamentada."},"ai21-labs/AI21-Jamba-1.5-Large":{"description":"Um modelo multil\xedngue com 398 bilh\xf5es de par\xe2metros (94 bilh\xf5es ativos), oferecendo janela de contexto longa de 256K, chamadas de fun\xe7\xe3o, sa\xedda estruturada e gera\xe7\xe3o baseada em fatos."},"ai21-labs/AI21-Jamba-1.5-Mini":{"description":"Um modelo multil\xedngue com 52 bilh\xf5es de par\xe2metros (12 bilh\xf5es ativos), oferecendo janela de contexto longa de 256K, chamadas de fun\xe7\xe3o, sa\xedda estruturada e gera\xe7\xe3o baseada em fatos."},"alibaba/qwen-3-14b":{"description":"Qwen3 \xe9 a mais recente gera\xe7\xe3o da s\xe9rie Qwen de grandes modelos de linguagem, oferecendo um conjunto abrangente de modelos densos e de especialistas mistos (MoE). Constru\xeddo com base em um treinamento extensivo, o Qwen3 proporciona avan\xe7os revolucion\xe1rios em racioc\xednio, conformidade com instru\xe7\xf5es, capacidades de agente e suporte multil\xedngue."},"alibaba/qwen-3-235b":{"description":"Qwen3 \xe9 a mais recente gera\xe7\xe3o da s\xe9rie Qwen de grandes modelos de linguagem, oferecendo um conjunto abrangente de modelos densos e de especialistas mistos (MoE). Constru\xeddo com base em um treinamento extensivo, o Qwen3 proporciona avan\xe7os revolucion\xe1rios em racioc\xednio, conformidade com instru\xe7\xf5es, capacidades de agente e suporte multil\xedngue."},"alibaba/qwen-3-30b":{"description":"Qwen3 \xe9 a mais recente gera\xe7\xe3o da s\xe9rie Qwen de grandes modelos de linguagem, oferecendo um conjunto abrangente de modelos densos e de especialistas mistos (MoE). Constru\xeddo com base em um treinamento extensivo, o Qwen3 proporciona avan\xe7os revolucion\xe1rios em racioc\xednio, conformidade com instru\xe7\xf5es, capacidades de agente e suporte multil\xedngue."},"alibaba/qwen-3-32b":{"description":"Qwen3 \xe9 a mais recente gera\xe7\xe3o da s\xe9rie Qwen de grandes modelos de linguagem, oferecendo um conjunto abrangente de modelos densos e de especialistas mistos (MoE). Constru\xeddo com base em um treinamento extensivo, o Qwen3 proporciona avan\xe7os revolucion\xe1rios em racioc\xednio, conformidade com instru\xe7\xf5es, capacidades de agente e suporte multil\xedngue."},"alibaba/qwen3-coder":{"description":"Qwen3-Coder-480B-A35B-Instruct \xe9 o modelo de c\xf3digo mais agente da s\xe9rie Qwen, com desempenho not\xe1vel em codifica\xe7\xe3o de agentes, uso de navegadores por agentes e outras tarefas b\xe1sicas de codifica\xe7\xe3o, alcan\xe7ando resultados compar\xe1veis ao Claude Sonnet."},"amazon/nova-lite":{"description":"Um modelo multimodal de custo muito baixo, que processa entradas de imagem, v\xeddeo e texto com velocidade extremamente r\xe1pida."},"amazon/nova-micro":{"description":"Um modelo apenas de texto que oferece respostas com a menor lat\xeancia a um custo muito baixo."},"amazon/nova-pro":{"description":"Um modelo multimodal altamente capaz, com a melhor combina\xe7\xe3o de precis\xe3o, velocidade e custo, adequado para uma ampla gama de tarefas."},"amazon/titan-embed-text-v2":{"description":"Amazon Titan Text Embeddings V2 \xe9 um modelo leve e eficiente de embeddings multil\xedngues, suportando dimens\xf5es de 1024, 512 e 256."},"anthropic.claude-3-5-sonnet-20240620-v1:0":{"description":"O Claude 3.5 Sonnet eleva o padr\xe3o da ind\xfastria, superando modelos concorrentes e o Claude 3 Opus, apresentando um desempenho excepcional em avalia\xe7\xf5es amplas, ao mesmo tempo que mant\xe9m a velocidade e o custo de nossos modelos de n\xedvel m\xe9dio."},"anthropic.claude-3-5-sonnet-20241022-v2:0":{"description":"Claude 3.5 Sonnet elevou o padr\xe3o da ind\xfastria, superando modelos concorrentes e o Claude 3 Opus, apresentando um desempenho excepcional em avalia\xe7\xf5es amplas, enquanto mant\xe9m a velocidade e o custo de nossos modelos de n\xedvel m\xe9dio."},"anthropic.claude-3-haiku-20240307-v1:0":{"description":"O Claude 3 Haiku \xe9 o modelo mais r\xe1pido e compacto da Anthropic, oferecendo uma velocidade de resposta quase instant\xe2nea. Ele pode responder rapidamente a consultas e solicita\xe7\xf5es simples. Os clientes poder\xe3o construir uma experi\xeancia de IA sem costura que imita a intera\xe7\xe3o humana. O Claude 3 Haiku pode processar imagens e retornar sa\xeddas de texto, com uma janela de contexto de 200K."},"anthropic.claude-3-opus-20240229-v1:0":{"description":"O Claude 3 Opus \xe9 o modelo de IA mais poderoso da Anthropic, com desempenho de ponta em tarefas altamente complexas. Ele pode lidar com prompts abertos e cen\xe1rios n\xe3o vistos, apresentando flu\xeancia excepcional e compreens\xe3o semelhante \xe0 humana. O Claude 3 Opus demonstra as possibilidades de gera\xe7\xe3o de IA na vanguarda. O Claude 3 Opus pode processar imagens e retornar sa\xeddas de texto, com uma janela de contexto de 200K."},"anthropic.claude-3-sonnet-20240229-v1:0":{"description":"O Claude 3 Sonnet da Anthropic alcan\xe7a um equil\xedbrio ideal entre intelig\xeancia e velocidade — especialmente adequado para cargas de trabalho empresariais. Ele oferece a m\xe1xima utilidade a um custo inferior ao dos concorrentes e foi projetado para ser um modelo confi\xe1vel e dur\xe1vel, adequado para implanta\xe7\xf5es de IA em larga escala. O Claude 3 Sonnet pode processar imagens e retornar sa\xeddas de texto, com uma janela de contexto de 200K."},"anthropic.claude-instant-v1":{"description":"Um modelo r\xe1pido, econ\xf4mico e ainda muito capaz, capaz de lidar com uma variedade de tarefas, incluindo di\xe1logos cotidianos, an\xe1lise de texto, resumos e perguntas e respostas de documentos."},"anthropic.claude-v2":{"description":"O modelo da Anthropic demonstra alta capacidade em uma ampla gama de tarefas, desde di\xe1logos complexos e gera\xe7\xe3o de conte\xfado criativo at\xe9 o seguimento detalhado de instru\xe7\xf5es."},"anthropic.claude-v2:1":{"description":"A vers\xe3o atualizada do Claude 2, com o dobro da janela de contexto, al\xe9m de melhorias na confiabilidade, taxa de alucina\xe7\xe3o e precis\xe3o baseada em evid\xeancias em documentos longos e contextos RAG."},"anthropic/claude-3-haiku":{"description":"Claude 3 Haiku \xe9 o modelo mais r\xe1pido da Anthropic at\xe9 hoje, projetado para cargas de trabalho empresariais que geralmente envolvem prompts longos. Haiku pode analisar rapidamente grandes volumes de documentos, como arquivos trimestrais, contratos ou casos jur\xeddicos, com custo equivalente \xe0 metade de outros modelos em sua classe de desempenho."},"anthropic/claude-3-opus":{"description":"Claude 3 Opus \xe9 o modelo mais inteligente da Anthropic, com desempenho l\xedder de mercado em tarefas altamente complexas. Ele navega com fluidez excepcional e compreens\xe3o humana em prompts abertos e cen\xe1rios in\xe9ditos."},"anthropic/claude-3.5-haiku":{"description":"Claude 3.5 Haiku \xe9 a pr\xf3xima gera\xe7\xe3o do nosso modelo mais r\xe1pido. Com velocidade semelhante ao Claude 3 Haiku, o Claude 3.5 Haiku apresenta melhorias em todas as habilidades e supera nosso maior modelo da gera\xe7\xe3o anterior, Claude 3 Opus, em muitos benchmarks de intelig\xeancia."},"anthropic/claude-3.5-sonnet":{"description":"Claude 3.5 Sonnet alcan\xe7a um equil\xedbrio ideal entre intelig\xeancia e velocidade — especialmente para cargas de trabalho empresariais. Em compara\xe7\xe3o com produtos similares, oferece desempenho robusto a um custo menor e \xe9 projetado para alta durabilidade em implanta\xe7\xf5es de IA em larga escala."},"anthropic/claude-3.7-sonnet":{"description":"Claude 3.7 Sonnet \xe9 o primeiro modelo de racioc\xednio h\xedbrido e o mais inteligente da Anthropic at\xe9 hoje. Ele oferece desempenho de ponta em codifica\xe7\xe3o, gera\xe7\xe3o de conte\xfado, an\xe1lise de dados e tarefas de planejamento, constru\xeddo sobre as capacidades de engenharia de software e computa\xe7\xe3o do seu predecessor, Claude 3.5 Sonnet."},"anthropic/claude-opus-4":{"description":"Claude Opus 4 \xe9 o modelo mais poderoso da Anthropic at\xe9 hoje e o melhor modelo de codifica\xe7\xe3o do mundo, liderando nos benchmarks SWE-bench (72,5%) e Terminal-bench (43,2%). Ele oferece desempenho sustentado para tarefas de longo prazo que exigem esfor\xe7o concentrado e milhares de etapas, podendo trabalhar continuamente por horas — ampliando significativamente as capacidades dos agentes de IA."},"anthropic/claude-opus-4.1":{"description":"Claude Opus 4.1 \xe9 uma alternativa plug-and-play ao Opus 4, oferecendo desempenho e precis\xe3o excepcionais para tarefas pr\xe1ticas de codifica\xe7\xe3o e agentes. Ele eleva o desempenho de codifica\xe7\xe3o de ponta para 74,5% no SWE-bench Verified e lida com problemas complexos de m\xfaltiplas etapas com maior rigor e aten\xe7\xe3o aos detalhes."},"anthropic/claude-sonnet-4":{"description":"Claude Sonnet 4 apresenta melhorias significativas sobre a capacidade l\xedder do setor do Sonnet 3.7, destacando-se em codifica\xe7\xe3o com um desempenho de ponta de 72,7% no SWE-bench. O modelo equilibra desempenho e efici\xeancia, adequado para casos de uso internos e externos, e oferece maior controle sobre as implementa\xe7\xf5es por meio de controlabilidade aprimorada."},"anthropic/claude-sonnet-4.5":{"description":"Claude Sonnet 4.5 \xe9 o modelo mais inteligente da Anthropic at\xe9 agora."},"ascend-tribe/pangu-pro-moe":{"description":"Pangu-Pro-MoE 72B-A16B \xe9 um modelo de linguagem grande esparso com 72 bilh\xf5es de par\xe2metros e 16 bilh\xf5es de par\xe2metros ativados, baseado na arquitetura Mixture of Experts em grupos (MoGE). Ele agrupa especialistas na fase de sele\xe7\xe3o e restringe a ativa\xe7\xe3o de um n\xfamero igual de especialistas dentro de cada grupo para cada token, alcan\xe7ando equil\xedbrio na carga dos especialistas e melhorando significativamente a efici\xeancia de implanta\xe7\xe3o do modelo na plataforma Ascend."},"aya":{"description":"Aya 23 \xe9 um modelo multil\xedngue lan\xe7ado pela Cohere, suportando 23 idiomas, facilitando aplica\xe7\xf5es lingu\xedsticas diversificadas."},"aya:35b":{"description":"Aya 23 \xe9 um modelo multil\xedngue lan\xe7ado pela Cohere, suportando 23 idiomas, facilitando aplica\xe7\xf5es lingu\xedsticas diversificadas."},"azure-DeepSeek-R1-0528":{"description":"Implantado e fornecido pela Microsoft; o modelo DeepSeek R1 passou por uma atualiza\xe7\xe3o menor, a vers\xe3o atual \xe9 DeepSeek-R1-0528. Na atualiza\xe7\xe3o mais recente, o DeepSeek R1 aumentou significativamente a profundidade de infer\xeancia e a capacidade de dedu\xe7\xe3o ao adicionar recursos computacionais e introduzir mecanismos de otimiza\xe7\xe3o algor\xedtmica na fase p\xf3s-treinamento. Este modelo apresenta desempenho excelente em v\xe1rios benchmarks, incluindo matem\xe1tica, programa\xe7\xe3o e l\xf3gica geral, com desempenho geral pr\xf3ximo aos modelos l\xedderes, como O3 e Gemini 2.5 Pro."},"baichuan-m2-32b":{"description":"Baichuan M2 32B \xe9 um modelo especialista h\xedbrido desenvolvido pela Baichuan Intelligence, com poderosa capacidade de racioc\xednio."},"baichuan/baichuan2-13b-chat":{"description":"Baichuan-13B \xe9 um modelo de linguagem de c\xf3digo aberto e comercializ\xe1vel desenvolvido pela Baichuan Intelligence, contendo 13 bilh\xf5es de par\xe2metros, alcan\xe7ando os melhores resultados em benchmarks de chin\xeas e ingl\xeas na mesma dimens\xe3o."},"baidu/ERNIE-4.5-300B-A47B":{"description":"ERNIE-4.5-300B-A47B \xe9 um modelo de linguagem grande baseado na arquitetura Mixture of Experts (MoE), desenvolvido pela Baidu. Com um total de 300 bilh\xf5es de par\xe2metros, ativa apenas 47 bilh\xf5es por token durante a infer\xeancia, equilibrando desempenho robusto e efici\xeancia computacional. Como um dos modelos centrais da s\xe9rie ERNIE 4.5, demonstra capacidades excepcionais em compreens\xe3o, gera\xe7\xe3o, racioc\xednio textual e programa\xe7\xe3o. O modelo utiliza um m\xe9todo inovador de pr\xe9-treinamento multimodal heterog\xeaneo MoE, treinando conjuntamente texto e vis\xe3o, o que melhora significativamente suas habilidades gerais, especialmente em seguir instru\xe7\xf5es e mem\xf3ria de conhecimento mundial."},"c4ai-aya-expanse-32b":{"description":"Aya Expanse \xe9 um modelo multil\xedngue de alto desempenho com 32B, projetado para desafiar o desempenho de modelos monol\xedngues por meio de inova\xe7\xf5es em ajuste por instru\xe7\xe3o, arbitragem de dados, treinamento de prefer\xeancias e fus\xe3o de modelos. Ele suporta 23 idiomas."},"c4ai-aya-expanse-8b":{"description":"Aya Expanse \xe9 um modelo multil\xedngue de alto desempenho com 8B, projetado para desafiar o desempenho de modelos monol\xedngues por meio de inova\xe7\xf5es em ajuste por instru\xe7\xe3o, arbitragem de dados, treinamento de prefer\xeancias e fus\xe3o de modelos. Ele suporta 23 idiomas."},"c4ai-aya-vision-32b":{"description":"Aya Vision \xe9 um modelo multimodal de ponta, apresentando desempenho excepcional em m\xfaltiplos benchmarks cr\xedticos de linguagem, texto e imagem. Esta vers\xe3o de 32 bilh\xf5es de par\xe2metros foca no desempenho multil\xedngue de ponta."},"c4ai-aya-vision-8b":{"description":"Aya Vision \xe9 um modelo multimodal de ponta, apresentando desempenho excepcional em m\xfaltiplos benchmarks cr\xedticos de linguagem, texto e imagem. Esta vers\xe3o de 8 bilh\xf5es de par\xe2metros foca em baixa lat\xeancia e desempenho ideal."},"charglm-3":{"description":"O CharGLM-3 \xe9 projetado para interpreta\xe7\xe3o de personagens e companhia emocional, suportando mem\xf3ria de m\xfaltiplas rodadas e di\xe1logos personalizados, com ampla aplica\xe7\xe3o."},"charglm-4":{"description":"CharGLM-4 \xe9 projetado para interpreta\xe7\xe3o de personagens e companhia emocional, suportando mem\xf3ria de m\xfaltiplas rodadas de longa dura\xe7\xe3o e di\xe1logos personalizados, com ampla aplica\xe7\xe3o."},"chatgpt-4o-latest":{"description":"O ChatGPT-4o \xe9 um modelo din\xe2mico, atualizado em tempo real para manter a vers\xe3o mais atual. Ele combina uma poderosa capacidade de compreens\xe3o e gera\xe7\xe3o de linguagem, adequado para cen\xe1rios de aplica\xe7\xe3o em larga escala, incluindo atendimento ao cliente, educa\xe7\xe3o e suporte t\xe9cnico."},"claude-2.0":{"description":"Claude 2 oferece avan\xe7os em capacidades cr\xedticas para empresas, incluindo um contexto l\xedder do setor de 200K tokens, uma redu\xe7\xe3o significativa na taxa de alucina\xe7\xe3o do modelo, prompts de sistema e uma nova funcionalidade de teste: chamadas de ferramentas."},"claude-2.1":{"description":"Claude 2 oferece avan\xe7os em capacidades cr\xedticas para empresas, incluindo um contexto l\xedder do setor de 200K tokens, uma redu\xe7\xe3o significativa na taxa de alucina\xe7\xe3o do modelo, prompts de sistema e uma nova funcionalidade de teste: chamadas de ferramentas."},"claude-3-5-haiku-20241022":{"description":"Claude 3.5 Haiku \xe9 o modelo de pr\xf3xima gera\xe7\xe3o mais r\xe1pido da Anthropic. Em compara\xe7\xe3o com o Claude 3 Haiku, o Claude 3.5 Haiku apresenta melhorias em v\xe1rias habilidades e superou o maior modelo da gera\xe7\xe3o anterior, o Claude 3 Opus, em muitos testes de refer\xeancia de intelig\xeancia."},"claude-3-5-haiku-latest":{"description":"Claude 3.5 Haiku oferece respostas r\xe1pidas, ideal para tarefas leves."},"claude-3-7-sonnet-20250219":{"description":"Claude 3.7 Sonnet \xe9 o modelo de IA mais poderoso da Anthropic, com desempenho de ponta em tarefas altamente complexas. Ele pode lidar com prompts abertos e cen\xe1rios n\xe3o vistos, apresentando flu\xeancia excepcional e compreens\xe3o semelhante \xe0 humana. O Claude 3.7 Sonnet demonstra as possibilidades de gera\xe7\xe3o de IA na vanguarda."},"claude-3-7-sonnet-latest":{"description":"Claude 3.7 Sonnet \xe9 o modelo mais poderoso da Anthropic para lidar com tarefas altamente complexas. Ele se destaca em desempenho, intelig\xeancia, fluidez e compreens\xe3o."},"claude-3-haiku-20240307":{"description":"Claude 3 Haiku \xe9 o modelo mais r\xe1pido e compacto da Anthropic, projetado para respostas quase instant\xe2neas. Ele possui desempenho direcionado r\xe1pido e preciso."},"claude-3-opus-20240229":{"description":"Claude 3 Opus \xe9 o modelo mais poderoso da Anthropic para lidar com tarefas altamente complexas. Ele se destaca em desempenho, intelig\xeancia, flu\xeancia e compreens\xe3o."},"claude-3-sonnet-20240229":{"description":"Claude 3 Sonnet oferece um equil\xedbrio ideal entre intelig\xeancia e velocidade para cargas de trabalho empresariais. Ele fornece m\xe1xima utilidade a um custo mais baixo, sendo confi\xe1vel e adequado para implanta\xe7\xe3o em larga escala."},"claude-haiku-4-5-20251001":{"description":"Claude Haiku 4.5 \xe9 o modelo Haiku mais r\xe1pido e inteligente da Anthropic, com velocidade rel\xe2mpago e capacidade de racioc\xednio expandida."},"claude-opus-4-1-20250805":{"description":"Claude Opus 4.1 \xe9 o modelo mais poderoso e recente da Anthropic para lidar com tarefas altamente complexas. Ele se destaca em desempenho, intelig\xeancia, fluidez e compreens\xe3o."},"claude-opus-4-1-20250805-thinking":{"description":"Modelo de pensamento Claude Opus 4.1, uma vers\xe3o avan\xe7ada que pode demonstrar seu processo de racioc\xednio."},"claude-opus-4-20250514":{"description":"Claude Opus 4 \xe9 o modelo mais poderoso da Anthropic para lidar com tarefas altamente complexas. Ele se destaca em desempenho, intelig\xeancia, flu\xeancia e compreens\xe3o."},"claude-sonnet-4-20250514":{"description":"Claude Sonnet 4 pode gerar respostas quase instant\xe2neas ou um pensamento gradual prolongado, permitindo que o usu\xe1rio veja claramente esses processos."},"claude-sonnet-4-20250514-thinking":{"description":"Modelo de pensamento Claude Sonnet 4 pode gerar respostas quase instant\xe2neas ou um pensamento gradual prolongado, permitindo que o usu\xe1rio veja claramente esses processos."},"claude-sonnet-4-5-20250929":{"description":"Claude Sonnet 4.5 \xe9 o modelo mais inteligente da Anthropic at\xe9 agora."},"codegeex-4":{"description":"O CodeGeeX-4 \xe9 um poderoso assistente de programa\xe7\xe3o AI, suportando perguntas e respostas inteligentes e autocompletar em v\xe1rias linguagens de programa\xe7\xe3o, aumentando a efici\xeancia do desenvolvimento."},"codegeex4-all-9b":{"description":"CodeGeeX4-ALL-9B \xe9 um modelo de gera\xe7\xe3o de c\xf3digo multil\xedngue, suportando funcionalidades abrangentes, incluindo completude e gera\xe7\xe3o de c\xf3digo, interpretador de c\xf3digo, busca na web, chamadas de fun\xe7\xe3o e perguntas e respostas em n\xedvel de reposit\xf3rio, cobrindo diversos cen\xe1rios de desenvolvimento de software. \xc9 um modelo de gera\xe7\xe3o de c\xf3digo de ponta com menos de 10B de par\xe2metros."},"codegemma":{"description":"CodeGemma \xe9 um modelo de linguagem leve especializado em diferentes tarefas de programa\xe7\xe3o, suportando itera\xe7\xf5es r\xe1pidas e integra\xe7\xe3o."},"codegemma:2b":{"description":"CodeGemma \xe9 um modelo de linguagem leve especializado em diferentes tarefas de programa\xe7\xe3o, suportando itera\xe7\xf5es r\xe1pidas e integra\xe7\xe3o."},"codellama":{"description":"Code Llama \xe9 um LLM focado em gera\xe7\xe3o e discuss\xe3o de c\xf3digo, combinando suporte a uma ampla gama de linguagens de programa\xe7\xe3o, adequado para ambientes de desenvolvedores."},"codellama/CodeLlama-34b-Instruct-hf":{"description":"Code Llama \xe9 um LLM focado em gera\xe7\xe3o e discuss\xe3o de c\xf3digo, combinando amplo suporte a linguagens de programa\xe7\xe3o, adequado para ambientes de desenvolvedores."},"codellama:13b":{"description":"Code Llama \xe9 um LLM focado em gera\xe7\xe3o e discuss\xe3o de c\xf3digo, combinando suporte a uma ampla gama de linguagens de programa\xe7\xe3o, adequado para ambientes de desenvolvedores."},"codellama:34b":{"description":"Code Llama \xe9 um LLM focado em gera\xe7\xe3o e discuss\xe3o de c\xf3digo, combinando suporte a uma ampla gama de linguagens de programa\xe7\xe3o, adequado para ambientes de desenvolvedores."},"codellama:70b":{"description":"Code Llama \xe9 um LLM focado em gera\xe7\xe3o e discuss\xe3o de c\xf3digo, combinando suporte a uma ampla gama de linguagens de programa\xe7\xe3o, adequado para ambientes de desenvolvedores."},"codeqwen":{"description":"CodeQwen1.5 \xe9 um modelo de linguagem de grande escala treinado com uma vasta quantidade de dados de c\xf3digo, projetado para resolver tarefas de programa\xe7\xe3o complexas."},"codestral":{"description":"Codestral \xe9 o primeiro modelo de c\xf3digo da Mistral AI, oferecendo suporte excepcional para tarefas de gera\xe7\xe3o de c\xf3digo."},"codestral-latest":{"description":"Codestral \xe9 um modelo gerador de ponta focado em gera\xe7\xe3o de c\xf3digo, otimizado para preenchimento intermedi\xe1rio e tarefas de conclus\xe3o de c\xf3digo."},"codex-mini-latest":{"description":"codex-mini-latest \xe9 uma vers\xe3o ajustada do o4-mini, especialmente para Codex CLI. Para uso direto via API, recomendamos come\xe7ar pelo gpt-4.1."},"cogview-4":{"description":"CogView-4 \xe9 o primeiro modelo de gera\xe7\xe3o de imagens a partir de texto open source da Zhipu que suporta a gera\xe7\xe3o de caracteres chineses. Ele apresenta melhorias abrangentes em compreens\xe3o sem\xe2ntica, qualidade de gera\xe7\xe3o de imagens e capacidade de gera\xe7\xe3o de textos em chin\xeas e ingl\xeas, suportando entradas bil\xedngues de qualquer comprimento e podendo gerar imagens em qualquer resolu\xe7\xe3o dentro do intervalo especificado."},"cohere-command-r":{"description":"Command R \xe9 um modelo generativo escal\xe1vel voltado para RAG e uso de ferramentas, permitindo IA em escala de produ\xe7\xe3o para empresas."},"cohere-command-r-plus":{"description":"Command R+ \xe9 um modelo otimizado para RAG de \xfaltima gera\xe7\xe3o, projetado para lidar com cargas de trabalho de n\xedvel empresarial."},"cohere/Cohere-command-r":{"description":"Command R \xe9 um modelo generativo escal\xe1vel projetado para uso com RAG e ferramentas, permitindo que empresas implementem IA em n\xedvel de produ\xe7\xe3o."},"cohere/Cohere-command-r-plus":{"description":"Command R+ \xe9 um modelo otimizado de ponta para RAG, projetado para cargas de trabalho empresariais."},"cohere/command-a":{"description":"Command A \xe9 o modelo de maior desempenho da Cohere at\xe9 hoje, destacando-se no uso de ferramentas, agentes, gera\xe7\xe3o aprimorada por recupera\xe7\xe3o (RAG) e casos multil\xedngues. Com um comprimento de contexto de 256K, roda em apenas dois GPUs, oferecendo um aumento de 150% na taxa de transfer\xeancia em compara\xe7\xe3o com o Command R+ 08-2024."},"cohere/command-r":{"description":"Command R \xe9 um grande modelo de linguagem otimizado para intera\xe7\xf5es de di\xe1logo e tarefas de contexto longo. Ele se posiciona na categoria \\"escal\xe1vel\\", equilibrando alto desempenho e forte precis\xe3o, permitindo que empresas avancem al\xe9m da prova de conceito para produ\xe7\xe3o."},"cohere/command-r-plus":{"description":"Command R+ \xe9 o mais recente grande modelo de linguagem da Cohere, otimizado para intera\xe7\xf5es de di\xe1logo e tarefas de contexto longo. Seu objetivo \xe9 oferecer desempenho excepcional, permitindo que empresas avancem al\xe9m da prova de conceito para produ\xe7\xe3o."},"cohere/embed-v4.0":{"description":"Um modelo que permite classificar texto, imagens ou conte\xfado misto ou convert\xea-los em embeddings."},"comfyui/flux-dev":{"description":"FLUX.1 Dev - Modelo de gera\xe7\xe3o de imagens a partir de texto de alta qualidade, gera em 10 a 50 etapas, ideal para cria\xe7\xf5es art\xedsticas e obras visuais refinadas"},"comfyui/flux-kontext-dev":{"description":"FLUX.1 Kontext-dev - Modelo de edi\xe7\xe3o de imagens, permite modificar imagens existentes com instru\xe7\xf5es em texto, com suporte para edi\xe7\xf5es locais e transfer\xeancia de estilo"},"comfyui/flux-krea-dev":{"description":"FLUX.1 Krea-dev - Modelo de gera\xe7\xe3o de imagens com seguran\xe7a aprimorada, desenvolvido em parceria com a Krea, com filtros de seguran\xe7a integrados"},"comfyui/flux-schnell":{"description":"FLUX.1 Schnell - Modelo ultrarr\xe1pido de gera\xe7\xe3o de imagens a partir de texto, produz imagens de alta qualidade em apenas 1 a 4 etapas, ideal para aplica\xe7\xf5es em tempo real e prototipagem r\xe1pida"},"comfyui/stable-diffusion-15":{"description":"Modelo Stable Diffusion 1.5 para gera\xe7\xe3o de imagens a partir de texto, cl\xe1ssico com resolu\xe7\xe3o 512x512, ideal para prototipagem r\xe1pida e experimenta\xe7\xe3o criativa"},"comfyui/stable-diffusion-35":{"description":"Stable Diffusion 3.5 - nova gera\xe7\xe3o de modelo de gera\xe7\xe3o de imagens, dispon\xedvel nas vers\xf5es Large e Medium, requer arquivos externos de codificador CLIP, oferece excelente qualidade de imagem e precis\xe3o na interpreta\xe7\xe3o de prompts"},"comfyui/stable-diffusion-35-inclclip":{"description":"Stable Diffusion 3.5 com codificadores CLIP/T5 integrados, n\xe3o requer arquivos externos, compat\xedvel com modelos como sd3.5_medium_incl_clips, com menor uso de recursos"},"comfyui/stable-diffusion-custom":{"description":"Modelo SD personalizado para gera\xe7\xe3o de imagens a partir de texto. Nomeie o arquivo do modelo como custom_sd_lobe.safetensors e, se houver VAE, use custom_sd_vae_lobe.safetensors. Os arquivos devem ser colocados nas pastas corretas conforme exigido pelo Comfy"},"comfyui/stable-diffusion-custom-refiner":{"description":"Modelo SDXL personalizado para convers\xe3o de imagem para imagem. Nomeie o arquivo do modelo como custom_sd_lobe.safetensors e, se houver VAE, use custom_sd_vae_lobe.safetensors. Os arquivos devem ser colocados nas pastas corretas conforme exigido pelo Comfy"},"comfyui/stable-diffusion-refiner":{"description":"Modelo SDXL para convers\xe3o de imagem para imagem, gera imagens de alta qualidade com base em uma imagem de entrada, com suporte para transfer\xeancia de estilo, restaura\xe7\xe3o de imagem e transforma\xe7\xf5es criativas"},"comfyui/stable-diffusion-xl":{"description":"Modelo SDXL para gera\xe7\xe3o de imagens a partir de texto, com suporte para resolu\xe7\xe3o alta de 1024x1024, oferecendo melhor qualidade de imagem e riqueza de detalhes"},"command":{"description":"Um modelo de di\xe1logo que segue instru\xe7\xf5es, apresentando alta qualidade e confiabilidade em tarefas lingu\xedsticas, al\xe9m de um comprimento de contexto mais longo em compara\xe7\xe3o com nosso modelo de gera\xe7\xe3o b\xe1sico."},"command-a-03-2025":{"description":"O Command A \xe9 o nosso modelo mais poderoso at\xe9 agora, apresentando um desempenho excepcional em uso de ferramentas, agentes, gera\xe7\xe3o aumentada por recupera\xe7\xe3o (RAG) e cen\xe1rios de aplica\xe7\xe3o multil\xedngue. O Command A possui um comprimento de contexto de 256K, pode ser executado com apenas duas GPUs e, em compara\xe7\xe3o com o Command R+ 08-2024, teve um aumento de 150% na taxa de transfer\xeancia."},"command-light":{"description":"Uma vers\xe3o do Command que \xe9 menor e mais r\xe1pida, quase t\xe3o poderosa, mas com maior velocidade."},"command-light-nightly":{"description":"Para reduzir o intervalo entre os lan\xe7amentos de vers\xf5es principais, lan\xe7amos vers\xf5es noturnas do modelo Command. Para a s\xe9rie command-light, essa vers\xe3o \xe9 chamada de command-light-nightly. Observe que o command-light-nightly \xe9 a vers\xe3o mais recente, experimental e (possivelmente) inst\xe1vel. As vers\xf5es noturnas s\xe3o atualizadas regularmente e sem aviso pr\xe9vio, portanto, n\xe3o s\xe3o recomendadas para uso em ambientes de produ\xe7\xe3o."},"command-nightly":{"description":"Para reduzir o intervalo entre os lan\xe7amentos de vers\xf5es principais, lan\xe7amos vers\xf5es noturnas do modelo Command. Para a s\xe9rie Command, essa vers\xe3o \xe9 chamada de command-cightly. Observe que o command-nightly \xe9 a vers\xe3o mais recente, experimental e (possivelmente) inst\xe1vel. As vers\xf5es noturnas s\xe3o atualizadas regularmente e sem aviso pr\xe9vio, portanto, n\xe3o s\xe3o recomendadas para uso em ambientes de produ\xe7\xe3o."},"command-r":{"description":"Command R \xe9 um LLM otimizado para tarefas de di\xe1logo e longos contextos, especialmente adequado para intera\xe7\xf5es din\xe2micas e gerenciamento de conhecimento."},"command-r-03-2024":{"description":"O Command R \xe9 um modelo de di\xe1logo que segue instru\xe7\xf5es, apresentando maior qualidade e confiabilidade em tarefas lingu\xedsticas, al\xe9m de um comprimento de contexto mais longo em compara\xe7\xe3o com modelos anteriores. Ele pode ser utilizado em fluxos de trabalho complexos, como gera\xe7\xe3o de c\xf3digo, gera\xe7\xe3o aumentada por recupera\xe7\xe3o (RAG), uso de ferramentas e agentes."},"command-r-08-2024":{"description":"O command-r-08-2024 \xe9 uma vers\xe3o atualizada do modelo Command R, lan\xe7ada em agosto de 2024."},"command-r-plus":{"description":"Command R+ \xe9 um modelo de linguagem de grande porte de alto desempenho, projetado para cen\xe1rios empresariais reais e aplica\xe7\xf5es complexas."},"command-r-plus-04-2024":{"description":"O Command R+ \xe9 um modelo de di\xe1logo que segue instru\xe7\xf5es, apresentando maior qualidade e confiabilidade em tarefas lingu\xedsticas, al\xe9m de um comprimento de contexto mais longo em compara\xe7\xe3o com modelos anteriores. \xc9 mais adequado para fluxos de trabalho complexos de RAG e uso de ferramentas em m\xfaltiplas etapas."},"command-r-plus-08-2024":{"description":"Command R+ \xe9 um modelo de di\xe1logo que segue instru\xe7\xf5es, apresentando maior qualidade e confiabilidade em tarefas de linguagem, al\xe9m de ter um comprimento de contexto mais longo em compara\xe7\xe3o com modelos anteriores. \xc9 mais adequado para fluxos de trabalho RAG complexos e uso de ferramentas em m\xfaltiplas etapas."},"command-r7b-12-2024":{"description":"O command-r7b-12-2024 \xe9 uma vers\xe3o compacta e eficiente, lan\xe7ada em dezembro de 2024. Ele se destaca em tarefas que exigem racioc\xednio complexo e processamento em m\xfaltiplas etapas, como RAG, uso de ferramentas e agentes."},"computer-use-preview":{"description":"O modelo computer-use-preview \xe9 um modelo dedicado projetado para \\"ferramentas de uso de computador\\", treinado para entender e executar tarefas relacionadas a computadores."},"dall-e-2":{"description":"O segundo modelo DALL\xb7E, suporta gera\xe7\xe3o de imagens mais realistas e precisas, com resolu\xe7\xe3o quatro vezes maior que a da primeira gera\xe7\xe3o."},"dall-e-3":{"description":"O mais recente modelo DALL\xb7E, lan\xe7ado em novembro de 2023. Suporta gera\xe7\xe3o de imagens mais realistas e precisas, com maior capacidade de detalhamento."},"databricks/dbrx-instruct":{"description":"DBRX Instruct oferece capacidade de processamento de instru\xe7\xf5es altamente confi\xe1vel, suportando aplica\xe7\xf5es em diversos setores."},"deepseek-ai/DeepSeek-OCR":{"description":"O DeepSeek-OCR \xe9 um modelo de linguagem visual desenvolvido pela DeepSeek AI, com foco em reconhecimento \xf3ptico de caracteres (OCR) e \\"compress\xe3o \xf3ptica contextual\\". O modelo explora os limites da compress\xe3o de informa\xe7\xf5es contextuais a partir de imagens, sendo capaz de processar documentos de forma eficiente e convert\xea-los em formatos estruturados como Markdown. Ele reconhece com precis\xe3o o conte\xfado textual em imagens, sendo especialmente adequado para digitaliza\xe7\xe3o de documentos, extra\xe7\xe3o de texto e processamento estruturado."},"deepseek-ai/DeepSeek-R1":{"description":"DeepSeek-R1 \xe9 um modelo de infer\xeancia impulsionado por aprendizado por refor\xe7o (RL), que resolve problemas de repetitividade e legibilidade no modelo. Antes do RL, o DeepSeek-R1 introduziu dados de inicializa\xe7\xe3o a frio, otimizando ainda mais o desempenho da infer\xeancia. Ele apresenta desempenho compar\xe1vel ao OpenAI-o1 em tarefas matem\xe1ticas, de c\xf3digo e de infer\xeancia, e melhora o resultado geral por meio de m\xe9todos de treinamento cuidadosamente projetados."},"deepseek-ai/DeepSeek-R1-0528":{"description":"DeepSeek R1, ao utilizar recursos computacionais ampliados e introduzir mecanismos de otimiza\xe7\xe3o algor\xedtmica durante o p\xf3s-treinamento, aumentou significativamente a profundidade de suas capacidades de racioc\xednio e infer\xeancia. Este modelo apresenta desempenho excelente em diversos benchmarks, incluindo matem\xe1tica, programa\xe7\xe3o e l\xf3gica geral. Seu desempenho geral est\xe1 pr\xf3ximo de modelos l\xedderes, como O3 e Gemini 2.5 Pro."},"deepseek-ai/DeepSeek-R1-0528-Qwen3-8B":{"description":"DeepSeek-R1-0528-Qwen3-8B \xe9 um modelo obtido pela destila\xe7\xe3o da cadeia de pensamento do DeepSeek-R1-0528 para o Qwen3 8B Base. Este modelo alcan\xe7a desempenho de ponta (SOTA) entre modelos open source, superando o Qwen3 8B em 10% no teste AIME 2024 e atingindo o n\xedvel do Qwen3-235B-thinking. Apresenta excelente desempenho em racioc\xednio matem\xe1tico, programa\xe7\xe3o e l\xf3gica geral, compartilhando a arquitetura do Qwen3-8B, mas utilizando a configura\xe7\xe3o de tokeniza\xe7\xe3o do DeepSeek-R1-0528."},"deepseek-ai/DeepSeek-R1-Distill-Llama-70B":{"description":"Modelo de destila\xe7\xe3o DeepSeek-R1, otimizado para desempenho de infer\xeancia atrav\xe9s de aprendizado por refor\xe7o e dados de inicializa\xe7\xe3o fria, modelo de c\xf3digo aberto que redefine os padr\xf5es de m\xfaltiplas tarefas."},"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B":{"description":"Modelo de destila\xe7\xe3o DeepSeek-R1, otimizado para desempenho de infer\xeancia atrav\xe9s de aprendizado por refor\xe7o e dados de inicializa\xe7\xe3o fria, modelo de c\xf3digo aberto que redefine os padr\xf5es de m\xfaltiplas tarefas."},"deepseek-ai/DeepSeek-R1-Distill-Qwen-14B":{"description":"Modelo de destila\xe7\xe3o DeepSeek-R1, otimizado para desempenho de infer\xeancia atrav\xe9s de aprendizado por refor\xe7o e dados de inicializa\xe7\xe3o fria, modelo de c\xf3digo aberto que redefine os padr\xf5es de m\xfaltiplas tarefas."},"deepseek-ai/DeepSeek-R1-Distill-Qwen-32B":{"description":"DeepSeek-R1-Distill-Qwen-32B \xe9 um modelo obtido atrav\xe9s da destila\xe7\xe3o do Qwen2.5-32B. Este modelo foi ajustado com 800 mil amostras selecionadas geradas pelo DeepSeek-R1, demonstrando desempenho excepcional em v\xe1rias \xe1reas, como matem\xe1tica, programa\xe7\xe3o e racioc\xednio. Obteve resultados not\xe1veis em v\xe1rios testes de refer\xeancia, alcan\xe7ando uma precis\xe3o de 94,3% no MATH-500, demonstrando forte capacidade de racioc\xednio matem\xe1tico."},"deepseek-ai/DeepSeek-R1-Distill-Qwen-7B":{"description":"DeepSeek-R1-Distill-Qwen-7B \xe9 um modelo obtido atrav\xe9s da destila\xe7\xe3o do Qwen2.5-Math-7B. Este modelo foi ajustado com 800 mil amostras selecionadas geradas pelo DeepSeek-R1, demonstrando excelente capacidade de infer\xeancia. Apresentou desempenho not\xe1vel em v\xe1rios testes de refer\xeancia, alcan\xe7ando uma precis\xe3o de 92,8% no MATH-500, uma taxa de aprova\xe7\xe3o de 55,5% no AIME 2024 e uma pontua\xe7\xe3o de 1189 no CodeForces, demonstrando forte capacidade matem\xe1tica e de programa\xe7\xe3o para um modelo de 7B."},"deepseek-ai/DeepSeek-V2.5":{"description":"DeepSeek V2.5 combina as excelentes caracter\xedsticas das vers\xf5es anteriores, aprimorando a capacidade geral e de codifica\xe7\xe3o."},"deepseek-ai/DeepSeek-V3":{"description":"DeepSeek-V3 \xe9 um modelo de linguagem de especialistas mistos (MoE) com 671 bilh\xf5es de par\xe2metros, utilizando aten\xe7\xe3o latente de m\xfaltiplas cabe\xe7as (MLA) e a arquitetura DeepSeekMoE, combinando uma estrat\xe9gia de balanceamento de carga sem perda auxiliar para otimizar a efici\xeancia de infer\xeancia e treinamento. Ap\xf3s ser pr\xe9-treinado em 14,8 trilh\xf5es de tokens de alta qualidade e passar por ajuste fino supervisionado e aprendizado por refor\xe7o, o DeepSeek-V3 supera outros modelos de c\xf3digo aberto em desempenho, aproximando-se de modelos fechados l\xedderes."},"deepseek-ai/DeepSeek-V3.1":{"description":"O modelo DeepSeek V3.1 adota uma arquitetura de infer\xeancia h\xedbrida, suportando tanto o modo de racioc\xednio quanto o modo n\xe3o-racional."},"deepseek-ai/DeepSeek-V3.1-Terminus":{"description":"DeepSeek-V3.1-Terminus \xe9 uma vers\xe3o atualizada do modelo V3.1 lan\xe7ado pela DeepSeek, posicionada como um modelo de linguagem grande com agentes h\xedbridos. Esta atualiza\xe7\xe3o mant\xe9m as capacidades originais do modelo, focando na corre\xe7\xe3o de problemas reportados pelos usu\xe1rios e na melhoria da estabilidade. Houve uma melhoria significativa na consist\xeancia lingu\xedstica, reduzindo o uso misto de chin\xeas e ingl\xeas e a ocorr\xeancia de caracteres an\xf4malos. O modelo integra o “Modo de Pensamento” e o “Modo N\xe3o-Pensamento”, permitindo que os usu\xe1rios alternem flexivelmente entre eles via templates de chat para diferentes tarefas. Como uma otimiza\xe7\xe3o importante, o V3.1-Terminus aprimora o desempenho dos agentes de c\xf3digo e de busca, tornando-os mais confi\xe1veis na chamada de ferramentas e na execu\xe7\xe3o de tarefas complexas em m\xfaltiplas etapas."},"deepseek-ai/DeepSeek-V3.2-Exp":{"description":"DeepSeek-V3.2-Exp \xe9 a vers\xe3o experimental V3.2 lan\xe7ada pela DeepSeek, representando uma etapa intermedi\xe1ria rumo \xe0 pr\xf3xima gera\xe7\xe3o de arquitetura. Baseando-se no V3.1-Terminus, ela introduz o mecanismo de Aten\xe7\xe3o Esparsa DeepSeek (DeepSeek Sparse Attention, DSA) para melhorar a efici\xeancia de treinamento e infer\xeancia em contextos longos. Foi especialmente otimizada para chamadas de ferramentas, compreens\xe3o de documentos extensos e racioc\xednio em m\xfaltiplas etapas. A V3.2-Exp serve como uma ponte entre pesquisa e aplica\xe7\xe3o comercial, ideal para usu\xe1rios que buscam maior efici\xeancia de racioc\xednio em cen\xe1rios com or\xe7amentos de contexto elevados."},"deepseek-ai/deepseek-llm-67b-chat":{"description":"DeepSeek 67B \xe9 um modelo avan\xe7ado treinado para di\xe1logos de alta complexidade."},"deepseek-ai/deepseek-r1":{"description":"LLM avan\xe7ado e eficiente, especializado em racioc\xednio, matem\xe1tica e programa\xe7\xe3o."},"deepseek-ai/deepseek-v3.1":{"description":"DeepSeek V3.1: modelo de infer\xeancia de pr\xf3xima gera\xe7\xe3o, aprimorado para racioc\xednio complexo e pensamento em cadeia, ideal para tarefas que exigem an\xe1lise profunda."},"deepseek-ai/deepseek-v3.1-terminus":{"description":"DeepSeek V3.1: um modelo de infer\xeancia de nova gera\xe7\xe3o, com capacidades aprimoradas de racioc\xednio complexo e pensamento em cadeia, ideal para tarefas que exigem an\xe1lise aprofundada."},"deepseek-ai/deepseek-vl2":{"description":"DeepSeek-VL2 \xe9 um modelo de linguagem visual baseado no DeepSeekMoE-27B, desenvolvido como um especialista misto (MoE), utilizando uma arquitetura de MoE com ativa\xe7\xe3o esparsa, alcan\xe7ando desempenho excepcional com apenas 4,5 bilh\xf5es de par\xe2metros ativados. Este modelo se destaca em v\xe1rias tarefas, incluindo perguntas visuais, reconhecimento \xf3ptico de caracteres, compreens\xe3o de documentos/tabelas/gr\xe1ficos e localiza\xe7\xe3o visual."},"deepseek-chat":{"description":"Um novo modelo de c\xf3digo aberto que combina capacidades gerais e de codifica\xe7\xe3o, n\xe3o apenas preservando a capacidade de di\xe1logo geral do modelo Chat original e a poderosa capacidade de processamento de c\xf3digo do modelo Coder, mas tamb\xe9m alinhando-se melhor \xe0s prefer\xeancias humanas. Al\xe9m disso, o DeepSeek-V2.5 tamb\xe9m alcan\xe7ou melhorias significativas em v\xe1rias \xe1reas, como tarefas de escrita e seguimento de instru\xe7\xf5es."},"deepseek-coder-33B-instruct":{"description":"DeepSeek Coder 33B \xe9 um modelo de linguagem de c\xf3digo, treinado com 20 trilh\xf5es de dados, dos quais 87% s\xe3o c\xf3digo e 13% s\xe3o em chin\xeas e ingl\xeas. O modelo introduz uma janela de 16K e tarefas de preenchimento, oferecendo funcionalidades de completude de c\xf3digo e preenchimento de fragmentos em n\xedvel de projeto."},"deepseek-coder-v2":{"description":"DeepSeek Coder V2 \xe9 um modelo de c\xf3digo de especialistas abertos, destacando-se em tarefas de codifica\xe7\xe3o, compar\xe1vel ao GPT4-Turbo."},"deepseek-coder-v2:236b":{"description":"DeepSeek Coder V2 \xe9 um modelo de c\xf3digo de especialistas abertos, destacando-se em tarefas de codifica\xe7\xe3o, compar\xe1vel ao GPT4-Turbo."},"deepseek-r1":{"description":"DeepSeek-R1 \xe9 um modelo de infer\xeancia impulsionado por aprendizado por refor\xe7o (RL), que resolve problemas de repetitividade e legibilidade no modelo. Antes do RL, o DeepSeek-R1 introduziu dados de inicializa\xe7\xe3o a frio, otimizando ainda mais o desempenho da infer\xeancia. Ele apresenta desempenho compar\xe1vel ao OpenAI-o1 em tarefas matem\xe1ticas, de c\xf3digo e de infer\xeancia, e melhora o resultado geral por meio de m\xe9todos de treinamento cuidadosamente projetados."},"deepseek-r1-0528":{"description":"Modelo completo de 685B, lan\xe7ado em 28 de maio de 2025. O DeepSeek-R1 utilizou amplamente t\xe9cnicas de aprendizado por refor\xe7o na fase p\xf3s-treinamento, aumentando significativamente a capacidade de racioc\xednio do modelo mesmo com poucos dados anotados. Apresenta alto desempenho e forte capacidade em tarefas de matem\xe1tica, c\xf3digo e racioc\xednio em linguagem natural."},"deepseek-r1-250528":{"description":"DeepSeek R1 250528, vers\xe3o completa do modelo de infer\xeancia DeepSeek-R1, ideal para tarefas complexas de matem\xe1tica e l\xf3gica."},"deepseek-r1-70b-fast-online":{"description":"DeepSeek R1 70B vers\xe3o r\xe1pida, suporta busca em tempo real, oferecendo maior velocidade de resposta enquanto mant\xe9m o desempenho do modelo."},"deepseek-r1-70b-online":{"description":"DeepSeek R1 70B vers\xe3o padr\xe3o, suporta busca em tempo real, adequado para di\xe1logos e tarefas de processamento de texto que requerem informa\xe7\xf5es atualizadas."},"deepseek-r1-distill-llama":{"description":"deepseek-r1-distill-llama \xe9 um modelo baseado no Llama, destilado a partir do DeepSeek-R1."},"deepseek-r1-distill-llama-70b":{"description":"DeepSeek R1 Distill Llama 70B, modelo destilado que combina a capacidade de infer\xeancia R1 com o ecossistema Llama."},"deepseek-r1-distill-llama-8b":{"description":"DeepSeek-R1-Distill-Llama-8B \xe9 um modelo de linguagem grande destilado baseado no Llama-3.1-8B, utilizando sa\xeddas do DeepSeek R1."},"deepseek-r1-distill-qianfan-70b":{"description":"DeepSeek R1 Distill Qianfan 70B, modelo R1 destilado baseado no Qianfan-70B, com excelente custo-benef\xedcio."},"deepseek-r1-distill-qianfan-8b":{"description":"DeepSeek R1 Distill Qianfan 8B, modelo R1 destilado baseado no Qianfan-8B, ideal para aplica\xe7\xf5es de pequeno e m\xe9dio porte."},"deepseek-r1-distill-qianfan-llama-70b":{"description":"DeepSeek R1 Distill Qianfan Llama 70B, modelo R1 destilado baseado no Llama-70B."},"deepseek-r1-distill-qwen":{"description":"deepseek-r1-distill-qwen \xe9 um modelo derivado do Qwen, destilado a partir do DeepSeek-R1."},"deepseek-r1-distill-qwen-1.5b":{"description":"DeepSeek R1 Distill Qwen 1.5B, modelo R1 destilado ultraleve, ideal para ambientes com recursos extremamente limitados."},"deepseek-r1-distill-qwen-14b":{"description":"DeepSeek R1 Distill Qwen 14B, modelo R1 destilado de porte m\xe9dio, adequado para implanta\xe7\xe3o em m\xfaltiplos cen\xe1rios."},"deepseek-r1-distill-qwen-32b":{"description":"DeepSeek R1 Distill Qwen 32B, modelo R1 destilado baseado no Qwen-32B, equilibrando desempenho e custo."},"deepseek-r1-distill-qwen-7b":{"description":"DeepSeek R1 Distill Qwen 7B, modelo R1 destilado leve, ideal para ambientes de borda e implanta\xe7\xf5es privadas corporativas."},"deepseek-r1-fast-online":{"description":"DeepSeek R1 vers\xe3o completa r\xe1pida, suporta busca em tempo real, combinando a poderosa capacidade de 671B de par\xe2metros com maior velocidade de resposta."},"deepseek-r1-online":{"description":"DeepSeek R1 vers\xe3o completa, com 671B de par\xe2metros, suporta busca em tempo real, apresentando capacidades de compreens\xe3o e gera\xe7\xe3o mais robustas."},"deepseek-reasoner":{"description":"Modo de pensamento do DeepSeek V3.2. Antes de fornecer a resposta final, o modelo gera uma cadeia de racioc\xednio para melhorar a precis\xe3o da resposta."},"deepseek-v2":{"description":"DeepSeek V2 \xe9 um modelo de linguagem eficiente Mixture-of-Experts, adequado para demandas de processamento econ\xf4mico."},"deepseek-v2:236b":{"description":"DeepSeek V2 236B \xe9 o modelo de c\xf3digo projetado do DeepSeek, oferecendo forte capacidade de gera\xe7\xe3o de c\xf3digo."},"deepseek-v3":{"description":"DeepSeek-V3 \xe9 um modelo MoE desenvolvido pela Hangzhou DeepSeek Artificial Intelligence Technology Research Co., Ltd., com desempenho destacado em v\xe1rias avalia\xe7\xf5es, ocupando o primeiro lugar entre os modelos de c\xf3digo aberto nas principais listas. Em compara\xe7\xe3o com o modelo V2.5, a velocidade de gera\xe7\xe3o do V3 foi aumentada em 3 vezes, proporcionando uma experi\xeancia de uso mais r\xe1pida e fluida."},"deepseek-v3-0324":{"description":"DeepSeek-V3-0324 \xe9 um modelo MoE com 671 bilh\xf5es de par\xe2metros, destacando-se em habilidades de programa\xe7\xe3o e t\xe9cnicas, compreens\xe3o de contexto e processamento de textos longos."},"deepseek-v3.1":{"description":"DeepSeek-V3.1 \xe9 o novo modelo h\xedbrido de racioc\xednio lan\xe7ado pela DeepSeek, suportando dois modos de racioc\xednio: com e sem pensamento, com efici\xeancia de pensamento superior ao DeepSeek-R1-0528. Ap\xf3s otimiza\xe7\xe3o p\xf3s-treinamento, o uso de ferramentas Agent e o desempenho em tarefas inteligentes foram significativamente aprimorados. Suporta janela de contexto de 128k e comprimento m\xe1ximo de sa\xedda de 64k tokens."},"deepseek-v3.1-terminus":{"description":"DeepSeek-V3.1-Terminus \xe9 uma vers\xe3o otimizada para dispositivos finais do modelo de linguagem de grande escala lan\xe7ado pela DeepSeek."},"deepseek-v3.1-think-250821":{"description":"DeepSeek V3.1 Think 250821, modelo de pensamento profundo correspondente \xe0 vers\xe3o Terminus, ideal para cen\xe1rios de infer\xeancia de alto desempenho."},"deepseek-v3.1:671b":{"description":"DeepSeek V3.1: modelo de infer\xeancia de pr\xf3xima gera\xe7\xe3o, aprimorado para racioc\xednio complexo e pensamento em cadeia, ideal para tarefas que exigem an\xe1lise profunda."},"deepseek-v3.2-exp":{"description":"deepseek-v3.2-exp introduz um mecanismo de aten\xe7\xe3o esparsa, visando melhorar a efici\xeancia de treinamento e infer\xeancia no processamento de textos longos, com pre\xe7o inferior ao do deepseek-v3.1."},"deepseek-v3.2-think":{"description":"DeepSeek V3.2 Think, vers\xe3o completa do modelo de pensamento profundo, com capacidade refor\xe7ada de racioc\xednio em cadeia longa."},"deepseek-vl2":{"description":"DeepSeek VL2, modelo multimodal com suporte para compreens\xe3o de imagem e texto e perguntas visuais de alta granularidade."},"deepseek-vl2-small":{"description":"DeepSeek VL2 Small, vers\xe3o multimodal leve, ideal para cen\xe1rios com recursos limitados e alta concorr\xeancia."},"deepseek/deepseek-chat-v3-0324":{"description":"O DeepSeek V3 \xe9 um modelo misto especializado com 685B de par\xe2metros, sendo a mais recente itera\xe7\xe3o da s\xe9rie de modelos de chat da equipe DeepSeek.\\n\\nEle herda o modelo [DeepSeek V3](/deepseek/deepseek-chat-v3) e se destaca em v\xe1rias tarefas."},"deepseek/deepseek-chat-v3-0324:free":{"description":"O DeepSeek V3 \xe9 um modelo misto especializado com 685B de par\xe2metros, sendo a mais recente itera\xe7\xe3o da s\xe9rie de modelos de chat da equipe DeepSeek.\\n\\nEle herda o modelo [DeepSeek V3](/deepseek/deepseek-chat-v3) e se destaca em v\xe1rias tarefas."},"deepseek/deepseek-chat-v3.1":{"description":"DeepSeek-V3.1 \xe9 um grande modelo h\xedbrido de racioc\xednio que suporta contexto longo de 128K e troca eficiente de modos, alcan\xe7ando desempenho e velocidade excepcionais em chamadas de ferramentas, gera\xe7\xe3o de c\xf3digo e tarefas complexas de racioc\xednio."},"deepseek/deepseek-r1":{"description":"O modelo DeepSeek R1 recebeu uma atualiza\xe7\xe3o menor, atualmente na vers\xe3o DeepSeek-R1-0528. Na atualiza\xe7\xe3o mais recente, o DeepSeek R1 melhorou significativamente a profundidade e capacidade de racioc\xednio ao aproveitar recursos computacionais aumentados e introduzir mecanismos de otimiza\xe7\xe3o algor\xedtmica p\xf3s-treinamento. O modelo apresenta desempenho excelente em benchmarks de matem\xe1tica, programa\xe7\xe3o e l\xf3gica geral, aproximando-se do desempenho de modelos l\xedderes como O3 e Gemini 2.5 Pro."},"deepseek/deepseek-r1-0528":{"description":"DeepSeek-R1 melhora significativamente a capacidade de racioc\xednio do modelo mesmo com poucos dados anotados. Antes de fornecer a resposta final, o modelo gera uma cadeia de pensamento para aumentar a precis\xe3o da resposta."},"deepseek/deepseek-r1-0528:free":{"description":"DeepSeek-R1 melhora significativamente a capacidade de racioc\xednio do modelo mesmo com poucos dados anotados. Antes de fornecer a resposta final, o modelo gera uma cadeia de pensamento para aumentar a precis\xe3o da resposta."},"deepseek/deepseek-r1-distill-llama-70b":{"description":"O DeepSeek R1 Distill Llama 70B \xe9 um modelo de linguagem de grande porte baseado no Llama3.3 70B. Utilizando o ajuste fino derivado da sa\xedda do DeepSeek R1, ele alcan\xe7a um desempenho competitivo compar\xe1vel aos modelos de ponta de grande escala."},"deepseek/deepseek-r1-distill-llama-8b":{"description":"DeepSeek R1 Distill Llama 8B \xe9 um modelo de linguagem grande destilado baseado no Llama-3.1-8B-Instruct, treinado usando a sa\xedda do DeepSeek R1."},"deepseek/deepseek-r1-distill-qwen-14b":{"description":"DeepSeek R1 Distill Qwen 14B \xe9 um modelo de linguagem grande destilado baseado no Qwen 2.5 14B, treinado usando a sa\xedda do DeepSeek R1. Este modelo superou o o1-mini da OpenAI em v\xe1rios benchmarks, alcan\xe7ando os mais recentes avan\xe7os tecnol\xf3gicos em modelos densos (state-of-the-art). Aqui est\xe3o alguns resultados de benchmarks:\\nAIME 2024 pass@1: 69.7\\nMATH-500 pass@1: 93.9\\nClassifica\xe7\xe3o CodeForces: 1481\\nEste modelo, ajustado a partir da sa\xedda do DeepSeek R1, demonstrou desempenho competitivo compar\xe1vel a modelos de ponta de maior escala."},"deepseek/deepseek-r1-distill-qwen-32b":{"description":"DeepSeek R1 Distill Qwen 32B \xe9 um modelo de linguagem grande destilado baseado no Qwen 2.5 32B, treinado usando a sa\xedda do DeepSeek R1. Este modelo superou o o1-mini da OpenAI em v\xe1rios benchmarks, alcan\xe7ando os mais recentes avan\xe7os tecnol\xf3gicos em modelos densos (state-of-the-art). Aqui est\xe3o alguns resultados de benchmarks:\\nAIME 2024 pass@1: 72.6\\nMATH-500 pass@1: 94.3\\nClassifica\xe7\xe3o CodeForces: 1691\\nEste modelo, ajustado a partir da sa\xedda do DeepSeek R1, demonstrou desempenho competitivo compar\xe1vel a modelos de ponta de maior escala."},"deepseek/deepseek-r1/community":{"description":"DeepSeek R1 \xe9 o mais recente modelo de c\xf3digo aberto lan\xe7ado pela equipe DeepSeek, com desempenho de infer\xeancia extremamente robusto, especialmente em tarefas de matem\xe1tica, programa\xe7\xe3o e racioc\xednio, alcan\xe7ando n\xedveis compar\xe1veis ao modelo o1 da OpenAI."},"deepseek/deepseek-r1:free":{"description":"DeepSeek-R1 melhorou significativamente a capacidade de racioc\xednio do modelo com muito poucos dados rotulados. Antes de fornecer a resposta final, o modelo gera uma cadeia de pensamento para aumentar a precis\xe3o da resposta final."},"deepseek/deepseek-v3":{"description":"Modelo grande de linguagem universal r\xe1pido com capacidades de racioc\xednio aprimoradas."},"deepseek/deepseek-v3.1-base":{"description":"DeepSeek V3.1 Base \xe9 uma vers\xe3o aprimorada do modelo DeepSeek V3."},"deepseek/deepseek-v3/community":{"description":"DeepSeek-V3 alcan\xe7ou um avan\xe7o significativo na velocidade de infer\xeancia em compara\xe7\xe3o com os modelos anteriores. Classificado como o n\xfamero um entre os modelos de c\xf3digo aberto, pode competir com os modelos fechados mais avan\xe7ados do mundo. DeepSeek-V3 utiliza a arquitetura de Aten\xe7\xe3o Multi-Cabe\xe7a (MLA) e DeepSeekMoE, que foram amplamente validadas no DeepSeek-V2. Al\xe9m disso, DeepSeek-V3 introduziu uma estrat\xe9gia auxiliar sem perdas para balanceamento de carga e definiu objetivos de treinamento de previs\xe3o de m\xfaltiplos r\xf3tulos para obter um desempenho mais forte."},"deepseek_r1":{"description":"DeepSeek-R1 \xe9 um modelo de infer\xeancia impulsionado por aprendizado por refor\xe7o (RL), que resolve problemas de repetitividade e legibilidade no modelo. Antes do RL, o DeepSeek-R1 introduziu dados de inicializa\xe7\xe3o a frio, otimizando ainda mais o desempenho de infer\xeancia. Ele se compara ao OpenAI-o1 em tarefas de matem\xe1tica, c\xf3digo e racioc\xednio, e, atrav\xe9s de m\xe9todos de treinamento cuidadosamente projetados, melhorou o desempenho geral."},"deepseek_r1_distill_llama_70b":{"description":"DeepSeek-R1-Distill-Llama-70B \xe9 um modelo obtido atrav\xe9s do treinamento de destila\xe7\xe3o do Llama-3.3-70B-Instruct. Este modelo \xe9 parte da s\xe9rie DeepSeek-R1 e, atrav\xe9s do uso de amostras geradas pelo DeepSeek-R1, demonstrou desempenho excepcional em matem\xe1tica, programa\xe7\xe3o e racioc\xednio."},"deepseek_r1_distill_qwen_14b":{"description":"DeepSeek-R1-Distill-Qwen-14B \xe9 um modelo obtido atrav\xe9s da destila\xe7\xe3o de conhecimento do Qwen2.5-14B. Este modelo foi ajustado com 800 mil amostras selecionadas geradas pelo DeepSeek-R1, demonstrando excelente capacidade de infer\xeancia."},"deepseek_r1_distill_qwen_32b":{"description":"DeepSeek-R1-Distill-Qwen-32B \xe9 um modelo obtido atrav\xe9s da destila\xe7\xe3o de conhecimento do Qwen2.5-32B. Este modelo foi ajustado com 800 mil amostras selecionadas geradas pelo DeepSeek-R1, demonstrando desempenho excepcional em v\xe1rias \xe1reas, incluindo matem\xe1tica, programa\xe7\xe3o e racioc\xednio."},"doubao-1.5-lite-32k":{"description":"Doubao-1.5-lite \xe9 a nova gera\xe7\xe3o de modelo leve, com velocidade de resposta extrema, alcan\xe7ando n\xedveis de desempenho e lat\xeancia de classe mundial."},"doubao-1.5-pro-256k":{"description":"Doubao-1.5-pro-256k \xe9 uma vers\xe3o totalmente aprimorada do Doubao-1.5-Pro, com um aumento significativo de 10% no desempenho geral. Suporta racioc\xednio com janelas de contexto de 256k e um comprimento de sa\xedda de at\xe9 12k tokens. Maior desempenho, janelas maiores e excelente custo-benef\xedcio, adequado para uma ampla gama de cen\xe1rios de aplica\xe7\xe3o."},"doubao-1.5-pro-32k":{"description":"Doubao-1.5-pro \xe9 a nova gera\xe7\xe3o de modelo principal, com desempenho totalmente aprimorado, destacando-se em conhecimento, c\xf3digo, racioc\xednio, entre outros aspectos."},"doubao-1.5-thinking-pro":{"description":"O modelo de pensamento profundo Doubao-1.5 apresenta um desempenho excepcional em \xe1reas especializadas como matem\xe1tica, programa\xe7\xe3o e racioc\xednio cient\xedfico, al\xe9m de tarefas gerais como escrita criativa. Ele alcan\xe7ou ou se aproximou do n\xedvel de elite da ind\xfastria em v\xe1rias refer\xeancias respeit\xe1veis, como AIME 2024, Codeforces e GPQA. Suporta uma janela de contexto de 128k e uma sa\xedda de 16k."},"doubao-1.5-thinking-pro-m":{"description":"Doubao-1.5 \xe9 um novo modelo de pensamento profundo (vers\xe3o m com capacidade nativa de infer\xeancia multimodal profunda), destacando-se em matem\xe1tica, programa\xe7\xe3o, racioc\xednio cient\xedfico e tarefas gerais como escrita criativa. Alcan\xe7a ou se aproxima do topo da ind\xfastria em benchmarks como AIME 2024, Codeforces e GPQA. Suporta janela de contexto de 128k e sa\xedda de 16k."},"doubao-1.5-thinking-vision-pro":{"description":"Novo modelo de pensamento profundo visual, com capacidades avan\xe7adas de compreens\xe3o e infer\xeancia multimodal geral, alcan\xe7ando desempenho SOTA em 37 dos 59 benchmarks p\xfablicos."},"doubao-1.5-ui-tars":{"description":"Doubao-1.5-UI-TARS \xe9 um modelo Agent nativo para intera\xe7\xe3o com interfaces gr\xe1ficas (GUI). Possui habilidades humanas de percep\xe7\xe3o, racioc\xednio e a\xe7\xe3o para intera\xe7\xe3o fluida com GUIs."},"doubao-1.5-vision-lite":{"description":"Doubao-1.5-vision-lite \xe9 um modelo multimodal atualizado, suportando reconhecimento de imagens de qualquer resolu\xe7\xe3o e propor\xe7\xf5es extremas, melhorando a capacidade de racioc\xednio visual, reconhecimento de documentos, compreens\xe3o de informa\xe7\xf5es detalhadas e seguimento de instru\xe7\xf5es. Suporta uma janela de contexto de 128k, com comprimento de sa\xedda de at\xe9 16k tokens."},"doubao-1.5-vision-pro":{"description":"Doubao-1.5-vision-pro \xe9 um modelo multimodal avan\xe7ado, suportando reconhecimento de imagens em qualquer resolu\xe7\xe3o e propor\xe7\xe3o extrema, com capacidades aprimoradas de racioc\xednio visual, reconhecimento de documentos, compreens\xe3o de detalhes e seguimento de instru\xe7\xf5es."},"doubao-1.5-vision-pro-32k":{"description":"Doubao-1.5-vision-pro \xe9 um modelo multimodal avan\xe7ado, suportando reconhecimento de imagens em qualquer resolu\xe7\xe3o e propor\xe7\xe3o extrema, com capacidades aprimoradas de racioc\xednio visual, reconhecimento de documentos, compreens\xe3o de detalhes e seguimento de instru\xe7\xf5es."},"doubao-lite-128k":{"description":"Oferece velocidade de resposta extrema e melhor custo-benef\xedcio, proporcionando op\xe7\xf5es mais flex\xedveis para diferentes cen\xe1rios dos clientes. Suporta infer\xeancia e fine-tuning com janela de contexto de 128k."},"doubao-lite-32k":{"description":"Oferece velocidade de resposta extrema e melhor custo-benef\xedcio, proporcionando op\xe7\xf5es mais flex\xedveis para diferentes cen\xe1rios dos clientes. Suporta infer\xeancia e fine-tuning com janela de contexto de 32k."},"doubao-lite-4k":{"description":"Oferece velocidade de resposta extrema e melhor custo-benef\xedcio, proporcionando op\xe7\xf5es mais flex\xedveis para diferentes cen\xe1rios dos clientes. Suporta infer\xeancia e fine-tuning com janela de contexto de 4k."},"doubao-pro-256k":{"description":"Modelo principal com melhor desempenho, adequado para tarefas complexas, apresentando \xf3timos resultados em perguntas de refer\xeancia, resumos, cria\xe7\xe3o, classifica\xe7\xe3o de texto, interpreta\xe7\xe3o de pap\xe9is e outros cen\xe1rios. Suporta infer\xeancia e fine-tuning com janela de contexto de 256k."},"doubao-pro-32k":{"description":"Modelo principal com melhor desempenho, adequado para tarefas complexas, apresentando \xf3timos resultados em perguntas de refer\xeancia, resumos, cria\xe7\xe3o, classifica\xe7\xe3o de texto, interpreta\xe7\xe3o de pap\xe9is e outros cen\xe1rios. Suporta infer\xeancia e fine-tuning com janela de contexto de 32k."},"doubao-seed-1.6":{"description":"Doubao-Seed-1.6 \xe9 um novo modelo multimodal de pensamento profundo, suportando tr\xeas modos de pensamento: auto, thinking e non-thinking. No modo non-thinking, o desempenho supera significativamente o Doubao-1.5-pro/250115. Suporta janela de contexto de 256k e sa\xedda de at\xe9 16k tokens."},"doubao-seed-1.6-flash":{"description":"Doubao-Seed-1.6-flash \xe9 um modelo multimodal de pensamento profundo com velocidade de infer\xeancia extrema, TPOT de apenas 10ms; suporta compreens\xe3o textual e visual, com capacidade textual superior \xe0 gera\xe7\xe3o lite anterior e compreens\xe3o visual compar\xe1vel \xe0 s\xe9rie pro dos concorrentes. Suporta janela de contexto de 256k e sa\xedda de at\xe9 16k tokens."},"doubao-seed-1.6-lite":{"description":"Doubao-Seed-1.6-lite \xe9 um novo modelo multimodal de pensamento profundo, com suporte para n\xedveis ajust\xe1veis de esfor\xe7o de racioc\xednio (Minimal, Low, Medium, High). Oferece excelente custo-benef\xedcio e \xe9 a melhor escolha para tarefas comuns, com janela de contexto de at\xe9 256k."},"doubao-seed-1.6-thinking":{"description":"Doubao-Seed-1.6-thinking tem capacidade de pensamento significativamente refor\xe7ada, melhorando ainda mais habilidades b\xe1sicas como codifica\xe7\xe3o, matem\xe1tica e racioc\xednio l\xf3gico em compara\xe7\xe3o com Doubao-1.5-thinking-pro, al\xe9m de suportar compreens\xe3o visual. Suporta janela de contexto de 256k e sa\xedda de at\xe9 16k tokens."},"doubao-seed-1.6-vision":{"description":"Doubao-Seed-1.6-vision \xe9 um modelo de pensamento profundo visual que demonstra capacidades multimodais gerais mais fortes em cen\xe1rios como educa\xe7\xe3o, revis\xe3o de imagens, inspe\xe7\xe3o e seguran\xe7a, e busca e resposta por IA. Suporta janela de contexto de 256k e comprimento m\xe1ximo de sa\xedda de at\xe9 64k tokens."},"doubao-seededit-3-0-i2i-250628":{"description":"O modelo de gera\xe7\xe3o de imagens Doubao foi desenvolvido pela equipe Seed da ByteDance, suporta entrada de texto e imagem, oferecendo uma experi\xeancia de gera\xe7\xe3o de imagens altamente control\xe1vel e de alta qualidade. Suporta edi\xe7\xe3o de imagens por comandos de texto, gerando imagens com lados entre 512 e 1536 pixels."},"doubao-seedream-3-0-t2i-250415":{"description":"O modelo de gera\xe7\xe3o de imagens Seedream 3.0 foi desenvolvido pela equipe Seed da ByteDance, suporta entrada de texto e imagem, oferecendo uma experi\xeancia de gera\xe7\xe3o de imagens altamente control\xe1vel e de alta qualidade. Gera imagens baseadas em prompts de texto."},"doubao-seedream-4-0-250828":{"description":"O modelo de gera\xe7\xe3o de imagens Seedream 4.0 foi desenvolvido pela equipe Seed da ByteDance, suporta entrada de texto e imagem, oferecendo uma experi\xeancia de gera\xe7\xe3o de imagens altamente control\xe1vel e de alta qualidade. Gera imagens baseadas em prompts de texto."},"doubao-vision-lite-32k":{"description":"O modelo Doubao-vision \xe9 um grande modelo multimodal lan\xe7ado pela Doubao, com forte capacidade de compreens\xe3o e infer\xeancia de imagens, al\xe9m de compreens\xe3o precisa de instru\xe7\xf5es. O modelo demonstra desempenho robusto em extra\xe7\xe3o de informa\xe7\xf5es de texto em imagens e tarefas de infer\xeancia baseadas em imagens, podendo ser aplicado a tarefas visuais de perguntas e respostas mais complexas e amplas."},"doubao-vision-pro-32k":{"description":"O modelo Doubao-vision \xe9 um grande modelo multimodal lan\xe7ado pela Doubao, com forte capacidade de compreens\xe3o e infer\xeancia de imagens, al\xe9m de compreens\xe3o precisa de instru\xe7\xf5es. O modelo demonstra desempenho robusto em extra\xe7\xe3o de informa\xe7\xf5es de texto em imagens e tarefas de infer\xeancia baseadas em imagens, podendo ser aplicado a tarefas visuais de perguntas e respostas mais complexas e amplas."},"emohaa":{"description":"O Emohaa \xe9 um modelo psicol\xf3gico com capacidade de consultoria profissional, ajudando os usu\xe1rios a entender quest\xf5es emocionais."},"ernie-4.5-0.3b":{"description":"ERNIE 4.5 0.3B, modelo leve e de c\xf3digo aberto, ideal para implanta\xe7\xe3o local e personalizada."},"ernie-4.5-21b-a3b":{"description":"ERNIE 4.5 21B A3B, modelo de grande porte de c\xf3digo aberto, com desempenho superior em tarefas de compreens\xe3o e gera\xe7\xe3o."},"ernie-4.5-300b-a47b":{"description":"ERNIE 4.5 300B A47B \xe9 um modelo especialista h\xedbrido em larga escala lan\xe7ado pela Wenxin da Baidu, com desempenho excepcional em racioc\xednio."},"ernie-4.5-8k-preview":{"description":"ERNIE 4.5 8K Preview, modelo de pr\xe9-visualiza\xe7\xe3o com contexto de 8K, para testes e experimenta\xe7\xe3o das capacidades do Wenxin 4.5."},"ernie-4.5-turbo-128k":{"description":"ERNIE 4.5 Turbo 128K, modelo universal de alto desempenho com suporte para busca aprimorada e uso de ferramentas, ideal para perguntas e respostas, c\xf3digo, agentes inteligentes e outros cen\xe1rios."},"ernie-4.5-turbo-128k-preview":{"description":"ERNIE 4.5 Turbo 128K Preview, vers\xe3o de pr\xe9-visualiza\xe7\xe3o com capacidades equivalentes \xe0 vers\xe3o oficial, ideal para testes e integra\xe7\xe3o."},"ernie-4.5-turbo-32k":{"description":"ERNIE 4.5 Turbo 32K, vers\xe3o com contexto m\xe9dio-longo, ideal para perguntas e respostas, recupera\xe7\xe3o de conhecimento e di\xe1logos em m\xfaltiplas rodadas."},"ernie-4.5-turbo-latest":{"description":"ERNIE 4.5 Turbo Latest, vers\xe3o mais recente com desempenho otimizado, ideal como modelo principal em ambientes de produ\xe7\xe3o."},"ernie-4.5-turbo-vl":{"description":"ERNIE 4.5 Turbo VL, modelo multimodal maduro, ideal para tarefas de compreens\xe3o e reconhecimento de imagem e texto em produ\xe7\xe3o."},"ernie-4.5-turbo-vl-32k":{"description":"ERNIE 4.5 Turbo VL 32K, vers\xe3o multimodal com contexto m\xe9dio-longo, ideal para compreens\xe3o conjunta de documentos longos e imagens."},"ernie-4.5-turbo-vl-32k-preview":{"description":"ERNIE 4.5 Turbo VL 32K Preview, vers\xe3o de pr\xe9-visualiza\xe7\xe3o multimodal 32K, ideal para avalia\xe7\xe3o de capacidades visuais em contexto longo."},"ernie-4.5-turbo-vl-latest":{"description":"ERNIE 4.5 Turbo VL Latest, vers\xe3o multimodal mais recente, com melhor desempenho em compreens\xe3o e racioc\xednio de imagem e texto."},"ernie-4.5-turbo-vl-preview":{"description":"ERNIE 4.5 Turbo VL Preview, modelo multimodal de pr\xe9-visualiza\xe7\xe3o com suporte para compreens\xe3o e gera\xe7\xe3o de imagem e texto, ideal para perguntas visuais e experi\xeancias de entendimento de conte\xfado."},"ernie-4.5-vl-28b-a3b":{"description":"ERNIE 4.5 VL 28B A3B, modelo multimodal de c\xf3digo aberto com suporte para tarefas de compreens\xe3o e racioc\xednio de imagem e texto."},"ernie-5.0-thinking-preview":{"description":"Wenxin 5.0 Thinking Preview, modelo nativo multimodal de \xfaltima gera\xe7\xe3o com suporte unificado para texto, imagem, \xe1udio e v\xeddeo, com capacidades amplamente aprimoradas, ideal para perguntas complexas, cria\xe7\xe3o e agentes inteligentes."},"ernie-char-8k":{"description":"ERNIE Character 8K, modelo de di\xe1logo com personalidade, ideal para constru\xe7\xe3o de personagens e conversas de longo prazo."},"ernie-char-fiction-8k":{"description":"ERNIE Character Fiction 8K, modelo de personalidade voltado para cria\xe7\xe3o de hist\xf3rias e fic\xe7\xe3o, ideal para gera\xe7\xe3o de narrativas longas."},"ernie-char-fiction-8k-preview":{"description":"ERNIE Character Fiction 8K Preview, vers\xe3o de pr\xe9-visualiza\xe7\xe3o do modelo de cria\xe7\xe3o de personagens e enredos, para testes e experimenta\xe7\xe3o."},"ernie-irag-edit":{"description":"ERNIE iRAG Edit, modelo de edi\xe7\xe3o de imagem com suporte para remo\xe7\xe3o, repintura e gera\xe7\xe3o de variantes."},"ernie-lite-8k":{"description":"ERNIE Lite 8K, modelo universal leve, ideal para perguntas e respostas cotidianas e gera\xe7\xe3o de conte\xfado com baixo custo."},"ernie-lite-pro-128k":{"description":"ERNIE Lite Pro 128K, modelo leve de alto desempenho, ideal para cen\xe1rios sens\xedveis a lat\xeancia e custo."},"ernie-novel-8k":{"description":"ERNIE Novel 8K, modelo para cria\xe7\xe3o de romances longos e roteiros de IP, especializado em m\xfaltiplos personagens e narrativas paralelas."},"ernie-speed-128k":{"description":"ERNIE Speed 128K, modelo grande sem custo de entrada/sa\xedda, ideal para compreens\xe3o de textos longos e testes em larga escala."},"ernie-speed-8k":{"description":"ERNIE Speed 8K, modelo gratuito e r\xe1pido, ideal para di\xe1logos cotidianos e tarefas leves de texto."},"ernie-speed-pro-128k":{"description":"ERNIE Speed Pro 128K, modelo de alta concorr\xeancia e excelente custo-benef\xedcio, ideal para servi\xe7os online em larga escala e aplica\xe7\xf5es corporativas."},"ernie-tiny-8k":{"description":"ERNIE Tiny 8K, modelo ultraleve, ideal para perguntas simples, classifica\xe7\xe3o e infer\xeancia de baixo custo."},"ernie-x1-turbo-32k":{"description":"ERNIE X1 Turbo 32K, modelo de racioc\xednio r\xe1pido com contexto longo de 32K, ideal para infer\xeancia complexa e di\xe1logos em m\xfaltiplas rodadas."},"ernie-x1.1-preview":{"description":"ERNIE X1.1 Preview, vers\xe3o de pr\xe9-visualiza\xe7\xe3o do modelo de racioc\xednio ERNIE X1.1, ideal para testes e valida\xe7\xe3o de capacidades."},"fal-ai/bytedance/seedream/v4":{"description":"O modelo de gera\xe7\xe3o de imagens Seedream 4.0 foi desenvolvido pela equipe Seed da ByteDance, suporta entrada de texto e imagem, oferecendo uma experi\xeancia de gera\xe7\xe3o de imagens altamente control\xe1vel e de alta qualidade. Gera imagens baseadas em prompts de texto."},"fal-ai/flux-kontext/dev":{"description":"Modelo FLUX.1 focado em tarefas de edi\xe7\xe3o de imagens, suporta entrada de texto e imagem."},"fal-ai/flux-pro/kontext":{"description":"FLUX.1 Kontext [pro] pode processar texto e imagens de refer\xeancia como entrada, realizando edi\xe7\xf5es locais direcionadas e transforma\xe7\xf5es complexas de cenas inteiras de forma fluida."},"fal-ai/flux/krea":{"description":"Flux Krea [dev] \xe9 um modelo de gera\xe7\xe3o de imagens com prefer\xeancia est\xe9tica, visando criar imagens mais realistas e naturais."},"fal-ai/flux/schnell":{"description":"FLUX.1 [schnell] \xe9 um modelo de gera\xe7\xe3o de imagens com 12 bilh\xf5es de par\xe2metros, focado em gerar imagens de alta qualidade rapidamente."},"fal-ai/hunyuan-image/v3":{"description":"Um poderoso modelo nativo de gera\xe7\xe3o de imagens multimodais"},"fal-ai/imagen4/preview":{"description":"Modelo de gera\xe7\xe3o de imagens de alta qualidade fornecido pelo Google."},"fal-ai/nano-banana":{"description":"Nano Banana \xe9 o mais recente, r\xe1pido e eficiente modelo multimodal nativo do Google, que permite gerar e editar imagens por meio de conversas."},"fal-ai/qwen-image":{"description":"Modelo poderoso de imagens brutas da equipe Qwen, com impressionante capacidade de gera\xe7\xe3o de texto em chin\xeas e diversos estilos visuais de imagens."},"fal-ai/qwen-image-edit":{"description":"Modelo profissional de edi\xe7\xe3o de imagens lan\xe7ado pela equipe Qwen, suporta edi\xe7\xe3o sem\xe2ntica e visual, podendo editar com precis\xe3o textos em chin\xeas e ingl\xeas, realizar transforma\xe7\xe3o de estilo, rota\xe7\xe3o de objetos e outras edi\xe7\xf5es de alta qualidade."},"flux-1-schnell":{"description":"Modelo de gera\xe7\xe3o de imagens a partir de texto com 12 bilh\xf5es de par\xe2metros desenvolvido pela Black Forest Labs, utilizando t\xe9cnica de destila\xe7\xe3o de difus\xe3o adversarial latente, capaz de gerar imagens de alta qualidade em 1 a 4 passos. Seu desempenho \xe9 compar\xe1vel a alternativas propriet\xe1rias e \xe9 lan\xe7ado sob licen\xe7a Apache-2.0, adequado para uso pessoal, acad\xeamico e comercial."},"flux-dev":{"description":"FLUX.1 [dev] \xe9 um modelo open source refinado e com pesos voltado para aplica\xe7\xf5es n\xe3o comerciais. Mant\xe9m qualidade de imagem e capacidade de seguir instru\xe7\xf5es pr\xf3ximas \xe0 vers\xe3o profissional FLUX, com maior efici\xeancia operacional. Em compara\xe7\xe3o com modelos padr\xe3o de tamanho similar, \xe9 mais eficiente no uso de recursos."},"flux-kontext-max":{"description":"Gera\xe7\xe3o e edi\xe7\xe3o de imagens contextuais de ponta — combinando texto e imagens para obter resultados precisos e coerentes."},"flux-kontext-pro":{"description":"Gera\xe7\xe3o e edi\xe7\xe3o de imagens contextuais de ponta — combinando texto e imagens para obter resultados precisos e coerentes."},"flux-merged":{"description":"O modelo FLUX.1-merged combina as caracter\xedsticas profundas exploradas na fase de desenvolvimento \\"DEV\\" com as vantagens de execu\xe7\xe3o r\xe1pida representadas por \\"Schnell\\". Essa combina\xe7\xe3o n\xe3o s\xf3 eleva os limites de desempenho do modelo, como tamb\xe9m amplia seu campo de aplica\xe7\xe3o."},"flux-pro":{"description":"Modelo de gera\xe7\xe3o de imagens por IA de primeira linha para uso comercial — qualidade de imagem incompar\xe1vel e resultados altamente diversificados."},"flux-pro-1.1":{"description":"Modelo profissional aprimorado de gera\xe7\xe3o de imagens por IA — oferece qualidade de imagem excepcional e precis\xe3o no atendimento \xe0s instru\xe7\xf5es de prompt."},"flux-pro-1.1-ultra":{"description":"Gera\xe7\xe3o de imagens por IA em alt\xedssima resolu\xe7\xe3o — suporta sa\xedda de 4 megapixels e gera imagens em alta defini\xe7\xe3o em at\xe9 10 segundos."},"flux-schnell":{"description":"FLUX.1 [schnell] \xe9 atualmente o modelo open source mais avan\xe7ado de poucos passos, superando concorrentes e at\xe9 modelos n\xe3o destilados poderosos como Midjourney v6.0 e DALL\xb7E 3 (HD). Ajustado para preservar toda a diversidade de sa\xedda do pr\xe9-treinamento, oferece melhorias significativas em qualidade visual, conformidade com instru\xe7\xf5es, varia\xe7\xf5es de tamanho/propor\xe7\xe3o, tratamento de fontes e diversidade de sa\xedda, proporcionando uma experi\xeancia criativa mais rica e variada."},"flux.1-schnell":{"description":"FLUX.1-schnell, modelo de gera\xe7\xe3o de imagem de alto desempenho, ideal para cria\xe7\xe3o r\xe1pida de imagens em diversos estilos."},"gemini-1.0-pro-001":{"description":"Gemini 1.0 Pro 001 (Ajuste) oferece desempenho est\xe1vel e ajust\xe1vel, sendo a escolha ideal para solu\xe7\xf5es de tarefas complexas."},"gemini-1.0-pro-002":{"description":"Gemini 1.0 Pro 002 (Ajuste) oferece excelente suporte multimodal, focando na resolu\xe7\xe3o eficaz de tarefas complexas."},"gemini-1.0-pro-latest":{"description":"Gemini 1.0 Pro \xe9 o modelo de IA de alto desempenho do Google, projetado para expans\xe3o em uma ampla gama de tarefas."},"gemini-1.5-flash-001":{"description":"Gemini 1.5 Flash 001 \xe9 um modelo multimodal eficiente, suportando a expans\xe3o de aplica\xe7\xf5es amplas."},"gemini-1.5-flash-002":{"description":"O Gemini 1.5 Flash 002 \xe9 um modelo multimodal eficiente, que suporta uma ampla gama de aplica\xe7\xf5es."},"gemini-1.5-flash-8b":{"description":"O Gemini 1.5 Flash 8B \xe9 um modelo multimodal eficiente, com suporte para uma ampla gama de aplica\xe7\xf5es."},"gemini-1.5-flash-8b-exp-0924":{"description":"O Gemini 1.5 Flash 8B 0924 \xe9 o mais recente modelo experimental, com melhorias significativas de desempenho em casos de uso de texto e multim\xeddia."},"gemini-1.5-flash-8b-latest":{"description":"O Gemini 1.5 Flash 8B \xe9 um modelo multimodal eficiente que suporta uma ampla gama de aplica\xe7\xf5es em expans\xe3o."},"gemini-1.5-flash-exp-0827":{"description":"Gemini 1.5 Flash 0827 oferece capacidade de processamento multimodal otimizada, adequada para diversos cen\xe1rios de tarefas complexas."},"gemini-1.5-flash-latest":{"description":"Gemini 1.5 Flash \xe9 o mais recente modelo de IA multimodal do Google, com capacidade de processamento r\xe1pido, suportando entradas de texto, imagem e v\xeddeo, adequado para uma variedade de tarefas de expans\xe3o eficiente."},"gemini-1.5-pro-001":{"description":"Gemini 1.5 Pro 001 \xe9 uma solu\xe7\xe3o de IA multimodal escal\xe1vel, suportando uma ampla gama de tarefas complexas."},"gemini-1.5-pro-002":{"description":"O Gemini 1.5 Pro 002 \xe9 o mais recente modelo pronto para produ\xe7\xe3o, oferecendo sa\xeddas de maior qualidade, com melhorias significativas em tarefas matem\xe1ticas, contextos longos e tarefas visuais."},"gemini-1.5-pro-exp-0801":{"description":"Gemini 1.5 Pro 0801 oferece excelente capacidade de processamento multimodal, proporcionando maior flexibilidade para o desenvolvimento de aplica\xe7\xf5es."},"gemini-1.5-pro-exp-0827":{"description":"Gemini 1.5 Pro 0827 combina as mais recentes t\xe9cnicas de otimiza\xe7\xe3o, proporcionando uma capacidade de processamento de dados multimodal mais eficiente."},"gemini-1.5-pro-latest":{"description":"Gemini 1.5 Pro suporta at\xe9 2 milh\xf5es de tokens, sendo a escolha ideal para modelos multimodais de m\xe9dio porte, adequados para suporte multifacetado em tarefas complexas."},"gemini-2.0-flash":{"description":"Gemini 2.0 Flash oferece funcionalidades e melhorias de pr\xf3xima gera\xe7\xe3o, incluindo velocidade excepcional, uso nativo de ferramentas, gera\xe7\xe3o multimodal e uma janela de contexto de 1M tokens."},"gemini-2.0-flash-001":{"description":"Gemini 2.0 Flash oferece funcionalidades e melhorias de pr\xf3xima gera\xe7\xe3o, incluindo velocidade excepcional, uso nativo de ferramentas, gera\xe7\xe3o multimodal e uma janela de contexto de 1M tokens."},"gemini-2.0-flash-exp":{"description":"Variante do modelo Gemini 2.0 Flash, otimizada para custo-benef\xedcio e baixa lat\xeancia."},"gemini-2.0-flash-exp-image-generation":{"description":"Modelo experimental Gemini 2.0 Flash, suporta gera\xe7\xe3o de imagens"},"gemini-2.0-flash-lite":{"description":"Variante do modelo Gemini 2.0 Flash, otimizada para custo-benef\xedcio e baixa lat\xeancia."},"gemini-2.0-flash-lite-001":{"description":"Variante do modelo Gemini 2.0 Flash, otimizada para custo-benef\xedcio e baixa lat\xeancia."},"gemini-2.5-flash":{"description":"Gemini 2.5 Flash \xe9 o modelo com melhor custo-benef\xedcio do Google, oferecendo funcionalidades abrangentes."},"gemini-2.5-flash-image":{"description":"Nano Banana \xe9 o mais novo, r\xe1pido e eficiente modelo multimodal nativo do Google, que permite gerar e editar imagens por meio de conversas."},"gemini-2.5-flash-image-preview":{"description":"Nano Banana \xe9 o mais recente, r\xe1pido e eficiente modelo multimodal nativo do Google, que permite gerar e editar imagens por meio de conversas."},"gemini-2.5-flash-image-preview:image":{"description":"Nano Banana \xe9 o mais recente, r\xe1pido e eficiente modelo multimodal nativo do Google, que permite gerar e editar imagens por meio de conversas."},"gemini-2.5-flash-image:image":{"description":"Nano Banana \xe9 o mais novo, r\xe1pido e eficiente modelo multimodal nativo do Google, que permite gerar e editar imagens por meio de conversas."},"gemini-2.5-flash-lite":{"description":"Gemini 2.5 Flash-Lite \xe9 o modelo mais compacto e com melhor custo-benef\xedcio do Google, projetado para uso em larga escala."},"gemini-2.5-flash-lite-preview-06-17":{"description":"Gemini 2.5 Flash-Lite Preview \xe9 o modelo mais compacto e com melhor custo-benef\xedcio do Google, projetado para uso em larga escala."},"gemini-2.5-flash-lite-preview-09-2025":{"description":"Vers\xe3o pr\xe9via (25 de setembro de 2025) do Gemini 2.5 Flash-Lite"},"gemini-2.5-flash-preview-04-17":{"description":"O Gemini 2.5 Flash Preview \xe9 o modelo mais acess\xedvel do Google, oferecendo uma gama completa de funcionalidades."},"gemini-2.5-flash-preview-09-2025":{"description":"Vers\xe3o pr\xe9via (25 de setembro de 2025) do Gemini 2.5 Flash"},"gemini-2.5-pro":{"description":"Gemini 2.5 Pro \xe9 o modelo de pensamento mais avan\xe7ado do Google, capaz de raciocinar sobre c\xf3digo, matem\xe1tica e problemas complexos nas \xe1reas de STEM, al\xe9m de analisar grandes conjuntos de dados, bases de c\xf3digo e documentos usando contextos longos."},"gemini-2.5-pro-preview-03-25":{"description":"O Gemini 2.5 Pro Preview \xe9 o modelo de pensamento mais avan\xe7ado do Google, capaz de raciocinar sobre problemas complexos em c\xf3digo, matem\xe1tica e \xe1reas STEM, al\xe9m de analisar grandes conjuntos de dados, bibliotecas de c\xf3digo e documentos usando longos contextos."},"gemini-2.5-pro-preview-05-06":{"description":"O Gemini 2.5 Pro Preview \xe9 o modelo de pensamento mais avan\xe7ado do Google, capaz de raciocinar sobre problemas complexos em c\xf3digo, matem\xe1tica e \xe1reas STEM, al\xe9m de analisar grandes conjuntos de dados, bibliotecas de c\xf3digo e documentos usando longos contextos."},"gemini-2.5-pro-preview-06-05":{"description":"Gemini 2.5 Pro Preview \xe9 o modelo de pensamento mais avan\xe7ado do Google, capaz de raciocinar sobre problemas complexos em c\xf3digo, matem\xe1tica e \xe1reas STEM, al\xe9m de analisar grandes conjuntos de dados, bibliotecas de c\xf3digo e documentos usando contexto extenso."},"gemini-3-pro-preview":{"description":"O Gemini 3 Pro \xe9 o modelo mais inteligente do Google, com racioc\xednio de \xfaltima gera\xe7\xe3o, compreens\xe3o multimodal e poderosos recursos de agente e codifica\xe7\xe3o de contexto."},"gemini-flash-latest":{"description":"\xdaltima vers\xe3o do Gemini Flash"},"gemini-flash-lite-latest":{"description":"\xdaltima vers\xe3o do Gemini Flash-Lite"},"gemini-pro-latest":{"description":"\xdaltima vers\xe3o do Gemini Pro"},"gemma-7b-it":{"description":"Gemma 7B \xe9 adequado para o processamento de tarefas de pequeno a m\xe9dio porte, combinando custo e efici\xeancia."},"gemma2":{"description":"Gemma 2 \xe9 um modelo eficiente lan\xe7ado pelo Google, abrangendo uma variedade de cen\xe1rios de aplica\xe7\xe3o, desde aplica\xe7\xf5es pequenas at\xe9 processamento de dados complexos."},"gemma2-9b-it":{"description":"Gemma 2 9B \xe9 um modelo otimizado para integra\xe7\xe3o de tarefas e ferramentas espec\xedficas."},"gemma2:27b":{"description":"Gemma 2 \xe9 um modelo eficiente lan\xe7ado pelo Google, abrangendo uma variedade de cen\xe1rios de aplica\xe7\xe3o, desde aplica\xe7\xf5es pequenas at\xe9 processamento de dados complexos."},"gemma2:2b":{"description":"Gemma 2 \xe9 um modelo eficiente lan\xe7ado pelo Google, abrangendo uma variedade de cen\xe1rios de aplica\xe7\xe3o, desde aplica\xe7\xf5es pequenas at\xe9 processamento de dados complexos."},"generalv3":{"description":"Spark Pro \xe9 um modelo de linguagem de alto desempenho otimizado para \xe1reas profissionais, focando em matem\xe1tica, programa\xe7\xe3o, medicina, educa\xe7\xe3o e outros campos, e suportando busca online e plugins integrados como clima e data. Seu modelo otimizado apresenta desempenho excepcional e efici\xeancia em perguntas e respostas complexas, compreens\xe3o de linguagem e cria\xe7\xe3o de texto de alto n\xedvel, sendo a escolha ideal para cen\xe1rios de aplica\xe7\xe3o profissional."},"generalv3.5":{"description":"Spark3.5 Max \xe9 a vers\xe3o mais completa, suportando busca online e muitos plugins integrados. Suas capacidades centrais totalmente otimizadas, juntamente com a defini\xe7\xe3o de pap\xe9is do sistema e a funcionalidade de chamada de fun\xe7\xf5es, fazem com que seu desempenho em v\xe1rios cen\xe1rios de aplica\xe7\xe3o complexos seja extremamente excepcional."},"glm-4":{"description":"O GLM-4 \xe9 a vers\xe3o antiga lan\xe7ada em janeiro de 2024, atualmente substitu\xedda pelo mais poderoso GLM-4-0520."},"glm-4-0520":{"description":"O GLM-4-0520 \xe9 a vers\xe3o mais recente do modelo, projetada para tarefas altamente complexas e diversificadas, com desempenho excepcional."},"glm-4-32b-0414":{"description":"GLM-4 32B 0414, vers\xe3o do modelo universal da s\xe9rie GLM, com suporte para gera\xe7\xe3o e compreens\xe3o de texto em m\xfaltiplas tarefas."},"glm-4-9b-chat":{"description":"GLM-4-9B-Chat apresenta alto desempenho em sem\xe2ntica, matem\xe1tica, racioc\xednio, programa\xe7\xe3o e conhecimento. Tamb\xe9m oferece suporte a navega\xe7\xe3o na web, execu\xe7\xe3o de c\xf3digo, uso de ferramentas personalizadas e racioc\xednio com textos longos. Suporta 26 idiomas, incluindo japon\xeas, coreano e alem\xe3o."},"glm-4-air":{"description":"O GLM-4-Air \xe9 uma vers\xe3o econ\xf4mica, com desempenho pr\xf3ximo ao GLM-4, oferecendo alta velocidade a um pre\xe7o acess\xedvel."},"glm-4-air-250414":{"description":"GLM-4-Air \xe9 uma vers\xe3o de bom custo-benef\xedcio, com desempenho pr\xf3ximo ao GLM-4, oferecendo alta velocidade a um pre\xe7o acess\xedvel."},"glm-4-airx":{"description":"O GLM-4-AirX oferece uma vers\xe3o eficiente do GLM-4-Air, com velocidade de infer\xeancia at\xe9 2,6 vezes mais r\xe1pida."},"glm-4-alltools":{"description":"O GLM-4-AllTools \xe9 um modelo de agente multifuncional, otimizado para suportar planejamento de instru\xe7\xf5es complexas e chamadas de ferramentas, como navega\xe7\xe3o na web, interpreta\xe7\xe3o de c\xf3digo e gera\xe7\xe3o de texto, adequado para execu\xe7\xe3o de m\xfaltiplas tarefas."},"glm-4-flash":{"description":"O GLM-4-Flash \xe9 a escolha ideal para tarefas simples, com a maior velocidade e o pre\xe7o mais acess\xedvel."},"glm-4-flash-250414":{"description":"GLM-4-Flash \xe9 a escolha ideal para tarefas simples, sendo a mais r\xe1pida e gratuita."},"glm-4-flashx":{"description":"GLM-4-FlashX \xe9 uma vers\xe3o aprimorada do Flash, com velocidade de infer\xeancia super r\xe1pida."},"glm-4-long":{"description":"O GLM-4-Long suporta entradas de texto superlongas, adequado para tarefas de mem\xf3ria e processamento de documentos em larga escala."},"glm-4-plus":{"description":"O GLM-4-Plus, como um modelo de alta intelig\xeancia, possui uma forte capacidade de lidar com textos longos e tarefas complexas, com desempenho amplamente aprimorado."},"glm-4.1v-thinking-flash":{"description":"A s\xe9rie GLM-4.1V-Thinking \xe9 atualmente o modelo visual mais potente conhecido na categoria de VLMs de 10 bilh\xf5es de par\xe2metros, integrando tarefas de linguagem visual de ponta no mesmo n\xedvel, incluindo compreens\xe3o de v\xeddeo, perguntas e respostas sobre imagens, resolu\xe7\xe3o de problemas acad\xeamicos, reconhecimento \xf3ptico de caracteres (OCR), interpreta\xe7\xe3o de documentos e gr\xe1ficos, agentes GUI, codifica\xe7\xe3o front-end para web, grounding, entre outros. Suas capacidades em v\xe1rias tarefas superam at\xe9 modelos com 8 vezes mais par\xe2metros, como o Qwen2.5-VL-72B. Por meio de t\xe9cnicas avan\xe7adas de aprendizado por refor\xe7o, o modelo domina o racioc\xednio em cadeia para melhorar a precis\xe3o e riqueza das respostas, superando significativamente modelos tradicionais sem o mecanismo thinking em termos de resultados finais e interpretabilidade."},"glm-4.1v-thinking-flashx":{"description":"A s\xe9rie GLM-4.1V-Thinking \xe9 atualmente o modelo visual mais potente conhecido na categoria de VLMs de 10 bilh\xf5es de par\xe2metros, integrando tarefas de linguagem visual de ponta no mesmo n\xedvel, incluindo compreens\xe3o de v\xeddeo, perguntas e respostas sobre imagens, resolu\xe7\xe3o de problemas acad\xeamicos, reconhecimento \xf3ptico de caracteres (OCR), interpreta\xe7\xe3o de documentos e gr\xe1ficos, agentes GUI, codifica\xe7\xe3o front-end para web, grounding, entre outros. Suas capacidades em v\xe1rias tarefas superam at\xe9 modelos com 8 vezes mais par\xe2metros, como o Qwen2.5-VL-72B. Por meio de t\xe9cnicas avan\xe7adas de aprendizado por refor\xe7o, o modelo domina o racioc\xednio em cadeia para melhorar a precis\xe3o e riqueza das respostas, superando significativamente modelos tradicionais sem o mecanismo thinking em termos de resultados finais e interpretabilidade."},"glm-4.5":{"description":"Modelo principal da Zhipu, suporta altern\xe2ncia de modos de racioc\xednio, com capacidade abrangente alcan\xe7ando o n\xedvel SOTA dos modelos open source, e comprimento de contexto de at\xe9 128K."},"glm-4.5-air":{"description":"Vers\xe3o leve do GLM-4.5, equilibrando desempenho e custo-benef\xedcio, com capacidade flex\xedvel de alternar entre modos h\xedbridos de pensamento."},"glm-4.5-airx":{"description":"Vers\xe3o ultrarr\xe1pida do GLM-4.5-Air, com resposta mais r\xe1pida, projetada para demandas de alta velocidade e grande escala."},"glm-4.5-flash":{"description":"Vers\xe3o gratuita do GLM-4.5, com desempenho destacado em infer\xeancia, codifica\xe7\xe3o e agentes inteligentes."},"glm-4.5-x":{"description":"Vers\xe3o ultrarr\xe1pida do GLM-4.5, combinando alto desempenho com velocidade de gera\xe7\xe3o de at\xe9 100 tokens por segundo."},"glm-4.5v":{"description":"A nova gera\xe7\xe3o do modelo de racioc\xednio visual da Zhipu, baseada na arquitetura MOE, com 106B de par\xe2metros totais e 12B de par\xe2metros de ativa\xe7\xe3o, alcan\xe7a o estado da arte (SOTA) entre modelos multimodais de c\xf3digo aberto de n\xedvel semelhante em diversos benchmarks, abrangendo tarefas comuns como compreens\xe3o de imagens, v\xeddeos, documentos e de interfaces gr\xe1ficas (GUI)."},"glm-4.6":{"description":"O mais recente modelo principal da Zhipu, GLM-4.6 (355B), supera amplamente a gera\xe7\xe3o anterior em codifica\xe7\xe3o avan\xe7ada, processamento de textos longos, infer\xeancia e capacidades de agentes inteligentes, especialmente alinhado com Claude Sonnet 4 em habilidades de programa\xe7\xe3o, tornando-se o modelo de codifica\xe7\xe3o de ponta nacional."},"glm-4v":{"description":"O GLM-4V oferece uma forte capacidade de compreens\xe3o e racioc\xednio de imagens, suportando v\xe1rias tarefas visuais."},"glm-4v-flash":{"description":"GLM-4V-Flash \xe9 focado na compreens\xe3o eficiente de uma \xfanica imagem, adequado para cen\xe1rios de an\xe1lise de imagem r\xe1pida, como an\xe1lise de imagem em tempo real ou processamento em lote de imagens."},"glm-4v-plus":{"description":"O GLM-4V-Plus possui a capacidade de entender conte\xfado de v\xeddeo e m\xfaltiplas imagens, adequado para tarefas multimodais."},"glm-4v-plus-0111":{"description":"GLM-4V-Plus possui capacidade de compreens\xe3o de conte\xfado de v\xeddeo e m\xfaltiplas imagens, adequado para tarefas multimodais."},"glm-z1-air":{"description":"Modelo de infer\xeancia: possui forte capacidade de infer\xeancia, adequado para tarefas que exigem racioc\xednio profundo."},"glm-z1-airx":{"description":"Infer\xeancia ultrarr\xe1pida: com velocidade de infer\xeancia super r\xe1pida e forte efeito de racioc\xednio."},"glm-z1-flash":{"description":"S\xe9rie GLM-Z1 com forte capacidade de racioc\xednio complexo, destacando-se em l\xf3gica, matem\xe1tica e programa\xe7\xe3o."},"glm-z1-flashx":{"description":"Alta velocidade e baixo custo: vers\xe3o aprimorada Flash, com infer\xeancia ultrarr\xe1pida e garantia de concorr\xeancia mais r\xe1pida."},"glm-zero-preview":{"description":"O GLM-Zero-Preview possui uma poderosa capacidade de racioc\xednio complexo, destacando-se em \xe1reas como racioc\xednio l\xf3gico, matem\xe1tica e programa\xe7\xe3o."},"google/gemini-2.0-flash":{"description":"Gemini 2.0 Flash oferece funcionalidades de pr\xf3xima gera\xe7\xe3o e melhorias, incluindo velocidade excepcional, uso integrado de ferramentas, gera\xe7\xe3o multimodal e janela de contexto de 1 milh\xe3o de tokens."},"google/gemini-2.0-flash-001":{"description":"Gemini 2.0 Flash oferece funcionalidades e melhorias de pr\xf3xima gera\xe7\xe3o, incluindo velocidade excepcional, uso nativo de ferramentas, gera\xe7\xe3o multimodal e uma janela de contexto de 1M tokens."},"google/gemini-2.0-flash-exp:free":{"description":"O Gemini 2.0 Flash Experimental \xe9 o mais recente modelo de IA multimodal experimental do Google, com melhorias de qualidade em compara\xe7\xe3o com vers\xf5es anteriores, especialmente em conhecimento do mundo, c\xf3digo e longos contextos."},"google/gemini-2.0-flash-lite":{"description":"Gemini 2.0 Flash Lite oferece funcionalidades de pr\xf3xima gera\xe7\xe3o e melhorias, incluindo velocidade excepcional, uso integrado de ferramentas, gera\xe7\xe3o multimodal e janela de contexto de 1 milh\xe3o de tokens."},"google/gemini-2.5-flash":{"description":"Gemini 2.5 Flash \xe9 um modelo de racioc\xednio que oferece capacidades abrangentes excepcionais. Projetado para equilibrar pre\xe7o e desempenho, suporta multimodalidade e janela de contexto de 1 milh\xe3o de tokens."},"google/gemini-2.5-flash-image-preview":{"description":"Modelo experimental Gemini 2.5 Flash, com suporte para gera\xe7\xe3o de imagens."},"google/gemini-2.5-flash-lite":{"description":"Gemini 2.5 Flash-Lite \xe9 um modelo equilibrado e de baixa lat\xeancia, com or\xe7amento de racioc\xednio configur\xe1vel e conectividade de ferramentas (por exemplo, pesquisa Google fundamentada e execu\xe7\xe3o de c\xf3digo). Suporta entrada multimodal e oferece janela de contexto de 1 milh\xe3o de tokens."},"google/gemini-2.5-flash-preview":{"description":"O Gemini 2.5 Flash \xe9 o modelo principal mais avan\xe7ado do Google, projetado para racioc\xednio avan\xe7ado, codifica\xe7\xe3o, matem\xe1tica e tarefas cient\xedficas. Ele possui a capacidade de \'pensar\' embutida, permitindo que forne\xe7a respostas com maior precis\xe3o e um tratamento de contexto mais detalhado.\\n\\nNota: Este modelo possui duas variantes: com e sem \'pensamento\'. A precifica\xe7\xe3o da sa\xedda varia significativamente dependendo da ativa\xe7\xe3o da capacidade de pensamento. Se voc\xea escolher a variante padr\xe3o (sem o sufixo \':thinking\'), o modelo evitar\xe1 explicitamente gerar tokens de pensamento.\\n\\nPara aproveitar a capacidade de pensamento e receber tokens de pensamento, voc\xea deve escolher a variante \':thinking\', que resultar\xe1 em uma precifica\xe7\xe3o de sa\xedda de pensamento mais alta.\\n\\nAl\xe9m disso, o Gemini 2.5 Flash pode ser configurado atrav\xe9s do par\xe2metro \'n\xfamero m\xe1ximo de tokens para racioc\xednio\', conforme descrito na documenta\xe7\xe3o (https://openrouter.ai/docs/use-cases/reasoning-tokens#max-tokens-for-reasoning)."},"google/gemini-2.5-flash-preview:thinking":{"description":"O Gemini 2.5 Flash \xe9 o modelo principal mais avan\xe7ado do Google, projetado para racioc\xednio avan\xe7ado, codifica\xe7\xe3o, matem\xe1tica e tarefas cient\xedficas. Ele possui a capacidade de \'pensar\' embutida, permitindo que forne\xe7a respostas com maior precis\xe3o e um tratamento de contexto mais detalhado.\\n\\nNota: Este modelo possui duas variantes: com e sem \'pensamento\'. A precifica\xe7\xe3o da sa\xedda varia significativamente dependendo da ativa\xe7\xe3o da capacidade de pensamento. Se voc\xea escolher a variante padr\xe3o (sem o sufixo \':thinking\'), o modelo evitar\xe1 explicitamente gerar tokens de pensamento.\\n\\nPara aproveitar a capacidade de pensamento e receber tokens de pensamento, voc\xea deve escolher a variante \':thinking\', que resultar\xe1 em uma precifica\xe7\xe3o de sa\xedda de pensamento mais alta.\\n\\nAl\xe9m disso, o Gemini 2.5 Flash pode ser configurado atrav\xe9s do par\xe2metro \'n\xfamero m\xe1ximo de tokens para racioc\xednio\', conforme descrito na documenta\xe7\xe3o (https://openrouter.ai/docs/use-cases/reasoning-tokens#max-tokens-for-reasoning)."},"google/gemini-2.5-pro":{"description":"Gemini 2.5 Pro \xe9 nosso modelo Gemini de racioc\xednio mais avan\xe7ado, capaz de resolver problemas complexos. Possui janela de contexto de 2 milh\xf5es de tokens e suporta entrada multimodal, incluindo texto, imagem, \xe1udio, v\xeddeo e documentos PDF."},"google/gemini-2.5-pro-preview":{"description":"Gemini 2.5 Pro Preview \xe9 o modelo de pensamento mais avan\xe7ado do Google, capaz de raciocinar sobre problemas complexos em c\xf3digo, matem\xe1tica e \xe1reas STEM, al\xe9m de analisar grandes conjuntos de dados, bases de c\xf3digo e documentos usando contexto extenso."},"google/gemini-embedding-001":{"description":"Modelo de embeddings de \xfaltima gera\xe7\xe3o com desempenho excelente em tarefas de ingl\xeas, multil\xedngue e c\xf3digo."},"google/gemini-flash-1.5":{"description":"Gemini 1.5 Flash oferece capacidades de processamento multimodal otimizadas, adequadas para uma variedade de cen\xe1rios de tarefas complexas."},"google/gemini-pro-1.5":{"description":"Gemini 1.5 Pro combina as mais recentes tecnologias de otimiza\xe7\xe3o, proporcionando uma capacidade de processamento de dados multimodais mais eficiente."},"google/gemma-2-27b":{"description":"Gemma 2 \xe9 um modelo eficiente lan\xe7ado pelo Google, abrangendo uma variedade de cen\xe1rios de aplica\xe7\xe3o, desde pequenos aplicativos at\xe9 processamento de dados complexos."},"google/gemma-2-27b-it":{"description":"Gemma 2 continua a filosofia de design leve e eficiente."},"google/gemma-2-2b-it":{"description":"Modelo leve de ajuste de instru\xe7\xf5es do Google."},"google/gemma-2-9b":{"description":"Gemma 2 \xe9 um modelo eficiente lan\xe7ado pelo Google, abrangendo uma variedade de cen\xe1rios de aplica\xe7\xe3o, desde pequenos aplicativos at\xe9 processamento de dados complexos."},"google/gemma-2-9b-it":{"description":"Gemma 2 \xe9 uma s\xe9rie de modelos de texto de c\xf3digo aberto leve da Google."},"google/gemma-2-9b-it:free":{"description":"Gemma 2 \xe9 uma s\xe9rie de modelos de texto de c\xf3digo aberto leve da Google."},"google/gemma-2b-it":{"description":"Gemma Instruct (2B) oferece capacidade b\xe1sica de processamento de instru\xe7\xf5es, adequada para aplica\xe7\xf5es leves."},"google/gemma-3-12b-it":{"description":"Gemma 3 12B \xe9 um modelo de linguagem open source do Google que estabelece novos padr\xf5es em efici\xeancia e desempenho."},"google/gemma-3-27b-it":{"description":"Gemma 3 27B \xe9 um modelo de linguagem de c\xf3digo aberto do Google, que estabelece novos padr\xf5es em efici\xeancia e desempenho."},"google/text-embedding-005":{"description":"Modelo de embeddings de texto focado em ingl\xeas, otimizado para tarefas de c\xf3digo e linguagem inglesa."},"google/text-multilingual-embedding-002":{"description":"Modelo de embeddings de texto multil\xedngue otimizado para tarefas cross-lingu\xedsticas, suportando m\xfaltiplos idiomas."},"gpt-3.5-turbo":{"description":"O GPT 3.5 Turbo \xe9 adequado para uma variedade de tarefas de gera\xe7\xe3o e compreens\xe3o de texto, atualmente apontando para gpt-3.5-turbo-0125."},"gpt-3.5-turbo-0125":{"description":"O GPT 3.5 Turbo \xe9 adequado para uma variedade de tarefas de gera\xe7\xe3o e compreens\xe3o de texto, atualmente apontando para gpt-3.5-turbo-0125."},"gpt-3.5-turbo-1106":{"description":"O GPT 3.5 Turbo \xe9 adequado para uma variedade de tarefas de gera\xe7\xe3o e compreens\xe3o de texto, atualmente apontando para gpt-3.5-turbo-0125."},"gpt-3.5-turbo-instruct":{"description":"O GPT 3.5 Turbo \xe9 adequado para uma variedade de tarefas de gera\xe7\xe3o e compreens\xe3o de texto, atualmente apontando para gpt-3.5-turbo-0125."},"gpt-35-turbo":{"description":"GPT 3.5 Turbo, um modelo eficiente fornecido pela OpenAI, adequado para tarefas de chat e gera\xe7\xe3o de texto, suportando chamadas de fun\xe7\xe3o paralelas."},"gpt-35-turbo-16k":{"description":"GPT 3.5 Turbo 16k, um modelo de gera\xe7\xe3o de texto de alta capacidade, adequado para tarefas complexas."},"gpt-4":{"description":"O GPT-4 oferece uma janela de contexto maior, capaz de lidar com entradas de texto mais longas, adequado para cen\xe1rios que exigem integra\xe7\xe3o ampla de informa\xe7\xf5es e an\xe1lise de dados."},"gpt-4-0125-preview":{"description":"O mais recente modelo GPT-4 Turbo possui funcionalidades visuais. Agora, solicita\xe7\xf5es visuais podem ser feitas usando o modo JSON e chamadas de fun\xe7\xe3o. O GPT-4 Turbo \xe9 uma vers\xe3o aprimorada, oferecendo suporte econ\xf4mico para tarefas multimodais. Ele encontra um equil\xedbrio entre precis\xe3o e efici\xeancia, adequado para aplica\xe7\xf5es que requerem intera\xe7\xe3o em tempo real."},"gpt-4-0613":{"description":"O GPT-4 oferece uma janela de contexto maior, capaz de lidar com entradas de texto mais longas, adequado para cen\xe1rios que exigem integra\xe7\xe3o ampla de informa\xe7\xf5es e an\xe1lise de dados."},"gpt-4-1106-preview":{"description":"O mais recente modelo GPT-4 Turbo possui funcionalidades visuais. Agora, solicita\xe7\xf5es visuais podem ser feitas usando o modo JSON e chamadas de fun\xe7\xe3o. O GPT-4 Turbo \xe9 uma vers\xe3o aprimorada, oferecendo suporte econ\xf4mico para tarefas multimodais. Ele encontra um equil\xedbrio entre precis\xe3o e efici\xeancia, adequado para aplica\xe7\xf5es que requerem intera\xe7\xe3o em tempo real."},"gpt-4-32k":{"description":"O GPT-4 oferece uma janela de contexto maior, capaz de lidar com entradas de texto mais longas, adequado para cen\xe1rios que exigem integra\xe7\xe3o ampla de informa\xe7\xf5es e an\xe1lise de dados."},"gpt-4-32k-0613":{"description":"O GPT-4 oferece uma janela de contexto maior, capaz de lidar com entradas de texto mais longas, adequado para cen\xe1rios que exigem integra\xe7\xe3o ampla de informa\xe7\xf5es e an\xe1lise de dados."},"gpt-4-turbo":{"description":"O mais recente modelo GPT-4 Turbo possui funcionalidades visuais. Agora, solicita\xe7\xf5es visuais podem ser feitas usando o modo JSON e chamadas de fun\xe7\xe3o. O GPT-4 Turbo \xe9 uma vers\xe3o aprimorada, oferecendo suporte econ\xf4mico para tarefas multimodais. Ele encontra um equil\xedbrio entre precis\xe3o e efici\xeancia, adequado para aplica\xe7\xf5es que requerem intera\xe7\xe3o em tempo real."},"gpt-4-turbo-2024-04-09":{"description":"O mais recente modelo GPT-4 Turbo possui funcionalidades visuais. Agora, solicita\xe7\xf5es visuais podem ser feitas usando o modo JSON e chamadas de fun\xe7\xe3o. O GPT-4 Turbo \xe9 uma vers\xe3o aprimorada, oferecendo suporte econ\xf4mico para tarefas multimodais. Ele encontra um equil\xedbrio entre precis\xe3o e efici\xeancia, adequado para aplica\xe7\xf5es que requerem intera\xe7\xe3o em tempo real."},"gpt-4-turbo-preview":{"description":"O mais recente modelo GPT-4 Turbo possui funcionalidades visuais. Agora, solicita\xe7\xf5es visuais podem ser feitas usando o modo JSON e chamadas de fun\xe7\xe3o. O GPT-4 Turbo \xe9 uma vers\xe3o aprimorada, oferecendo suporte econ\xf4mico para tarefas multimodais. Ele encontra um equil\xedbrio entre precis\xe3o e efici\xeancia, adequado para aplica\xe7\xf5es que requerem intera\xe7\xe3o em tempo real."},"gpt-4-vision-preview":{"description":"O mais recente modelo GPT-4 Turbo possui funcionalidades visuais. Agora, solicita\xe7\xf5es visuais podem ser feitas usando o modo JSON e chamadas de fun\xe7\xe3o. O GPT-4 Turbo \xe9 uma vers\xe3o aprimorada, oferecendo suporte econ\xf4mico para tarefas multimodais. Ele encontra um equil\xedbrio entre precis\xe3o e efici\xeancia, adequado para aplica\xe7\xf5es que requerem intera\xe7\xe3o em tempo real."},"gpt-4.1":{"description":"GPT-4.1 \xe9 nosso modelo principal para tarefas complexas. Ele \xe9 muito adequado para resolver problemas interdisciplinares."},"gpt-4.1-mini":{"description":"GPT-4.1 mini oferece um equil\xedbrio entre intelig\xeancia, velocidade e custo, tornando-se um modelo atraente para muitos casos de uso."},"gpt-4.1-nano":{"description":"GPT-4.1 mini oferece um equil\xedbrio entre intelig\xeancia, velocidade e custo, tornando-se um modelo atraente para muitos casos de uso."},"gpt-4.5-preview":{"description":"GPT-4.5-preview \xe9 o modelo de uso geral mais recente, com amplo conhecimento do mundo e uma compreens\xe3o aprimorada das inten\xe7\xf5es dos usu\xe1rios, sendo proficiente em tarefas criativas e no planejamento de agentes. A data de corte do conhecimento deste modelo \xe9 outubro de 2023."},"gpt-4o":{"description":"O ChatGPT-4o \xe9 um modelo din\xe2mico, atualizado em tempo real para manter a vers\xe3o mais atual. Ele combina uma poderosa capacidade de compreens\xe3o e gera\xe7\xe3o de linguagem, adequado para cen\xe1rios de aplica\xe7\xe3o em larga escala, incluindo atendimento ao cliente, educa\xe7\xe3o e suporte t\xe9cnico."},"gpt-4o-2024-05-13":{"description":"O ChatGPT-4o \xe9 um modelo din\xe2mico, atualizado em tempo real para manter a vers\xe3o mais atual. Ele combina uma poderosa capacidade de compreens\xe3o e gera\xe7\xe3o de linguagem, adequado para cen\xe1rios de aplica\xe7\xe3o em larga escala, incluindo atendimento ao cliente, educa\xe7\xe3o e suporte t\xe9cnico."},"gpt-4o-2024-08-06":{"description":"O ChatGPT-4o \xe9 um modelo din\xe2mico, atualizado em tempo real para manter a vers\xe3o mais atual. Ele combina uma poderosa capacidade de compreens\xe3o e gera\xe7\xe3o de linguagem, adequado para cen\xe1rios de aplica\xe7\xe3o em larga escala, incluindo atendimento ao cliente, educa\xe7\xe3o e suporte t\xe9cnico."},"gpt-4o-2024-11-20":{"description":"ChatGPT-4o \xe9 um modelo din\xe2mico, atualizado em tempo real para manter a vers\xe3o mais atualizada. Combina uma poderosa compreens\xe3o e capacidade de gera\xe7\xe3o de linguagem, adequado para cen\xe1rios de aplica\xe7\xe3o em larga escala, incluindo atendimento ao cliente, educa\xe7\xe3o e suporte t\xe9cnico."},"gpt-4o-audio-preview":{"description":"Modelo GPT-4o Audio Preview, com suporte para entrada e sa\xedda de \xe1udio."},"gpt-4o-mini":{"description":"O GPT-4o mini \xe9 o mais recente modelo lan\xe7ado pela OpenAI ap\xf3s o GPT-4 Omni, suportando entrada de texto e imagem e gerando texto como sa\xedda. Como seu modelo compacto mais avan\xe7ado, ele \xe9 muito mais acess\xedvel do que outros modelos de ponta recentes, custando mais de 60% menos que o GPT-3.5 Turbo. Ele mant\xe9m uma intelig\xeancia de ponta, ao mesmo tempo que oferece um custo-benef\xedcio significativo. O GPT-4o mini obteve uma pontua\xe7\xe3o de 82% no teste MMLU e atualmente est\xe1 classificado acima do GPT-4 em prefer\xeancias de chat."},"gpt-4o-mini-audio-preview":{"description":"Modelo GPT-4o mini Audio, suporta entrada e sa\xedda de \xe1udio."},"gpt-4o-mini-realtime-preview":{"description":"Vers\xe3o em tempo real do GPT-4o-mini, suporta entrada e sa\xedda de \xe1udio e texto em tempo real."},"gpt-4o-mini-search-preview":{"description":"A vers\xe3o pr\xe9via do GPT-4o mini para busca \xe9 um modelo treinado especificamente para compreender e executar consultas de busca na web, utilizando a API Chat Completions. Al\xe9m dos custos por token, as consultas de busca na web s\xe3o cobradas por chamada da ferramenta."},"gpt-4o-mini-transcribe":{"description":"GPT-4o Mini Transcribe \xe9 um modelo de transcri\xe7\xe3o de \xe1udio para texto que utiliza GPT-4o. Em compara\xe7\xe3o com o modelo Whisper original, melhora a taxa de erro de palavras, al\xe9m do reconhecimento e precis\xe3o lingu\xedstica. Use-o para obter transcri\xe7\xf5es mais precisas."},"gpt-4o-mini-tts":{"description":"GPT-4o mini TTS \xe9 um modelo de texto para fala baseado em GPT-4o mini, oferecendo uma gera\xe7\xe3o de voz de alta qualidade a um custo mais baixo."},"gpt-4o-realtime-preview":{"description":"Vers\xe3o em tempo real do GPT-4o, suporta entrada e sa\xedda de \xe1udio e texto em tempo real."},"gpt-4o-realtime-preview-2024-10-01":{"description":"Vers\xe3o em tempo real do GPT-4o, suporta entrada e sa\xedda de \xe1udio e texto em tempo real."},"gpt-4o-realtime-preview-2025-06-03":{"description":"Vers\xe3o em tempo real do GPT-4o, suportando entrada e sa\xedda de \xe1udio e texto em tempo real."},"gpt-4o-search-preview":{"description":"A vers\xe3o pr\xe9via do GPT-4o para busca \xe9 um modelo treinado especificamente para compreender e executar consultas de busca na web, utilizando a API Chat Completions. Al\xe9m dos custos por token, as consultas de busca na web s\xe3o cobradas por chamada da ferramenta."},"gpt-4o-transcribe":{"description":"GPT-4o Transcribe \xe9 um modelo de transcri\xe7\xe3o de \xe1udio para texto que utiliza GPT-4o. Em compara\xe7\xe3o com o modelo Whisper original, melhora a taxa de erro de palavras, al\xe9m do reconhecimento e precis\xe3o lingu\xedstica. Use-o para obter transcri\xe7\xf5es mais precisas."},"gpt-5":{"description":"O melhor modelo para tarefas de codifica\xe7\xe3o e agentes interdisciplinares. GPT-5 alcan\xe7a avan\xe7os em precis\xe3o, velocidade, racioc\xednio, reconhecimento de contexto, pensamento estruturado e resolu\xe7\xe3o de problemas."},"gpt-5-chat":{"description":"GPT-5 Chat \xe9 uma vers\xe3o pr\xe9via otimizada para cen\xe1rios de conversa\xe7\xe3o. Suporta entrada de texto e imagem, com sa\xedda apenas em texto, ideal para chatbots e aplica\xe7\xf5es de IA conversacional."},"gpt-5-chat-latest":{"description":"Modelo GPT-5 usado no ChatGPT. Combina forte compreens\xe3o e gera\xe7\xe3o de linguagem, ideal para aplica\xe7\xf5es de intera\xe7\xe3o conversacional."},"gpt-5-codex":{"description":"GPT-5 Codex \xe9 uma vers\xe3o do GPT-5 otimizada para tarefas de codifica\xe7\xe3o de agentes em ambientes Codex ou similares."},"gpt-5-mini":{"description":"Vers\xe3o mais r\xe1pida e econ\xf4mica do GPT-5, adequada para tarefas bem definidas. Oferece respostas mais r\xe1pidas mantendo alta qualidade de sa\xedda."},"gpt-5-nano":{"description":"Vers\xe3o mais r\xe1pida e econ\xf4mica do GPT-5. Muito adequada para cen\xe1rios que exigem respostas r\xe1pidas e sensibilidade a custos."},"gpt-5-pro":{"description":"O GPT-5 Pro utiliza mais poder computacional para pensar de forma mais profunda e fornecer respostas consistentemente melhores."},"gpt-5.1":{"description":"GPT-5.1 — Modelo principal otimizado para tarefas de codifica\xe7\xe3o e agentes, com suporte para intensidade de infer\xeancia configur\xe1vel e contexto mais longo."},"gpt-5.1-chat-latest":{"description":"GPT-5.1 Chat: Variante do GPT-5.1 para o ChatGPT, ideal para cen\xe1rios de conversa."},"gpt-5.1-codex":{"description":"GPT-5.1 Codex: Vers\xe3o do GPT-5.1 otimizada para tarefas de codifica\xe7\xe3o com agentes, utiliz\xe1vel na API de Respostas para fluxos de trabalho mais complexos envolvendo c\xf3digo e agentes."},"gpt-5.1-codex-mini":{"description":"GPT-5.1 Codex mini: Variante do Codex com menor tamanho e custo reduzido, otimizada para tarefas de codifica\xe7\xe3o com agentes."},"gpt-audio":{"description":"GPT Audio \xe9 um modelo de chat universal voltado para entrada e sa\xedda de \xe1udio, suportando uso de \xe1udio I/O na API de Chat Completions."},"gpt-image-1":{"description":"Modelo nativo multimodal de gera\xe7\xe3o de imagens do ChatGPT"},"gpt-image-1-mini":{"description":"Uma vers\xe3o mais econ\xf4mica do GPT Image 1, com suporte nativo para entrada de texto e imagem, al\xe9m de gera\xe7\xe3o de sa\xedda em imagem."},"gpt-oss-120b":{"description":"Este modelo requer solicita\xe7\xe3o para uso. GPT-OSS-120B \xe9 um modelo de linguagem de c\xf3digo aberto em larga escala lan\xe7ado pela OpenAI, com poderosa capacidade de gera\xe7\xe3o de texto."},"gpt-oss-20b":{"description":"Este modelo requer solicita\xe7\xe3o para uso. GPT-OSS-20B \xe9 um modelo de linguagem de c\xf3digo aberto de porte m\xe9dio lan\xe7ado pela OpenAI, com gera\xe7\xe3o de texto eficiente."},"gpt-oss:120b":{"description":"GPT-OSS 120B \xe9 um modelo de linguagem grande de c\xf3digo aberto lan\xe7ado pela OpenAI, utilizando a tecnologia de quantiza\xe7\xe3o MXFP4, sendo um modelo de ponta. Requer m\xfaltiplas GPUs ou esta\xe7\xf5es de trabalho de alto desempenho para execu\xe7\xe3o, oferecendo desempenho excepcional em racioc\xednio complexo, gera\xe7\xe3o de c\xf3digo e processamento multil\xedngue, com suporte a chamadas avan\xe7adas de fun\xe7\xf5es e integra\xe7\xe3o de ferramentas."},"gpt-oss:20b":{"description":"GPT-OSS 20B \xe9 um modelo de linguagem grande open source lan\xe7ado pela OpenAI, utilizando quantiza\xe7\xe3o MXFP4, adequado para execu\xe7\xe3o em GPUs de consumo avan\xe7ado ou Macs com Apple Silicon. O modelo apresenta excelente desempenho em gera\xe7\xe3o de di\xe1logo, codifica\xe7\xe3o e tarefas de infer\xeancia, suportando chamadas de fun\xe7\xe3o e uso de ferramentas."},"gpt-realtime":{"description":"Modelo universal em tempo real, suportando entrada e sa\xedda de texto e \xe1udio, al\xe9m de entrada de imagem."},"grok-2-image-1212":{"description":"Nosso mais recente modelo de gera\xe7\xe3o de imagens pode criar imagens v\xedvidas e realistas a partir de prompts textuais. Apresenta excelente desempenho em marketing, m\xeddias sociais e entretenimento."},"grok-2-vision-1212":{"description":"Este modelo apresenta melhorias em precis\xe3o, conformidade com instru\xe7\xf5es e capacidade multil\xedngue."},"grok-3":{"description":"Modelo de n\xedvel flagship, especializado em extra\xe7\xe3o de dados, programa\xe7\xe3o e resumo de texto para aplica\xe7\xf5es empresariais, com profundo conhecimento em finan\xe7as, sa\xfade, direito e ci\xeancias."},"grok-3-mini":{"description":"Modelo leve que pensa antes de responder. R\xe1pido e inteligente, adequado para tarefas l\xf3gicas que n\xe3o exigem conhecimento profundo de dom\xednio, e capaz de fornecer o rastro original do pensamento."},"grok-4":{"description":"Nosso mais recente e poderoso modelo principal, com desempenho excepcional em processamento de linguagem natural, c\xe1lculo matem\xe1tico e racioc\xednio — um competidor vers\xe1til perfeito."},"grok-4-0709":{"description":"Grok 4 da xAI, com forte capacidade de racioc\xednio."},"grok-4-1-fast-non-reasoning":{"description":"Modelo multimodal de ponta, otimizado especialmente para chamadas de ferramentas de agente de alto desempenho."},"grok-4-1-fast-reasoning":{"description":"Modelo multimodal de ponta, otimizado especialmente para chamadas de ferramentas de agente de alto desempenho."},"grok-4-fast-non-reasoning":{"description":"Temos o prazer de lan\xe7ar o Grok 4 Fast, nosso avan\xe7o mais recente em modelos de infer\xeancia com custo-benef\xedcio."},"grok-4-fast-reasoning":{"description":"Temos o prazer de lan\xe7ar o Grok 4 Fast, nosso avan\xe7o mais recente em modelos de infer\xeancia com custo-benef\xedcio."},"grok-code-fast-1":{"description":"Temos o prazer de apresentar o grok-code-fast-1, um modelo de infer\xeancia r\xe1pido e econ\xf4mico, que se destaca na codifica\xe7\xe3o de agentes."},"groq/compound":{"description":"Compound \xe9 um sistema de IA composto, suportado por v\xe1rios modelos abertos dispon\xedveis no GroqCloud, que pode usar ferramentas de forma inteligente e seletiva para responder \xe0s consultas dos usu\xe1rios."},"groq/compound-mini":{"description":"Compound-mini \xe9 um sistema de IA composto, suportado por modelos p\xfablicos dispon\xedveis no GroqCloud, que pode usar ferramentas de forma inteligente e seletiva para responder \xe0s consultas dos usu\xe1rios."},"gryphe/mythomax-l2-13b":{"description":"MythoMax l2 13B \xe9 um modelo de linguagem que combina criatividade e intelig\xeancia, integrando v\xe1rios modelos de ponta."},"hunyuan-a13b":{"description":"O primeiro modelo de racioc\xednio h\xedbrido da Hunyuan, uma vers\xe3o aprimorada do hunyuan-standard-256K, com 80 bilh\xf5es de par\xe2metros totais e 13 bilh\xf5es ativados. O modo padr\xe3o \xe9 o modo de pensamento lento, com suporte para altern\xe2ncia entre modos r\xe1pido e lento via par\xe2metros ou instru\xe7\xf5es, usando prefixos query / no_think para alternar. A capacidade geral foi amplamente melhorada em rela\xe7\xe3o \xe0 gera\xe7\xe3o anterior, especialmente em matem\xe1tica, ci\xeancias, compreens\xe3o de textos longos e habilidades de agente."},"hunyuan-code":{"description":"O mais recente modelo de gera\xe7\xe3o de c\xf3digo Hunyuan, treinado com 200B de dados de c\xf3digo de alta qualidade, com seis meses de treinamento de dados SFT de alta qualidade, aumentando o comprimento da janela de contexto para 8K, destacando-se em m\xe9tricas autom\xe1ticas de gera\xe7\xe3o de c\xf3digo em cinco linguagens; em avalia\xe7\xf5es de qualidade de c\xf3digo em dez aspectos em cinco linguagens, o desempenho est\xe1 na primeira divis\xe3o."},"hunyuan-functioncall":{"description":"O mais recente modelo FunctionCall da arquitetura MOE Hunyuan, treinado com dados de alta qualidade de FunctionCall, com uma janela de contexto de 32K, liderando em v\xe1rias m\xe9tricas de avalia\xe7\xe3o."},"hunyuan-large":{"description":"O modelo Hunyuan-large possui um total de aproximadamente 389B de par\xe2metros, com cerca de 52B de par\xe2metros ativados, sendo o modelo MoE de c\xf3digo aberto com a maior escala de par\xe2metros e melhor desempenho na arquitetura Transformer atualmente dispon\xedvel no mercado."},"hunyuan-large-longcontext":{"description":"Especializado em tarefas de texto longo, como resumo de documentos e perguntas e respostas de documentos, tamb\xe9m possui a capacidade de lidar com tarefas gerais de gera\xe7\xe3o de texto. Apresenta desempenho excepcional na an\xe1lise e gera\xe7\xe3o de textos longos, conseguindo atender efetivamente \xe0s demandas complexas e detalhadas de processamento de conte\xfado longo."},"hunyuan-large-vision":{"description":"Este modelo \xe9 adequado para cen\xe1rios de compreens\xe3o de imagens e texto, baseado no modelo visual-lingu\xedstico Hunyuan Large. Suporta entrada de m\xfaltiplas imagens em qualquer resolu\xe7\xe3o junto com texto, gerando conte\xfado textual, com foco em tarefas relacionadas \xe0 compreens\xe3o de imagens e texto, apresentando melhorias significativas em capacidades multil\xedngues."},"hunyuan-lite":{"description":"Atualizado para uma estrutura MOE, com uma janela de contexto de 256k, liderando em v\xe1rias avalia\xe7\xf5es em NLP, c\xf3digo, matem\xe1tica e setores diversos em compara\xe7\xe3o com muitos modelos de c\xf3digo aberto."},"hunyuan-lite-vision":{"description":"Modelo multimodal mais recente de 7B da Hunyuan, com janela de contexto de 32K, suporta di\xe1logos multimodais em cen\xe1rios em chin\xeas e portugu\xeas, reconhecimento de objetos em imagens, compreens\xe3o de documentos e tabelas, matem\xe1tica multimodal, entre outros, superando modelos concorrentes de 7B em v\xe1rias m\xe9tricas de avalia\xe7\xe3o."},"hunyuan-pro":{"description":"Modelo de texto longo MOE-32K com trilh\xf5es de par\xe2metros. Alcan\xe7a n\xedveis de lideran\xe7a absoluta em v\xe1rios benchmarks, com capacidades complexas de instru\xe7\xe3o e racioc\xednio, habilidades matem\xe1ticas complexas, suporte a chamadas de fun\xe7\xe3o, otimizado para \xe1reas como tradu\xe7\xe3o multil\xedngue, finan\xe7as, direito e sa\xfade."},"hunyuan-role":{"description":"O mais recente modelo de interpreta\xe7\xe3o de pap\xe9is Hunyuan, um modelo de interpreta\xe7\xe3o de pap\xe9is ajustado e treinado oficialmente pela Hunyuan, que combina o modelo Hunyuan com um conjunto de dados de cen\xe1rios de interpreta\xe7\xe3o de pap\xe9is, apresentando um desempenho b\xe1sico melhor em cen\xe1rios de interpreta\xe7\xe3o de pap\xe9is."},"hunyuan-standard":{"description":"Adota uma estrat\xe9gia de roteamento superior, ao mesmo tempo que mitiga problemas de balanceamento de carga e converg\xeancia de especialistas. Em termos de textos longos, o \xedndice de precis\xe3o atinge 99,9%. O MOE-32K oferece uma rela\xe7\xe3o custo-benef\xedcio relativamente melhor, equilibrando desempenho e pre\xe7o, permitindo o processamento de entradas de texto longo."},"hunyuan-standard-256K":{"description":"Adota uma estrat\xe9gia de roteamento superior, ao mesmo tempo que mitiga problemas de balanceamento de carga e converg\xeancia de especialistas. Em termos de textos longos, o \xedndice de precis\xe3o atinge 99,9%. O MOE-256K rompe ainda mais em comprimento e desempenho, expandindo significativamente o comprimento de entrada permitido."},"hunyuan-standard-vision":{"description":"Modelo multimodal mais recente da Hunyuan, suporta respostas em m\xfaltiplas l\xednguas, com habilidades equilibradas em chin\xeas e portugu\xeas."},"hunyuan-t1-20250321":{"description":"Modelo abrangente que constr\xf3i habilidades em ci\xeancias exatas e humanas, com forte capacidade de captura de informa\xe7\xf5es em textos longos. Suporta racioc\xednio para responder a problemas cient\xedficos de diversas dificuldades, incluindo matem\xe1tica, l\xf3gica, ci\xeancias e c\xf3digo."},"hunyuan-t1-20250403":{"description":"Melhore a capacidade de gera\xe7\xe3o de c\xf3digo em n\xedvel de projeto; aumente a qualidade da escrita gerada em texto; aprimore a compreens\xe3o de t\xf3picos em m\xfaltiplas rodadas, a conformidade com instru\xe7\xf5es do tipo tob e a compreens\xe3o de palavras; otimize problemas de sa\xedda com mistura de caracteres tradicionais e simplificados, bem como misturas de chin\xeas e ingl\xeas."},"hunyuan-t1-20250529":{"description":"Otimizado para cria\xe7\xe3o de textos, reda\xe7\xe3o de ensaios, aprimoramento em front-end de c\xf3digo, matem\xe1tica, racioc\xednio l\xf3gico e outras habilidades cient\xedficas, al\xe9m de melhorar a capacidade de seguir instru\xe7\xf5es."},"hunyuan-t1-20250711":{"description":"Melhora significativa em matem\xe1tica avan\xe7ada, l\xf3gica e habilidades de codifica\xe7\xe3o, otimiza a estabilidade da sa\xedda do modelo e aprimora a capacidade de lidar com textos longos."},"hunyuan-t1-latest":{"description":"Melhora significativamente as capacidades do modelo principal de pensamento lento em matem\xe1tica avan\xe7ada, racioc\xednio complexo, c\xf3digo dif\xedcil, conformidade com instru\xe7\xf5es e qualidade de cria\xe7\xe3o de texto."},"hunyuan-t1-vision-20250619":{"description":"A vers\xe3o mais recente do modelo de pensamento profundo multimodal t1-vision da Hunyuan, que suporta cadeias de pensamento nativas multimodais, com melhorias abrangentes em rela\xe7\xe3o \xe0 vers\xe3o padr\xe3o anterior."},"hunyuan-t1-vision-20250916":{"description":"A vers\xe3o mais recente do modelo de vis\xe3o com racioc\xednio profundo Hunyuan t1-vision apresenta melhorias abrangentes em tarefas como perguntas e respostas visuais, localiza\xe7\xe3o visual, OCR, gr\xe1ficos, resolu\xe7\xe3o de problemas a partir de fotos e cria\xe7\xe3o baseada em imagens. Houve tamb\xe9m uma otimiza\xe7\xe3o significativa nas capacidades em ingl\xeas e em idiomas menos comuns."},"hunyuan-turbo":{"description":"Vers\xe3o de pr\xe9-visualiza\xe7\xe3o do novo modelo de linguagem de pr\xf3xima gera\xe7\xe3o Hunyuan, utilizando uma nova estrutura de modelo de especialistas mistos (MoE), com efici\xeancia de infer\xeancia mais r\xe1pida e desempenho superior em compara\xe7\xe3o ao Hunyuan-Pro."},"hunyuan-turbo-20241223":{"description":"Esta vers\xe3o otimiza: escalonamento de instru\xe7\xf5es de dados, aumentando significativamente a capacidade de generaliza\xe7\xe3o do modelo; melhoria substancial nas habilidades matem\xe1ticas, de codifica\xe7\xe3o e de racioc\xednio l\xf3gico; otimiza\xe7\xe3o das capacidades de compreens\xe3o de texto e palavras; melhoria na qualidade da gera\xe7\xe3o de conte\xfado de cria\xe7\xe3o de texto."},"hunyuan-turbo-latest":{"description":"Otimiza\xe7\xe3o da experi\xeancia geral, incluindo compreens\xe3o de NLP, cria\xe7\xe3o de texto, conversas informais, perguntas e respostas de conhecimento, tradu\xe7\xe3o, entre outros; aumento da humaniza\xe7\xe3o, otimiza\xe7\xe3o da intelig\xeancia emocional do modelo; melhoria na capacidade do modelo de esclarecer ativamente em casos de inten\xe7\xe3o amb\xedgua; aprimoramento na capacidade de lidar com quest\xf5es de an\xe1lise de palavras; melhoria na qualidade e interatividade da cria\xe7\xe3o; aprimoramento da experi\xeancia em m\xfaltiplas intera\xe7\xf5es."},"hunyuan-turbo-vision":{"description":"Novo modelo de linguagem visual de pr\xf3xima gera\xe7\xe3o da Hunyuan, adotando uma nova estrutura de modelo de especialistas mistos (MoE), com melhorias abrangentes em rela\xe7\xe3o ao modelo anterior nas capacidades de reconhecimento b\xe1sico, cria\xe7\xe3o de conte\xfado, perguntas e respostas de conhecimento, e an\xe1lise e racioc\xednio relacionados \xe0 compreens\xe3o de texto e imagem."},"hunyuan-turbos-20250313":{"description":"Uniformiza\xe7\xe3o do estilo dos passos para resolu\xe7\xe3o de problemas matem\xe1ticos, refor\xe7ando perguntas e respostas em m\xfaltiplas rodadas na matem\xe1tica. Otimiza\xe7\xe3o do estilo de resposta na cria\xe7\xe3o de textos, eliminando tra\xe7os de IA e aumentando a expressividade liter\xe1ria."},"hunyuan-turbos-20250416":{"description":"Atualiza\xe7\xe3o da base pr\xe9-treinada para fortalecer a compreens\xe3o e conformidade com instru\xe7\xf5es; aprimoramento das habilidades em matem\xe1tica, c\xf3digo, l\xf3gica e ci\xeancias exatas na fase de alinhamento; melhoria da qualidade da escrita criativa, compreens\xe3o textual, precis\xe3o na tradu\xe7\xe3o e respostas a perguntas em ci\xeancias humanas; fortalecimento das capacidades de agentes em diversas \xe1reas, com foco especial na compreens\xe3o de di\xe1logos em m\xfaltiplas rodadas."},"hunyuan-turbos-20250604":{"description":"Atualiza\xe7\xe3o da base pr\xe9-treinada, com melhorias em escrita e compreens\xe3o de leitura, aumento significativo nas habilidades de c\xf3digo e ci\xeancias, e aprimoramento cont\xednuo no seguimento de instru\xe7\xf5es complexas."},"hunyuan-turbos-20250926":{"description":"Atualiza\xe7\xe3o na qualidade dos dados da base de pr\xe9-treinamento. Otimiza\xe7\xe3o da estrat\xe9gia de treinamento na fase p\xf3s-treinamento, com melhorias cont\xednuas nas capacidades de agentes, idiomas menores em ingl\xeas, conformidade com instru\xe7\xf5es, c\xf3digo e ci\xeancias exatas."},"hunyuan-turbos-latest":{"description":"A vers\xe3o mais recente do hunyuan-TurboS, o modelo de grande porte da Hunyuan, possui uma capacidade de racioc\xednio mais forte e uma experi\xeancia aprimorada."},"hunyuan-turbos-longtext-128k-20250325":{"description":"Especializado em tarefas de texto longo, como resumos de documentos e perguntas sobre documentos, tamb\xe9m possui a capacidade de lidar com tarefas gerais de gera\xe7\xe3o de texto. Destaca-se na an\xe1lise e gera\xe7\xe3o de textos longos, atendendo efetivamente a demandas complexas e detalhadas."},"hunyuan-turbos-role-plus":{"description":"Modelo de interpreta\xe7\xe3o de pap\xe9is da vers\xe3o mais recente do Hunyuan, ajustado finamente pela equipe oficial Hunyuan. Baseado no modelo Hunyuan e treinado adicionalmente com conjuntos de dados de cen\xe1rios de interpreta\xe7\xe3o de pap\xe9is, oferecendo melhores resultados b\xe1sicos nesses contextos."},"hunyuan-turbos-vision":{"description":"Este modelo \xe9 adequado para cen\xe1rios de compreens\xe3o de imagens e texto, baseado na mais recente gera\xe7\xe3o turbos da Hunyuan, um modelo de linguagem visual flagship focado em tarefas relacionadas \xe0 compreens\xe3o de imagens e texto, incluindo reconhecimento de entidades em imagens, perguntas e respostas baseadas em conhecimento, cria\xe7\xe3o de textos e resolu\xe7\xe3o de problemas por foto, com melhorias abrangentes em rela\xe7\xe3o \xe0 gera\xe7\xe3o anterior."},"hunyuan-turbos-vision-20250619":{"description":"A vers\xe3o mais recente do modelo flagship de linguagem visual turbos-vision da Hunyuan, com melhorias abrangentes em tarefas relacionadas \xe0 compreens\xe3o de imagens e texto, incluindo reconhecimento de entidades em imagens, perguntas e respostas baseadas em conhecimento, cria\xe7\xe3o de textos e resolu\xe7\xe3o de problemas por foto, em compara\xe7\xe3o com a vers\xe3o padr\xe3o anterior."},"hunyuan-vision":{"description":"O mais recente modelo multimodal Hunyuan, que suporta a entrada de imagens e texto para gerar conte\xfado textual."},"image-01":{"description":"Novo modelo de gera\xe7\xe3o de imagens com detalhes refinados, suportando gera\xe7\xe3o de imagens a partir de texto e de outras imagens."},"image-01-live":{"description":"Modelo de gera\xe7\xe3o de imagens com detalhes refinados, suportando gera\xe7\xe3o a partir de texto e configura\xe7\xe3o de estilo visual."},"imagen-4.0-fast-generate-001":{"description":"Imagen, s\xe9rie de modelos texto para imagem de 4\xaa gera\xe7\xe3o — vers\xe3o Fast"},"imagen-4.0-generate-001":{"description":"S\xe9rie de modelos Imagen de 4\xaa gera\xe7\xe3o para gerar imagens a partir de texto"},"imagen-4.0-generate-preview-06-06":{"description":"S\xe9rie de modelos de gera\xe7\xe3o de imagens da quarta gera\xe7\xe3o do Imagen."},"imagen-4.0-ultra-generate-001":{"description":"Imagen: modelo de gera\xe7\xe3o de imagens a partir de texto de 4\xaa gera\xe7\xe3o — vers\xe3o Ultra"},"imagen-4.0-ultra-generate-preview-06-06":{"description":"Vers\xe3o Ultra da s\xe9rie de modelos de gera\xe7\xe3o de imagens da quarta gera\xe7\xe3o do Imagen."},"inception/mercury-coder-small":{"description":"Mercury Coder Small \xe9 a escolha ideal para tarefas de gera\xe7\xe3o, depura\xe7\xe3o e refatora\xe7\xe3o de c\xf3digo, com lat\xeancia m\xednima."},"inclusionAI/Ling-1T":{"description":"Ling-1T \xe9 o primeiro modelo emblem\xe1tico da s\xe9rie \\"Ling 2.0\\" sem capacidade de racioc\xednio, com um total de 1 trilh\xe3o de par\xe2metros e cerca de 50 bilh\xf5es de par\xe2metros ativos por token. Constru\xeddo com base na arquitetura Ling 2.0, o Ling-1T visa ultrapassar os limites do racioc\xednio eficiente e da cogni\xe7\xe3o escal\xe1vel. O Ling-1T-base foi treinado com mais de 20 trilh\xf5es de tokens de alta qualidade e intensivos em racioc\xednio."},"inclusionAI/Ling-flash-2.0":{"description":"Ling-flash-2.0 \xe9 o terceiro modelo da s\xe9rie Ling 2.0, lan\xe7ado pela equipe Bailing do Ant Group. \xc9 um modelo de especialistas mistos (MoE) com 100 bilh\xf5es de par\xe2metros totais, mas ativa apenas 6,1 bilh\xf5es por token (4,8 bilh\xf5es excluindo embeddings). Como uma configura\xe7\xe3o leve, Ling-flash-2.0 demonstra desempenho compar\xe1vel ou superior a modelos densos de 40 bilh\xf5es e modelos MoE de maior escala em v\xe1rias avalia\xe7\xf5es autoritativas. O modelo busca explorar caminhos eficientes sob o consenso de que “modelos grandes equivalem a muitos par\xe2metros” por meio de design arquitet\xf4nico e estrat\xe9gias de treinamento extremas."},"inclusionAI/Ling-mini-2.0":{"description":"Ling-mini-2.0 \xe9 um modelo de linguagem grande de alto desempenho e pequeno porte baseado na arquitetura MoE. Possui 16 bilh\xf5es de par\xe2metros totais, mas ativa apenas 1,4 bilh\xe3o por token (789 milh\xf5es excluindo embeddings), alcan\xe7ando alta velocidade de gera\xe7\xe3o. Gra\xe7as ao design eficiente do MoE e a grandes volumes de dados de treinamento de alta qualidade, Ling-mini-2.0 apresenta desempenho de ponta em tarefas downstream, compar\xe1vel a modelos densos abaixo de 10 bilh\xf5es e modelos MoE de maior escala."},"inclusionAI/Ring-1T":{"description":"Ring-1T \xe9 um modelo de pensamento open-source com escala de trilh\xf5es de par\xe2metros, lan\xe7ado pela equipe Bailing. Baseado na arquitetura Ling 2.0 e no modelo base Ling-1T, possui 1 trilh\xe3o de par\xe2metros totais e 50 bilh\xf5es de par\xe2metros ativos, com suporte para janelas de contexto de at\xe9 128K. O modelo foi otimizado por meio de aprendizado por refor\xe7o com recompensas verific\xe1veis em larga escala."},"inclusionAI/Ring-flash-2.0":{"description":"Ring-flash-2.0 \xe9 um modelo de pensamento de alto desempenho profundamente otimizado a partir do Ling-flash-2.0-base. Utiliza arquitetura de especialistas mistos (MoE) com 100 bilh\xf5es de par\xe2metros totais, mas ativa apenas 6,1 bilh\xf5es por infer\xeancia. O modelo resolve a instabilidade do treinamento por refor\xe7o (RL) em grandes modelos MoE com o algoritmo inovador icepop, permitindo melhoria cont\xednua do racioc\xednio complexo em treinamentos longos. Ring-flash-2.0 alcan\xe7ou avan\xe7os significativos em competi\xe7\xf5es matem\xe1ticas, gera\xe7\xe3o de c\xf3digo e racioc\xednio l\xf3gico, superando modelos densos de at\xe9 40 bilh\xf5es de par\xe2metros e rivalizando com modelos MoE open source maiores e modelos de pensamento propriet\xe1rios de alto desempenho. Embora focado em racioc\xednio complexo, tamb\xe9m se destaca em tarefas criativas. Al\xe9m disso, gra\xe7as ao design eficiente, oferece alta velocidade de infer\xeancia e reduz significativamente o custo de implanta\xe7\xe3o em cen\xe1rios de alta concorr\xeancia."},"internlm/internlm2_5-7b-chat":{"description":"InternLM2.5 oferece solu\xe7\xf5es de di\xe1logo inteligente em m\xfaltiplos cen\xe1rios."},"internlm2.5-latest":{"description":"Nossa mais recente s\xe9rie de modelos, com desempenho de racioc\xednio excepcional, suportando um comprimento de contexto de 1M e capacidades aprimoradas de seguimento de instru\xe7\xf5es e chamadas de ferramentas."},"internlm3-latest":{"description":"Nossa mais recente s\xe9rie de modelos, com desempenho de infer\xeancia excepcional, liderando entre modelos de c\xf3digo aberto de mesma escala. Aponta por padr\xe3o para nossa mais recente s\xe9rie de modelos InternLM3."},"internvl2.5-38b-mpo":{"description":"InternVL2.5 38B MPO, modelo multimodal pr\xe9-treinado com suporte para tarefas complexas de racioc\xednio de imagem e texto."},"internvl2.5-latest":{"description":"Vers\xe3o InternVL2.5 que ainda estamos mantendo, com desempenho excelente e est\xe1vel. Aponta por padr\xe3o para nossa mais recente s\xe9rie de modelos InternVL2.5, atualmente direcionando para internvl2.5-78b."},"internvl3-14b":{"description":"InternVL3 14B, modelo multimodal de porte m\xe9dio, equilibrando desempenho e custo."},"internvl3-1b":{"description":"InternVL3 1B, modelo multimodal leve, ideal para implanta\xe7\xe3o em ambientes com recursos limitados."},"internvl3-38b":{"description":"InternVL3 38B, modelo multimodal de c\xf3digo aberto em larga escala, ideal para tarefas de compreens\xe3o de imagem e texto de alta precis\xe3o."},"internvl3-latest":{"description":"Lan\xe7amos nosso mais recente modelo multimodal, com habilidades aprimoradas de compreens\xe3o de texto e imagem, e capacidade de entender imagens em longas sequ\xeancias, com desempenho compar\xe1vel aos melhores modelos fechados. Aponta por padr\xe3o para nossa mais recente s\xe9rie de modelos InternVL, atualmente direcionando para internvl3-78b."},"irag-1.0":{"description":"ERNIE iRAG, modelo de gera\xe7\xe3o aprimorada por recupera\xe7\xe3o de imagem, com suporte para busca por imagem, recupera\xe7\xe3o de imagem e texto e gera\xe7\xe3o de conte\xfado."},"jamba-large":{"description":"Nosso modelo mais poderoso e avan\xe7ado, projetado para lidar com tarefas complexas em n\xedvel empresarial, com desempenho excepcional."},"jamba-mini":{"description":"O modelo mais eficiente da sua categoria, equilibrando velocidade e qualidade, com um tamanho menor."},"jina-deepsearch-v1":{"description":"A busca profunda combina pesquisa na web, leitura e racioc\xednio para realizar investiga\xe7\xf5es abrangentes. Voc\xea pode v\xea-la como um agente que aceita suas tarefas de pesquisa - ela realizar\xe1 uma busca extensa e passar\xe1 por v\xe1rias itera\xe7\xf5es antes de fornecer uma resposta. Esse processo envolve pesquisa cont\xednua, racioc\xednio e resolu\xe7\xe3o de problemas sob diferentes \xe2ngulos. Isso \xe9 fundamentalmente diferente de gerar respostas diretamente a partir de dados pr\xe9-treinados de grandes modelos padr\xe3o e de sistemas RAG tradicionais que dependem de buscas superficiais \xfanicas."},"kimi-k2":{"description":"Kimi-K2 \xe9 um modelo base com arquitetura MoE lan\xe7ado pela Moonshot AI, com capacidades avan\xe7adas de c\xf3digo e agente, totalizando 1 trilh\xe3o de par\xe2metros e 32 bilh\xf5es ativados. Em testes de desempenho em racioc\xednio geral, programa\xe7\xe3o, matem\xe1tica e agentes, supera outros modelos open source populares."},"kimi-k2-0711-preview":{"description":"kimi-k2 \xe9 um modelo base com arquitetura MoE, com capacidades excepcionais em c\xf3digo e agentes, totalizando 1T de par\xe2metros e 32B de par\xe2metros ativados. Nos principais benchmarks de racioc\xednio de conhecimento geral, programa\xe7\xe3o, matem\xe1tica e agentes, o modelo K2 supera outros modelos open source populares."},"kimi-k2-0905-preview":{"description":"O modelo kimi-k2-0905-preview possui comprimento de contexto de 256k, com capacidades aprimoradas de Agentic Coding, maior est\xe9tica e praticidade do c\xf3digo front-end, al\xe9m de melhor compreens\xe3o do contexto."},"kimi-k2-instruct":{"description":"Kimi K2 Instruct, modelo oficial de infer\xeancia da Kimi, com suporte para contexto longo, c\xf3digo, perguntas e respostas e outros cen\xe1rios."},"kimi-k2-turbo-preview":{"description":"kimi-k2 \xe9 um modelo base com arquitetura MoE que oferece capacidades avan\xe7adas para programa\xe7\xe3o e agentes, com 1T de par\xe2metros totais e 32B de par\xe2metros ativados. Em testes de benchmark nas principais categorias — racioc\xednio de conhecimento geral, programa\xe7\xe3o, matem\xe1tica e agentes — o desempenho do modelo K2 supera outros modelos de c\xf3digo aberto mais populares."},"kimi-k2:1t":{"description":"Kimi K2 \xe9 um modelo de linguagem de especialistas h\xedbridos em larga escala (MoE) desenvolvido pela AI do Lado Escuro da Lua, com um total de 1 trilh\xe3o de par\xe2metros e 32 bilh\xf5es de par\xe2metros ativados por passagem. Ele \xe9 otimizado para capacidades de agente, incluindo uso avan\xe7ado de ferramentas, racioc\xednio e s\xedntese de c\xf3digo."},"kimi-latest":{"description":"O produto assistente inteligente Kimi utiliza o mais recente modelo Kimi, que pode conter recursos ainda n\xe3o est\xe1veis. Suporta compreens\xe3o de imagens e seleciona automaticamente o modelo de cobran\xe7a de 8k/32k/128k com base no comprimento do contexto da solicita\xe7\xe3o."},"kimi-thinking-preview":{"description":"O modelo kimi-thinking-preview, fornecido pela Face Oculta da Lua, \xe9 um modelo multimodal de pensamento com capacidades de racioc\xednio multimodal e geral, especializado em racioc\xednio profundo para ajudar a resolver problemas mais complexos."},"learnlm-1.5-pro-experimental":{"description":"LearnLM \xe9 um modelo de linguagem experimental e espec\xedfico para tarefas, treinado para atender aos princ\xedpios da ci\xeancia da aprendizagem, podendo seguir instru\xe7\xf5es sistem\xe1ticas em cen\xe1rios de ensino e aprendizagem, atuando como um mentor especialista, entre outros."},"learnlm-2.0-flash-experimental":{"description":"LearnLM \xe9 um modelo de linguagem experimental, espec\xedfico para tarefas, treinado para atender aos princ\xedpios da ci\xeancia da aprendizagem, capaz de seguir instru\xe7\xf5es sistem\xe1ticas em cen\xe1rios de ensino e aprendizagem, atuando como um mentor especialista, entre outros."},"lite":{"description":"Spark Lite \xe9 um modelo de linguagem grande leve, com lat\xeancia extremamente baixa e alta efici\xeancia de processamento, totalmente gratuito e aberto, suportando funcionalidades de busca online em tempo real. Sua caracter\xedstica de resposta r\xe1pida o torna excelente para aplica\xe7\xf5es de infer\xeancia em dispositivos de baixo poder computacional e ajuste fino de modelos, proporcionando aos usu\xe1rios uma excelente rela\xe7\xe3o custo-benef\xedcio e experi\xeancia inteligente, especialmente em cen\xe1rios de perguntas e respostas, gera\xe7\xe3o de conte\xfado e busca."},"llama-3.1-70b-versatile":{"description":"Llama 3.1 70B oferece capacidade de racioc\xednio AI mais poderosa, adequada para aplica\xe7\xf5es complexas, suportando um processamento computacional extenso e garantindo efici\xeancia e precis\xe3o."},"llama-3.1-8b-instant":{"description":"Llama 3.1 8B \xe9 um modelo de alto desempenho, oferecendo capacidade de gera\xe7\xe3o de texto r\xe1pida, ideal para cen\xe1rios de aplica\xe7\xe3o que exigem efici\xeancia em larga escala e custo-benef\xedcio."},"llama-3.1-instruct":{"description":"O modelo Llama 3.1 com ajuste fino de instru\xe7\xf5es foi otimizado para cen\xe1rios de di\xe1logo, superando muitos modelos de chat de c\xf3digo aberto existentes em benchmarks comuns do setor."},"llama-3.2-11b-vision-instruct":{"description":"Capacidade excepcional de racioc\xednio visual em imagens de alta resolu\xe7\xe3o, adequada para aplica\xe7\xf5es de compreens\xe3o visual."},"llama-3.2-11b-vision-preview":{"description":"Llama 3.2 \xe9 projetado para lidar com tarefas que combinam dados visuais e textuais. Ele se destaca em tarefas como descri\xe7\xe3o de imagens e perguntas visuais, superando a lacuna entre gera\xe7\xe3o de linguagem e racioc\xednio visual."},"llama-3.2-90b-vision-instruct":{"description":"Capacidade avan\xe7ada de racioc\xednio visual para aplica\xe7\xf5es de agentes de compreens\xe3o visual."},"llama-3.2-90b-vision-preview":{"description":"Llama 3.2 \xe9 projetado para lidar com tarefas que combinam dados visuais e textuais. Ele se destaca em tarefas como descri\xe7\xe3o de imagens e perguntas visuais, superando a lacuna entre gera\xe7\xe3o de linguagem e racioc\xednio visual."},"llama-3.2-vision-instruct":{"description":"O modelo Llama 3.2-Vision com ajuste fino de instru\xe7\xf5es foi otimizado para reconhecimento visual, racioc\xednio com imagens, descri\xe7\xe3o de imagens e respostas a perguntas gerais relacionadas a imagens."},"llama-3.3-70b":{"description":"Llama 3.3 70B: modelo Llama de m\xe9dio a grande porte, equilibrando capacidade de racioc\xednio e desempenho de processamento."},"llama-3.3-70b-versatile":{"description":"O modelo de linguagem multil\xedngue Meta Llama 3.3 (LLM) \xe9 um modelo gerador pr\xe9-treinado e ajustado para instru\xe7\xf5es, com 70B (entrada/sa\xedda de texto). O modelo de texto puro ajustado para instru\xe7\xf5es do Llama 3.3 \xe9 otimizado para casos de uso de di\xe1logo multil\xedngue e supera muitos modelos de chat open source e fechados dispon\xedveis em benchmarks comuns da ind\xfastria."},"llama-3.3-instruct":{"description":"O modelo Llama 3.3 com ajuste fino de instru\xe7\xf5es foi otimizado para cen\xe1rios de di\xe1logo, superando muitos modelos de chat open-source existentes em benchmarks comuns do setor."},"llama-4-scout-17b-16e-instruct":{"description":"Llama 4 Scout: modelo de alto desempenho da s\xe9rie Llama, adequado para cen\xe1rios que exigem alta taxa de processamento e baixa lat\xeancia."},"llama3-70b-8192":{"description":"Meta Llama 3 70B oferece capacidade de processamento incompar\xe1vel para complexidade, projetado sob medida para projetos de alta demanda."},"llama3-8b-8192":{"description":"Meta Llama 3 8B oferece desempenho de racioc\xednio de alta qualidade, adequado para uma variedade de necessidades de aplica\xe7\xe3o."},"llama3-groq-70b-8192-tool-use-preview":{"description":"Llama 3 Groq 70B Tool Use oferece poderosa capacidade de chamada de ferramentas, suportando o processamento eficiente de tarefas complexas."},"llama3-groq-8b-8192-tool-use-preview":{"description":"Llama 3 Groq 8B Tool Use \xe9 um modelo otimizado para uso eficiente de ferramentas, suportando c\xe1lculos paralelos r\xe1pidos."},"llama3.1":{"description":"Llama 3.1 \xe9 um modelo l\xedder lan\xe7ado pela Meta, suportando at\xe9 405B de par\xe2metros, aplic\xe1vel em di\xe1logos complexos, tradu\xe7\xe3o multil\xedngue e an\xe1lise de dados."},"llama3.1-8b":{"description":"Llama 3.1 8B: variante compacta e de baixa lat\xeancia do Llama, ideal para infer\xeancia leve e intera\xe7\xf5es em tempo real."},"llama3.1:405b":{"description":"Llama 3.1 \xe9 um modelo l\xedder lan\xe7ado pela Meta, suportando at\xe9 405B de par\xe2metros, aplic\xe1vel em di\xe1logos complexos, tradu\xe7\xe3o multil\xedngue e an\xe1lise de dados."},"llama3.1:70b":{"description":"Llama 3.1 \xe9 um modelo l\xedder lan\xe7ado pela Meta, suportando at\xe9 405B de par\xe2metros, aplic\xe1vel em di\xe1logos complexos, tradu\xe7\xe3o multil\xedngue e an\xe1lise de dados."},"llava":{"description":"LLaVA \xe9 um modelo multimodal que combina um codificador visual e Vicuna, projetado para forte compreens\xe3o visual e lingu\xedstica."},"llava-v1.5-7b-4096-preview":{"description":"LLaVA 1.5 7B oferece capacidade de processamento visual integrada, gerando sa\xeddas complexas a partir de informa\xe7\xf5es visuais."},"llava:13b":{"description":"LLaVA \xe9 um modelo multimodal que combina um codificador visual e Vicuna, projetado para forte compreens\xe3o visual e lingu\xedstica."},"llava:34b":{"description":"LLaVA \xe9 um modelo multimodal que combina um codificador visual e Vicuna, projetado para forte compreens\xe3o visual e lingu\xedstica."},"magistral-medium-latest":{"description":"Magistral Medium 1.2 \xe9 um modelo de infer\xeancia de ponta com suporte visual, lan\xe7ado pela Mistral AI em setembro de 2025."},"magistral-small-2509":{"description":"Magistral Small 1.2 \xe9 um modelo de infer\xeancia pequeno e open source com suporte visual, lan\xe7ado pela Mistral AI em setembro de 2025."},"mathstral":{"description":"MathΣtral \xe9 projetado para pesquisa cient\xedfica e racioc\xednio matem\xe1tico, oferecendo capacidade de c\xe1lculo eficaz e interpreta\xe7\xe3o de resultados."},"max-32k":{"description":"Spark Max 32K possui uma capacidade de processamento de contexto grande, com melhor compreens\xe3o de contexto e capacidade de racioc\xednio l\xf3gico, suportando entradas de texto de 32K tokens, adequado para leitura de documentos longos, perguntas e respostas de conhecimento privado e outros cen\xe1rios."},"megrez-3b-instruct":{"description":"Megrez 3B Instruct \xe9 um modelo eficiente com poucos par\xe2metros desenvolvido pela Wuwen Xinqiong."},"meituan/longcat-flash-chat":{"description":"Modelo base n\xe3o reflexivo de c\xf3digo aberto da Meituan, otimizado para intera\xe7\xf5es em di\xe1logos e tarefas de agentes inteligentes, com desempenho excepcional em chamadas de ferramentas e cen\xe1rios complexos de m\xfaltiplas rodadas."},"meta-llama-3-70b-instruct":{"description":"Um poderoso modelo com 70 bilh\xf5es de par\xe2metros, destacando-se em racioc\xednio, codifica\xe7\xe3o e amplas aplica\xe7\xf5es lingu\xedsticas."},"meta-llama-3-8b-instruct":{"description":"Um modelo vers\xe1til com 8 bilh\xf5es de par\xe2metros, otimizado para tarefas de di\xe1logo e gera\xe7\xe3o de texto."},"meta-llama-3.1-405b-instruct":{"description":"Os modelos de texto apenas ajustados por instru\xe7\xe3o Llama 3.1 s\xe3o otimizados para casos de uso de di\xe1logo multil\xedngue e superam muitos dos modelos de chat de c\xf3digo aberto e fechado dispon\xedveis em benchmarks comuns da ind\xfastria."},"meta-llama-3.1-70b-instruct":{"description":"Os modelos de texto apenas ajustados por instru\xe7\xe3o Llama 3.1 s\xe3o otimizados para casos de uso de di\xe1logo multil\xedngue e superam muitos dos modelos de chat de c\xf3digo aberto e fechado dispon\xedveis em benchmarks comuns da ind\xfastria."},"meta-llama-3.1-8b-instruct":{"description":"Os modelos de texto apenas ajustados por instru\xe7\xe3o Llama 3.1 s\xe3o otimizados para casos de uso de di\xe1logo multil\xedngue e superam muitos dos modelos de chat de c\xf3digo aberto e fechado dispon\xedveis em benchmarks comuns da ind\xfastria."},"meta-llama/Llama-2-13b-chat-hf":{"description":"LLaMA-2 Chat (13B) oferece excelente capacidade de processamento de linguagem e uma experi\xeancia interativa not\xe1vel."},"meta-llama/Llama-2-70b-hf":{"description":"LLaMA-2 oferece excelente capacidade de processamento de linguagem e uma experi\xeancia interativa excepcional."},"meta-llama/Llama-3-70b-chat-hf":{"description":"LLaMA-3 Chat (70B) \xe9 um modelo de chat poderoso, suportando necessidades de di\xe1logo complexas."},"meta-llama/Llama-3-8b-chat-hf":{"description":"LLaMA-3 Chat (8B) oferece suporte multil\xedngue, abrangendo um rico conhecimento em diversas \xe1reas."},"meta-llama/Llama-3.2-11B-Vision-Instruct-Turbo":{"description":"LLaMA 3.2 \xe9 projetado para lidar com tarefas que combinam dados visuais e textuais. Ele se destaca em tarefas como descri\xe7\xe3o de imagens e perguntas visuais, superando a lacuna entre gera\xe7\xe3o de linguagem e racioc\xednio visual."},"meta-llama/Llama-3.2-3B-Instruct-Turbo":{"description":"LLaMA 3.2 \xe9 projetado para lidar com tarefas que combinam dados visuais e textuais. Ele se destaca em tarefas como descri\xe7\xe3o de imagens e perguntas visuais, superando a lacuna entre gera\xe7\xe3o de linguagem e racioc\xednio visual."},"meta-llama/Llama-3.2-90B-Vision-Instruct-Turbo":{"description":"LLaMA 3.2 \xe9 projetado para lidar com tarefas que combinam dados visuais e textuais. Ele se destaca em tarefas como descri\xe7\xe3o de imagens e perguntas visuais, superando a lacuna entre gera\xe7\xe3o de linguagem e racioc\xednio visual."},"meta-llama/Llama-3.3-70B-Instruct-Turbo":{"description":"O Meta Llama 3.3 \xe9 um modelo de linguagem de grande escala multil\xedngue (LLM) com 70B (entrada/sa\xedda de texto) que \xe9 um modelo gerado por pr\xe9-treinamento e ajuste de instru\xe7\xf5es. O modelo de texto puro ajustado por instru\xe7\xf5es do Llama 3.3 foi otimizado para casos de uso de di\xe1logo multil\xedngue e supera muitos modelos de chat de c\xf3digo aberto e fechados dispon\xedveis em benchmarks de ind\xfastria comuns."},"meta-llama/Llama-Vision-Free":{"description":"LLaMA 3.2 \xe9 projetado para lidar com tarefas que combinam dados visuais e textuais. Ele se destaca em tarefas como descri\xe7\xe3o de imagens e perguntas visuais, superando a lacuna entre gera\xe7\xe3o de linguagem e racioc\xednio visual."},"meta-llama/Meta-Llama-3-70B-Instruct-Lite":{"description":"Llama 3 70B Instruct Lite \xe9 ideal para ambientes que exigem alta efici\xeancia e baixa lat\xeancia."},"meta-llama/Meta-Llama-3-70B-Instruct-Turbo":{"description":"Llama 3 70B Instruct Turbo oferece uma capacidade excepcional de compreens\xe3o e gera\xe7\xe3o de linguagem, adequado para as tarefas computacionais mais exigentes."},"meta-llama/Meta-Llama-3-8B-Instruct-Lite":{"description":"Llama 3 8B Instruct Lite \xe9 adequado para ambientes com recursos limitados, oferecendo um excelente equil\xedbrio de desempenho."},"meta-llama/Meta-Llama-3-8B-Instruct-Turbo":{"description":"Llama 3 8B Instruct Turbo \xe9 um modelo de linguagem de alto desempenho, suportando uma ampla gama de cen\xe1rios de aplica\xe7\xe3o."},"meta-llama/Meta-Llama-3.1-405B-Instruct":{"description":"LLaMA 3.1 405B \xe9 um modelo poderoso para pr\xe9-treinamento e ajuste de instru\xe7\xf5es."},"meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo":{"description":"O modelo Llama 3.1 Turbo 405B oferece suporte a um contexto de capacidade extremamente grande para processamento de grandes volumes de dados, destacando-se em aplica\xe7\xf5es de intelig\xeancia artificial em larga escala."},"meta-llama/Meta-Llama-3.1-70B":{"description":"Llama 3.1 \xe9 o modelo l\xedder lan\xe7ado pela Meta, suportando at\xe9 405B de par\xe2metros, aplic\xe1vel em di\xe1logos complexos, tradu\xe7\xe3o multil\xedngue e an\xe1lise de dados."},"meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo":{"description":"O modelo Llama 3.1 70B \xe9 ajustado para aplica\xe7\xf5es de alta carga, quantizado para FP8, oferecendo maior efici\xeancia computacional e precis\xe3o, garantindo desempenho excepcional em cen\xe1rios complexos."},"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo":{"description":"O modelo Llama 3.1 8B utiliza quantiza\xe7\xe3o FP8, suportando at\xe9 131.072 tokens de contexto, destacando-se entre os modelos de c\xf3digo aberto, ideal para tarefas complexas e superando muitos benchmarks do setor."},"meta-llama/llama-3-70b-instruct":{"description":"Llama 3 70B Instruct \xe9 otimizado para cen\xe1rios de di\xe1logo de alta qualidade, apresentando desempenho excepcional em v\xe1rias avalia\xe7\xf5es humanas."},"meta-llama/llama-3-8b-instruct":{"description":"Llama 3 8B Instruct otimiza cen\xe1rios de di\xe1logo de alta qualidade, com desempenho superior a muitos modelos fechados."},"meta-llama/llama-3.1-70b-instruct":{"description":"Llama 3.1 70B Instruct \xe9 projetado para di\xe1logos de alta qualidade, destacando-se em avalia\xe7\xf5es humanas, especialmente em cen\xe1rios de alta intera\xe7\xe3o."},"meta-llama/llama-3.1-8b-instruct":{"description":"Llama 3.1 8B Instruct \xe9 a vers\xe3o mais recente lan\xe7ada pela Meta, otimizada para cen\xe1rios de di\xe1logo de alta qualidade, superando muitos modelos fechados de ponta."},"meta-llama/llama-3.1-8b-instruct:free":{"description":"LLaMA 3.1 oferece suporte multil\xedngue e \xe9 um dos modelos geradores l\xedderes do setor."},"meta-llama/llama-3.2-11b-vision-instruct":{"description":"LLaMA 3.2 \xe9 projetado para lidar com tarefas que combinam dados visuais e textuais. Ele se destaca em tarefas como descri\xe7\xe3o de imagens e perguntas visuais, superando a lacuna entre gera\xe7\xe3o de linguagem e racioc\xednio visual."},"meta-llama/llama-3.2-3b-instruct":{"description":"meta-llama/llama-3.2-3b-instruct"},"meta-llama/llama-3.2-90b-vision-instruct":{"description":"LLaMA 3.2 \xe9 projetado para lidar com tarefas que combinam dados visuais e textuais. Ele se destaca em tarefas como descri\xe7\xe3o de imagens e perguntas visuais, superando a lacuna entre gera\xe7\xe3o de linguagem e racioc\xednio visual."},"meta-llama/llama-3.3-70b-instruct":{"description":"Llama 3.3 \xe9 o modelo de linguagem de c\xf3digo aberto multil\xedngue mais avan\xe7ado da s\xe9rie Llama, oferecendo desempenho compar\xe1vel ao modelo 405B a um custo extremamente baixo. Baseado na estrutura Transformer, e aprimorado por meio de ajuste fino supervisionado (SFT) e aprendizado por refor\xe7o com feedback humano (RLHF) para aumentar a utilidade e a seguran\xe7a. Sua vers\xe3o ajustada para instru\xe7\xf5es \xe9 otimizada para di\xe1logos multil\xedngues, superando muitos modelos de chat de c\xf3digo aberto e fechado em v\xe1rios benchmarks da ind\xfastria. A data limite de conhecimento \xe9 dezembro de 2023."},"meta-llama/llama-3.3-70b-instruct:free":{"description":"Llama 3.3 \xe9 o modelo de linguagem de c\xf3digo aberto multil\xedngue mais avan\xe7ado da s\xe9rie Llama, oferecendo desempenho compar\xe1vel ao modelo 405B a um custo extremamente baixo. Baseado na estrutura Transformer, e aprimorado por meio de ajuste fino supervisionado (SFT) e aprendizado por refor\xe7o com feedback humano (RLHF) para aumentar a utilidade e a seguran\xe7a. Sua vers\xe3o ajustada para instru\xe7\xf5es \xe9 otimizada para di\xe1logos multil\xedngues, superando muitos modelos de chat de c\xf3digo aberto e fechado em v\xe1rios benchmarks da ind\xfastria. A data limite de conhecimento \xe9 dezembro de 2023."},"meta.llama3-1-405b-instruct-v1:0":{"description":"Meta Llama 3.1 405B Instruct \xe9 o maior e mais poderoso modelo da s\xe9rie Llama 3.1 Instruct, sendo um modelo altamente avan\xe7ado para racioc\xednio conversacional e gera\xe7\xe3o de dados sint\xe9ticos, que tamb\xe9m pode ser usado como base para pr\xe9-treinamento ou ajuste fino em dom\xednios espec\xedficos. Os modelos de linguagem de grande escala (LLMs) multil\xedngues oferecidos pelo Llama 3.1 s\xe3o um conjunto de modelos geradores pr\xe9-treinados e ajustados por instru\xe7\xf5es, incluindo tamanhos de 8B, 70B e 405B (entrada/sa\xedda de texto). Os modelos de texto ajustados por instru\xe7\xf5es do Llama 3.1 (8B, 70B, 405B) s\xe3o otimizados para casos de uso de di\xe1logo multil\xedngue e superaram muitos modelos de chat de c\xf3digo aberto dispon\xedveis em benchmarks comuns da ind\xfastria. O Llama 3.1 \xe9 projetado para uso comercial e de pesquisa em v\xe1rias l\xednguas. Os modelos de texto ajustados por instru\xe7\xf5es s\xe3o adequados para chats semelhantes a assistentes, enquanto os modelos pr\xe9-treinados podem se adaptar a v\xe1rias tarefas de gera\xe7\xe3o de linguagem natural. O modelo Llama 3.1 tamb\xe9m suporta a utiliza\xe7\xe3o de sua sa\xedda para melhorar outros modelos, incluindo gera\xe7\xe3o de dados sint\xe9ticos e refinamento. O Llama 3.1 \xe9 um modelo de linguagem autoregressivo que utiliza uma arquitetura de transformador otimizada. As vers\xf5es ajustadas utilizam ajuste fino supervisionado (SFT) e aprendizado por refor\xe7o com feedback humano (RLHF) para alinhar-se \xe0s prefer\xeancias humanas em rela\xe7\xe3o \xe0 utilidade e seguran\xe7a."},"meta.llama3-1-70b-instruct-v1:0":{"description":"A vers\xe3o atualizada do Meta Llama 3.1 70B Instruct, incluindo um comprimento de contexto expandido de 128K, multilinguismo e capacidades de racioc\xednio aprimoradas. Os modelos de linguagem de grande porte (LLMs) do Llama 3.1 s\xe3o um conjunto de modelos geradores pr\xe9-treinados e ajustados por instru\xe7\xf5es, incluindo tamanhos de 8B, 70B e 405B (entrada/sa\xedda de texto). Os modelos de texto ajustados por instru\xe7\xf5es do Llama 3.1 (8B, 70B, 405B) s\xe3o otimizados para casos de uso de di\xe1logo multil\xedngue e superaram muitos modelos de chat de c\xf3digo aberto dispon\xedveis em benchmarks de ind\xfastria comuns. O Llama 3.1 \xe9 projetado para uso comercial e de pesquisa em v\xe1rias l\xednguas. Os modelos de texto ajustados por instru\xe7\xf5es s\xe3o adequados para chats semelhantes a assistentes, enquanto os modelos pr\xe9-treinados podem se adaptar a v\xe1rias tarefas de gera\xe7\xe3o de linguagem natural. O modelo Llama 3.1 tamb\xe9m suporta a utiliza\xe7\xe3o de suas sa\xeddas para melhorar outros modelos, incluindo gera\xe7\xe3o de dados sint\xe9ticos e refinamento. O Llama 3.1 \xe9 um modelo de linguagem autoregressivo usando uma arquitetura de transformador otimizada. As vers\xf5es ajustadas utilizam ajuste fino supervisionado (SFT) e aprendizado por refor\xe7o com feedback humano (RLHF) para alinhar-se \xe0s prefer\xeancias humanas por ajuda e seguran\xe7a."},"meta.llama3-1-8b-instruct-v1:0":{"description":"A vers\xe3o atualizada do Meta Llama 3.1 8B Instruct, incluindo um comprimento de contexto expandido de 128K, multilinguismo e capacidades de racioc\xednio aprimoradas. Os modelos de linguagem de grande porte (LLMs) do Llama 3.1 s\xe3o um conjunto de modelos geradores pr\xe9-treinados e ajustados por instru\xe7\xf5es, incluindo tamanhos de 8B, 70B e 405B (entrada/sa\xedda de texto). Os modelos de texto ajustados por instru\xe7\xf5es do Llama 3.1 (8B, 70B, 405B) s\xe3o otimizados para casos de uso de di\xe1logo multil\xedngue e superaram muitos modelos de chat de c\xf3digo aberto dispon\xedveis em benchmarks de ind\xfastria comuns. O Llama 3.1 \xe9 projetado para uso comercial e de pesquisa em v\xe1rias l\xednguas. Os modelos de texto ajustados por instru\xe7\xf5es s\xe3o adequados para chats semelhantes a assistentes, enquanto os modelos pr\xe9-treinados podem se adaptar a v\xe1rias tarefas de gera\xe7\xe3o de linguagem natural. O modelo Llama 3.1 tamb\xe9m suporta a utiliza\xe7\xe3o de suas sa\xeddas para melhorar outros modelos, incluindo gera\xe7\xe3o de dados sint\xe9ticos e refinamento. O Llama 3.1 \xe9 um modelo de linguagem autoregressivo usando uma arquitetura de transformador otimizada. As vers\xf5es ajustadas utilizam ajuste fino supervisionado (SFT) e aprendizado por refor\xe7o com feedback humano (RLHF) para alinhar-se \xe0s prefer\xeancias humanas por ajuda e seguran\xe7a."},"meta.llama3-70b-instruct-v1:0":{"description":"Meta Llama 3 \xe9 um modelo de linguagem de grande escala (LLM) aberto voltado para desenvolvedores, pesquisadores e empresas, projetado para ajud\xe1-los a construir, experimentar e expandir suas ideias de IA geradora de forma respons\xe1vel. Como parte de um sistema de base para inova\xe7\xe3o da comunidade global, \xe9 ideal para cria\xe7\xe3o de conte\xfado, IA de di\xe1logo, compreens\xe3o de linguagem, P&D e aplica\xe7\xf5es empresariais."},"meta.llama3-8b-instruct-v1:0":{"description":"Meta Llama 3 \xe9 um modelo de linguagem de grande escala (LLM) aberto voltado para desenvolvedores, pesquisadores e empresas, projetado para ajud\xe1-los a construir, experimentar e expandir suas ideias de IA geradora de forma respons\xe1vel. Como parte de um sistema de base para inova\xe7\xe3o da comunidade global, \xe9 ideal para dispositivos de borda com capacidade de computa\xe7\xe3o e recursos limitados, al\xe9m de tempos de treinamento mais r\xe1pidos."},"meta/Llama-3.2-11B-Vision-Instruct":{"description":"Capacidades avan\xe7adas de racioc\xednio visual em imagens de alta resolu\xe7\xe3o, adequado para aplica\xe7\xf5es de compreens\xe3o visual."},"meta/Llama-3.2-90B-Vision-Instruct":{"description":"Capacidades avan\xe7adas de racioc\xednio visual para aplica\xe7\xf5es de agentes de compreens\xe3o visual."},"meta/Llama-3.3-70B-Instruct":{"description":"Llama 3.3 \xe9 o modelo de linguagem grande multil\xedngue open source mais avan\xe7ado da s\xe9rie Llama, oferecendo desempenho compar\xe1vel a modelos de 405B a um custo muito baixo. Baseado na arquitetura Transformer, aprimorado por fine-tuning supervisionado (SFT) e aprendizado por refor\xe7o com feedback humano (RLHF) para melhorar utilidade e seguran\xe7a. A vers\xe3o ajustada para instru\xe7\xf5es \xe9 otimizada para di\xe1logos multil\xedngues e supera muitos modelos de chat open source e propriet\xe1rios em v\xe1rios benchmarks do setor. Data de corte do conhecimento: dezembro de 2023."},"meta/Meta-Llama-3-70B-Instruct":{"description":"Um poderoso modelo de 70 bilh\xf5es de par\xe2metros, com desempenho excelente em racioc\xednio, codifica\xe7\xe3o e ampla gama de aplica\xe7\xf5es lingu\xedsticas."},"meta/Meta-Llama-3-8B-Instruct":{"description":"Um modelo vers\xe1til de 8 bilh\xf5es de par\xe2metros, otimizado para tarefas de di\xe1logo e gera\xe7\xe3o de texto."},"meta/Meta-Llama-3.1-405B-Instruct":{"description":"Modelo de texto ajustado para instru\xe7\xf5es Llama 3.1, otimizado para casos de uso de di\xe1logo multil\xedngue, com desempenho superior em benchmarks comuns do setor entre muitos modelos de chat open source e propriet\xe1rios dispon\xedveis."},"meta/Meta-Llama-3.1-70B-Instruct":{"description":"Modelo de texto ajustado para instru\xe7\xf5es Llama 3.1, otimizado para casos de uso de di\xe1logo multil\xedngue, com desempenho superior em benchmarks comuns do setor entre muitos modelos de chat open source e propriet\xe1rios dispon\xedveis."},"meta/Meta-Llama-3.1-8B-Instruct":{"description":"Modelo de texto ajustado para instru\xe7\xf5es Llama 3.1, otimizado para casos de uso de di\xe1logo multil\xedngue, com desempenho superior em benchmarks comuns do setor entre muitos modelos de chat open source e propriet\xe1rios dispon\xedveis."},"meta/llama-3-70b":{"description":"Modelo open source de 70 bilh\xf5es de par\xe2metros ajustado pela Meta para conformidade com instru\xe7\xf5es. Atendido pela Groq usando seu hardware personalizado de unidade de processamento de linguagem (LPU) para fornecer infer\xeancia r\xe1pida e eficiente."},"meta/llama-3-8b":{"description":"Modelo open source de 8 bilh\xf5es de par\xe2metros ajustado pela Meta para conformidade com instru\xe7\xf5es. Atendido pela Groq usando seu hardware personalizado de unidade de processamento de linguagem (LPU) para fornecer infer\xeancia r\xe1pida e eficiente."},"meta/llama-3.1-405b-instruct":{"description":"LLM avan\xe7ado, suporta gera\xe7\xe3o de dados sint\xe9ticos, destila\xe7\xe3o de conhecimento e racioc\xednio, adequado para chatbots, programa\xe7\xe3o e tarefas de dom\xednio espec\xedfico."},"meta/llama-3.1-70b":{"description":"Vers\xe3o atualizada do Meta Llama 3 70B Instruct, incluindo extens\xe3o do comprimento de contexto para 128K, multil\xedngue e capacidades de racioc\xednio aprimoradas."},"meta/llama-3.1-70b-instruct":{"description":"Capacita di\xe1logos complexos, com excelente compreens\xe3o de contexto, capacidade de racioc\xednio e gera\xe7\xe3o de texto."},"meta/llama-3.1-8b":{"description":"Llama 3.1 8B suporta janela de contexto de 128K, tornando-o ideal para interfaces de di\xe1logo em tempo real e an\xe1lise de dados, oferecendo economia significativa de custos em compara\xe7\xe3o com modelos maiores. Atendido pela Groq usando seu hardware personalizado de unidade de processamento de linguagem (LPU) para fornecer infer\xeancia r\xe1pida e eficiente."},"meta/llama-3.1-8b-instruct":{"description":"Modelo de ponta avan\xe7ado, com compreens\xe3o de linguagem, excelente capacidade de racioc\xednio e gera\xe7\xe3o de texto."},"meta/llama-3.2-11b":{"description":"Modelo de gera\xe7\xe3o de racioc\xednio visual ajustado por instru\xe7\xe3o (entrada de texto + imagem / sa\xedda de texto), otimizado para reconhecimento visual, racioc\xednio sobre imagens, gera\xe7\xe3o de legendas e respostas a perguntas gerais sobre imagens."},"meta/llama-3.2-11b-vision-instruct":{"description":"Modelo de vis\xe3o-linguagem de ponta, especializado em racioc\xednio de alta qualidade a partir de imagens."},"meta/llama-3.2-1b":{"description":"Modelo apenas de texto, suportando casos de uso em dispositivos, como recupera\xe7\xe3o de conhecimento local multil\xedngue, resumo e reescrita."},"meta/llama-3.2-1b-instruct":{"description":"Modelo de linguagem de ponta avan\xe7ado e compacto, com compreens\xe3o de linguagem, excelente capacidade de racioc\xednio e gera\xe7\xe3o de texto."},"meta/llama-3.2-3b":{"description":"Modelo apenas de texto, cuidadosamente ajustado para suportar casos de uso em dispositivos, como recupera\xe7\xe3o de conhecimento local multil\xedngue, resumo e reescrita."},"meta/llama-3.2-3b-instruct":{"description":"Modelo de linguagem de ponta avan\xe7ado e compacto, com compreens\xe3o de linguagem, excelente capacidade de racioc\xednio e gera\xe7\xe3o de texto."},"meta/llama-3.2-90b":{"description":"Modelo de gera\xe7\xe3o de racioc\xednio visual ajustado por instru\xe7\xe3o (entrada de texto + imagem / sa\xedda de texto), otimizado para reconhecimento visual, racioc\xednio sobre imagens, gera\xe7\xe3o de legendas e respostas a perguntas gerais sobre imagens."},"meta/llama-3.2-90b-vision-instruct":{"description":"Modelo de vis\xe3o-linguagem de ponta, especializado em racioc\xednio de alta qualidade a partir de imagens."},"meta/llama-3.3-70b":{"description":"Combina\xe7\xe3o perfeita de desempenho e efici\xeancia. Este modelo suporta IA de di\xe1logo de alto desempenho, projetado para cria\xe7\xe3o de conte\xfado, aplica\xe7\xf5es empresariais e pesquisa, oferecendo capacidades avan\xe7adas de compreens\xe3o de linguagem, incluindo resumo de texto, classifica\xe7\xe3o, an\xe1lise de sentimento e gera\xe7\xe3o de c\xf3digo."},"meta/llama-3.3-70b-instruct":{"description":"Modelo LLM avan\xe7ado, especializado em racioc\xednio, matem\xe1tica, conhecimento geral e chamadas de fun\xe7\xe3o."},"meta/llama-4-maverick":{"description":"A cole\xe7\xe3o de modelos Llama 4 \xe9 uma IA multimodal nativa, suportando experi\xeancias de texto e multimodais. Esses modelos utilizam arquitetura de especialistas mistos para oferecer desempenho l\xedder do setor em compreens\xe3o de texto e imagem. Llama 4 Maverick, um modelo de 17 bilh\xf5es de par\xe2metros com 128 especialistas. Atendido pela DeepInfra."},"meta/llama-4-scout":{"description":"A cole\xe7\xe3o de modelos Llama 4 \xe9 uma IA multimodal nativa, suportando experi\xeancias de texto e multimodais. Esses modelos utilizam arquitetura de especialistas mistos para oferecer desempenho l\xedder do setor em compreens\xe3o de texto e imagem. Llama 4 Scout, um modelo de 17 bilh\xf5es de par\xe2metros com 16 especialistas. Atendido pela DeepInfra."},"microsoft/Phi-3-medium-128k-instruct":{"description":"O mesmo modelo Phi-3-medium, mas com contexto maior, adequado para RAG ou poucos prompts."},"microsoft/Phi-3-medium-4k-instruct":{"description":"Um modelo de 14 bilh\xf5es de par\xe2metros, com qualidade superior ao Phi-3-mini, focado em dados de alta qualidade e racioc\xednio intensivo."},"microsoft/Phi-3-mini-128k-instruct":{"description":"O mesmo modelo Phi-3-mini, mas com contexto maior, adequado para RAG ou poucos prompts."},"microsoft/Phi-3-mini-4k-instruct":{"description":"O menor membro da fam\xedlia Phi-3, otimizado para qualidade e baixa lat\xeancia."},"microsoft/Phi-3-small-128k-instruct":{"description":"O mesmo modelo Phi-3-small, mas com contexto maior, adequado para RAG ou poucos prompts."},"microsoft/Phi-3-small-8k-instruct":{"description":"Um modelo de 7 bilh\xf5es de par\xe2metros, com qualidade superior ao Phi-3-mini, focado em dados de alta qualidade e racioc\xednio intensivo."},"microsoft/Phi-3.5-mini-instruct":{"description":"Vers\xe3o atualizada do modelo Phi-3-mini."},"microsoft/Phi-3.5-vision-instruct":{"description":"Vers\xe3o atualizada do modelo Phi-3-vision."},"microsoft/WizardLM-2-8x22B":{"description":"WizardLM 2 \xe9 um modelo de linguagem fornecido pela Microsoft AI, que se destaca em di\xe1logos complexos, multil\xedngue, racioc\xednio e assistentes inteligentes."},"microsoft/wizardlm-2-8x22b":{"description":"WizardLM-2 8x22B \xe9 o modelo Wizard mais avan\xe7ado da Microsoft, demonstrando um desempenho extremamente competitivo."},"minicpm-v":{"description":"MiniCPM-V \xe9 a nova gera\xe7\xe3o de grandes modelos multimodais lan\xe7ada pela OpenBMB, com excelente capacidade de reconhecimento de OCR e compreens\xe3o multimodal, suportando uma ampla gama de cen\xe1rios de aplica\xe7\xe3o."},"minimax-m2":{"description":"MiniMax M2 \xe9 um modelo de linguagem de grande escala, eficiente e desenvolvido para fluxos de trabalho de codifica\xe7\xe3o e agentes."},"minimax/minimax-m2":{"description":"Projetado para codifica\xe7\xe3o eficiente e fluxos de trabalho com agentes."},"minimaxai/minimax-m2":{"description":"O MiniMax-M2 \xe9 um modelo de especialistas mistos (MoE) compacto, r\xe1pido e econ\xf4mico, com 230 bilh\xf5es de par\xe2metros totais e 10 bilh\xf5es de par\xe2metros ativos, projetado para oferecer desempenho de alto n\xedvel em tarefas de codifica\xe7\xe3o e agentes, mantendo uma intelig\xeancia geral poderosa. O modelo se destaca em edi\xe7\xe3o de m\xfaltiplos arquivos, ciclos de codifica\xe7\xe3o-execu\xe7\xe3o-corre\xe7\xe3o, verifica\xe7\xe3o e corre\xe7\xe3o de testes, bem como em cadeias de ferramentas complexas e de longo alcance, sendo a escolha ideal para fluxos de trabalho de desenvolvedores."},"ministral-3b-latest":{"description":"Ministral 3B \xe9 o modelo de ponta da Mistral para aplica\xe7\xf5es de edge computing."},"ministral-8b-latest":{"description":"Ministral 8B \xe9 o modelo de edge computing altamente custo-efetivo da Mistral."},"mistral":{"description":"Mistral \xe9 um modelo de 7B lan\xe7ado pela Mistral AI, adequado para demandas de processamento de linguagem vari\xe1veis."},"mistral-ai/Mistral-Large-2411":{"description":"O modelo principal da Mistral, ideal para tarefas complexas que requerem racioc\xednio em grande escala ou alta especializa\xe7\xe3o (gera\xe7\xe3o de texto sint\xe9tico, gera\xe7\xe3o de c\xf3digo, RAG ou agentes)."},"mistral-ai/Mistral-Nemo":{"description":"Mistral Nemo \xe9 um modelo de linguagem avan\xe7ado (LLM) que oferece capacidades de racioc\xednio, conhecimento mundial e codifica\xe7\xe3o l\xedderes em sua categoria de tamanho."},"mistral-ai/mistral-small-2503":{"description":"Mistral Small \xe9 adequado para qualquer tarefa baseada em linguagem que exija alta efici\xeancia e baixa lat\xeancia."},"mistral-large":{"description":"Mixtral Large \xe9 o modelo de destaque da Mistral, combinando capacidades de gera\xe7\xe3o de c\xf3digo, matem\xe1tica e racioc\xednio, suportando uma janela de contexto de 128k."},"mistral-large-instruct":{"description":"Mistral-Large-Instruct-2407 \xe9 um modelo avan\xe7ado de linguagem densa (LLM) com 123 bilh\xf5es de par\xe2metros, oferecendo capacidades de racioc\xednio, conhecimento e codifica\xe7\xe3o de \xfaltima gera\xe7\xe3o."},"mistral-large-latest":{"description":"Mistral Large \xe9 o modelo de destaque, especializado em tarefas multil\xedngues, racioc\xednio complexo e gera\xe7\xe3o de c\xf3digo, sendo a escolha ideal para aplica\xe7\xf5es de alto n\xedvel."},"mistral-medium-latest":{"description":"O Mistral Medium 3 oferece desempenho de ponta a um custo 8 vezes menor e simplifica fundamentalmente a implanta\xe7\xe3o empresarial."},"mistral-nemo":{"description":"Mistral Nemo \xe9 um modelo de 12B desenvolvido em colabora\xe7\xe3o entre a Mistral AI e a NVIDIA, oferecendo desempenho eficiente."},"mistral-nemo-instruct":{"description":"Mistral-Nemo-Instruct-2407 \xe9 um modelo de linguagem grande (LLM) ajustado para instru\xe7\xf5es, baseado no Mistral-Nemo-Base-2407."},"mistral-small":{"description":"Mistral Small pode ser usado em qualquer tarefa baseada em linguagem que exija alta efici\xeancia e baixa lat\xeancia."},"mistral-small-latest":{"description":"Mistral Small \xe9 uma op\xe7\xe3o de alto custo-benef\xedcio, r\xe1pida e confi\xe1vel, adequada para casos de uso como tradu\xe7\xe3o, resumo e an\xe1lise de sentimentos."},"mistral/codestral":{"description":"Mistral Codestral 25.01 \xe9 um modelo de codifica\xe7\xe3o de ponta, otimizado para casos de uso de baixa lat\xeancia e alta frequ\xeancia. Fluente em mais de 80 linguagens de programa\xe7\xe3o, destaca-se em tarefas como preenchimento intermedi\xe1rio (FIM), corre\xe7\xe3o de c\xf3digo e gera\xe7\xe3o de testes."},"mistral/codestral-embed":{"description":"Modelo de embeddings de c\xf3digo que pode ser incorporado em bancos de dados e reposit\xf3rios de c\xf3digo para suportar assistentes de codifica\xe7\xe3o."},"mistral/devstral-small":{"description":"Devstral \xe9 um grande modelo de linguagem agente para tarefas de engenharia de software, tornando-o uma excelente escolha para agentes de engenharia de software."},"mistral/magistral-medium":{"description":"Pensamento complexo suportado por compreens\xe3o profunda, com racioc\xednio transparente que voc\xea pode seguir e verificar. O modelo mant\xe9m racioc\xednio de alta fidelidade em m\xfaltiplos idiomas, mesmo ao alternar idiomas no meio da tarefa."},"mistral/magistral-small":{"description":"Pensamento complexo suportado por compreens\xe3o profunda, com racioc\xednio transparente que voc\xea pode seguir e verificar. O modelo mant\xe9m racioc\xednio de alta fidelidade em m\xfaltiplos idiomas, mesmo ao alternar idiomas no meio da tarefa."},"mistral/ministral-3b":{"description":"Um modelo compacto e eficiente para tarefas em dispositivos, como assistentes inteligentes e an\xe1lises locais, oferecendo desempenho de baixa lat\xeancia."},"mistral/ministral-8b":{"description":"Um modelo mais poderoso, com infer\xeancia mais r\xe1pida e eficiente em mem\xf3ria, ideal para fluxos de trabalho complexos e aplica\xe7\xf5es de borda exigentes."},"mistral/mistral-embed":{"description":"Modelo universal de embeddings de texto para busca sem\xe2ntica, similaridade, agrupamento e fluxos de trabalho RAG."},"mistral/mistral-large":{"description":"Mistral Large \xe9 ideal para tarefas complexas que exigem grandes capacidades de racioc\xednio ou alta especializa\xe7\xe3o — como gera\xe7\xe3o de texto sint\xe9tico, gera\xe7\xe3o de c\xf3digo, RAG ou agentes."},"mistral/mistral-small":{"description":"Mistral Small \xe9 ideal para tarefas simples que podem ser processadas em lote — como classifica\xe7\xe3o, suporte ao cliente ou gera\xe7\xe3o de texto. Oferece excelente desempenho a um pre\xe7o acess\xedvel."},"mistral/mixtral-8x22b-instruct":{"description":"Modelo 8x22b Instruct. 8x22b \xe9 um modelo open source de especialistas mistos atendido pela Mistral."},"mistral/pixtral-12b":{"description":"Um modelo de 12 bilh\xf5es com capacidades de compreens\xe3o de imagem, al\xe9m de texto."},"mistral/pixtral-large":{"description":"Pixtral Large \xe9 o segundo modelo da nossa fam\xedlia multimodal, demonstrando compreens\xe3o de imagem em n\xedvel de ponta. Especificamente, o modelo pode entender documentos, gr\xe1ficos e imagens naturais, mantendo a lideran\xe7a em compreens\xe3o de texto do Mistral Large 2."},"mistralai/Mistral-7B-Instruct-v0.1":{"description":"Mistral (7B) Instruct \xe9 conhecido por seu alto desempenho, adequado para diversas tarefas de linguagem."},"mistralai/Mistral-7B-Instruct-v0.2":{"description":"Mistral 7B \xe9 um modelo ajustado sob demanda, oferecendo respostas otimizadas para tarefas."},"mistralai/Mistral-7B-Instruct-v0.3":{"description":"Mistral (7B) Instruct v0.3 oferece capacidade computacional eficiente e compreens\xe3o de linguagem natural, adequada para uma ampla gama de aplica\xe7\xf5es."},"mistralai/Mistral-7B-v0.1":{"description":"Mistral 7B \xe9 um modelo compacto, mas de alto desempenho, especializado em processamento em lote e tarefas simples, como classifica\xe7\xe3o e gera\xe7\xe3o de texto, com boa capacidade de racioc\xednio."},"mistralai/Mixtral-8x22B-Instruct-v0.1":{"description":"Mixtral-8x22B Instruct (141B) \xe9 um super modelo de linguagem, suportando demandas de processamento extremamente altas."},"mistralai/Mixtral-8x7B-Instruct-v0.1":{"description":"Mixtral 8x7B \xe9 um modelo de especialistas esparsos pr\xe9-treinados, utilizado para tarefas de texto de uso geral."},"mistralai/Mixtral-8x7B-v0.1":{"description":"Mixtral 8x7B \xe9 um modelo de especialistas esparsos, que utiliza m\xfaltiplos par\xe2metros para aumentar a velocidade de racioc\xednio, ideal para tarefas de gera\xe7\xe3o de c\xf3digo e multil\xedngues."},"mistralai/mistral-nemo":{"description":"Mistral Nemo \xe9 um modelo de 7.3B par\xe2metros com suporte multil\xedngue e programa\xe7\xe3o de alto desempenho."},"mixtral":{"description":"Mixtral \xe9 o modelo de especialistas da Mistral AI, com pesos de c\xf3digo aberto, oferecendo suporte em gera\xe7\xe3o de c\xf3digo e compreens\xe3o de linguagem."},"mixtral-8x7b-32768":{"description":"Mixtral 8x7B oferece alta capacidade de computa\xe7\xe3o paralela com toler\xe2ncia a falhas, adequado para tarefas complexas."},"mixtral:8x22b":{"description":"Mixtral \xe9 o modelo de especialistas da Mistral AI, com pesos de c\xf3digo aberto, oferecendo suporte em gera\xe7\xe3o de c\xf3digo e compreens\xe3o de linguagem."},"moonshot-v1-128k":{"description":"Moonshot V1 128K \xe9 um modelo com capacidade de processamento de contexto ultra longo, adequado para gerar textos muito longos, atendendo a demandas complexas de gera\xe7\xe3o, capaz de lidar com at\xe9 128.000 tokens, ideal para pesquisa, acad\xeamicos e gera\xe7\xe3o de documentos extensos."},"moonshot-v1-128k-vision-preview":{"description":"O modelo visual Kimi (incluindo moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-preview, etc.) \xe9 capaz de entender o conte\xfado das imagens, incluindo texto, cores e formas dos objetos."},"moonshot-v1-32k":{"description":"Moonshot V1 32K oferece capacidade de processamento de contexto de comprimento m\xe9dio, capaz de lidar com 32.768 tokens, especialmente adequado para gerar v\xe1rios documentos longos e di\xe1logos complexos, aplic\xe1vel em cria\xe7\xe3o de conte\xfado, gera\xe7\xe3o de relat\xf3rios e sistemas de di\xe1logo."},"moonshot-v1-32k-vision-preview":{"description":"O modelo visual Kimi (incluindo moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-preview, etc.) \xe9 capaz de entender o conte\xfado das imagens, incluindo texto, cores e formas dos objetos."},"moonshot-v1-8k":{"description":"Moonshot V1 8K \xe9 projetado para tarefas de gera\xe7\xe3o de texto curto, com desempenho de processamento eficiente, capaz de lidar com 8.192 tokens, ideal para di\xe1logos curtos, anota\xe7\xf5es e gera\xe7\xe3o r\xe1pida de conte\xfado."},"moonshot-v1-8k-vision-preview":{"description":"O modelo visual Kimi (incluindo moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-preview, etc.) \xe9 capaz de entender o conte\xfado das imagens, incluindo texto, cores e formas dos objetos."},"moonshot-v1-auto":{"description":"O Moonshot V1 Auto pode escolher o modelo adequado com base na quantidade de Tokens ocupados pelo contexto atual."},"moonshotai/Kimi-Dev-72B":{"description":"Kimi-Dev-72B \xe9 um modelo de c\xf3digo aberto de grande porte, otimizado por meio de aprendizado refor\xe7ado em larga escala, capaz de gerar patches robustos e prontos para produ\xe7\xe3o. Este modelo alcan\xe7ou uma nova pontua\xe7\xe3o m\xe1xima de 60,4% no SWE-bench Verified, estabelecendo um recorde entre modelos de c\xf3digo aberto em tarefas automatizadas de engenharia de software, como corre\xe7\xe3o de defeitos e revis\xe3o de c\xf3digo."},"moonshotai/Kimi-K2-Instruct-0905":{"description":"Kimi K2-Instruct-0905 \xe9 a vers\xe3o mais recente e poderosa do Kimi K2. Trata-se de um modelo de linguagem de especialistas mistos (MoE) de ponta, com um total de 1 trilh\xe3o de par\xe2metros e 32 bilh\xf5es de par\xe2metros ativados. As principais caracter\xedsticas deste modelo incluem: intelig\xeancia aprimorada para codifica\xe7\xe3o de agentes, demonstrando melhorias significativas em testes de refer\xeancia p\xfablicos e em tarefas reais de codifica\xe7\xe3o de agentes; experi\xeancia de codifica\xe7\xe3o front-end melhorada, com avan\xe7os tanto na est\xe9tica quanto na funcionalidade da programa\xe7\xe3o front-end."},"moonshotai/kimi-k2":{"description":"Kimi K2 \xe9 um modelo de linguagem de especialistas mistos (MoE) em grande escala desenvolvido pela Moonshot AI, com 1 trilh\xe3o de par\xe2metros totais e 32 bilh\xf5es de par\xe2metros ativos por passagem. Otimizado para capacidades de agente, incluindo uso avan\xe7ado de ferramentas, racioc\xednio e s\xedntese de c\xf3digo."},"moonshotai/kimi-k2-0905":{"description":"O modelo kimi-k2-0905-preview possui comprimento de contexto de 256k, com capacidades aprimoradas de Agentic Coding, maior est\xe9tica e praticidade do c\xf3digo front-end, al\xe9m de melhor compreens\xe3o do contexto."},"moonshotai/kimi-k2-instruct-0905":{"description":"O modelo kimi-k2-0905-preview possui comprimento de contexto de 256k, com capacidades aprimoradas de Agentic Coding, maior est\xe9tica e praticidade do c\xf3digo front-end, al\xe9m de melhor compreens\xe3o do contexto."},"morph/morph-v3-fast":{"description":"Morph oferece um modelo de IA especializado que aplica rapidamente as altera\xe7\xf5es de c\xf3digo sugeridas por modelos de ponta como Claude ou GPT-4o aos seus arquivos de c\xf3digo existentes — R\xc1PIDO - mais de 4500 tokens/segundo. Atua como a etapa final no fluxo de trabalho de codifica\xe7\xe3o de IA. Suporta 16k tokens de entrada e 16k tokens de sa\xedda."},"morph/morph-v3-large":{"description":"Morph oferece um modelo de IA especializado que aplica as altera\xe7\xf5es de c\xf3digo sugeridas por modelos de ponta como Claude ou GPT-4o aos seus arquivos de c\xf3digo existentes — R\xc1PIDO - mais de 2500 tokens/segundo. Atua como a etapa final no fluxo de trabalho de codifica\xe7\xe3o de IA. Suporta 16k tokens de entrada e 16k tokens de sa\xedda."},"nousresearch/hermes-2-pro-llama-3-8b":{"description":"Hermes 2 Pro Llama 3 8B \xe9 uma vers\xe3o aprimorada do Nous Hermes 2, contendo os conjuntos de dados mais recentes desenvolvidos internamente."},"nvidia/Llama-3.1-Nemotron-70B-Instruct-HF":{"description":"Llama 3.1 Nemotron 70B \xe9 um modelo de linguagem em larga escala personalizado pela NVIDIA, projetado para aumentar a utilidade das respostas geradas pelo LLM em rela\xe7\xe3o \xe0s consultas dos usu\xe1rios. Este modelo se destacou em benchmarks como Arena Hard, AlpacaEval 2 LC e GPT-4-Turbo MT-Bench, ocupando o primeiro lugar em todos os tr\xeas benchmarks de alinhamento autom\xe1tico at\xe9 1\xba de outubro de 2024. O modelo foi treinado usando RLHF (especialmente REINFORCE), Llama-3.1-Nemotron-70B-Reward e HelpSteer2-Preference prompts, com base no modelo Llama-3.1-70B-Instruct."},"nvidia/llama-3.1-nemotron-51b-instruct":{"description":"Modelo de linguagem \xfanico, oferecendo precis\xe3o e efici\xeancia incompar\xe1veis."},"nvidia/llama-3.1-nemotron-70b-instruct":{"description":"Llama-3.1-Nemotron-70B-Instruct \xe9 um modelo de linguagem de grande porte personalizado pela NVIDIA, projetado para melhorar a utilidade das respostas geradas pelo LLM."},"o1":{"description":"Focado em racioc\xednio avan\xe7ado e resolu\xe7\xe3o de problemas complexos, incluindo tarefas matem\xe1ticas e cient\xedficas. Muito adequado para aplicativos que exigem compreens\xe3o profunda do contexto e gerenciamento de fluxos de trabalho."},"o1-mini":{"description":"o1-mini \xe9 um modelo de racioc\xednio r\xe1pido e econ\xf4mico, projetado para cen\xe1rios de programa\xe7\xe3o, matem\xe1tica e ci\xeancias. Este modelo possui um contexto de 128K e uma data limite de conhecimento em outubro de 2023."},"o1-preview":{"description":"Focado em racioc\xednio avan\xe7ado e na resolu\xe7\xe3o de problemas complexos, incluindo tarefas de matem\xe1tica e ci\xeancias. Muito adequado para aplica\xe7\xf5es que exigem compreens\xe3o profunda do contexto e fluxos de trabalho aut\xf4nomos."},"o1-pro":{"description":"A s\xe9rie o1 \xe9 treinada com aprendizado por refor\xe7o, capaz de pensar antes de responder e executar tarefas complexas de racioc\xednio. O modelo o1-pro utiliza mais recursos computacionais para um pensamento mais profundo, oferecendo respostas de qualidade superior continuamente."},"o3":{"description":"o3 \xe9 um modelo vers\xe1til e poderoso, com excelente desempenho em v\xe1rias \xe1reas. Ele estabelece novos padr\xf5es para tarefas de matem\xe1tica, ci\xeancia, programa\xe7\xe3o e racioc\xednio visual. Tamb\xe9m \xe9 bom em reda\xe7\xe3o t\xe9cnica e seguimento de instru\xe7\xf5es. Os usu\xe1rios podem utiliz\xe1-lo para analisar textos, c\xf3digos e imagens, resolvendo problemas complexos em m\xfaltiplas etapas."},"o3-2025-04-16":{"description":"o3 \xe9 o novo modelo de racioc\xednio da OpenAI, suporta entrada de texto e imagem e gera texto, adequado para tarefas complexas que exigem amplo conhecimento geral."},"o3-deep-research":{"description":"o3-deep-research \xe9 o nosso modelo avan\xe7ado de pesquisa profunda, projetado para lidar com tarefas complexas de pesquisa em m\xfaltiplas etapas. Ele pode buscar e sintetizar informa\xe7\xf5es da internet, al\xe9m de acessar e utilizar seus dados pr\xf3prios por meio do conector MCP."},"o3-mini":{"description":"o3-mini \xe9 nosso mais recente modelo de infer\xeancia em miniatura, oferecendo alta intelig\xeancia com os mesmos custos e metas de lat\xeancia que o o1-mini."},"o3-pro":{"description":"O modelo o3-pro utiliza mais computa\xe7\xe3o para pensar mais profundamente e sempre fornecer respostas melhores, suportado apenas via API Responses."},"o3-pro-2025-06-10":{"description":"o3 Pro \xe9 o novo modelo de racioc\xednio da OpenAI, suporta entrada de texto e imagem e gera texto, adequado para tarefas complexas que exigem amplo conhecimento geral."},"o4-mini":{"description":"o4-mini \xe9 nosso mais recente modelo compacto da s\xe9rie o. Ele \xe9 otimizado para infer\xeancia r\xe1pida e eficaz, apresentando alta efici\xeancia e desempenho em tarefas de codifica\xe7\xe3o e visuais."},"o4-mini-2025-04-16":{"description":"o4-mini \xe9 um modelo de racioc\xednio da OpenAI, suporta entrada de texto e imagem e gera texto, adequado para tarefas complexas que exigem amplo conhecimento geral. Este modelo possui contexto de 200K."},"o4-mini-deep-research":{"description":"o4-mini-deep-research \xe9 o nosso modelo de pesquisa profunda mais r\xe1pido e acess\xedvel — ideal para lidar com tarefas complexas de pesquisa em m\xfaltiplas etapas. Ele pode buscar e sintetizar informa\xe7\xf5es da internet, al\xe9m de acessar e utilizar seus dados pr\xf3prios por meio do conector MCP."},"open-codestral-mamba":{"description":"Codestral Mamba \xe9 um modelo de linguagem Mamba 2 focado em gera\xe7\xe3o de c\xf3digo, oferecendo forte suporte para tarefas avan\xe7adas de codifica\xe7\xe3o e racioc\xednio."},"open-mistral-7b":{"description":"Mistral 7B \xe9 um modelo compacto, mas de alto desempenho, especializado em processamento em lote e tarefas simples, como classifica\xe7\xe3o e gera\xe7\xe3o de texto, com boa capacidade de racioc\xednio."},"open-mistral-nemo":{"description":"Mistral Nemo \xe9 um modelo de 12B desenvolvido em colabora\xe7\xe3o com a Nvidia, oferecendo excelente desempenho em racioc\xednio e codifica\xe7\xe3o, f\xe1cil de integrar e substituir."},"open-mixtral-8x22b":{"description":"Mixtral 8x22B \xe9 um modelo de especialistas maior, focado em tarefas complexas, oferecendo excelente capacidade de racioc\xednio e maior taxa de transfer\xeancia."},"open-mixtral-8x7b":{"description":"Mixtral 8x7B \xe9 um modelo de especialistas esparsos, utilizando m\xfaltiplos par\xe2metros para aumentar a velocidade de racioc\xednio, adequado para tarefas de gera\xe7\xe3o de linguagem e c\xf3digo."},"openai/gpt-3.5-turbo":{"description":"O modelo mais capaz e econ\xf4mico da s\xe9rie GPT-3.5 da OpenAI, otimizado para fins de chat, mas tamb\xe9m com bom desempenho em tarefas tradicionais de completamento."},"openai/gpt-3.5-turbo-instruct":{"description":"Capacidades semelhantes aos modelos da era GPT-3. Compat\xedvel com endpoints tradicionais de completamento, em vez de endpoints de completamento de chat."},"openai/gpt-4-turbo":{"description":"O gpt-4-turbo da OpenAI possui amplo conhecimento geral e especializa\xe7\xe3o em dom\xednios, permitindo seguir instru\xe7\xf5es complexas em linguagem natural e resolver problemas dif\xedceis com precis\xe3o. Sua data de corte de conhecimento \xe9 abril de 2023, com janela de contexto de 128.000 tokens."},"openai/gpt-4.1":{"description":"GPT 4.1 \xe9 o modelo principal da OpenAI, adequado para tarefas complexas. \xc9 excelente para resolver problemas interdisciplinares."},"openai/gpt-4.1-mini":{"description":"GPT 4.1 mini equilibra intelig\xeancia, velocidade e custo, tornando-o um modelo atraente para muitos casos de uso."},"openai/gpt-4.1-nano":{"description":"GPT-4.1 nano \xe9 o modelo GPT 4.1 mais r\xe1pido e econ\xf4mico."},"openai/gpt-4o":{"description":"GPT-4o da OpenAI possui amplo conhecimento geral e especializa\xe7\xe3o em dom\xednios, capaz de seguir instru\xe7\xf5es complexas em linguagem natural e resolver problemas dif\xedceis com precis\xe3o. Oferece desempenho equivalente ao GPT-4 Turbo com API mais r\xe1pida e barata."},"openai/gpt-4o-mini":{"description":"GPT-4o mini da OpenAI \xe9 seu modelo pequeno mais avan\xe7ado e econ\xf4mico. \xc9 multimodal (aceita entrada de texto ou imagem e gera texto) e mais inteligente que o gpt-3.5-turbo, mantendo a mesma velocidade."},"openai/gpt-5":{"description":"GPT-5 \xe9 o modelo de linguagem principal da OpenAI, excelente em racioc\xednio complexo, amplo conhecimento do mundo real, tarefas intensivas em c\xf3digo e agentes de m\xfaltiplas etapas."},"openai/gpt-5-mini":{"description":"GPT-5 mini \xe9 um modelo otimizado para custo, com bom desempenho em tarefas de racioc\xednio/chat. Oferece o melhor equil\xedbrio entre velocidade, custo e capacidade."},"openai/gpt-5-nano":{"description":"GPT-5 nano \xe9 um modelo de alto rendimento, excelente para tarefas simples de instru\xe7\xe3o ou classifica\xe7\xe3o."},"openai/gpt-oss-120b":{"description":"Modelo grande de linguagem geral extremamente capaz, com forte capacidade de racioc\xednio control\xe1vel."},"openai/gpt-oss-20b":{"description":"Modelo de linguagem compacto com pesos open source, otimizado para baixa lat\xeancia e ambientes com recursos limitados, incluindo implanta\xe7\xe3o local e na borda."},"openai/o1":{"description":"O o1 da OpenAI \xe9 o modelo principal de racioc\xednio, projetado para problemas complexos que exigem pensamento profundo. Oferece forte capacidade de racioc\xednio e maior precis\xe3o para tarefas complexas de m\xfaltiplas etapas."},"openai/o1-mini":{"description":"o1-mini \xe9 um modelo de racioc\xednio r\xe1pido e econ\xf4mico, projetado para cen\xe1rios de programa\xe7\xe3o, matem\xe1tica e ci\xeancias. Este modelo possui um contexto de 128K e uma data limite de conhecimento em outubro de 2023."},"openai/o1-preview":{"description":"o1 \xe9 o novo modelo de racioc\xednio da OpenAI, adequado para tarefas complexas que exigem amplo conhecimento geral. Este modelo possui um contexto de 128K e uma data limite de conhecimento em outubro de 2023."},"openai/o3":{"description":"O o3 da OpenAI \xe9 o modelo de racioc\xednio mais poderoso, estabelecendo novos padr\xf5es em codifica\xe7\xe3o, matem\xe1tica, ci\xeancia e percep\xe7\xe3o visual. \xc9 excelente para consultas complexas que exigem an\xe1lise multifacetada, com vantagens especiais na an\xe1lise de imagens, gr\xe1ficos e diagramas."},"openai/o3-mini":{"description":"o3-mini \xe9 o mais recente modelo pequeno de racioc\xednio da OpenAI, oferecendo alta intelig\xeancia com os mesmos objetivos de custo e lat\xeancia do o1-mini."},"openai/o3-mini-high":{"description":"o3-mini de alta capacidade de racioc\xednio oferece alta intelig\xeancia com os mesmos objetivos de custo e lat\xeancia que o o1-mini."},"openai/o4-mini":{"description":"O o4-mini da OpenAI oferece racioc\xednio r\xe1pido e econ\xf4mico, com desempenho excepcional para seu tamanho, especialmente em matem\xe1tica (melhor desempenho no benchmark AIME), codifica\xe7\xe3o e tarefas visuais."},"openai/o4-mini-high":{"description":"Vers\xe3o de alto n\xedvel de infer\xeancia do o4-mini, otimizada para infer\xeancia r\xe1pida e eficaz, apresentando alta efici\xeancia e desempenho em tarefas de codifica\xe7\xe3o e visuais."},"openai/text-embedding-3-large":{"description":"O modelo de embeddings mais capaz da OpenAI, adequado para tarefas em ingl\xeas e n\xe3o ingl\xeas."},"openai/text-embedding-3-small":{"description":"Vers\xe3o aprimorada e de melhor desempenho do modelo ada de embeddings da OpenAI."},"openai/text-embedding-ada-002":{"description":"Modelo tradicional de embeddings de texto da OpenAI."},"openrouter/auto":{"description":"Com base no comprimento do contexto, tema e complexidade, sua solicita\xe7\xe3o ser\xe1 enviada para Llama 3 70B Instruct, Claude 3.5 Sonnet (autoajust\xe1vel) ou GPT-4o."},"perplexity/sonar":{"description":"Produto leve da Perplexity com capacidade de pesquisa fundamentada, mais r\xe1pido e barato que o Sonar Pro."},"perplexity/sonar-pro":{"description":"Produto principal da Perplexity com capacidade de pesquisa fundamentada, suportando consultas avan\xe7adas e opera\xe7\xf5es subsequentes."},"perplexity/sonar-reasoning":{"description":"Modelo focado em racioc\xednio que gera cadeias de pensamento (CoT) nas respostas, oferecendo explica\xe7\xf5es detalhadas com pesquisa fundamentada."},"perplexity/sonar-reasoning-pro":{"description":"Modelo avan\xe7ado focado em racioc\xednio que gera cadeias de pensamento (CoT) nas respostas, oferecendo explica\xe7\xf5es abrangentes com capacidade de pesquisa aprimorada e m\xfaltiplas consultas de pesquisa por solicita\xe7\xe3o."},"phi3":{"description":"Phi-3 \xe9 um modelo leve e aberto lan\xe7ado pela Microsoft, adequado para integra\xe7\xe3o eficiente e racioc\xednio de conhecimento em larga escala."},"phi3:14b":{"description":"Phi-3 \xe9 um modelo leve e aberto lan\xe7ado pela Microsoft, adequado para integra\xe7\xe3o eficiente e racioc\xednio de conhecimento em larga escala."},"pixtral-12b-2409":{"description":"O modelo Pixtral demonstra forte capacidade em tarefas de compreens\xe3o de gr\xe1ficos e imagens, perguntas e respostas de documentos, racioc\xednio multimodal e seguimento de instru\xe7\xf5es, podendo ingerir imagens em resolu\xe7\xe3o natural e propor\xe7\xf5es, al\xe9m de processar um n\xfamero arbitr\xe1rio de imagens em uma janela de contexto longa de at\xe9 128K tokens."},"pixtral-large-latest":{"description":"Pixtral Large \xe9 um modelo multimodal de c\xf3digo aberto com 124 bilh\xf5es de par\xe2metros, baseado no Mistral Large 2. Este \xe9 o segundo modelo da nossa fam\xedlia multimodal, demonstrando capacidades de compreens\xe3o de imagem de n\xedvel avan\xe7ado."},"pro-128k":{"description":"Spark Pro 128K possui uma capacidade de processamento de contexto extremamente grande, capaz de lidar com at\xe9 128K de informa\xe7\xf5es contextuais, especialmente adequado para an\xe1lise completa e processamento de associa\xe7\xf5es l\xf3gicas de longo prazo em conte\xfados longos, podendo oferecer l\xf3gica fluida e consistente e suporte a diversas cita\xe7\xf5es em comunica\xe7\xf5es textuais complexas."},"pro-deepseek-r1":{"description":"Modelo exclusivo para servi\xe7os empresariais, com suporte a servi\xe7os simult\xe2neos."},"pro-deepseek-v3":{"description":"Modelo exclusivo para servi\xe7os empresariais, com suporte a servi\xe7os simult\xe2neos."},"qianfan-70b":{"description":"Qianfan 70B, modelo em chin\xeas de grande porte, ideal para gera\xe7\xe3o de conte\xfado de alta qualidade e tarefas de racioc\xednio complexas."},"qianfan-8b":{"description":"Qianfan 8B, modelo geral de porte m\xe9dio, adequado para gera\xe7\xe3o de texto e perguntas e respostas com equil\xedbrio entre custo e desempenho."},"qianfan-agent-intent-32k":{"description":"Qianfan Agent Intent 32K, modelo voltado para reconhecimento de inten\xe7\xe3o e orquestra\xe7\xe3o de agentes, com suporte a contextos longos."},"qianfan-agent-lite-8k":{"description":"Qianfan Agent Lite 8K, modelo leve de agente inteligente, ideal para di\xe1logos de m\xfaltiplas rodadas e orquestra\xe7\xe3o de neg\xf3cios com baixo custo."},"qianfan-agent-speed-32k":{"description":"Qianfan Agent Speed 32K, modelo de agente com alto controle de fluxo, ideal para aplica\xe7\xf5es em larga escala e multitarefa."},"qianfan-agent-speed-8k":{"description":"Qianfan Agent Speed 8K, modelo de agente de alta concorr\xeancia, voltado para di\xe1logos curtos e respostas r\xe1pidas."},"qianfan-check-vl":{"description":"Qianfan Check VL, modelo multimodal para auditoria e detec\xe7\xe3o de conte\xfado, com suporte a conformidade e reconhecimento de imagem e texto."},"qianfan-composition":{"description":"Qianfan Composition, modelo multimodal de cria\xe7\xe3o, com suporte \xe0 compreens\xe3o e gera\xe7\xe3o integrada de imagem e texto."},"qianfan-engcard-vl":{"description":"Qianfan EngCard VL, modelo multimodal focado em cen\xe1rios em ingl\xeas."},"qianfan-lightning-128b-a19b":{"description":"Qianfan Lightning 128B A19B, modelo geral de alto desempenho em chin\xeas, ideal para perguntas e respostas complexas e racioc\xednio em larga escala."},"qianfan-llama-vl-8b":{"description":"Qianfan Llama VL 8B, modelo multimodal baseado no Llama, voltado para tarefas gerais de compreens\xe3o de imagem e texto."},"qianfan-multipicocr":{"description":"Qianfan MultiPicOCR, modelo OCR para m\xfaltiplas imagens, com suporte \xe0 detec\xe7\xe3o e reconhecimento de texto em v\xe1rias imagens."},"qianfan-qi-vl":{"description":"Qianfan QI VL, modelo multimodal de perguntas e respostas, com suporte \xe0 recupera\xe7\xe3o e resposta precisa em cen\xe1rios complexos de imagem e texto."},"qianfan-singlepicocr":{"description":"Qianfan SinglePicOCR, modelo OCR para imagem \xfanica, com reconhecimento de caracteres de alta precis\xe3o."},"qianfan-vl-70b":{"description":"Qianfan VL 70B, modelo de linguagem visual de grande porte, ideal para cen\xe1rios complexos de compreens\xe3o de imagem e texto."},"qianfan-vl-8b":{"description":"Qianfan VL 8B, modelo leve de linguagem visual, adequado para perguntas e respostas e an\xe1lises cotidianas de imagem e texto."},"qvq-72b-preview":{"description":"O modelo QVQ \xe9 um modelo de pesquisa experimental desenvolvido pela equipe Qwen, focado em melhorar a capacidade de racioc\xednio visual, especialmente na \xe1rea de racioc\xednio matem\xe1tico."},"qvq-max":{"description":"Modelo de racioc\xednio visual QVQ Tongyi Qianwen, que suporta entrada visual e sa\xedda de cadeia de pensamento, demonstrando capacidades superiores em matem\xe1tica, programa\xe7\xe3o, an\xe1lise visual, cria\xe7\xe3o e tarefas gerais."},"qvq-plus":{"description":"Modelo de racioc\xednio visual. Suporta entrada visual e sa\xedda em cadeia de pensamento. Vers\xe3o plus lan\xe7ada ap\xf3s o modelo qvq-max, com velocidade de racioc\xednio mais r\xe1pida e melhor equil\xedbrio entre desempenho e custo em compara\xe7\xe3o ao qvq-max."},"qwen-3-32b":{"description":"Qwen 3 32B: modelo da s\xe9rie Qwen com excelente desempenho em tarefas multil\xedngues e de codifica\xe7\xe3o, adequado para aplica\xe7\xf5es de produ\xe7\xe3o em escala m\xe9dia."},"qwen-3-coder-480b":{"description":"Qwen 3 Coder 480B: modelo com contexto longo voltado para gera\xe7\xe3o de c\xf3digo e tarefas complexas de programa\xe7\xe3o."},"qwen-coder-plus":{"description":"Modelo de c\xf3digo Tongyi Qianwen."},"qwen-coder-turbo":{"description":"Modelo de c\xf3digo Tongyi Qianwen."},"qwen-coder-turbo-latest":{"description":"Modelo de c\xf3digo Qwen."},"qwen-flash":{"description":"A s\xe9rie Tongyi Qianwen oferece modelos com a maior velocidade e custo muito baixo, adequados para tarefas simples."},"qwen-image":{"description":"Qwen-Image \xe9 um modelo de gera\xe7\xe3o de imagens de uso geral que suporta diversos estilos art\xedsticos. \xc9 especialmente eficaz na renderiza\xe7\xe3o de textos complexos, em particular na renderiza\xe7\xe3o de textos em chin\xeas e ingl\xeas. O modelo oferece suporte a layouts de m\xfaltiplas linhas, gera\xe7\xe3o de texto em n\xedvel de par\xe1grafo e detalhamento de alta precis\xe3o, possibilitando a cria\xe7\xe3o de designs complexos com layouts h\xedbridos de imagem e texto."},"qwen-image-edit":{"description":"Qwen Image Edit \xe9 um modelo de gera\xe7\xe3o de imagens que suporta edi\xe7\xe3o e modifica\xe7\xe3o de imagens com base em uma imagem de entrada e instru\xe7\xf5es de texto, capaz de ajustar e transformar a imagem original com precis\xe3o e criatividade conforme as necessidades do usu\xe1rio."},"qwen-long":{"description":"O Qwen \xe9 um modelo de linguagem em larga escala que suporta contextos de texto longos e funcionalidades de di\xe1logo baseadas em documentos longos e m\xfaltiplos cen\xe1rios."},"qwen-math-plus":{"description":"Modelo matem\xe1tico Tongyi Qianwen especializado em resolu\xe7\xe3o de problemas matem\xe1ticos."},"qwen-math-plus-latest":{"description":"O modelo de matem\xe1tica Qwen \xe9 especificamente projetado para resolver problemas matem\xe1ticos."},"qwen-math-turbo":{"description":"Modelo matem\xe1tico Tongyi Qianwen especializado em resolu\xe7\xe3o de problemas matem\xe1ticos."},"qwen-math-turbo-latest":{"description":"O modelo de matem\xe1tica Qwen \xe9 especificamente projetado para resolver problemas matem\xe1ticos."},"qwen-max":{"description":"Modelo de linguagem em larga escala com trilh\xf5es de par\xe2metros do Qwen, suportando entradas em diferentes idiomas, como portugu\xeas e ingl\xeas, atualmente a vers\xe3o API por tr\xe1s do produto Qwen 2.5."},"qwen-omni-turbo":{"description":"A s\xe9rie de modelos Qwen-Omni suporta entrada de m\xfaltiplas modalidades, incluindo v\xeddeo, \xe1udio, imagem e texto, e gera sa\xedda em \xe1udio e texto."},"qwen-plus":{"description":"Vers\xe3o aprimorada do modelo de linguagem em larga escala Qwen, que suporta entradas em diferentes idiomas, como portugu\xeas e ingl\xeas."},"qwen-turbo":{"description":"通义千问 Turbo n\xe3o receber\xe1 mais atualiza\xe7\xf5es; recomendamos substitu\xed-lo pelo 通义千问 Flash. 通义千问 \xe9 um modelo de linguagem em larga escala que suporta entradas em chin\xeas, ingl\xeas e outros idiomas."},"qwen-vl-chat-v1":{"description":"O Qwen VL suporta uma maneira de intera\xe7\xe3o flex\xedvel, incluindo m\xfaltiplas imagens, perguntas e respostas em v\xe1rias rodadas, e capacidades criativas."},"qwen-vl-max":{"description":"Modelo visual-lingu\xedstico de escala ultra grande Tongyi Qianwen. Em compara\xe7\xe3o com a vers\xe3o aprimorada, ele eleva ainda mais a capacidade de racioc\xednio visual e conformidade com instru\xe7\xf5es, oferecendo n\xedveis superiores de percep\xe7\xe3o e cogni\xe7\xe3o visual."},"qwen-vl-max-latest":{"description":"Modelo de linguagem visual em escala ultra grande Qwen. Em compara\xe7\xe3o com a vers\xe3o aprimorada, melhora ainda mais a capacidade de racioc\xednio visual e de seguir instru\xe7\xf5es, oferecendo um n\xedvel mais alto de percep\xe7\xe3o e cogni\xe7\xe3o visual."},"qwen-vl-ocr":{"description":"Tongyi Qianwen OCR \xe9 um modelo propriet\xe1rio para extra\xe7\xe3o de texto, focado em imagens de documentos, tabelas, quest\xf5es e escrita manual. Ele pode reconhecer m\xfaltiplos idiomas, incluindo chin\xeas, ingl\xeas, franc\xeas, japon\xeas, coreano, alem\xe3o, russo, italiano, vietnamita e \xe1rabe."},"qwen-vl-plus":{"description":"Vers\xe3o aprimorada do modelo visual-lingu\xedstico em larga escala Tongyi Qianwen. Melhora significativamente a capacidade de reconhecimento de detalhes e texto, suportando imagens com resolu\xe7\xe3o superior a um milh\xe3o de pixels e propor\xe7\xf5es de qualquer tamanho."},"qwen-vl-plus-latest":{"description":"Vers\xe3o aprimorada do modelo de linguagem visual em larga escala Qwen. Aumenta significativamente a capacidade de reconhecimento de detalhes e de texto, suportando resolu\xe7\xe3o de mais de um milh\xe3o de pixels e imagens de qualquer propor\xe7\xe3o."},"qwen-vl-v1":{"description":"Inicializado com o modelo de linguagem Qwen-7B, adicionando um modelo de imagem, um modelo pr\xe9-treinado com resolu\xe7\xe3o de entrada de imagem de 448."},"qwen/qwen-2-7b-instruct":{"description":"Qwen2 \xe9 uma nova s\xe9rie de modelos de linguagem grande Qwen. Qwen2 7B \xe9 um modelo baseado em transformer, com excelente desempenho em compreens\xe3o de linguagem, capacidade multil\xedngue, programa\xe7\xe3o, matem\xe1tica e racioc\xednio."},"qwen/qwen-2-7b-instruct:free":{"description":"Qwen2 \xe9 uma nova s\xe9rie de grandes modelos de linguagem, com capacidades de compreens\xe3o e gera\xe7\xe3o mais robustas."},"qwen/qwen-2-vl-72b-instruct":{"description":"Qwen2-VL \xe9 a vers\xe3o mais recente do modelo Qwen-VL, alcan\xe7ando desempenho de ponta em benchmarks de compreens\xe3o visual, incluindo MathVista, DocVQA, RealWorldQA e MTVQA. Qwen2-VL \xe9 capaz de entender v\xeddeos de mais de 20 minutos, permitindo perguntas e respostas, di\xe1logos e cria\xe7\xe3o de conte\xfado de alta qualidade baseados em v\xeddeo. Ele tamb\xe9m possui capacidades complexas de racioc\xednio e tomada de decis\xe3o, podendo ser integrado a dispositivos m\xf3veis, rob\xf4s, etc., para opera\xe7\xf5es autom\xe1ticas baseadas em ambientes visuais e instru\xe7\xf5es textuais. Al\xe9m do ingl\xeas e do chin\xeas, o Qwen2-VL agora tamb\xe9m suporta a compreens\xe3o de texto em diferentes idiomas em imagens, incluindo a maioria das l\xednguas europeias, japon\xeas, coreano, \xe1rabe e vietnamita."},"qwen/qwen-2.5-72b-instruct":{"description":"Qwen2.5-72B-Instruct \xe9 uma das mais recentes s\xe9ries de modelos de linguagem grande lan\xe7adas pela Alibaba Cloud. Este modelo de 72B apresenta capacidades significativamente aprimoradas em \xe1reas como codifica\xe7\xe3o e matem\xe1tica. O modelo tamb\xe9m oferece suporte a m\xfaltiplas l\xednguas, cobrindo mais de 29 idiomas, incluindo chin\xeas e ingl\xeas. O modelo teve melhorias significativas em seguir instru\xe7\xf5es, entender dados estruturados e gerar sa\xeddas estruturadas (especialmente JSON)."},"qwen/qwen2.5-32b-instruct":{"description":"Qwen2.5-32B-Instruct \xe9 uma das mais recentes s\xe9ries de modelos de linguagem grande lan\xe7adas pela Alibaba Cloud. Este modelo de 32B apresenta capacidades significativamente aprimoradas em \xe1reas como codifica\xe7\xe3o e matem\xe1tica. O modelo oferece suporte a m\xfaltiplas l\xednguas, cobrindo mais de 29 idiomas, incluindo chin\xeas e ingl\xeas. O modelo teve melhorias significativas em seguir instru\xe7\xf5es, entender dados estruturados e gerar sa\xeddas estruturadas (especialmente JSON)."},"qwen/qwen2.5-7b-instruct":{"description":"LLM voltado para chin\xeas e ingl\xeas, focado em linguagem, programa\xe7\xe3o, matem\xe1tica, racioc\xednio e outras \xe1reas."},"qwen/qwen2.5-coder-32b-instruct":{"description":"LLM avan\xe7ado, suporta gera\xe7\xe3o de c\xf3digo, racioc\xednio e corre\xe7\xe3o, abrangendo linguagens de programa\xe7\xe3o populares."},"qwen/qwen2.5-coder-7b-instruct":{"description":"Modelo de c\xf3digo de m\xe9dio porte poderoso, suporta comprimento de contexto de 32K, especializado em programa\xe7\xe3o multil\xedngue."},"qwen/qwen3-14b":{"description":"Qwen3-14B \xe9 um modelo de linguagem causal denso de 14 bilh\xf5es de par\xe2metros da s\xe9rie Qwen3, projetado para racioc\xednio complexo e di\xe1logos eficientes. Ele suporta a altern\xe2ncia sem costura entre o modo de \'pensamento\' para tarefas de matem\xe1tica, programa\xe7\xe3o e racioc\xednio l\xf3gico e o modo \'n\xe3o pensante\' para di\xe1logos gerais. Este modelo foi ajustado para seguir instru\xe7\xf5es, usar ferramentas de agentes, escrever criativamente e realizar tarefas multil\xedngues em mais de 100 idiomas e dialetos. Ele processa nativamente um contexto de 32K tokens e pode ser expandido para 131K tokens usando uma extens\xe3o baseada em YaRN."},"qwen/qwen3-14b:free":{"description":"Qwen3-14B \xe9 um modelo de linguagem causal denso de 14 bilh\xf5es de par\xe2metros da s\xe9rie Qwen3, projetado para racioc\xednio complexo e di\xe1logos eficientes. Ele suporta a altern\xe2ncia sem costura entre o modo de \'pensamento\' para tarefas de matem\xe1tica, programa\xe7\xe3o e racioc\xednio l\xf3gico e o modo \'n\xe3o pensante\' para di\xe1logos gerais. Este modelo foi ajustado para seguir instru\xe7\xf5es, usar ferramentas de agentes, escrever criativamente e realizar tarefas multil\xedngues em mais de 100 idiomas e dialetos. Ele processa nativamente um contexto de 32K tokens e pode ser expandido para 131K tokens usando uma extens\xe3o baseada em YaRN."},"qwen/qwen3-235b-a22b":{"description":"Qwen3-235B-A22B \xe9 um modelo de mistura especializada (MoE) de 235 bilh\xf5es de par\xe2metros desenvolvido pela Qwen, ativando 22 bilh\xf5es de par\xe2metros a cada passagem para frente. Ele suporta a altern\xe2ncia sem costura entre o modo de \'pensamento\' para racioc\xednio complexo, matem\xe1tica e tarefas de c\xf3digo e o modo \'n\xe3o pensante\' para efici\xeancia em di\xe1logos gerais. Este modelo demonstra forte capacidade de racioc\xednio, suporte multil\xedngue (mais de 100 idiomas e dialetos), alta capacidade de seguir instru\xe7\xf5es e chamar ferramentas de agentes. Ele processa nativamente uma janela de contexto de 32K tokens e pode ser expandido para 131K tokens usando uma extens\xe3o baseada em YaRN."},"qwen/qwen3-235b-a22b:free":{"description":"Qwen3-235B-A22B \xe9 um modelo de mistura especializada (MoE) de 235 bilh\xf5es de par\xe2metros desenvolvido pela Qwen, ativando 22 bilh\xf5es de par\xe2metros a cada passagem para frente. Ele suporta a altern\xe2ncia sem costura entre o modo de \'pensamento\' para racioc\xednio complexo, matem\xe1tica e tarefas de c\xf3digo e o modo \'n\xe3o pensante\' para efici\xeancia em di\xe1logos gerais. Este modelo demonstra forte capacidade de racioc\xednio, suporte multil\xedngue (mais de 100 idiomas e dialetos), alta capacidade de seguir instru\xe7\xf5es e chamar ferramentas de agentes. Ele processa nativamente uma janela de contexto de 32K tokens e pode ser expandido para 131K tokens usando uma extens\xe3o baseada em YaRN."},"qwen/qwen3-30b-a3b":{"description":"Qwen3 \xe9 a \xfaltima gera\xe7\xe3o da s\xe9rie de modelos de linguagem Qwen, com uma arquitetura de mistura densa e especializada (MoE), destacando-se em racioc\xednio, suporte multil\xedngue e tarefas avan\xe7adas de agente. Sua capacidade \xfanica de alternar sem costura entre modos de pensamento para racioc\xednio complexo e modos n\xe3o pensantes para di\xe1logos eficientes garante um desempenho multifuncional e de alta qualidade.\\n\\nQwen3 supera significativamente modelos anteriores, como QwQ e Qwen2.5, oferecendo habilidades excepcionais em matem\xe1tica, codifica\xe7\xe3o, racioc\xednio l\xf3gico, escrita criativa e di\xe1logos interativos. A variante Qwen3-30B-A3B cont\xe9m 30,5 bilh\xf5es de par\xe2metros (3,3 bilh\xf5es de par\xe2metros ativados), 48 camadas, 128 especialistas (8 ativados por tarefa) e suporta um contexto de at\xe9 131K tokens (usando YaRN), estabelecendo um novo padr\xe3o para modelos de c\xf3digo aberto."},"qwen/qwen3-30b-a3b:free":{"description":"Qwen3 \xe9 a \xfaltima gera\xe7\xe3o da s\xe9rie de modelos de linguagem Qwen, com uma arquitetura de mistura densa e especializada (MoE), destacando-se em racioc\xednio, suporte multil\xedngue e tarefas avan\xe7adas de agente. Sua capacidade \xfanica de alternar sem costura entre modos de pensamento para racioc\xednio complexo e modos n\xe3o pensantes para di\xe1logos eficientes garante um desempenho multifuncional e de alta qualidade.\\n\\nQwen3 supera significativamente modelos anteriores, como QwQ e Qwen2.5, oferecendo habilidades excepcionais em matem\xe1tica, codifica\xe7\xe3o, racioc\xednio l\xf3gico, escrita criativa e di\xe1logos interativos. A variante Qwen3-30B-A3B cont\xe9m 30,5 bilh\xf5es de par\xe2metros (3,3 bilh\xf5es de par\xe2metros ativados), 48 camadas, 128 especialistas (8 ativados por tarefa) e suporta um contexto de at\xe9 131K tokens (usando YaRN), estabelecendo um novo padr\xe3o para modelos de c\xf3digo aberto."},"qwen/qwen3-32b":{"description":"Qwen3-32B \xe9 um modelo de linguagem causal denso de 32 bilh\xf5es de par\xe2metros da s\xe9rie Qwen3, otimizado para racioc\xednio complexo e di\xe1logos eficientes. Ele suporta a altern\xe2ncia sem costura entre o modo de \'pensamento\' para tarefas de matem\xe1tica, codifica\xe7\xe3o e racioc\xednio l\xf3gico e o modo \'n\xe3o pensante\' para di\xe1logos mais r\xe1pidos e gerais. Este modelo demonstra um desempenho robusto em seguir instru\xe7\xf5es, usar ferramentas de agentes, escrever criativamente e realizar tarefas multil\xedngues em mais de 100 idiomas e dialetos. Ele processa nativamente um contexto de 32K tokens e pode ser expandido para 131K tokens usando uma extens\xe3o baseada em YaRN."},"qwen/qwen3-32b:free":{"description":"Qwen3-32B \xe9 um modelo de linguagem causal denso de 32 bilh\xf5es de par\xe2metros da s\xe9rie Qwen3, otimizado para racioc\xednio complexo e di\xe1logos eficientes. Ele suporta a altern\xe2ncia sem costura entre o modo de \'pensamento\' para tarefas de matem\xe1tica, codifica\xe7\xe3o e racioc\xednio l\xf3gico e o modo \'n\xe3o pensante\' para di\xe1logos mais r\xe1pidos e gerais. Este modelo demonstra um desempenho robusto em seguir instru\xe7\xf5es, usar ferramentas de agentes, escrever criativamente e realizar tarefas multil\xedngues em mais de 100 idiomas e dialetos. Ele processa nativamente um contexto de 32K tokens e pode ser expandido para 131K tokens usando uma extens\xe3o baseada em YaRN."},"qwen/qwen3-8b:free":{"description":"Qwen3-8B \xe9 um modelo de linguagem causal denso de 8 bilh\xf5es de par\xe2metros da s\xe9rie Qwen3, projetado para tarefas intensivas em racioc\xednio e di\xe1logos eficientes. Ele suporta a altern\xe2ncia sem costura entre o modo de \'pensamento\' para matem\xe1tica, codifica\xe7\xe3o e racioc\xednio l\xf3gico e o modo \'n\xe3o pensante\' para di\xe1logos gerais. Este modelo foi ajustado para seguir instru\xe7\xf5es, integrar agentes, escrever criativamente e usar em mais de 100 idiomas e dialetos. Ele suporta nativamente uma janela de contexto de 32K tokens e pode ser expandido para 131K tokens atrav\xe9s do YaRN."},"qwen2":{"description":"Qwen2 \xe9 a nova gera\xe7\xe3o de modelo de linguagem em larga escala da Alibaba, oferecendo desempenho excepcional para atender a diversas necessidades de aplica\xe7\xe3o."},"qwen2.5":{"description":"Qwen2.5 \xe9 a nova gera\xe7\xe3o de modelo de linguagem em larga escala da Alibaba, oferecendo desempenho excepcional para atender a diversas necessidades de aplica\xe7\xe3o."},"qwen2.5-14b-instruct":{"description":"Modelo de 14B par\xe2metros do Qwen 2.5, dispon\xedvel como c\xf3digo aberto."},"qwen2.5-14b-instruct-1m":{"description":"Modelo de 72B de c\xf3digo aberto do Qwen2.5."},"qwen2.5-32b-instruct":{"description":"Modelo de 32B par\xe2metros do Qwen 2.5, dispon\xedvel como c\xf3digo aberto."},"qwen2.5-72b-instruct":{"description":"Modelo de 72B par\xe2metros do Qwen 2.5, dispon\xedvel como c\xf3digo aberto."},"qwen2.5-7b-instruct":{"description":"Qwen2.5 7B Instruct, modelo de instru\xe7\xe3o open-source maduro, adequado para di\xe1logos e gera\xe7\xe3o em m\xfaltiplos cen\xe1rios."},"qwen2.5-coder-1.5b-instruct":{"description":"Vers\xe3o open source do modelo de c\xf3digo do Qwen."},"qwen2.5-coder-14b-instruct":{"description":"Vers\xe3o open source do modelo de c\xf3digo Tongyi Qianwen."},"qwen2.5-coder-32b-instruct":{"description":"Vers\xe3o open source do modelo de c\xf3digo Qwen."},"qwen2.5-coder-7b-instruct":{"description":"Vers\xe3o de c\xf3digo aberto do modelo de c\xf3digo Qwen."},"qwen2.5-coder-instruct":{"description":"Qwen2.5-Coder \xe9 o mais recente modelo de linguagem de grande escala especializado em c\xf3digo da s\xe9rie Qwen (anteriormente conhecido como CodeQwen)."},"qwen2.5-instruct":{"description":"Qwen2.5 \xe9 a mais recente s\xe9rie de modelos de linguagem de grande escala Qwen. Para o Qwen2.5, lan\xe7amos diversos modelos de linguagem base e modelos de linguagem ajustados por instru\xe7\xe3o, com par\xe2metros variando de 500 milh\xf5es a 7,2 bilh\xf5es."},"qwen2.5-math-1.5b-instruct":{"description":"O modelo Qwen-Math possui poderosas capacidades de resolu\xe7\xe3o de problemas matem\xe1ticos."},"qwen2.5-math-72b-instruct":{"description":"O modelo Qwen-Math possui uma forte capacidade de resolu\xe7\xe3o de problemas matem\xe1ticos."},"qwen2.5-math-7b-instruct":{"description":"O modelo Qwen-Math possui uma forte capacidade de resolu\xe7\xe3o de problemas matem\xe1ticos."},"qwen2.5-omni-7b":{"description":"O modelo da s\xe9rie Qwen-Omni suporta a entrada de m\xfaltiplos tipos de dados, incluindo v\xeddeo, \xe1udio, imagens e texto, e produz sa\xeddas em \xe1udio e texto."},"qwen2.5-vl-32b-instruct":{"description":"Qwen2.5 VL 32B Instruct, modelo multimodal open-source, ideal para implanta\xe7\xe3o privada e aplica\xe7\xf5es em diversos cen\xe1rios."},"qwen2.5-vl-72b-instruct":{"description":"Aprimoramento geral em seguimento de instru\xe7\xf5es, matem\xe1tica, resolu\xe7\xe3o de problemas e c\xf3digo, com capacidade de reconhecimento de objetos aprimorada, suporte a formatos diversos para localiza\xe7\xe3o precisa de elementos visuais, compreens\xe3o de arquivos de v\xeddeo longos (at\xe9 10 minutos) e localiza\xe7\xe3o de eventos em segundos, capaz de entender a sequ\xeancia e a velocidade do tempo, suportando controle de agentes em OS ou Mobile com forte capacidade de extra\xe7\xe3o de informa\xe7\xf5es e sa\xedda em formato Json. Esta vers\xe3o \xe9 a de 72B, a mais poderosa da s\xe9rie."},"qwen2.5-vl-7b-instruct":{"description":"Qwen2.5 VL 7B Instruct, modelo multimodal leve, equilibrando custo de implanta\xe7\xe3o e capacidade de reconhecimento."},"qwen2.5-vl-instruct":{"description":"Qwen2.5-VL \xe9 a vers\xe3o mais recente do modelo de linguagem visual da fam\xedlia de modelos Qwen."},"qwen2.5:0.5b":{"description":"Qwen2.5 \xe9 a nova gera\xe7\xe3o de modelo de linguagem em larga escala da Alibaba, oferecendo desempenho excepcional para atender a diversas necessidades de aplica\xe7\xe3o."},"qwen2.5:1.5b":{"description":"Qwen2.5 \xe9 a nova gera\xe7\xe3o de modelo de linguagem em larga escala da Alibaba, oferecendo desempenho excepcional para atender a diversas necessidades de aplica\xe7\xe3o."},"qwen2.5:72b":{"description":"Qwen2.5 \xe9 a nova gera\xe7\xe3o de modelo de linguagem em larga escala da Alibaba, oferecendo desempenho excepcional para atender a diversas necessidades de aplica\xe7\xe3o."},"qwen2:0.5b":{"description":"Qwen2 \xe9 a nova gera\xe7\xe3o de modelo de linguagem em larga escala da Alibaba, oferecendo desempenho excepcional para atender a diversas necessidades de aplica\xe7\xe3o."},"qwen2:1.5b":{"description":"Qwen2 \xe9 a nova gera\xe7\xe3o de modelo de linguagem em larga escala da Alibaba, oferecendo desempenho excepcional para atender a diversas necessidades de aplica\xe7\xe3o."},"qwen2:72b":{"description":"Qwen2 \xe9 a nova gera\xe7\xe3o de modelo de linguagem em larga escala da Alibaba, oferecendo desempenho excepcional para atender a diversas necessidades de aplica\xe7\xe3o."},"qwen3":{"description":"Qwen3 \xe9 a nova gera\xe7\xe3o do modelo de linguagem em larga escala da Alibaba, que oferece desempenho excepcional para atender a diversas necessidades de aplica\xe7\xe3o."},"qwen3-0.6b":{"description":"Qwen3 0.6B, modelo de entrada, ideal para racioc\xednio simples e ambientes com recursos extremamente limitados."},"qwen3-1.7b":{"description":"Qwen3 1.7B, modelo ultraleve, f\xe1cil de implantar em dispositivos de borda e terminais."},"qwen3-14b":{"description":"Qwen3 14B, modelo de porte m\xe9dio, adequado para perguntas e respostas multil\xedngues e gera\xe7\xe3o de texto."},"qwen3-235b-a22b":{"description":"Qwen3 235B A22B, modelo geral de grande porte, voltado para diversas tarefas complexas."},"qwen3-235b-a22b-instruct-2507":{"description":"Qwen3 235B A22B Instruct 2507, modelo Instruct de ponta, ideal para gera\xe7\xe3o e racioc\xednio em m\xfaltiplos contextos."},"qwen3-235b-a22b-thinking-2507":{"description":"Qwen3 235B A22B Thinking 2507, modelo de racioc\xednio em larga escala, ideal para tarefas de alta complexidade."},"qwen3-30b-a3b":{"description":"Qwen3 30B A3B, modelo geral de m\xe9dio a grande porte, equilibrando custo e desempenho."},"qwen3-30b-a3b-instruct-2507":{"description":"Qwen3 30B A3B Instruct 2507, modelo Instruct de m\xe9dio a grande porte, ideal para gera\xe7\xe3o e perguntas e respostas de alta qualidade."},"qwen3-30b-a3b-thinking-2507":{"description":"Qwen3 30B A3B Thinking 2507, modelo de racioc\xednio de m\xe9dio a grande porte, equilibrando precis\xe3o e custo."},"qwen3-32b":{"description":"Qwen3 32B, ideal para tarefas gerais que exigem maior capacidade de compreens\xe3o."},"qwen3-4b":{"description":"Qwen3 4B, adequado para aplica\xe7\xf5es de pequeno a m\xe9dio porte e cen\xe1rios de racioc\xednio local."},"qwen3-8b":{"description":"Qwen3 8B, modelo leve com implanta\xe7\xe3o flex\xedvel, ideal para servi\xe7os de alta concorr\xeancia."},"qwen3-coder-30b-a3b-instruct":{"description":"Vers\xe3o open-source do modelo de c\xf3digo Tongyi Qianwen. O mais recente qwen3-coder-30b-a3b-instruct \xe9 um modelo de gera\xe7\xe3o de c\xf3digo baseado no Qwen3, com poderosas capacidades de agente de codifica\xe7\xe3o, especializado em chamadas de ferramentas e intera\xe7\xe3o com ambientes, capaz de programa\xe7\xe3o aut\xf4noma com excel\xeancia em c\xf3digo e habilidades gerais."},"qwen3-coder-480b-a35b-instruct":{"description":"Qwen3 Coder 480B A35B Instruct, modelo de c\xf3digo de n\xedvel flagship, com suporte a programa\xe7\xe3o multil\xedngue e compreens\xe3o de c\xf3digo complexa."},"qwen3-coder-flash":{"description":"Modelo de c\xf3digo Tongyi Qianwen. A mais recente s\xe9rie de modelos Qwen3-Coder \xe9 baseada no Qwen3 para gera\xe7\xe3o de c\xf3digo, com forte capacidade de agente de codifica\xe7\xe3o, especializada em chamadas de ferramentas e intera\xe7\xe3o com o ambiente, capaz de programa\xe7\xe3o aut\xf4noma, combinando excelente habilidade de codifica\xe7\xe3o com capacidades gerais."},"qwen3-coder-plus":{"description":"Modelo de c\xf3digo Tongyi Qianwen. A mais recente s\xe9rie de modelos Qwen3-Coder \xe9 baseada no Qwen3 para gera\xe7\xe3o de c\xf3digo, com forte capacidade de agente de codifica\xe7\xe3o, especializada em chamadas de ferramentas e intera\xe7\xe3o com o ambiente, capaz de programa\xe7\xe3o aut\xf4noma, combinando excelente habilidade de codifica\xe7\xe3o com capacidades gerais."},"qwen3-coder:480b":{"description":"Modelo de contexto longo de alto desempenho da Alibaba, voltado para tarefas de agentes e codifica\xe7\xe3o."},"qwen3-max":{"description":"A s\xe9rie Max do Tongyi Qianwen 3 apresenta melhorias significativas em rela\xe7\xe3o \xe0 s\xe9rie 2.5 na capacidade geral, compreens\xe3o de texto em chin\xeas e ingl\xeas, seguimento de instru\xe7\xf5es complexas, tarefas abertas subjetivas, multilinguismo e chamadas de ferramentas; o modelo apresenta menos alucina\xe7\xf5es de conhecimento. A vers\xe3o mais recente do qwen3-max, em compara\xe7\xe3o com a pr\xe9via, recebeu atualiza\xe7\xf5es espec\xedficas para programa\xe7\xe3o de agentes e chamadas de ferramentas. O modelo oficial lan\xe7ado atinge o estado da arte no dom\xednio, adaptando-se a demandas mais complexas de agentes."},"qwen3-max-preview":{"description":"O modelo mais avan\xe7ado da s\xe9rie Qwen, ideal para tarefas complexas e de m\xfaltiplas etapas. A vers\xe3o de pr\xe9via j\xe1 suporta racioc\xednio."},"qwen3-next-80b-a3b-instruct":{"description":"Modelo open source de nova gera\xe7\xe3o no modo n\xe3o reflexivo baseado no Qwen3, que apresenta melhor compreens\xe3o de texto em chin\xeas, capacidades aprimoradas de racioc\xednio l\xf3gico e desempenho superior em tarefas de gera\xe7\xe3o de texto em compara\xe7\xe3o com a vers\xe3o anterior (Tongyi Qianwen 3-235B-A22B-Instruct-2507)."},"qwen3-next-80b-a3b-thinking":{"description":"Qwen3 Next 80B A3B Thinking, vers\xe3o de racioc\xednio flagship voltada para tarefas complexas."},"qwen3-omni-flash":{"description":"O modelo Qwen-Omni aceita entradas combinadas de texto, imagem, \xe1udio e v\xeddeo, e gera respostas em forma de texto ou voz. Oferece m\xfaltiplas vozes humanizadas, com suporte para sa\xedda de voz em v\xe1rios idiomas e dialetos. Pode ser aplicado em cria\xe7\xe3o de texto, reconhecimento visual, assistentes de voz e outros cen\xe1rios."},"qwen3-vl-235b-a22b-instruct":{"description":"Qwen3 VL 235B A22B Instruct, modelo multimodal de ponta, voltado para cen\xe1rios exigentes de compreens\xe3o e cria\xe7\xe3o."},"qwen3-vl-235b-a22b-thinking":{"description":"Qwen3 VL 235B A22B Thinking, vers\xe3o de racioc\xednio de ponta, para tarefas complexas de planejamento e racioc\xednio multimodal."},"qwen3-vl-30b-a3b-instruct":{"description":"Qwen3 VL 30B A3B Instruct, modelo multimodal de grande porte, equilibrando precis\xe3o e desempenho de racioc\xednio."},"qwen3-vl-30b-a3b-thinking":{"description":"Qwen3 VL 30B A3B Thinking, vers\xe3o de racioc\xednio profundo voltada para tarefas multimodais complexas."},"qwen3-vl-32b-instruct":{"description":"Qwen3 VL 32B Instruct, modelo multimodal ajustado por instru\xe7\xf5es, ideal para perguntas e respostas visuais e cria\xe7\xe3o de alta qualidade."},"qwen3-vl-32b-thinking":{"description":"Qwen3 VL 32B Thinking, vers\xe3o de racioc\xednio multimodal profundo, com foco em racioc\xednio complexo e an\xe1lise de longo alcance."},"qwen3-vl-8b-instruct":{"description":"Qwen3 VL 8B Instruct, modelo multimodal leve, ideal para perguntas e respostas visuais do dia a dia e integra\xe7\xe3o de aplica\xe7\xf5es."},"qwen3-vl-8b-thinking":{"description":"Qwen3 VL 8B Thinking, modelo de cadeia de racioc\xednio multimodal, ideal para racioc\xednio detalhado sobre informa\xe7\xf5es visuais."},"qwen3-vl-flash":{"description":"Qwen3 VL Flash: vers\xe3o leve e de infer\xeancia r\xe1pida, ideal para cen\xe1rios sens\xedveis \xe0 lat\xeancia ou com grandes volumes de requisi\xe7\xf5es."},"qwen3-vl-plus":{"description":"Tongyi Qianwen VL \xe9 um modelo gerador de texto com capacidade de compreens\xe3o visual (imagens), capaz n\xe3o s\xf3 de realizar OCR (reconhecimento de texto em imagens), mas tamb\xe9m de resumir e inferir, como extrair atributos de fotos de produtos e resolver problemas a partir de imagens de exerc\xedcios."},"qwq":{"description":"QwQ \xe9 um modelo de pesquisa experimental, focado em melhorar a capacidade de racioc\xednio da IA."},"qwq-32b":{"description":"Modelo de infer\xeancia QwQ treinado com base no modelo Qwen2.5-32B, que melhorou significativamente a capacidade de infer\xeancia do modelo atrav\xe9s de aprendizado por refor\xe7o. Os indicadores principais do modelo, como c\xf3digo matem\xe1tico (AIME 24/25, LiveCodeBench) e alguns indicadores gerais (IFEval, LiveBench, etc.), alcan\xe7aram o n\xedvel do DeepSeek-R1 vers\xe3o completa, com todos os indicadores superando significativamente o DeepSeek-R1-Distill-Qwen-32B, que tamb\xe9m \xe9 baseado no Qwen2.5-32B."},"qwq-32b-preview":{"description":"O modelo QwQ \xe9 um modelo de pesquisa experimental desenvolvido pela equipe Qwen, focado em aprimorar a capacidade de racioc\xednio da IA."},"qwq-plus":{"description":"Modelo de racioc\xednio QwQ treinado com base no modelo Qwen2.5, que aprimora significativamente a capacidade de racioc\xednio por meio de aprendizado por refor\xe7o. Os principais indicadores em matem\xe1tica e c\xf3digo (AIME 24/25, LiveCodeBench), bem como alguns indicadores gerais (IFEval, LiveBench, etc.), alcan\xe7am o n\xedvel completo do DeepSeek-R1."},"qwq_32b":{"description":"Modelo de infer\xeancia de tamanho m\xe9dio da s\xe9rie Qwen. Comparado a modelos tradicionais de ajuste de instru\xe7\xf5es, o QwQ, com suas capacidades de pensamento e racioc\xednio, pode melhorar significativamente o desempenho em tarefas de downstream, especialmente na resolu\xe7\xe3o de problemas dif\xedceis."},"r1-1776":{"description":"R1-1776 \xe9 uma vers\xe3o do modelo DeepSeek R1, treinada posteriormente para fornecer informa\xe7\xf5es factuais n\xe3o filtradas e imparciais."},"solar-mini":{"description":"Solar Mini \xe9 um LLM compacto, com desempenho superior ao GPT-3.5, possuindo forte capacidade multil\xedngue, suportando ingl\xeas e coreano, oferecendo uma solu\xe7\xe3o eficiente e compacta."},"solar-mini-ja":{"description":"Solar Mini (Ja) expande as capacidades do Solar Mini, focando no japon\xeas, enquanto mant\xe9m efici\xeancia e desempenho excepcional no uso de ingl\xeas e coreano."},"solar-pro":{"description":"Solar Pro \xe9 um LLM de alta intelig\xeancia lan\xe7ado pela Upstage, focado na capacidade de seguir instru\xe7\xf5es em um \xfanico GPU, com pontua\xe7\xe3o IFEval acima de 80. Atualmente suporta ingl\xeas, com uma vers\xe3o oficial planejada para lan\xe7amento em novembro de 2024, que expandir\xe1 o suporte a idiomas e comprimento de contexto."},"sonar":{"description":"Produto de busca leve baseado em contexto de busca, mais r\xe1pido e mais barato que o Sonar Pro."},"sonar-deep-research":{"description":"A Pesquisa Profunda realiza uma pesquisa abrangente de n\xedvel especialista e a sintetiza em relat\xf3rios acess\xedveis e acion\xe1veis."},"sonar-pro":{"description":"Produto de busca avan\xe7ada que suporta contexto de busca, consultas avan\xe7adas e acompanhamento."},"sonar-reasoning":{"description":"Novo produto API suportado pelo modelo de racioc\xednio da DeepSeek."},"sonar-reasoning-pro":{"description":"Um novo produto de API suportado pelo modelo de racioc\xednio DeepSeek."},"stable-diffusion-3-medium":{"description":"Modelo de gera\xe7\xe3o de imagens a partir de texto mais recente lan\xe7ado pela Stability AI. Esta vers\xe3o mant\xe9m as vantagens das anteriores e apresenta melhorias significativas na qualidade da imagem, compreens\xe3o textual e diversidade de estilos, capaz de interpretar prompts complexos de linguagem natural com maior precis\xe3o e gerar imagens mais precisas e variadas."},"stable-diffusion-3.5-large":{"description":"stable-diffusion-3.5-large \xe9 um modelo multimodal de difus\xe3o transformadora (MMDiT) para gera\xe7\xe3o de imagens a partir de texto com 800 milh\xf5es de par\xe2metros, oferecendo qualidade de imagem excepcional e alta correspond\xeancia com prompts, suportando gera\xe7\xe3o de imagens de alta resolu\xe7\xe3o de at\xe9 1 milh\xe3o de pixels, e operando eficientemente em hardware de consumo comum."},"stable-diffusion-3.5-large-turbo":{"description":"stable-diffusion-3.5-large-turbo \xe9 um modelo baseado no stable-diffusion-3.5-large que utiliza a t\xe9cnica de destila\xe7\xe3o de difus\xe3o adversarial (ADD), oferecendo maior velocidade."},"stable-diffusion-v1.5":{"description":"stable-diffusion-v1.5 \xe9 inicializado com pesos do checkpoint stable-diffusion-v1.2 e ajustado por 595k passos em \\"laion-aesthetics v2 5+\\" com resolu\xe7\xe3o 512x512, reduzindo em 10% a condicionamento textual para melhorar a amostragem guiada sem classificador."},"stable-diffusion-xl":{"description":"stable-diffusion-xl apresenta melhorias significativas em rela\xe7\xe3o \xe0 v1.5, com desempenho compar\xe1vel ao modelo open source SOTA midjourney. As melhorias incluem: backbone unet tr\xeas vezes maior; m\xf3dulo de refinamento para melhorar a qualidade da imagem gerada; t\xe9cnicas de treinamento mais eficientes, entre outras."},"stable-diffusion-xl-base-1.0":{"description":"Grande modelo de gera\xe7\xe3o de imagens a partir de texto desenvolvido e open source pela Stability AI, com capacidade criativa de ponta na ind\xfastria. Possui excelente compreens\xe3o de instru\xe7\xf5es e suporta defini\xe7\xe3o de prompts inversos para gera\xe7\xe3o precisa de conte\xfado."},"step-1-128k":{"description":"Equilibra desempenho e custo, adequado para cen\xe1rios gerais."},"step-1-256k":{"description":"Possui capacidade de processamento de contexto ultra longo, especialmente adequado para an\xe1lise de documentos longos."},"step-1-32k":{"description":"Suporta di\xe1logos de comprimento m\xe9dio, adequado para diversas aplica\xe7\xf5es."},"step-1-8k":{"description":"Modelo pequeno, adequado para tarefas leves."},"step-1-flash":{"description":"Modelo de alta velocidade, adequado para di\xe1logos em tempo real."},"step-1.5v-mini":{"description":"Este modelo possui uma poderosa capacidade de compreens\xe3o de v\xeddeo."},"step-1o-turbo-vision":{"description":"Este modelo possui uma poderosa capacidade de compreens\xe3o de imagens, superando o 1o em \xe1reas de matem\xe1tica e programa\xe7\xe3o. O modelo \xe9 menor que o 1o e oferece uma velocidade de sa\xedda mais r\xe1pida."},"step-1o-vision-32k":{"description":"Este modelo possui uma poderosa capacidade de compreens\xe3o de imagens. Em compara\xe7\xe3o com a s\xe9rie de modelos step-1v, apresenta um desempenho visual superior."},"step-1v-32k":{"description":"Suporta entradas visuais, aprimorando a experi\xeancia de intera\xe7\xe3o multimodal."},"step-1v-8k":{"description":"Modelo visual compacto, adequado para tarefas b\xe1sicas de texto e imagem."},"step-1x-edit":{"description":"Modelo focado em tarefas de edi\xe7\xe3o de imagens, capaz de modificar e aprimorar imagens com base em imagens e descri\xe7\xf5es textuais fornecidas pelo usu\xe1rio. Suporta m\xfaltiplos formatos de entrada, incluindo descri\xe7\xf5es textuais e imagens de exemplo. O modelo compreende a inten\xe7\xe3o do usu\xe1rio e gera resultados de edi\xe7\xe3o de imagem conforme solicitado."},"step-1x-medium":{"description":"Modelo com forte capacidade de gera\xe7\xe3o de imagens, suportando entrada via descri\xe7\xf5es textuais. Possui suporte nativo ao chin\xeas, compreendendo e processando melhor descri\xe7\xf5es textuais em chin\xeas, capturando com maior precis\xe3o as informa\xe7\xf5es sem\xe2nticas para convert\xea-las em caracter\xedsticas visuais, permitindo gera\xe7\xe3o de imagens mais precisas. Gera imagens de alta resolu\xe7\xe3o e qualidade, com certa capacidade de transfer\xeancia de estilo."},"step-2-16k":{"description":"Suporta intera\xe7\xf5es de contexto em larga escala, adequado para cen\xe1rios de di\xe1logo complexos."},"step-2-16k-exp":{"description":"Vers\xe3o experimental do modelo step-2, contendo os recursos mais recentes, em atualiza\xe7\xe3o cont\xednua. N\xe3o \xe9 recomendado para uso em ambientes de produ\xe7\xe3o formal."},"step-2-mini":{"description":"Um modelo de grande escala de alta velocidade baseado na nova arquitetura de aten\xe7\xe3o auto-desenvolvida MFA, alcan\xe7ando resultados semelhantes ao step1 com um custo muito baixo, enquanto mant\xe9m uma maior taxa de transfer\xeancia e um tempo de resposta mais r\xe1pido. Capaz de lidar com tarefas gerais, possui especializa\xe7\xe3o em habilidades de codifica\xe7\xe3o."},"step-2x-large":{"description":"Nova gera\xe7\xe3o do modelo Xingchen Step, focado em gera\xe7\xe3o de imagens, capaz de criar imagens de alta qualidade a partir de descri\xe7\xf5es textuais fornecidas pelo usu\xe1rio. O novo modelo gera imagens com textura mais realista e melhor capacidade de gera\xe7\xe3o de texto em chin\xeas e ingl\xeas."},"step-3":{"description":"Este modelo possui forte percep\xe7\xe3o visual e capacidade de racioc\xednio complexo. Pode realizar com precis\xe3o a compreens\xe3o de conhecimentos complexos entre diferentes \xe1reas, a an\xe1lise cruzada entre informa\xe7\xf5es matem\xe1ticas e visuais, al\xe9m de resolver diversos tipos de problemas de an\xe1lise visual do cotidiano."},"step-r1-v-mini":{"description":"Este modelo \xe9 um grande modelo de infer\xeancia com forte capacidade de compreens\xe3o de imagens, capaz de processar informa\xe7\xf5es de imagem e texto, gerando conte\xfado textual ap\xf3s um profundo racioc\xednio. O modelo se destaca no campo do racioc\xednio visual, al\xe9m de possuir habilidades de racioc\xednio matem\xe1tico, c\xf3digo e texto de primeira linha. O comprimento do contexto \xe9 de 100k."},"step3":{"description":"Step3 \xe9 um modelo multimodal lan\xe7ado pela StepStar, com poderosa capacidade de compreens\xe3o visual."},"stepfun-ai/step3":{"description":"Step3 \xe9 um modelo avan\xe7ado de racioc\xednio multimodal lan\xe7ado pela StepFun, constru\xeddo sobre uma arquitetura de mistura de especialistas (Mixture of Experts, MoE) com 321B de par\xe2metros totais e 38B de par\xe2metros de ativa\xe7\xe3o. O modelo adota um design ponta a ponta, visando minimizar o custo de decodifica\xe7\xe3o enquanto oferece desempenho de primeira linha em racioc\xednio vis\xe3o-linguagem. Por meio do design cooperativo de Aten\xe7\xe3o por Decomposi\xe7\xe3o em M\xfaltiplas Matrizes (MFA) e do Desacoplamento Aten\xe7\xe3o-FFN (AFD), o Step3 mant\xe9m excelente efici\xeancia tanto em aceleradores de alto desempenho quanto em aceleradores de baixo custo. Na fase de pr\xe9-treinamento, o Step3 processou mais de 20T tokens de texto e 4T tokens multimodais de imagem e texto, cobrindo mais de dez idiomas. O modelo alcan\xe7ou posi\xe7\xf5es de lideran\xe7a entre modelos open-source em v\xe1rios benchmarks, incluindo matem\xe1tica, c\xf3digo e tarefas multimodais."},"taichu_llm":{"description":"O modelo de linguagem Taichu possui uma forte capacidade de compreens\xe3o de linguagem, al\xe9m de habilidades em cria\xe7\xe3o de texto, perguntas e respostas, programa\xe7\xe3o de c\xf3digo, c\xe1lculos matem\xe1ticos, racioc\xednio l\xf3gico, an\xe1lise de sentimentos e resumo de texto. Inova ao combinar pr\xe9-treinamento com grandes dados e conhecimento rico de m\xfaltiplas fontes, aprimorando continuamente a tecnologia de algoritmos e absorvendo novos conhecimentos de vocabul\xe1rio, estrutura, gram\xe1tica e sem\xe2ntica de grandes volumes de dados textuais, proporcionando aos usu\xe1rios informa\xe7\xf5es e servi\xe7os mais convenientes e uma experi\xeancia mais inteligente."},"taichu_o1":{"description":"taichu_o1 \xe9 um novo grande modelo de infer\xeancia de pr\xf3xima gera\xe7\xe3o, que realiza cadeias de pensamento humano por meio de intera\xe7\xf5es multimodais e aprendizado por refor\xe7o, suportando dedu\xe7\xf5es de decis\xf5es complexas, enquanto exibe caminhos de racioc\xednio model\xe1veis com alta precis\xe3o de sa\xedda, adequado para an\xe1lise de estrat\xe9gias e racioc\xednio profundo."},"taichu_vl":{"description":"Integra capacidades de compreens\xe3o de imagens, transfer\xeancia de conhecimento e atribui\xe7\xe3o l\xf3gica, destacando-se na \xe1rea de perguntas e respostas baseadas em texto e imagem."},"tencent/Hunyuan-A13B-Instruct":{"description":"Hunyuan-A13B-Instruct possui 80 bilh\xf5es de par\xe2metros, ativando 13 bilh\xf5es para competir com modelos maiores, suportando racioc\xednio h\xedbrido de “pensamento r\xe1pido/pensamento lento”; compreens\xe3o est\xe1vel de textos longos; validado pelo BFCL-v3 e τ-Bench, com capacidades de agente l\xedderes; combinando GQA e m\xfaltiplos formatos de quantiza\xe7\xe3o para infer\xeancia eficiente."},"tencent/Hunyuan-MT-7B":{"description":"O modelo de tradu\xe7\xe3o Hunyuan (Hunyuan Translation Model) \xe9 composto pelo modelo de tradu\xe7\xe3o Hunyuan-MT-7B e pelo modelo integrado Hunyuan-MT-Chimera. O Hunyuan-MT-7B \xe9 um modelo leve com 7 bilh\xf5es de par\xe2metros, projetado para traduzir textos da l\xedngua de origem para a l\xedngua de destino. Suporta tradu\xe7\xe3o entre 33 idiomas e 5 l\xednguas de minorias \xe9tnicas chinesas. No concurso internacional de tradu\xe7\xe3o autom\xe1tica WMT25, o Hunyuan-MT-7B conquistou o primeiro lugar em 30 das 31 categorias lingu\xedsticas em que participou, demonstrando sua excel\xeancia em tradu\xe7\xe3o. A Tencent prop\xf4s um paradigma completo de treinamento para cen\xe1rios de tradu\xe7\xe3o, que vai do pr\xe9-treinamento ao ajuste supervisionado, seguido por refor\xe7o de tradu\xe7\xe3o e refor\xe7o integrado, alcan\xe7ando desempenho l\xedder na ind\xfastria entre modelos de mesma escala. O modelo \xe9 eficiente em termos computacionais, f\xe1cil de implantar e adequado para diversos cen\xe1rios de aplica\xe7\xe3o."},"text-embedding-3-large":{"description":"O modelo de vetoriza\xe7\xe3o mais poderoso, adequado para tarefas em ingl\xeas e n\xe3o ingl\xeas."},"text-embedding-3-small":{"description":"Modelo de Embedding de nova gera\xe7\xe3o, eficiente e econ\xf4mico, adequado para recupera\xe7\xe3o de conhecimento, aplica\xe7\xf5es RAG e outros cen\xe1rios."},"thudm/glm-4-32b":{"description":"O GLM-4-32B-0414 \xe9 um modelo de linguagem de pesos abertos bil\xedngue (chin\xeas-ingl\xeas) de 32B, otimizado para gera\xe7\xe3o de c\xf3digo, chamadas de fun\xe7\xe3o e tarefas baseadas em agentes. Ele foi pr\xe9-treinado em 15T de dados de alta qualidade e re-racioc\xednio, e aprimorado com alinhamento de prefer\xeancias humanas, amostragem de rejei\xe7\xe3o e aprendizado por refor\xe7o. Este modelo se destaca em racioc\xednio complexo, gera\xe7\xe3o de artefatos e tarefas de sa\xedda estruturada, alcan\xe7ando desempenho compar\xe1vel ao GPT-4o e DeepSeek-V3-0324 em v\xe1rios testes de refer\xeancia."},"thudm/glm-4-32b:free":{"description":"O GLM-4-32B-0414 \xe9 um modelo de linguagem de pesos abertos bil\xedngue (chin\xeas-ingl\xeas) de 32B, otimizado para gera\xe7\xe3o de c\xf3digo, chamadas de fun\xe7\xe3o e tarefas baseadas em agentes. Ele foi pr\xe9-treinado em 15T de dados de alta qualidade e re-racioc\xednio, e aprimorado com alinhamento de prefer\xeancias humanas, amostragem de rejei\xe7\xe3o e aprendizado por refor\xe7o. Este modelo se destaca em racioc\xednio complexo, gera\xe7\xe3o de artefatos e tarefas de sa\xedda estruturada, alcan\xe7ando desempenho compar\xe1vel ao GPT-4o e DeepSeek-V3-0324 em v\xe1rios testes de refer\xeancia."},"thudm/glm-4-9b-chat":{"description":"Vers\xe3o de c\xf3digo aberto da \xfaltima gera\xe7\xe3o do modelo pr\xe9-treinado GLM-4, lan\xe7ado pela Zhizhu AI."},"thudm/glm-z1-32b":{"description":"O GLM-Z1-32B-0414 \xe9 uma variante de racioc\xednio aprimorada do GLM-4-32B, constru\xedda para resolver problemas de matem\xe1tica profunda, l\xf3gica e voltados para c\xf3digo. Ele aplica aprendizado por refor\xe7o estendido (tarefa espec\xedfica e baseado em prefer\xeancias emparelhadas gerais) para melhorar o desempenho em tarefas complexas de m\xfaltiplos passos. Em compara\xe7\xe3o com o modelo base GLM-4-32B, o Z1 melhora significativamente as capacidades de racioc\xednio estruturado e formal.\\n\\nEste modelo suporta a execu\xe7\xe3o for\xe7ada de etapas de \'pensamento\' por meio de engenharia de prompts e oferece maior coer\xeancia para sa\xeddas de formato longo. Ele \xe9 otimizado para fluxos de trabalho de agentes e suporta longos contextos (via YaRN), chamadas de ferramentas JSON e configura\xe7\xf5es de amostragem de granularidade fina para racioc\xednio est\xe1vel. \xc9 ideal para casos de uso que exigem racioc\xednio cuidadoso, de m\xfaltiplos passos ou dedu\xe7\xf5es formais."},"thudm/glm-z1-rumination-32b":{"description":"THUDM: GLM Z1 Rumination 32B \xe9 um modelo de racioc\xednio profundo de 32 bilh\xf5es de par\xe2metros da s\xe9rie GLM-4-Z1, otimizado para tarefas complexas e abertas que exigem longos per\xedodos de reflex\xe3o. Ele \xe9 constru\xeddo sobre o glm-4-32b-0414, adicionando uma fase de aprendizado por refor\xe7o adicional e estrat\xe9gias de alinhamento em m\xfaltiplas etapas, introduzindo a capacidade de \'reflex\xe3o\' destinada a simular processamento cognitivo expandido. Isso inclui racioc\xednio iterativo, an\xe1lise de m\xfaltiplos saltos e fluxos de trabalho aprimorados por ferramentas, como busca, recupera\xe7\xe3o e s\xedntese consciente de cita\xe7\xf5es.\\n\\nEste modelo se destaca em escrita de pesquisa, an\xe1lise comparativa e perguntas complexas. Ele suporta chamadas de fun\xe7\xe3o para primitivos de busca e navega\xe7\xe3o (`search`, `click`, `open`, `finish`), permitindo seu uso em pipelines baseados em agentes. O comportamento reflexivo \xe9 moldado por recompensas baseadas em regras e um mecanismo de decis\xe3o atrasada controlado por m\xfaltiplos ciclos, com refer\xeancia a estruturas de pesquisa profunda como a pilha de alinhamento interna da OpenAI. Esta variante \xe9 adequada para cen\xe1rios que exigem profundidade em vez de velocidade."},"tngtech/deepseek-r1t-chimera:free":{"description":"DeepSeek-R1T-Chimera \xe9 criado pela combina\xe7\xe3o do DeepSeek-R1 e DeepSeek-V3 (0324), unindo a capacidade de racioc\xednio do R1 e as melhorias de efici\xeancia de tokens do V3. Ele \xe9 baseado na arquitetura DeepSeek-MoE Transformer e otimizado para tarefas gerais de gera\xe7\xe3o de texto.\\n\\nEste modelo combina os pesos pr\xe9-treinados de duas fontes para equilibrar o desempenho em racioc\xednio, efici\xeancia e tarefas de seguir instru\xe7\xf5es. Ele \xe9 lan\xe7ado sob a licen\xe7a MIT, destinado a uso em pesquisa e comercial."},"togethercomputer/StripedHyena-Nous-7B":{"description":"StripedHyena Nous (7B) oferece capacidade de computa\xe7\xe3o aprimorada atrav\xe9s de estrat\xe9gias e arquiteturas de modelo eficientes."},"tts-1":{"description":"O mais recente modelo de texto para fala, otimizado para velocidade em cen\xe1rios em tempo real."},"tts-1-hd":{"description":"O mais recente modelo de texto para fala, otimizado para qualidade."},"upstage/SOLAR-10.7B-Instruct-v1.0":{"description":"Upstage SOLAR Instruct v1 (11B) \xe9 adequado para tarefas de instru\xe7\xe3o refinadas, oferecendo excelente capacidade de processamento de linguagem."},"us.anthropic.claude-3-5-sonnet-20241022-v2:0":{"description":"Claude 3.5 Sonnet eleva o padr\xe3o da ind\xfastria, superando modelos concorrentes e Claude 3 Opus, apresentando um desempenho excepcional em uma ampla gama de avalia\xe7\xf5es, enquanto mant\xe9m a velocidade e o custo de nossos modelos de n\xedvel m\xe9dio."},"us.anthropic.claude-3-7-sonnet-20250219-v1:0":{"description":"Claude 3.7 sonnet \xe9 o modelo de pr\xf3xima gera\xe7\xe3o mais r\xe1pido da Anthropic. Em compara\xe7\xe3o com o Claude 3 Haiku, o Claude 3.7 Sonnet apresenta melhorias em v\xe1rias habilidades e supera o maior modelo da gera\xe7\xe3o anterior, o Claude 3 Opus, em muitos testes de refer\xeancia de intelig\xeancia."},"us.anthropic.claude-haiku-4-5-20251001-v1:0":{"description":"Claude Haiku 4.5 \xe9 o modelo Haiku mais r\xe1pido e inteligente da Anthropic, com velocidade rel\xe2mpago e capacidade de racioc\xednio expandida."},"us.anthropic.claude-sonnet-4-5-20250929-v1:0":{"description":"Claude Sonnet 4.5 \xe9 o modelo mais inteligente j\xe1 desenvolvido pela Anthropic at\xe9 o momento."},"v0-1.0-md":{"description":"O modelo v0-1.0-md \xe9 uma vers\xe3o antiga que oferece servi\xe7os atrav\xe9s da API v0"},"v0-1.5-lg":{"description":"O modelo v0-1.5-lg \xe9 adequado para tarefas avan\xe7adas de pensamento ou racioc\xednio"},"v0-1.5-md":{"description":"O modelo v0-1.5-md \xe9 adequado para tarefas di\xe1rias e gera\xe7\xe3o de interfaces de usu\xe1rio (UI)"},"vercel/v0-1.0-md":{"description":"Acesso ao modelo por tr\xe1s do v0 para gerar, corrigir e otimizar aplica\xe7\xf5es web modernas, com racioc\xednio espec\xedfico para frameworks e conhecimento atualizado."},"vercel/v0-1.5-md":{"description":"Acesso ao modelo por tr\xe1s do v0 para gerar, corrigir e otimizar aplica\xe7\xf5es web modernas, com racioc\xednio espec\xedfico para frameworks e conhecimento atualizado."},"wan2.2-t2i-flash":{"description":"Vers\xe3o ultrarr\xe1pida Wanxiang 2.2, modelo mais recente. Atualiza\xe7\xf5es abrangentes em criatividade, estabilidade e realismo, com alta velocidade de gera\xe7\xe3o e excelente custo-benef\xedcio."},"wan2.2-t2i-plus":{"description":"Vers\xe3o profissional Wanxiang 2.2, modelo mais recente. Atualiza\xe7\xf5es abrangentes em criatividade, estabilidade e realismo, com gera\xe7\xe3o de detalhes ricos."},"wanx-v1":{"description":"Modelo b\xe1sico de gera\xe7\xe3o de imagens a partir de texto, correspondente ao modelo geral 1.0 do site oficial Tongyi Wanxiang."},"wanx2.0-t2i-turbo":{"description":"Especializado em retratos com textura, velocidade m\xe9dia e custo baixo. Corresponde ao modelo ultrarr\xe1pido 2.0 do site oficial Tongyi Wanxiang."},"wanx2.1-t2i-plus":{"description":"Vers\xe3o totalmente atualizada. Gera\xe7\xe3o de imagens com detalhes mais ricos, velocidade um pouco mais lenta. Corresponde ao modelo profissional 2.1 do site oficial Tongyi Wanxiang."},"wanx2.1-t2i-turbo":{"description":"Vers\xe3o totalmente atualizada. Gera\xe7\xe3o r\xe1pida, resultados abrangentes e excelente custo-benef\xedcio. Corresponde ao modelo ultrarr\xe1pido 2.1 do site oficial Tongyi Wanxiang."},"whisper-1":{"description":"Modelo universal de reconhecimento de voz, suportando reconhecimento de voz multil\xedngue, tradu\xe7\xe3o de voz e identifica\xe7\xe3o de idioma."},"wizardlm2":{"description":"WizardLM 2 \xe9 um modelo de linguagem fornecido pela Microsoft AI, destacando-se em di\xe1logos complexos, multil\xedngue, racioc\xednio e assistentes inteligentes."},"wizardlm2:8x22b":{"description":"WizardLM 2 \xe9 um modelo de linguagem fornecido pela Microsoft AI, destacando-se em di\xe1logos complexos, multil\xedngue, racioc\xednio e assistentes inteligentes."},"x-ai/grok-4-fast":{"description":"Temos o prazer de apresentar o Grok 4 Fast, nosso mais recente avan\xe7o em modelos de racioc\xednio com excelente custo-benef\xedcio."},"x-ai/grok-code-fast-1":{"description":"Temos o prazer de lan\xe7ar o grok-code-fast-1, um modelo de racioc\xednio r\xe1pido e econ\xf4mico, com desempenho excepcional em codifica\xe7\xe3o assistida por agentes."},"x1":{"description":"O modelo Spark X1 ser\xe1 aprimorado ainda mais, mantendo a lideran\xe7a em tarefas matem\xe1ticas no pa\xeds, e alcan\xe7ando resultados em tarefas gerais como racioc\xednio, gera\xe7\xe3o de texto e compreens\xe3o de linguagem que se comparam ao OpenAI o1 e DeepSeek R1."},"xai/grok-2":{"description":"Grok 2 \xe9 um modelo de linguagem de ponta com capacidades avan\xe7adas de racioc\xednio. Possui habilidades avan\xe7adas em chat, codifica\xe7\xe3o e racioc\xednio, superando Claude 3.5 Sonnet e GPT-4-Turbo no ranking LMSYS."},"xai/grok-2-vision":{"description":"O modelo visual Grok 2 apresenta desempenho excepcional em tarefas baseadas em vis\xe3o, oferecendo desempenho de ponta em racioc\xednio matem\xe1tico visual (MathVista) e perguntas e respostas baseadas em documentos (DocVQA). Ele pode processar diversos tipos de informa\xe7\xf5es visuais, incluindo documentos, gr\xe1ficos, tabelas, capturas de tela e fotos."},"xai/grok-3":{"description":"Modelo principal da xAI, com desempenho excelente em casos de uso empresariais como extra\xe7\xe3o de dados, codifica\xe7\xe3o e resumo de texto. Possui profundo conhecimento em finan\xe7as, sa\xfade, direito e ci\xeancias."},"xai/grok-3-fast":{"description":"Modelo principal da xAI, com desempenho excelente em casos de uso empresariais como extra\xe7\xe3o de dados, codifica\xe7\xe3o e resumo de texto. A variante r\xe1pida do modelo \xe9 atendida em infraestrutura mais veloz, oferecendo tempos de resposta muito mais r\xe1pidos que o padr\xe3o. O aumento de velocidade tem custo maior por token de sa\xedda."},"xai/grok-3-mini":{"description":"Modelo leve da xAI que pensa antes de responder. Ideal para tarefas simples ou baseadas em l\xf3gica que n\xe3o exigem profundo conhecimento de dom\xednio. A trajet\xf3ria de pensamento bruta \xe9 acess\xedvel."},"xai/grok-3-mini-fast":{"description":"Modelo leve da xAI que pensa antes de responder. Ideal para tarefas simples ou baseadas em l\xf3gica que n\xe3o exigem profundo conhecimento de dom\xednio. A trajet\xf3ria de pensamento bruta \xe9 acess\xedvel. A variante r\xe1pida do modelo \xe9 atendida em infraestrutura mais veloz, oferecendo tempos de resposta muito mais r\xe1pidos que o padr\xe3o. O aumento de velocidade tem custo maior por token de sa\xedda."},"xai/grok-4":{"description":"O mais recente e melhor modelo principal da xAI, oferecendo desempenho incompar\xe1vel em linguagem natural, matem\xe1tica e racioc\xednio — o competidor perfeito para todas as tarefas."},"yi-large":{"description":"Modelo de nova gera\xe7\xe3o com trilh\xf5es de par\xe2metros, oferecendo capacidades excepcionais de perguntas e respostas e gera\xe7\xe3o de texto."},"yi-large-fc":{"description":"Baseado no modelo yi-large, suporta e aprimora a capacidade de chamadas de ferramentas, adequado para diversos cen\xe1rios de neg\xf3cios que exigem a constru\xe7\xe3o de agentes ou fluxos de trabalho."},"yi-large-preview":{"description":"Vers\xe3o inicial, recomenda-se o uso do yi-large (nova vers\xe3o)."},"yi-large-rag":{"description":"Servi\xe7o de alto n\xedvel baseado no modelo yi-large, combinando t\xe9cnicas de recupera\xe7\xe3o e gera\xe7\xe3o para fornecer respostas precisas, com servi\xe7os de busca em tempo real na web."},"yi-large-turbo":{"description":"Excelente rela\xe7\xe3o custo-benef\xedcio e desempenho excepcional. Ajuste de alta precis\xe3o baseado em desempenho, velocidade de racioc\xednio e custo."},"yi-lightning":{"description":"Modelo de alto desempenho mais recente, garantindo sa\xedda de alta qualidade enquanto a velocidade de racioc\xednio \xe9 significativamente aprimorada."},"yi-lightning-lite":{"description":"Vers\xe3o leve, recomendada para uso com yi-lightning."},"yi-medium":{"description":"Modelo de tamanho m\xe9dio com ajuste fino, equilibrando capacidades e custo. Otimiza\xe7\xe3o profunda da capacidade de seguir instru\xe7\xf5es."},"yi-medium-200k":{"description":"Janela de contexto ultra longa de 200K, oferecendo compreens\xe3o e gera\xe7\xe3o de texto em profundidade."},"yi-spark":{"description":"Modelo leve e \xe1gil. Oferece capacidades aprimoradas de c\xe1lculos matem\xe1ticos e escrita de c\xf3digo."},"yi-vision":{"description":"Modelo para tarefas visuais complexas, oferecendo alta performance em compreens\xe3o e an\xe1lise de imagens."},"yi-vision-v2":{"description":"Modelo para tarefas visuais complexas, oferecendo alta performance em compreens\xe3o e an\xe1lise baseadas em m\xfaltiplas imagens."},"z-ai/glm-4.6":{"description":"GLM-4.6, o mais novo modelo carro-chefe da Zhipu, supera amplamente a gera\xe7\xe3o anterior em codifica\xe7\xe3o avan\xe7ada, processamento de textos longos, racioc\xednio e capacidades de agentes inteligentes."},"zai-org/GLM-4.5":{"description":"GLM-4.5 \xe9 um modelo base projetado para aplica\xe7\xf5es de agentes inteligentes, utilizando arquitetura Mixture-of-Experts (MoE). Otimizado para chamadas de ferramentas, navega\xe7\xe3o web, engenharia de software e programa\xe7\xe3o front-end, suporta integra\xe7\xe3o perfeita com agentes de c\xf3digo como Claude Code e Roo Code. Adota modo de racioc\xednio h\xedbrido, adaptando-se a cen\xe1rios de racioc\xednio complexo e uso cotidiano."},"zai-org/GLM-4.5-Air":{"description":"GLM-4.5-Air \xe9 um modelo base projetado para aplica\xe7\xf5es de agentes inteligentes, utilizando arquitetura Mixture-of-Experts (MoE). Otimizado para chamadas de ferramentas, navega\xe7\xe3o web, engenharia de software e programa\xe7\xe3o front-end, suporta integra\xe7\xe3o perfeita com agentes de c\xf3digo como Claude Code e Roo Code. Adota modo de racioc\xednio h\xedbrido, adaptando-se a cen\xe1rios de racioc\xednio complexo e uso cotidiano."},"zai-org/GLM-4.5V":{"description":"GLM-4.5V \xe9 a mais recente gera\xe7\xe3o de modelo de linguagem visual (VLM) lan\xe7ada pela Zhipu AI (智谱 AI). O modelo \xe9 constru\xeddo sobre o modelo de texto carro‑chefe GLM-4.5-Air, que possui 106 bilh\xf5es de par\xe2metros totais e 12 bilh\xf5es de par\xe2metros de ativa\xe7\xe3o, adotando uma arquitetura de especialistas mistos (MoE) com o objetivo de oferecer desempenho de alto n\xedvel a um custo de infer\xeancia reduzido. Tecnicamente, o GLM-4.5V d\xe1 continuidade \xe0 linha do GLM-4.1V-Thinking e introduz inova\xe7\xf5es como a codifica\xe7\xe3o de posi\xe7\xe3o rotacional 3D (3D-RoPE), que aumentam significativamente a percep\xe7\xe3o e o racioc\xednio sobre rela\xe7\xf5es espaciais tridimensionais. Por meio de otimiza\xe7\xf5es nas fases de pr\xe9-treinamento, ajuste fino supervisionado e aprendizado por refor\xe7o, o modelo \xe9 capaz de processar diversos tipos de conte\xfado visual — incluindo imagens, v\xeddeos e longos documentos — e alcan\xe7ou desempenho de ponta entre modelos open-source da mesma categoria em 41 benchmarks multimodais p\xfablicos. Al\xe9m disso, o modelo inclui um interruptor de \\"modo de pensamento\\", que permite aos usu\xe1rios alternar de forma flex\xedvel entre respostas r\xe1pidas e racioc\xednio aprofundado, equilibrando efici\xeancia e efic\xe1cia."},"zai-org/GLM-4.6":{"description":"Comparado ao GLM-4.5, o GLM-4.6 traz v\xe1rias melhorias importantes. Sua janela de contexto foi expandida de 128K para 200K tokens, permitindo que o modelo lide com tarefas de agentes mais complexas. O modelo alcan\xe7ou pontua\xe7\xf5es mais altas em benchmarks de c\xf3digo e demonstrou desempenho superior em aplica\xe7\xf5es como Claude Code, Cline, Roo Code e Kilo Code, incluindo melhorias na gera\xe7\xe3o de interfaces front-end visualmente refinadas. O GLM-4.6 apresenta melhorias claras no desempenho de infer\xeancia e suporta o uso de ferramentas durante a infer\xeancia, proporcionando capacidades integradas mais robustas. Ele se destaca no uso de ferramentas e agentes baseados em busca, al\xe9m de integrar-se de forma mais eficaz em frameworks de agentes. Na escrita, o modelo oferece estilo e legibilidade mais alinhados \xe0s prefer\xeancias humanas e atua de forma mais natural em cen\xe1rios de interpreta\xe7\xe3o de pap\xe9is."},"zai/glm-4.5":{"description":"A s\xe9rie de modelos GLM-4.5 \xe9 uma base projetada especificamente para agentes. O modelo principal GLM-4.5 integra 355 bilh\xf5es de par\xe2metros totais (32 bilh\xf5es ativos), unificando racioc\xednio, codifica\xe7\xe3o e capacidades de agente para atender a demandas complexas de aplica\xe7\xf5es. Como sistema de racioc\xednio h\xedbrido, oferece modos operacionais duplos."},"zai/glm-4.5-air":{"description":"GLM-4.5 e GLM-4.5-Air s\xe3o nossos modelos principais mais recentes, projetados especificamente como bases para aplica\xe7\xf5es de agentes. Ambos utilizam arquitetura de especialistas mistos (MoE). GLM-4.5 possui 355 bilh\xf5es de par\xe2metros totais com 32 bilh\xf5es ativos por passagem, enquanto GLM-4.5-Air tem design mais simplificado, com 106 bilh\xf5es de par\xe2metros totais e 12 bilh\xf5es ativos."},"zai/glm-4.5v":{"description":"GLM-4.5V \xe9 constru\xeddo sobre o modelo base GLM-4.5-Air, herdando a tecnologia comprovada do GLM-4.1V-Thinking, enquanto alcan\xe7a escalabilidade eficiente por meio da poderosa arquitetura MoE de 106 bilh\xf5es de par\xe2metros."}}')}}]);