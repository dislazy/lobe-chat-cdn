"use strict";(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[24149],{24149:o=>{o.exports=JSON.parse('{"01-ai/yi-1.5-34b-chat":{"description":"Zero One, najnowszy model open source z dostrojeniem, zawierający 34 miliardy parametr\xf3w, dostosowany do r\xf3żnych scenariuszy dialogowych, z wysokiej jakości danymi treningowymi, dostosowany do preferencji ludzkich."},"01-ai/yi-1.5-9b-chat":{"description":"Zero One, najnowszy model open source z dostrojeniem, zawierający 9 miliard\xf3w parametr\xf3w, dostosowany do r\xf3żnych scenariuszy dialogowych, z wysokiej jakości danymi treningowymi, dostosowany do preferencji ludzkich."},"360/deepseek-r1":{"description":"[Wersja 360] DeepSeek-R1 wykorzystuje techniki uczenia przez wzmocnienie na dużą skalę w fazie po treningu, znacznie poprawiając zdolności wnioskowania modelu przy minimalnej ilości oznaczonych danych. W zadaniach matematycznych, kodowania i wnioskowania w języku naturalnym osiąga wyniki por\xf3wnywalne z oficjalną wersją OpenAI o1."},"360gpt-pro":{"description":"360GPT Pro, jako ważny członek serii modeli AI 360, zaspokaja r\xf3żnorodne potrzeby aplikacji przetwarzania języka naturalnego dzięki wydajnym zdolnościom przetwarzania tekstu, obsługując zrozumienie długich tekst\xf3w i wielokrotne dialogi."},"360gpt-pro-trans":{"description":"Model dedykowany do tłumaczeń, głęboko dostrojony i zoptymalizowany, oferujący wiodące efekty tłumaczeniowe."},"360gpt-turbo":{"description":"360GPT Turbo oferuje potężne zdolności obliczeniowe i dialogowe, charakteryzując się doskonałym rozumieniem semantycznym i wydajnością generacyjną, stanowiąc idealne rozwiązanie dla firm i deweloper\xf3w jako inteligentny asystent."},"360gpt-turbo-responsibility-8k":{"description":"360GPT Turbo Responsibility 8K kładzie nacisk na bezpieczeństwo semantyczne i odpowiedzialność, zaprojektowany specjalnie dla aplikacji o wysokich wymaganiach dotyczących bezpieczeństwa treści, zapewniając dokładność i stabilność doświadczeń użytkownik\xf3w."},"360gpt2-o1":{"description":"360gpt2-o1 wykorzystuje wyszukiwanie drzew do budowy łańcucha myślenia i wprowadza mechanizm refleksji, wykorzystując uczenie przez wzmocnienie, model posiada zdolność do samorefleksji i korekty błęd\xf3w."},"360gpt2-pro":{"description":"360GPT2 Pro to zaawansowany model przetwarzania języka naturalnego wydany przez firmę 360, charakteryzujący się doskonałymi zdolnościami generowania i rozumienia tekstu, szczeg\xf3lnie w obszarze generowania i tworzenia treści, zdolny do obsługi skomplikowanych zadań związanych z konwersją językową i odgrywaniem r\xf3l."},"360zhinao2-o1":{"description":"Model 360zhinao2-o1 wykorzystuje wyszukiwanie drzewne do budowy łańcucha myślowego i wprowadza mechanizm refleksji, wykorzystując uczenie przez wzmocnienie do treningu, co pozwala modelowi na samorefleksję i korekcję błęd\xf3w."},"4.0Ultra":{"description":"Spark4.0 Ultra to najsilniejsza wersja w serii modeli Spark, kt\xf3ra, opr\xf3cz ulepszonego łącza wyszukiwania w sieci, zwiększa zdolność rozumienia i podsumowywania treści tekstowych. Jest to kompleksowe rozwiązanie mające na celu zwiększenie wydajności biurowej i dokładne odpowiadanie na potrzeby, stanowiące inteligentny produkt wiodący w branży."},"AnimeSharp":{"description":"AnimeSharp (znany r\xf3wnież jako „4x‑AnimeSharp”) to otwarty model superrozdzielczości opracowany przez Kim2091 na bazie architektury ESRGAN, skoncentrowany na powiększaniu i wyostrzaniu obraz\xf3w w stylu anime. W lutym 2022 roku zmieniono jego nazwę z „4x-TextSharpV1”. Początkowo model był r\xf3wnież stosowany do obraz\xf3w tekstowych, ale jego wydajność została znacznie zoptymalizowana pod kątem treści anime."},"Baichuan2-Turbo":{"description":"Wykorzystuje technologię wzmacniania wyszukiwania, aby połączyć duży model z wiedzą branżową i wiedzą z całej sieci. Obsługuje przesyłanie r\xf3żnych dokument\xf3w, takich jak PDF, Word, oraz wprowadzanie adres\xf3w URL, zapewniając szybki i kompleksowy dostęp do informacji oraz dokładne i profesjonalne wyniki."},"Baichuan3-Turbo":{"description":"Optymalizowany pod kątem częstych scenariuszy biznesowych, znacznie poprawiający efektywność i oferujący korzystny stosunek jakości do ceny. W por\xf3wnaniu do modelu Baichuan2, generowanie treści wzrosło o 20%, pytania o wiedzę o 17%, a zdolności odgrywania r\xf3l o 40%. Og\xf3lna wydajność jest lepsza niż GPT3.5."},"Baichuan3-Turbo-128k":{"description":"Oferuje 128K ultra długi kontekst, zoptymalizowany pod kątem częstych scenariuszy biznesowych, znacznie poprawiający efektywność i oferujący korzystny stosunek jakości do ceny. W por\xf3wnaniu do modelu Baichuan2, generowanie treści wzrosło o 20%, pytania o wiedzę o 17%, a zdolności odgrywania r\xf3l o 40%. Og\xf3lna wydajność jest lepsza niż GPT3.5."},"Baichuan4":{"description":"Model o najwyższej wydajności w kraju, przewyższający zagraniczne modele w zadaniach związanych z encyklopedią, długimi tekstami i generowaniem treści w języku chińskim. Posiada r\xf3wnież wiodące w branży zdolności multimodalne, osiągając doskonałe wyniki w wielu autorytatywnych testach."},"Baichuan4-Air":{"description":"Model o najlepszych możliwościach w kraju, przewyższający zagraniczne modele w zadaniach związanych z wiedzą encyklopedyczną, długimi tekstami i tw\xf3rczością w języku chińskim. Posiada r\xf3wnież wiodące w branży możliwości multimodalne, osiągając doskonałe wyniki w wielu autorytatywnych testach."},"Baichuan4-Turbo":{"description":"Model o najlepszych możliwościach w kraju, przewyższający zagraniczne modele w zadaniach związanych z wiedzą encyklopedyczną, długimi tekstami i tw\xf3rczością w języku chińskim. Posiada r\xf3wnież wiodące w branży możliwości multimodalne, osiągając doskonałe wyniki w wielu autorytatywnych testach."},"ByteDance-Seed/Seed-OSS-36B-Instruct":{"description":"Seed-OSS to seria otwartych modeli językowych dużej skali opracowanych przez zesp\xf3ł Seed ByteDance, zaprojektowanych specjalnie do zaawansowanego przetwarzania długich kontekst\xf3w, wnioskowania, agent\xf3w i zdolności og\xf3lnych. Model Seed-OSS-36B-Instruct z tej serii to model dostrojony instrukcyjnie z 36 miliardami parametr\xf3w, natywnie obsługujący bardzo długie konteksty, co pozwala na jednorazowe przetwarzanie ogromnych dokument\xf3w lub złożonych baz kodu. Model jest szczeg\xf3lnie zoptymalizowany pod kątem wnioskowania, generowania kodu i zadań agent\xf3w (np. użycia narzędzi), zachowując jednocześnie zr\xf3wnoważone i doskonałe zdolności og\xf3lne. Jedną z kluczowych cech tego modelu jest funkcja „budżetu myślenia” (Thinking Budget), kt\xf3ra pozwala użytkownikom elastycznie dostosowywać długość wnioskowania, skutecznie zwiększając efektywność w praktycznych zastosowaniach."},"DeepSeek-R1":{"description":"Najnowocześniejszy, wydajny LLM, specjalizujący się w wnioskowaniu, matematyce i programowaniu."},"DeepSeek-R1-Distill-Llama-70B":{"description":"DeepSeek R1 — większy i inteligentniejszy model w zestawie DeepSeek — został skondensowany do architektury Llama 70B. Na podstawie test\xf3w por\xf3wnawczych i ocen ludzkich, model ten jest bardziej inteligentny niż oryginalny Llama 70B, zwłaszcza w zadaniach wymagających precyzji matematycznej i faktograficznej."},"DeepSeek-R1-Distill-Qwen-1.5B":{"description":"Model destylacyjny DeepSeek-R1 oparty na Qwen2.5-Math-1.5B, optymalizujący wydajność wnioskowania dzięki uczeniu przez wzmocnienie i danym z zimnego startu, otwarty model ustanawiający nowe standardy w wielu zadaniach."},"DeepSeek-R1-Distill-Qwen-14B":{"description":"Model destylacyjny DeepSeek-R1 oparty na Qwen2.5-14B, optymalizujący wydajność wnioskowania dzięki uczeniu przez wzmocnienie i danym z zimnego startu, otwarty model ustanawiający nowe standardy w wielu zadaniach."},"DeepSeek-R1-Distill-Qwen-32B":{"description":"Seria DeepSeek-R1 optymalizuje wydajność wnioskowania dzięki uczeniu przez wzmocnienie i danym z zimnego startu, otwarty model ustanawiający nowe standardy w wielu zadaniach, przewyższający poziom OpenAI-o1-mini."},"DeepSeek-R1-Distill-Qwen-7B":{"description":"Model destylacyjny DeepSeek-R1 oparty na Qwen2.5-Math-7B, optymalizujący wydajność wnioskowania dzięki uczeniu przez wzmocnienie i danym z zimnego startu, otwarty model ustanawiający nowe standardy w wielu zadaniach."},"DeepSeek-V3":{"description":"DeepSeek-V3 to model MoE opracowany przez firmę DeepSeek. Wyniki DeepSeek-V3 w wielu testach przewyższają inne modele open source, takie jak Qwen2.5-72B i Llama-3.1-405B, a jego wydajność jest por\xf3wnywalna z najlepszymi zamkniętymi modelami na świecie, takimi jak GPT-4o i Claude-3.5-Sonnet."},"DeepSeek-V3-1":{"description":"DeepSeek V3.1: model nowej generacji do wnioskowania, poprawiający zdolności do złożonych rozumowań i myślenia łańcuchowego, idealny do zadań wymagających dogłębnej analizy."},"DeepSeek-V3-Fast":{"description":"Dostawca modelu: platforma sophnet. DeepSeek V3 Fast to szybka wersja o wysokim TPS modelu DeepSeek V3 0324, w pełni nienkwantyzowana, z ulepszonym kodem i zdolnościami matematycznymi, zapewniająca szybszą reakcję!"},"DeepSeek-V3.1":{"description":"DeepSeek-V3.1 tryb bez myślenia; DeepSeek-V3.1 to nowy hybrydowy model wnioskowania od DeepSeek, obsługujący dwa tryby: myślenia i bez myślenia, z wyższą efektywnością myślenia niż DeepSeek-R1-0528. Po optymalizacji post-treningowej znacznie poprawiono użycie narzędzi agenta oraz wydajność zadań agent\xf3w."},"DeepSeek-V3.1-Fast":{"description":"DeepSeek V3.1 Fast to szybka wersja DeepSeek V3.1 o wysokim TPS. Hybrydowy tryb myślenia: poprzez zmianę szablonu rozmowy jeden model może obsługiwać jednocześnie tryb myślenia i bez myślenia. Inteligentniejsze wywoływanie narzędzi: dzięki optymalizacji po treningu model znacząco poprawił wydajność w użyciu narzędzi i zadaniach agent\xf3w."},"DeepSeek-V3.1-Think":{"description":"DeepSeek-V3.1 tryb myślenia; DeepSeek-V3.1 to nowy hybrydowy model wnioskowania od DeepSeek, obsługujący dwa tryby: myślenia i bez myślenia, z wyższą efektywnością myślenia niż DeepSeek-R1-0528. Po optymalizacji post-treningowej znacznie poprawiono użycie narzędzi agenta oraz wydajność zadań agent\xf3w."},"DeepSeek-V3.2-Exp":{"description":"DeepSeek V3.2 to najnowszy uniwersalny model dużej skali DeepSeek, wspierający hybrydową architekturę inferencyjną i oferujący znacznie ulepszone możliwości agenta."},"DeepSeek-V3.2-Exp-Think":{"description":"Tryb myślenia DeepSeek V3.2. Przed wygenerowaniem ostatecznej odpowiedzi model najpierw przedstawia łańcuch rozumowania, co zwiększa dokładność końcowej odpowiedzi."},"Doubao-lite-128k":{"description":"Doubao-lite oferuje niezwykle szybkie reakcje i lepszy stosunek jakości do ceny, zapewniając klientom elastyczne opcje dla r\xf3żnych scenariuszy. Obsługuje wnioskowanie i dostrajanie z kontekstem do 128k."},"Doubao-lite-32k":{"description":"Doubao-lite oferuje niezwykle szybkie reakcje i lepszy stosunek jakości do ceny, zapewniając klientom elastyczne opcje dla r\xf3żnych scenariuszy. Obsługuje wnioskowanie i dostrajanie z kontekstem do 32k."},"Doubao-lite-4k":{"description":"Doubao-lite oferuje niezwykle szybkie reakcje i lepszy stosunek jakości do ceny, zapewniając klientom elastyczne opcje dla r\xf3żnych scenariuszy. Obsługuje wnioskowanie i dostrajanie z kontekstem do 4k."},"Doubao-pro-128k":{"description":"Najlepszy model gł\xf3wny, odpowiedni do złożonych zadań, osiągający doskonałe wyniki w scenariuszach takich jak pytania i odpowiedzi, streszczenia, tw\xf3rczość, klasyfikacja tekstu i odgrywanie r\xf3l. Obsługuje wnioskowanie i dostrajanie z kontekstem do 128k."},"Doubao-pro-32k":{"description":"Najlepszy model gł\xf3wny, odpowiedni do złożonych zadań, osiągający doskonałe wyniki w scenariuszach takich jak pytania i odpowiedzi, streszczenia, tw\xf3rczość, klasyfikacja tekstu i odgrywanie r\xf3l. Obsługuje wnioskowanie i dostrajanie z kontekstem do 32k."},"Doubao-pro-4k":{"description":"Najlepszy model gł\xf3wny, odpowiedni do złożonych zadań, osiągający doskonałe wyniki w scenariuszach takich jak pytania i odpowiedzi, streszczenia, tw\xf3rczość, klasyfikacja tekstu i odgrywanie r\xf3l. Obsługuje wnioskowanie i dostrajanie z kontekstem do 4k."},"DreamO":{"description":"DreamO to otwarty model generowania obraz\xf3w opracowany wsp\xf3lnie przez ByteDance i Uniwersytet Pekiński, mający na celu wsparcie wielozadaniowej generacji obraz\xf3w w ramach jednolitej architektury. Wykorzystuje efektywną metodę modelowania kombinacyjnego, umożliwiając generowanie sp\xf3jnych i dostosowanych obraz\xf3w na podstawie wielu warunk\xf3w, takich jak tożsamość, temat, styl czy tło wskazane przez użytkownika."},"ERNIE-3.5-128K":{"description":"Flagowy model dużego języka opracowany przez Baidu, obejmujący ogromne zbiory danych w języku chińskim i angielskim, charakteryzujący się silnymi zdolnościami og\xf3lnymi, zdolny do spełnienia wymagań w większości scenariuszy związanych z pytaniami i odpowiedziami, generowaniem treści oraz aplikacjami wtyczek; wspiera automatyczne połączenie z wtyczką wyszukiwania Baidu, zapewniając aktualność informacji w odpowiedziach."},"ERNIE-3.5-8K":{"description":"Flagowy model dużego języka opracowany przez Baidu, obejmujący ogromne zbiory danych w języku chińskim i angielskim, charakteryzujący się silnymi zdolnościami og\xf3lnymi, zdolny do spełnienia wymagań w większości scenariuszy związanych z pytaniami i odpowiedziami, generowaniem treści oraz aplikacjami wtyczek; wspiera automatyczne połączenie z wtyczką wyszukiwania Baidu, zapewniając aktualność informacji w odpowiedziach."},"ERNIE-3.5-8K-Preview":{"description":"Flagowy model dużego języka opracowany przez Baidu, obejmujący ogromne zbiory danych w języku chińskim i angielskim, charakteryzujący się silnymi zdolnościami og\xf3lnymi, zdolny do spełnienia wymagań w większości scenariuszy związanych z pytaniami i odpowiedziami, generowaniem treści oraz aplikacjami wtyczek; wspiera automatyczne połączenie z wtyczką wyszukiwania Baidu, zapewniając aktualność informacji w odpowiedziach."},"ERNIE-4.0-8K-Latest":{"description":"Flagowy model ultra dużego języka opracowany przez Baidu, w por\xf3wnaniu do ERNIE 3.5, oferujący kompleksową aktualizację możliwości modelu, szeroko stosowany w złożonych scenariuszach w r\xf3żnych dziedzinach; wspiera automatyczne połączenie z wtyczką wyszukiwania Baidu, zapewniając aktualność informacji."},"ERNIE-4.0-8K-Preview":{"description":"Flagowy model ultra dużego języka opracowany przez Baidu, w por\xf3wnaniu do ERNIE 3.5, oferujący kompleksową aktualizację możliwości modelu, szeroko stosowany w złożonych scenariuszach w r\xf3żnych dziedzinach; wspiera automatyczne połączenie z wtyczką wyszukiwania Baidu, zapewniając aktualność informacji."},"ERNIE-4.0-Turbo-8K-Latest":{"description":"Opracowany przez Baidu flagowy, ultra-duży model językowy, kt\xf3ry wykazuje doskonałe og\xf3lne rezultaty i jest szeroko stosowany w złożonych zadaniach w r\xf3żnych dziedzinach; obsługuje automatyczne łączenie z wtyczką wyszukiwania Baidu, zapewniając aktualność informacji odpowiadających na pytania. W por\xf3wnaniu do ERNIE 4.0 wykazuje lepszą wydajność."},"ERNIE-4.0-Turbo-8K-Preview":{"description":"Flagowy model ultra dużego języka opracowany przez Baidu, charakteryzujący się doskonałymi wynikami og\xf3lnymi, szeroko stosowany w złożonych scenariuszach w r\xf3żnych dziedzinach; wspiera automatyczne połączenie z wtyczką wyszukiwania Baidu, zapewniając aktualność informacji. W por\xf3wnaniu do ERNIE 4.0, oferuje lepsze wyniki wydajności."},"ERNIE-Character-8K":{"description":"Model dużego języka opracowany przez Baidu, skoncentrowany na specyficznych scenariuszach, odpowiedni do zastosowań takich jak NPC w grach, rozmowy z obsługą klienta, odgrywanie r\xf3l w dialogach, charakteryzujący się wyraźnym i sp\xf3jnym stylem postaci, silniejszą zdolnością do przestrzegania poleceń oraz lepszą wydajnością wnioskowania."},"ERNIE-Lite-Pro-128K":{"description":"Lekki model dużego języka opracowany przez Baidu, łączący doskonałe wyniki modelu z wydajnością wnioskowania, oferujący lepsze wyniki niż ERNIE Lite, odpowiedni do użycia w niskomocowych kartach przyspieszających AI."},"ERNIE-Speed-128K":{"description":"Najnowocześniejszy model dużego języka opracowany przez Baidu w 2024 roku, charakteryzujący się doskonałymi zdolnościami og\xf3lnymi, odpowiedni jako model bazowy do dalszego dostosowywania, lepiej radzący sobie z problemami w specyficznych scenariuszach, a także zapewniający doskonałą wydajność wnioskowania."},"ERNIE-Speed-Pro-128K":{"description":"Najnowocześniejszy model dużego języka opracowany przez Baidu w 2024 roku, charakteryzujący się doskonałymi zdolnościami og\xf3lnymi, oferujący lepsze wyniki niż ERNIE Speed, odpowiedni jako model bazowy do dalszego dostosowywania, lepiej radzący sobie z problemami w specyficznych scenariuszach, a także zapewniający doskonałą wydajność wnioskowania."},"FLUX-1.1-pro":{"description":"FLUX.1.1 Pro"},"FLUX.1-Kontext-dev":{"description":"FLUX.1-Kontext-dev to multimodalny model generowania i edycji obraz\xf3w opracowany przez Black Forest Labs, oparty na architekturze Rectified Flow Transformer, posiadający 12 miliard\xf3w parametr\xf3w. Skupia się na generowaniu, rekonstrukcji, wzmacnianiu i edycji obraz\xf3w w oparciu o podane warunki kontekstowe. Model łączy zalety kontrolowanej generacji modeli dyfuzyjnych z możliwościami modelowania kontekstu transformera, oferując wysoką jakość obraz\xf3w i szerokie zastosowanie w zadaniach takich jak naprawa, uzupełnianie i rekonstrukcja scen wizualnych."},"FLUX.1-Kontext-pro":{"description":"FLUX.1 Kontext [pro]"},"FLUX.1-dev":{"description":"FLUX.1-dev to otwarty multimodalny model językowy (MLLM) opracowany przez Black Forest Labs, zoptymalizowany pod kątem zadań tekstowo-obrazowych, łączący zdolności rozumienia i generowania obraz\xf3w oraz tekstu. Bazuje na zaawansowanych dużych modelach językowych (np. Mistral-7B) i dzięki starannie zaprojektowanemu enkoderowi wizualnemu oraz wieloetapowemu dostrajaniu instrukcji umożliwia wsp\xf3łpracę tekstu i obrazu oraz złożone wnioskowanie."},"Gryphe/MythoMax-L2-13b":{"description":"MythoMax-L2 (13B) to innowacyjny model, idealny do zastosowań w wielu dziedzinach i złożonych zadań."},"HelloMeme":{"description":"HelloMeme to narzędzie AI, kt\xf3re automatycznie generuje memy, animacje lub kr\xf3tkie filmy na podstawie dostarczonych przez Ciebie obraz\xf3w lub ruch\xf3w. Nie wymaga żadnych umiejętności rysunkowych ani programistycznych — wystarczy przygotować obraz referencyjny, a narzędzie stworzy atrakcyjne, zabawne i sp\xf3jne stylistycznie treści."},"HiDream-I1-Full":{"description":"HiDream-E1-Full to otwarty, multimodalny model do edycji obraz\xf3w opracowany przez HiDream.ai, oparty na zaawansowanej architekturze Diffusion Transformer i wyposażony w potężne zdolności rozumienia języka (wbudowany LLaMA 3.1-8B-Instruct). Umożliwia generowanie obraz\xf3w, transfer stylu, lokalną edycję i przerysowywanie treści za pomocą naturalnych poleceń językowych, oferując doskonałe rozumienie i realizację zadań tekstowo-obrazowych."},"HunyuanDiT-v1.2-Diffusers-Distilled":{"description":"hunyuandit-v1.2-distilled to lekki model generowania obraz\xf3w na podstawie tekstu, zoptymalizowany przez destylację, umożliwiający szybkie tworzenie wysokiej jakości obraz\xf3w, szczeg\xf3lnie odpowiedni do środowisk o ograniczonych zasobach i zadań generacji w czasie rzeczywistym."},"InstantCharacter":{"description":"InstantCharacter to model generowania spersonalizowanych postaci bez potrzeby dostrajania, wydany przez zesp\xf3ł AI Tencent w 2025 roku. Model umożliwia wierne i sp\xf3jne generowanie postaci w r\xf3żnych scenariuszach na podstawie pojedynczego obrazu referencyjnego oraz elastyczne przenoszenie tej postaci do r\xf3żnych styl\xf3w, ruch\xf3w i tła."},"InternVL2-8B":{"description":"InternVL2-8B to potężny model językowy wizualny, wspierający przetwarzanie multimodalne obraz\xf3w i tekstu, zdolny do precyzyjnego rozpoznawania treści obraz\xf3w i generowania odpowiednich opis\xf3w lub odpowiedzi."},"InternVL2.5-26B":{"description":"InternVL2.5-26B to potężny model językowy wizualny, wspierający przetwarzanie multimodalne obraz\xf3w i tekstu, zdolny do precyzyjnego rozpoznawania treści obraz\xf3w i generowania odpowiednich opis\xf3w lub odpowiedzi."},"Kolors":{"description":"Kolors to model generowania obraz\xf3w na podstawie tekstu opracowany przez zesp\xf3ł Kolors z Kuaishou. Trenowany na miliardach parametr\xf3w, wyr\xf3żnia się wysoką jakością wizualną, doskonałym rozumieniem semantyki języka chińskiego oraz precyzyjnym renderowaniem tekstu."},"Kwai-Kolors/Kolors":{"description":"Kolors to duży model generowania obraz\xf3w na podstawie tekstu oparty na latentnej dyfuzji, opracowany przez zesp\xf3ł Kolors z Kuaishou. Trenowany na miliardach par tekst-obraz, wykazuje znakomitą jakość wizualną, precyzję w rozumieniu złożonych semantyk oraz doskonałe renderowanie znak\xf3w chińskich i angielskich. Obsługuje wejścia w języku chińskim i angielskim, a także wyr\xf3żnia się w generowaniu specyficznych treści w języku chińskim."},"Kwaipilot/KAT-Dev":{"description":"KAT-Dev (32B) to otwarty model z 32 miliardami parametr\xf3w, zaprojektowany specjalnie do zadań inżynierii oprogramowania. W teście por\xf3wnawczym SWE-Bench Verified osiągnął wskaźnik rozwiązania na poziomie 62,4%, co plasuje go na piątym miejscu wśr\xf3d wszystkich otwartych modeli r\xf3żnej wielkości. Model został zoptymalizowany w kilku etapach, w tym poprzez trening pośredni, nadzorowane dostrajanie (SFT) oraz uczenie przez wzmacnianie (RL), aby zapewnić solidne wsparcie w złożonych zadaniach programistycznych, takich jak uzupełnianie kodu, naprawa błęd\xf3w czy przegląd kodu."},"Llama-3.2-11B-Vision-Instruct":{"description":"Wyr\xf3żniające się zdolnościami wnioskowania obraz\xf3w na wysokiej rozdzielczości, odpowiednie do zastosowań w rozumieniu wizualnym."},"Llama-3.2-90B-Vision-Instruct\\t":{"description":"Zaawansowane zdolności wnioskowania obraz\xf3w, odpowiednie do zastosowań w agentach rozumienia wizualnego."},"Meta-Llama-3-3-70B-Instruct":{"description":"Llama 3.3 70B: uniwersalny model Transformer, odpowiedni do zadań dialogowych i generowania tekstu."},"Meta-Llama-3.1-405B-Instruct":{"description":"Model tekstowy Llama 3.1 dostosowany do instrukcji, zoptymalizowany do wielojęzycznych przypadk\xf3w użycia dialog\xf3w, osiągający doskonałe wyniki w wielu dostępnych modelach czatu, zar\xf3wno otwartych, jak i zamkniętych, w powszechnych benchmarkach branżowych."},"Meta-Llama-3.1-70B-Instruct":{"description":"Model tekstowy Llama 3.1 dostosowany do instrukcji, zoptymalizowany do wielojęzycznych przypadk\xf3w użycia dialog\xf3w, osiągający doskonałe wyniki w wielu dostępnych modelach czatu, zar\xf3wno otwartych, jak i zamkniętych, w powszechnych benchmarkach branżowych."},"Meta-Llama-3.1-8B-Instruct":{"description":"Model tekstowy Llama 3.1 dostosowany do instrukcji, zoptymalizowany do wielojęzycznych przypadk\xf3w użycia dialog\xf3w, osiągający doskonałe wyniki w wielu dostępnych modelach czatu, zar\xf3wno otwartych, jak i zamkniętych, w powszechnych benchmarkach branżowych."},"Meta-Llama-3.2-1B-Instruct":{"description":"Zaawansowany, nowoczesny mały model językowy, posiadający zdolności rozumienia języka, doskonałe umiejętności wnioskowania oraz generowania tekstu."},"Meta-Llama-3.2-3B-Instruct":{"description":"Zaawansowany, nowoczesny mały model językowy, posiadający zdolności rozumienia języka, doskonałe umiejętności wnioskowania oraz generowania tekstu."},"Meta-Llama-3.3-70B-Instruct":{"description":"Llama 3.3 to najnowocześniejszy wielojęzyczny otwarty model językowy z serii Llama, oferujący wydajność por\xf3wnywalną z modelem 405B przy bardzo niskich kosztach. Oparty na strukturze Transformer, poprawiony dzięki nadzorowanemu dostrajaniu (SFT) oraz uczeniu ze wzmocnieniem opartym na ludzkiej opinii (RLHF), co zwiększa jego użyteczność i bezpieczeństwo. Jego wersja dostosowana do instrukcji została zoptymalizowana do wielojęzycznych dialog\xf3w, osiągając lepsze wyniki niż wiele dostępnych modeli czatu, zar\xf3wno otwartych, jak i zamkniętych, w wielu branżowych benchmarkach. Data graniczna wiedzy to grudzień 2023."},"Meta-Llama-4-Maverick-17B-128E-Instruct-FP8":{"description":"Llama 4 Maverick: duży model oparty na architekturze Mixture-of-Experts, oferujący efektywną strategię aktywacji ekspert\xf3w dla doskonałej wydajności podczas wnioskowania."},"MiniMax-M1":{"description":"Nowy, samodzielnie opracowany model wnioskowania. Światowy lider: 80K łańcuch\xf3w myślowych x 1M danych wejściowych, osiągi por\xf3wnywalne z czołowymi modelami zagranicznymi."},"MiniMax-M2":{"description":"Stworzony z myślą o wydajnym kodowaniu i przepływach pracy opartych na agentach."},"MiniMax-Text-01":{"description":"W serii modeli MiniMax-01 wprowadziliśmy odważne innowacje: po raz pierwszy na dużą skalę zrealizowano mechanizm liniowej uwagi, tradycyjna architektura Transformera nie jest już jedynym wyborem. Liczba parametr\xf3w tego modelu wynosi aż 456 miliard\xf3w, z aktywacją wynoszącą 45,9 miliarda. Og\xf3lna wydajność modelu dor\xf3wnuje najlepszym modelom zagranicznym, jednocześnie efektywnie przetwarzając kontekst o długości do 4 milion\xf3w token\xf3w, co stanowi 32 razy więcej niż GPT-4o i 20 razy więcej niż Claude-3.5-Sonnet."},"MiniMaxAI/MiniMax-M1-80k":{"description":"MiniMax-M1 to otwartoźr\xf3dłowy model inferencyjny o dużej skali z mieszanym mechanizmem uwagi, posiadający 456 miliard\xf3w parametr\xf3w, z kt\xf3rych około 45,9 miliarda jest aktywowanych na każdy token. Model natywnie obsługuje ultra-długi kontekst do 1 miliona token\xf3w i dzięki mechanizmowi błyskawicznej uwagi oszczędza 75% operacji zmiennoprzecinkowych w zadaniach generowania na 100 tysiącach token\xf3w w por\xf3wnaniu do DeepSeek R1. Ponadto MiniMax-M1 wykorzystuje architekturę MoE (mieszani eksperci), łącząc algorytm CISPO z efektywnym treningiem wzmacniającym opartym na mieszanej uwadze, osiągając wiodącą w branży wydajność w inferencji długich wejść i rzeczywistych scenariuszach inżynierii oprogramowania."},"MiniMaxAI/MiniMax-M2":{"description":"MiniMax-M2 na nowo definiuje wydajność agent\xf3w inteligentnych. To kompaktowy, szybki i ekonomiczny model MoE (Mixture of Experts) z 230 miliardami całkowitych parametr\xf3w i 10 miliardami aktywnych parametr\xf3w, zaprojektowany z myślą o najwyższej wydajności w zadaniach kodowania i agentowych, przy jednoczesnym zachowaniu silnej inteligencji og\xf3lnej. Dzięki zaledwie 10 miliardom aktywnych parametr\xf3w, MiniMax-M2 oferuje wydajność por\xf3wnywalną z dużymi modelami, co czyni go idealnym wyborem dla zastosowań wymagających wysokiej efektywności."},"Moonshot-Kimi-K2-Instruct":{"description":"Model o łącznej liczbie parametr\xf3w 1 biliona i aktywowanych 32 miliardach parametr\xf3w. Wśr\xf3d modeli nie myślących osiąga czołowe wyniki w wiedzy specjalistycznej, matematyce i kodowaniu, lepiej radząc sobie z zadaniami og\xf3lnymi agenta. Model jest starannie zoptymalizowany pod kątem zadań agenta, potrafi nie tylko odpowiadać na pytania, ale także podejmować działania. Idealny do improwizacji, og\xf3lnej rozmowy i doświadczeń agenta, działający na poziomie refleksu bez potrzeby długiego przetwarzania."},"NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO":{"description":"Nous Hermes 2 - Mixtral 8x7B-DPO (46.7B) to model poleceń o wysokiej precyzji, idealny do złożonych obliczeń."},"OmniConsistency":{"description":"OmniConsistency poprawia sp\xf3jność stylu i zdolność generalizacji w zadaniach obraz-do-obrazu (Image-to-Image) poprzez wprowadzenie dużych modeli Diffusion Transformers (DiTs) oraz parowanych danych stylizowanych, zapobiegając degradacji stylu."},"Phi-3-medium-128k-instruct":{"description":"Ten sam model Phi-3-medium, ale z większym rozmiarem kontekstu do RAG lub kilku strzałowego wywoływania."},"Phi-3-medium-4k-instruct":{"description":"Model z 14 miliardami parametr\xf3w, oferujący lepszą jakość niż Phi-3-mini, z naciskiem na dane o wysokiej jakości i gęstości rozumowania."},"Phi-3-mini-128k-instruct":{"description":"Ten sam model Phi-3-mini, ale z większym rozmiarem kontekstu do RAG lub kilku strzałowego wywoływania."},"Phi-3-mini-4k-instruct":{"description":"Najmniejszy członek rodziny Phi-3. Zoptymalizowany zar\xf3wno pod kątem jakości, jak i niskiej latencji."},"Phi-3-small-128k-instruct":{"description":"Ten sam model Phi-3-small, ale z większym rozmiarem kontekstu do RAG lub kilku strzałowego wywoływania."},"Phi-3-small-8k-instruct":{"description":"Model z 7 miliardami parametr\xf3w, oferujący lepszą jakość niż Phi-3-mini, z naciskiem na dane o wysokiej jakości i gęstości rozumowania."},"Phi-3.5-mini-instruct":{"description":"Zaktualizowana wersja modelu Phi-3-mini."},"Phi-3.5-vision-instrust":{"description":"Zaktualizowana wersja modelu Phi-3-vision."},"Pro/Qwen/Qwen2-7B-Instruct":{"description":"Qwen2-7B-Instruct to model dużego języka z serii Qwen2, dostosowany do instrukcji, o rozmiarze parametr\xf3w wynoszącym 7B. Model ten oparty jest na architekturze Transformer, wykorzystując funkcję aktywacji SwiGLU, przesunięcia QKV w uwadze oraz grupowe zapytania uwagi. Może obsługiwać duże wejścia. Model ten wykazuje doskonałe wyniki w wielu testach benchmarkowych dotyczących rozumienia języka, generowania, zdolności wielojęzycznych, kodowania, matematyki i wnioskowania, przewyższając większość modeli open-source i wykazując konkurencyjność z modelami własnościowymi w niekt\xf3rych zadaniach. Qwen2-7B-Instruct wykazuje znaczną poprawę wydajności w wielu ocenach w por\xf3wnaniu do Qwen1.5-7B-Chat."},"Pro/Qwen/Qwen2.5-7B-Instruct":{"description":"Qwen2.5-7B-Instruct to jeden z najnowszych modeli dużych język\xf3w wydanych przez Alibaba Cloud. Model 7B ma znacząco poprawione zdolności w zakresie kodowania i matematyki. Oferuje r\xf3wnież wsparcie dla wielu język\xf3w, obejmując ponad 29 język\xf3w, w tym chiński i angielski. Model ten wykazuje znaczną poprawę w zakresie przestrzegania instrukcji, rozumienia danych strukturalnych oraz generowania strukturalnych wynik\xf3w (szczeg\xf3lnie JSON)."},"Pro/Qwen/Qwen2.5-Coder-7B-Instruct":{"description":"Qwen2.5-Coder-7B-Instruct to najnowsza wersja serii dużych modeli językowych specyficznych dla kodu wydana przez Alibaba Cloud. Model ten, oparty na Qwen2.5, został przeszkolony na 55 bilionach token\xf3w, znacznie poprawiając zdolności generowania kodu, wnioskowania i naprawy. Wzmacnia on nie tylko zdolności kodowania, ale także utrzymuje przewagę w zakresie matematyki i og\xf3lnych umiejętności. Model ten stanowi bardziej kompleksową podstawę dla rzeczywistych zastosowań, takich jak inteligentne agenty kodowe."},"Pro/Qwen/Qwen2.5-VL-7B-Instruct":{"description":"Qwen2.5-VL to nowa wersja serii Qwen, posiadająca zaawansowane zdolności zrozumienia wizualnego. Potrafi analizować tekst, wykresy i układ w obrazach, a także zrozumieć długie filmy i wykrywać zdarzenia. Jest zdolny do przeprowadzania wnioskowania, operowania narzędziami, obsługuje lokalizację obiekt\xf3w w r\xf3żnych formatach i generowanie wyjścia strukturalnego. Optymalizuje trening rozdzielczości i klatki wideo, a także zwiększa efektywność kodera wizualnego."},"Pro/THUDM/GLM-4.1V-9B-Thinking":{"description":"GLM-4.1V-9B-Thinking to otwarty model wizualno-językowy (VLM) opracowany wsp\xf3lnie przez Zhipu AI i Laboratorium KEG Uniwersytetu Tsinghua, zaprojektowany do obsługi złożonych zadań poznawczych wielomodalnych. Model opiera się na bazowym modelu GLM-4-9B-0414 i znacząco poprawia zdolności wnioskowania międzymodalnego oraz stabilność dzięki wprowadzeniu mechanizmu rozumowania „łańcucha myślowego” (Chain-of-Thought) oraz zastosowaniu strategii uczenia ze wzmocnieniem."},"Pro/THUDM/glm-4-9b-chat":{"description":"GLM-4-9B-Chat to otwarta wersja modelu pretrenowanego z serii GLM-4, wydana przez Zhipu AI. Model ten wykazuje doskonałe wyniki w zakresie semantyki, matematyki, wnioskowania, kodu i wiedzy. Opr\xf3cz wsparcia dla wieloetapowych rozm\xf3w, GLM-4-9B-Chat oferuje r\xf3wnież zaawansowane funkcje, takie jak przeglądanie stron internetowych, wykonywanie kodu, wywoływanie niestandardowych narzędzi (Function Call) oraz wnioskowanie z długich tekst\xf3w. Model obsługuje 26 język\xf3w, w tym chiński, angielski, japoński, koreański i niemiecki. W wielu testach benchmarkowych, takich jak AlignBench-v2, MT-Bench, MMLU i C-Eval, GLM-4-9B-Chat wykazuje doskonałą wydajność. Model obsługuje maksymalną długość kontekstu 128K, co czyni go odpowiednim do badań akademickich i zastosowań komercyjnych."},"Pro/deepseek-ai/DeepSeek-R1":{"description":"DeepSeek-R1 to model wnioskowania napędzany uczeniem ze wzmocnieniem (RL), kt\xf3ry rozwiązuje problemy z powtarzalnością i czytelnością modeli. Przed RL, DeepSeek-R1 wprowadził dane do zimnego startu, co dodatkowo zoptymalizowało wydajność wnioskowania. W zadaniach matematycznych, kodowych i wnioskowania, osiąga wyniki por\xf3wnywalne z OpenAI-o1, a dzięki starannie zaprojektowanym metodom treningowym poprawia og\xf3lne wyniki."},"Pro/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B":{"description":"DeepSeek-R1-Distill-Qwen-7B to model stworzony na podstawie Qwen2.5-Math-7B poprzez proces wiedzy distylacji. Model ten został wytrenowany na 800 000 wybrukowanych pr\xf3bkach wygenerowanych przez DeepSeek-R1, co pozwoliło mu wykazać się doskonałymi zdolnościami wnioskowania. W wielu testach referencyjnych osiągnął znakomite wyniki, w tym 92,8% dokładności na MATH-500, 55,5% sukces\xf3w na AIME 2024 oraz 1189 punkt\xf3w na CodeForces, co potwierdza jego silne umiejętności matematyczne i programistyczne jako modelu o rozmiarze 7B."},"Pro/deepseek-ai/DeepSeek-V3":{"description":"DeepSeek-V3 to model językowy z 6710 miliardami parametr\xf3w, oparty na architekturze mieszanych ekspert\xf3w (MoE), wykorzystujący wielogłowicową potencjalną uwagę (MLA) oraz strategię r\xf3wnoważenia obciążenia bez dodatkowych strat, co optymalizuje wydajność wnioskowania i treningu. Dzięki wstępnemu treningowi na 14,8 bilionach wysokiej jakości token\xf3w oraz nadzorowanemu dostrajaniu i uczeniu ze wzmocnieniem, DeepSeek-V3 przewyższa inne modele open source, zbliżając się do wiodących modeli zamkniętych."},"Pro/deepseek-ai/DeepSeek-V3.1-Terminus":{"description":"DeepSeek-V3.1-Terminus to zaktualizowana wersja modelu V3.1 wydanego przez DeepSeek, zaprojektowana jako hybrydowy model językowy z agentami. Aktualizacja skupia się na naprawie zgłoszonych przez użytkownik\xf3w problem\xf3w i poprawie stabilności, zachowując jednocześnie dotychczasowe możliwości modelu. Znacząco poprawiono sp\xf3jność językową, zmniejszając mieszanie języka chińskiego i angielskiego oraz eliminując nieprawidłowe znaki. Model integruje tryb myślenia (Thinking Mode) oraz tryb bez myślenia (Non-thinking Mode), kt\xf3re użytkownicy mogą elastycznie przełączać za pomocą szablon\xf3w czatu, dostosowując się do r\xf3żnych zadań. Ważną optymalizacją jest wzmocnienie wydajności agenta kodu (Code Agent) i agenta wyszukiwania (Search Agent), co czyni je bardziej niezawodnymi w wywoływaniu narzędzi i realizacji wieloetapowych, złożonych zadań."},"Pro/deepseek-ai/DeepSeek-V3.2-Exp":{"description":"DeepSeek-V3.2-Exp to eksperymentalna wersja V3.2 wydana przez DeepSeek, stanowiąca etap przejściowy w kierunku nowej generacji architektury. Na bazie V3.1-Terminus wprowadza mechanizm rzadkiej uwagi DeepSeek (DeepSeek Sparse Attention, DSA), kt\xf3ry zwiększa efektywność trenowania i wnioskowania w kontekście długich sekwencji. Model został specjalnie zoptymalizowany pod kątem wywoływania narzędzi, rozumienia długich dokument\xf3w i wieloetapowego wnioskowania. V3.2-Exp stanowi pomost między badaniami a wdrożeniem komercyjnym i jest odpowiedni dla użytkownik\xf3w poszukujących wyższej efektywności wnioskowania w scenariuszach z dużym budżetem kontekstowym."},"Pro/moonshotai/Kimi-K2-Instruct-0905":{"description":"Kimi K2-Instruct-0905 to najnowsza i najpotężniejsza wersja Kimi K2. Jest to zaawansowany model językowy typu Mixture of Experts (MoE) z 1 bilionem parametr\xf3w og\xf3łem i 32 miliardami aktywowanych parametr\xf3w. Gł\xf3wne cechy modelu to: wzmocniona inteligencja kodowania agent\xf3w, kt\xf3ra wykazuje znaczącą poprawę wydajności w publicznych testach por\xf3wnawczych oraz w rzeczywistych zadaniach kodowania agent\xf3w; ulepszone doświadczenie kodowania front-end, z postępami zar\xf3wno w estetyce, jak i funkcjonalności programowania front-endowego."},"QwQ-32B-Preview":{"description":"QwQ-32B-Preview to innowacyjny model przetwarzania języka naturalnego, kt\xf3ry efektywnie radzi sobie z złożonymi zadaniami generowania dialog\xf3w i rozumienia kontekstu."},"Qwen/QVQ-72B-Preview":{"description":"QVQ-72B-Preview to model badawczy opracowany przez zesp\xf3ł Qwen, skoncentrowany na zdolnościach wnioskowania wizualnego, kt\xf3ry ma unikalne zalety w zrozumieniu złożonych scenariuszy i rozwiązywaniu wizualnie związanych problem\xf3w matematycznych."},"Qwen/QwQ-32B":{"description":"QwQ jest modelem inferencyjnym z serii Qwen. W por\xf3wnaniu do tradycyjnych modeli dostosowanych do instrukcji, QwQ posiada zdolności myślenia i wnioskowania, co pozwala na znaczące zwiększenie wydajności w zadaniach końcowych, szczeg\xf3lnie w rozwiązywaniu trudnych problem\xf3w. QwQ-32B to średniej wielkości model inferencyjny, kt\xf3ry osiąga konkurencyjną wydajność w por\xf3wnaniu z najnowocześniejszymi modelami inferencyjnymi, takimi jak DeepSeek-R1 i o1-mini. Model ten wykorzystuje technologie takie jak RoPE, SwiGLU, RMSNorm oraz Attention QKV bias, posiada 64-warstwową strukturę sieci i 40 głowic uwagi Q (w architekturze GQA KV wynosi 8)."},"Qwen/QwQ-32B-Preview":{"description":"QwQ-32B-Preview to najnowszy eksperymentalny model badawczy Qwen, skoncentrowany na zwiększeniu zdolności wnioskowania AI. Poprzez eksplorację złożonych mechanizm\xf3w, takich jak mieszanie język\xf3w i wnioskowanie rekurencyjne, gł\xf3wne zalety obejmują silne zdolności analizy wnioskowania, matematyki i programowania. Jednocześnie występują problemy z przełączaniem język\xf3w, cyklami wnioskowania, kwestiami bezpieczeństwa oraz r\xf3żnicami w innych zdolnościach."},"Qwen/Qwen-Image":{"description":"Qwen-Image to podstawowy model generowania obraz\xf3w opracowany przez zesp\xf3ł Tongyi Qianwen z Alibaba, zawierający 20 miliard\xf3w parametr\xf3w. Model ten osiągnął znaczące postępy w złożonym renderowaniu tekstu oraz precyzyjnej edycji obraz\xf3w, szczeg\xf3lnie wyr\xf3żniając się w generowaniu obraz\xf3w zawierających teksty w języku chińskim i angielskim o wysokiej wierności. Qwen-Image potrafi nie tylko obsługiwać układy wielowierszowe i teksty na poziomie akapit\xf3w, ale także zachowuje sp\xf3jność typograficzną i kontekstową podczas generowania obraz\xf3w. Opr\xf3cz doskonałych możliwości renderowania tekstu, model obsługuje szeroką gamę styl\xf3w artystycznych – od realistycznych fotografii po estetykę anime – elastycznie dostosowując się do r\xf3żnych potrzeb tw\xf3rczych. Ponadto posiada zaawansowane możliwości edycji i rozumienia obraz\xf3w, wspierając takie operacje jak transfer stylu, dodawanie i usuwanie obiekt\xf3w, wzmacnianie detali, edycję tekstu, a nawet manipulację postawą ciała, dążąc do bycia kompleksowym, inteligentnym modelem bazowym do tworzenia i przetwarzania wizualnego, łączącym język, układ i obraz."},"Qwen/Qwen-Image-Edit-2509":{"description":"Qwen-Image-Edit-2509 to najnowsza wersja edytora obraz\xf3w Qwen-Image, opracowana przez zesp\xf3ł Tongyi Qianwen z Alibaba. Model ten został głęboko wytrenowany na bazie 20-miliardowego modelu Qwen-Image, skutecznie rozszerzając jego unikalne możliwości renderowania tekstu na obszar edycji obraz\xf3w, umożliwiając precyzyjną edycję tekstu w obrazach. Qwen-Image-Edit wykorzystuje innowacyjną architekturę, w kt\xf3rej obraz wejściowy trafia jednocześnie do Qwen2.5-VL (do kontroli semantyki wizualnej) oraz do VAE Encoder (do kontroli wyglądu wizualnego), co zapewnia podw\xf3jną zdolność edycji – zar\xf3wno semantyczną, jak i wizualną. Oznacza to, że model obsługuje nie tylko lokalne zmiany wyglądu, takie jak dodawanie, usuwanie czy modyfikacja element\xf3w, ale także zaawansowaną edycję semantyczną, wymagającą sp\xf3jności znaczeniowej – jak np. tworzenie IP, transfer stylu itp. Model osiąga najwyższe wyniki (SOTA) w wielu publicznych benchmarkach, czyniąc go potężnym podstawowym modelem do edycji obraz\xf3w."},"Qwen/Qwen2-72B-Instruct":{"description":"Qwen2 to zaawansowany uniwersalny model językowy, wspierający r\xf3żne typy poleceń."},"Qwen/Qwen2-7B-Instruct":{"description":"Qwen2-72B-Instruct to model dużego języka z serii Qwen2, dostosowany do instrukcji, o rozmiarze parametr\xf3w wynoszącym 72B. Model ten oparty jest na architekturze Transformer, wykorzystując funkcję aktywacji SwiGLU, przesunięcia QKV w uwadze oraz grupowe zapytania uwagi. Może obsługiwać duże wejścia. Model ten wykazuje doskonałe wyniki w wielu testach benchmarkowych dotyczących rozumienia języka, generowania, zdolności wielojęzycznych, kodowania, matematyki i wnioskowania, przewyższając większość modeli open-source i wykazując konkurencyjność z modelami własnościowymi w niekt\xf3rych zadaniach."},"Qwen/Qwen2-VL-72B-Instruct":{"description":"Qwen2-VL to najnowsza iteracja modelu Qwen-VL, osiągająca najnowocześniejsze wyniki w benchmarkach zrozumienia wizualnego."},"Qwen/Qwen2.5-14B-Instruct":{"description":"Qwen2.5 to nowa seria dużych modeli językowych, zaprojektowana w celu optymalizacji przetwarzania zadań instrukcyjnych."},"Qwen/Qwen2.5-32B-Instruct":{"description":"Qwen2.5 to nowa seria dużych modeli językowych, zaprojektowana w celu optymalizacji przetwarzania zadań instrukcyjnych."},"Qwen/Qwen2.5-72B-Instruct":{"description":"Duży model językowy opracowany przez zesp\xf3ł Alibaba Cloud Tongyi Qianwen"},"Qwen/Qwen2.5-72B-Instruct-128K":{"description":"Qwen2.5 to nowa seria dużych modeli językowych, charakteryzująca się mocniejszymi zdolnościami rozumienia i generowania."},"Qwen/Qwen2.5-72B-Instruct-Turbo":{"description":"Qwen2.5 to nowa seria dużych modeli językowych, mająca na celu optymalizację przetwarzania zadań instruktażowych."},"Qwen/Qwen2.5-7B-Instruct":{"description":"Qwen2.5 to nowa seria dużych modeli językowych, zaprojektowana w celu optymalizacji przetwarzania zadań instrukcyjnych."},"Qwen/Qwen2.5-7B-Instruct-Turbo":{"description":"Qwen2.5 to nowa seria dużych modeli językowych, mająca na celu optymalizację przetwarzania zadań instruktażowych."},"Qwen/Qwen2.5-Coder-32B-Instruct":{"description":"Qwen2.5-Coder koncentruje się na pisaniu kodu."},"Qwen/Qwen2.5-Coder-7B-Instruct":{"description":"Qwen2.5-Coder-7B-Instruct to najnowsza wersja serii dużych modeli językowych specyficznych dla kodu wydana przez Alibaba Cloud. Model ten, oparty na Qwen2.5, został przeszkolony na 55 bilionach token\xf3w, znacznie poprawiając zdolności generowania kodu, wnioskowania i naprawy. Wzmacnia on nie tylko zdolności kodowania, ale także utrzymuje przewagę w zakresie matematyki i og\xf3lnych umiejętności. Model ten stanowi bardziej kompleksową podstawę dla rzeczywistych zastosowań, takich jak inteligentne agenty kodowe."},"Qwen/Qwen2.5-VL-32B-Instruct":{"description":"Qwen2.5-VL-32B-Instruct to wielomodalny model stworzony przez zesp\xf3ł Qwen2.5-VL, kt\xf3ry jest częścią serii Qwen2.5-VL. Ten model nie tylko doskonale rozpoznaje obiekty, ale także analizuje tekst, wykresy, ikony, rysunki i układ w obrazach. Może działać jako inteligentny agent wizualny, kt\xf3ry potrafi rozumować i dynamicznie sterować narzędziami, posiadając umiejętności korzystania z komputer\xf3w i telefon\xf3w. Ponadto, ten model może precyzyjnie lokalizować obiekty w obrazach i generować strukturalne wyjścia dla faktur, tabel i innych dokument\xf3w. W por\xf3wnaniu do poprzedniego modelu Qwen2-VL, ta wersja została dalej rozwinięta w zakresie umiejętności matematycznych i rozwiązywania problem\xf3w poprzez uczenie wzmacnianie, a styl odpowiedzi jest bardziej zgodny z preferencjami ludzkimi."},"Qwen/Qwen2.5-VL-72B-Instruct":{"description":"Qwen2.5-VL to model językowo-wizualny z serii Qwen2.5. Ten model przynosi znaczące poprawy w wielu aspektach: posiada lepsze zdolności zrozumienia wizualnego, umożliwiając rozpoznawanie powszechnych obiekt\xf3w, analizowanie tekstu, wykres\xf3w i układu; jako wizualny agent może wnioskować i dynamicznie kierować użyciem narzędzi; obsługuje zrozumienie film\xf3w o długości przekraczającej 1 godzinę i łapanie kluczowych zdarzeń; może precyzyjnie lokalizować obiekty na obrazach poprzez generowanie ramki granicznej lub punkt\xf3w; obsługuje generowanie danych strukturalnych, szczeg\xf3lnie przydatnych dla skanowanych danych, takich jak faktury i tabele."},"Qwen/Qwen3-14B":{"description":"Qwen3 to nowa generacja modelu Qwen, kt\xf3ra znacznie zwiększa zdolności w zakresie wnioskowania, og\xf3lnych zadań, agent\xf3w i wielojęzyczności, osiągając wiodące w branży wyniki oraz wspierając przełączanie trybu myślenia."},"Qwen/Qwen3-235B-A22B":{"description":"Qwen3 to nowa generacja modelu Qwen, kt\xf3ra znacznie zwiększa zdolności w zakresie wnioskowania, og\xf3lnych zadań, agent\xf3w i wielojęzyczności, osiągając wiodące w branży wyniki oraz wspierając przełączanie trybu myślenia."},"Qwen/Qwen3-235B-A22B-Instruct-2507":{"description":"Qwen3-235B-A22B-Instruct-2507 to flagowy model dużego języka hybrydowego ekspert\xf3w (MoE) z serii Qwen3, opracowany przez zesp\xf3ł Alibaba Cloud Tongyi Qianwen. Model posiada 235 miliard\xf3w parametr\xf3w og\xf3łem, z 22 miliardami aktywowanymi podczas inferencji. Jest to zaktualizowana wersja trybu nie myślącego Qwen3-235B-A22B, skupiająca się na znaczącej poprawie w zakresie przestrzegania instrukcji, wnioskowania logicznego, rozumienia tekstu, matematyki, nauki, programowania i użycia narzędzi. Model rozszerza pokrycie wiedzy wielojęzycznej i lepiej dostosowuje się do preferencji użytkownik\xf3w w zadaniach subiektywnych i otwartych, generując bardziej pomocne i wysokiej jakości teksty."},"Qwen/Qwen3-235B-A22B-Thinking-2507":{"description":"Qwen3-235B-A22B-Thinking-2507 to model z serii Qwen3 opracowany przez zesp\xf3ł Alibaba Tongyi Qianwen, skoncentrowany na złożonych zadaniach wymagających zaawansowanego wnioskowania. Model oparty na architekturze hybrydowych ekspert\xf3w (MoE) posiada 235 miliard\xf3w parametr\xf3w, z aktywacją około 22 miliard\xf3w parametr\xf3w na token, co pozwala na wysoką wydajność przy efektywności obliczeniowej. Jako model „myślący” osiąga czołowe wyniki w zadaniach wymagających wiedzy specjalistycznej, takich jak logika, matematyka, nauka, programowanie i testy akademickie. Ponadto wzmacnia zdolności og\xf3lne, takie jak przestrzeganie instrukcji, użycie narzędzi i generowanie tekstu, oraz natywnie obsługuje kontekst o długości do 256K token\xf3w, co czyni go idealnym do głębokiego wnioskowania i pracy z długimi dokumentami."},"Qwen/Qwen3-30B-A3B":{"description":"Qwen3 to nowa generacja modelu Qwen, kt\xf3ra znacznie zwiększa zdolności w zakresie wnioskowania, og\xf3lnych zadań, agent\xf3w i wielojęzyczności, osiągając wiodące w branży wyniki oraz wspierając przełączanie trybu myślenia."},"Qwen/Qwen3-30B-A3B-Instruct-2507":{"description":"Qwen3-30B-A3B-Instruct-2507 to zaktualizowana wersja modelu Qwen3-30B-A3B w trybie bez myślenia. Jest to model ekspertowy mieszany (MoE) z 30,5 miliardami parametr\xf3w og\xf3łem i 3,3 miliardami parametr\xf3w aktywacyjnych. Model został znacząco ulepszony pod wieloma względami, w tym w zakresie przestrzegania instrukcji, rozumowania logicznego, rozumienia tekstu, matematyki, nauki, kodowania oraz korzystania z narzędzi. Ponadto osiągnął istotny postęp w pokryciu wiedzy wielojęzycznej oraz lepsze dopasowanie do preferencji użytkownik\xf3w w zadaniach subiektywnych i otwartych, co pozwala generować bardziej pomocne odpowiedzi i teksty wyższej jakości. Dodatkowo zdolność rozumienia długich tekst\xf3w została zwiększona do 256K. Model ten obsługuje wyłącznie tryb bez myślenia i nie generuje tag\xf3w `<think></think>` w swoich odpowiedziach."},"Qwen/Qwen3-30B-A3B-Thinking-2507":{"description":"Qwen3-30B-A3B-Thinking-2507 jest najnowszym modelem „Thinking” z serii Qwen3, wydanym przez zesp\xf3ł Tongyi Qianwen firmy Alibaba. Jako hybrydowy model ekspert\xf3w (MoE) z 30,5 mld parametr\xf3w łącznie i 3,3 mld parametr\xf3w aktywacji koncentruje się na zwiększaniu zdolności do obsługi złożonych zadań. Model wykazuje znaczące usprawnienia wydajności w benchmarkach akademickich obejmujących rozumowanie logiczne, matematykę, nauki ścisłe, programowanie oraz zadania wymagające wiedzy eksperckiej. Ponadto jego og\xf3lne możliwości — takie jak zgodność z instrukcjami, korzystanie z narzędzi, generowanie tekstu i dostosowanie do preferencji użytkownik\xf3w — zostały istotnie wzmocnione. Model natywnie obsługuje długi kontekst o długości 256K token\xf3w i można go skalować do 1 miliona token\xf3w. Ta wersja została zaprojektowana do \'trybu myślenia\' i ma na celu rozwiązywanie wysoce złożonych zadań poprzez szczeg\xf3łowe, krok po kroku rozumowanie; jego zdolności jako agenta także wypadają znakomicie."},"Qwen/Qwen3-32B":{"description":"Qwen3 to nowa generacja modelu Qwen, kt\xf3ra znacznie zwiększa zdolności w zakresie wnioskowania, og\xf3lnych zadań, agent\xf3w i wielojęzyczności, osiągając wiodące w branży wyniki oraz wspierając przełączanie trybu myślenia."},"Qwen/Qwen3-8B":{"description":"Qwen3 to nowa generacja modelu Qwen, kt\xf3ra znacznie zwiększa zdolności w zakresie wnioskowania, og\xf3lnych zadań, agent\xf3w i wielojęzyczności, osiągając wiodące w branży wyniki oraz wspierając przełączanie trybu myślenia."},"Qwen/Qwen3-Coder-30B-A3B-Instruct":{"description":"Qwen3-Coder-30B-A3B-Instruct jest modelem kodowania z serii Qwen3 opracowanym przez zesp\xf3ł Tongyi Qianwen firmy Alibaba. Jako model poddany uproszczeniu i optymalizacji, przy zachowaniu wysokiej wydajności i efektywności, skupia się na udoskonaleniu zdolności przetwarzania kodu. Model wykazuje wyraźną przewagę wydajnościową wśr\xf3d modeli open-source w złożonych zadaniach, takich jak programowanie agentowe (Agentic Coding), automatyzacja działań w przeglądarce oraz wywoływanie narzędzi. Natywnie obsługuje długi kontekst o długości 256K token\xf3w i można go rozszerzyć do 1M token\xf3w, co pozwala na lepsze rozumienie i przetwarzanie na poziomie repozytorium kodu. Ponadto model zapewnia silne wsparcie dla agentowego kodowania na platformach takich jak Qwen Code i CLINE oraz został zaprojektowany z dedykowanym formatem wywoływania funkcji."},"Qwen/Qwen3-Coder-480B-A35B-Instruct":{"description":"Qwen3-Coder-480B-A35B-Instruct został wydany przez Alibaba i jest jak dotąd modelem kodowania o największych zdolnościach agentskich (agentic). Jest to model typu Mixture-of-Experts (MoE) z 480 miliardami parametr\xf3w og\xf3łem i 35 miliardami parametr\xf3w aktywacyjnych, osiągający r\xf3wnowagę między wydajnością a efektywnością. Model natywnie obsługuje kontekst o długości 256K (około 260 tys.) token\xf3w i może być rozszerzony do 1 miliona token\xf3w za pomocą metod ekstrapolacji, takich jak YaRN, co pozwala mu przetwarzać duże repozytoria kodu i złożone zadania programistyczne. Qwen3-Coder został zaprojektowany pod kątem agentowego przepływu pracy kodowania — nie tylko generuje kod, ale r\xf3wnież potrafi autonomicznie wsp\xf3łdziałać z narzędziami i środowiskami deweloperskimi, aby rozwiązywać złożone problemy programistyczne. W wielu benchmarkach dotyczących zadań kodowania i agentowych model osiągnął czołowe wyniki wśr\xf3d modeli open-source, a jego wydajność dor\xf3wnuje wiodącym modelom, takim jak Claude Sonnet 4."},"Qwen/Qwen3-Next-80B-A3B-Instruct":{"description":"Qwen3-Next-80B-A3B-Instruct to kolejna generacja modelu bazowego wydanego przez zesp\xf3ł Tongyi Qianwen z Alibaba. Opiera się na nowej architekturze Qwen3-Next, zaprojektowanej w celu osiągnięcia maksymalnej efektywności treningu i inferencji. Model wykorzystuje innowacyjny hybrydowy mechanizm uwagi (Gated DeltaNet i Gated Attention), wysoko rzadką strukturę ekspert\xf3w mieszanych (MoE) oraz liczne optymalizacje stabilności treningu. Jako model rzadki z 80 miliardami parametr\xf3w, podczas inferencji aktywuje jedynie około 3 miliard\xf3w parametr\xf3w, co znacznie obniża koszty obliczeniowe. Przy zadaniach z bardzo długim kontekstem przekraczającym 32 tysiące token\xf3w, przepustowość inferencji jest ponad 10 razy wyższa niż w modelu Qwen3-32B. Ten model jest wersją dostrojoną pod kątem instrukcji, zaprojektowaną do zadań og\xf3lnego przeznaczenia i nie obsługuje trybu łańcucha myślenia (Thinking). Pod względem wydajności dor\xf3wnuje flagowemu modelowi Tongyi Qianwen Qwen3-235B w niekt\xf3rych benchmarkach, szczeg\xf3lnie wykazując wyraźną przewagę w zadaniach z bardzo długim kontekstem."},"Qwen/Qwen3-Next-80B-A3B-Thinking":{"description":"Qwen3-Next-80B-A3B-Thinking to kolejna generacja modelu bazowego wydanego przez zesp\xf3ł Tongyi Qianwen z Alibaba, specjalnie zaprojektowana do złożonych zadań wnioskowania. Opiera się na innowacyjnej architekturze Qwen3-Next, kt\xf3ra łączy hybrydowy mechanizm uwagi (Gated DeltaNet i Gated Attention) oraz wysoko rzadką strukturę ekspert\xf3w mieszanych (MoE), dążąc do maksymalnej efektywności treningu i inferencji. Jako model rzadki z 80 miliardami parametr\xf3w, podczas inferencji aktywuje jedynie około 3 miliard\xf3w parametr\xf3w, co znacznie obniża koszty obliczeniowe. Przy zadaniach z bardzo długim kontekstem przekraczającym 32 tysiące token\xf3w, przepustowość jest ponad 10 razy wyższa niż w modelu Qwen3-32B. Wersja „Thinking” jest zoptymalizowana do wykonywania złożonych, wieloetapowych zadań takich jak dowody matematyczne, synteza kodu, analiza logiczna i planowanie, domyślnie generując proces wnioskowania w ustrukturyzowanej formie łańcucha myślenia. Pod względem wydajności przewyższa modele o wyższych kosztach, takie jak Qwen3-32B-Thinking, a także w wielu benchmarkach jest lepszy od Gemini-2.5-Flash-Thinking."},"Qwen/Qwen3-Omni-30B-A3B-Captioner":{"description":"Qwen3-Omni-30B-A3B-Captioner to model językowo-wizualny (VLM) z serii Qwen3 opracowanej przez zesp\xf3ł Tongyi Qianwen z Alibaba. Został zaprojektowany do generowania wysokiej jakości, szczeg\xf3łowych i precyzyjnych opis\xf3w obraz\xf3w. Model oparty jest na architekturze mieszanych ekspert\xf3w (MoE) z 30 miliardami parametr\xf3w, co pozwala mu na głębokie zrozumienie zawartości obrazu i przekształcanie jej w naturalny, płynny opis tekstowy. Wyr\xf3żnia się w takich zadaniach jak uchwycenie detali, rozumienie scen, rozpoznawanie obiekt\xf3w i wnioskowanie relacji, co czyni go idealnym do zastosowań wymagających precyzyjnego rozumienia i opisu obraz\xf3w."},"Qwen/Qwen3-Omni-30B-A3B-Instruct":{"description":"Qwen3-Omni-30B-A3B-Instruct to jeden z najnowszych modeli z serii Qwen3 opracowanej przez zesp\xf3ł Tongyi Qianwen z Alibaba. Jest to model mieszanych ekspert\xf3w (MoE) z 30 miliardami parametr\xf3w całkowitych i 3 miliardami aktywnych parametr\xf3w, kt\xf3ry łączy wysoką wydajność z efektywnością obliczeniową. Trening oparty na danych wysokiej jakości, pochodzących z wielu źr\xf3deł i w wielu językach, zapewnia mu silne zdolności og\xf3lne. Obsługuje wejścia w pełnym zakresie modalności – tekst, obraz, dźwięk i wideo – umożliwiając zrozumienie i generowanie treści między modalnościami."},"Qwen/Qwen3-Omni-30B-A3B-Thinking":{"description":"Qwen3-Omni-30B-A3B-Thinking to kluczowy komponent „myślący” (Thinker) w pełnomodalnym modelu Qwen3-Omni. Odpowiada za przetwarzanie danych wejściowych w r\xf3żnych modalnościach – tekst, dźwięk, obraz i wideo – oraz wykonywanie złożonych wnioskowań łańcuchowych. Jako „m\xf3zg” procesu wnioskowania, model ten ujednolica wszystkie dane wejściowe w jednej przestrzeni reprezentacji, umożliwiając głębokie zrozumienie i złożone wnioskowanie między modalnościami. Bazuje na architekturze mieszanych ekspert\xf3w (MoE) z 30 miliardami parametr\xf3w całkowitych i 3 miliardami aktywnych, zapewniając wysoką wydajność przy zoptymalizowanej efektywności obliczeniowej."},"Qwen/Qwen3-VL-235B-A22B-Instruct":{"description":"Qwen3-VL-235B-A22B-Instruct to duży model z serii Qwen3-VL dostrojony do wykonywania poleceń, oparty na architekturze mieszanych ekspert\xf3w (MoE). Wyr\xf3żnia się doskonałymi zdolnościami rozumienia i generowania treści multimodalnych, natywnie obsługuje kontekst o długości 256K i nadaje się do produkcyjnych usług multimodalnych o wysokiej r\xf3wnoległości."},"Qwen/Qwen3-VL-235B-A22B-Thinking":{"description":"Qwen3-VL-235B-A22B-Thinking to flagowa wersja myśląca z serii Qwen3-VL, specjalnie zoptymalizowana pod kątem złożonego wnioskowania multimodalnego, długiego kontekstu oraz interakcji z agentami. Idealna do zastosowań korporacyjnych wymagających głębokiego rozumowania i wnioskowania wizualnego."},"Qwen/Qwen3-VL-30B-A3B-Instruct":{"description":"Qwen3-VL-30B-A3B-Instruct to wersja modelu z serii Qwen3-VL dostrojona do wykonywania poleceń, oferująca zaawansowane możliwości rozumienia i generowania treści wizualno-językowych. Natywnie obsługuje kontekst o długości 256K i nadaje się do dialog\xf3w multimodalnych oraz zadań generowania warunkowanego obrazem."},"Qwen/Qwen3-VL-30B-A3B-Thinking":{"description":"Qwen3-VL-30B-A3B-Thinking to rozszerzona wersja modelu Qwen3-VL skoncentrowana na wnioskowaniu (Thinking), zoptymalizowana pod kątem zadań takich jak multimodalne wnioskowanie, konwersja obrazu na kod oraz złożone rozumienie wizualne. Obsługuje kontekst 256K i oferuje zaawansowane możliwości rozumowania łańcuchowego."},"Qwen/Qwen3-VL-32B-Instruct":{"description":"Qwen3-VL-32B-Instruct to model językowo-wizualny opracowany przez zesp\xf3ł Tongyi Qianwen z Alibaba, kt\xf3ry osiągnął wiodące wyniki SOTA w wielu testach por\xf3wnawczych. Obsługuje obrazy o wysokiej rozdzielczości na poziomie milion\xf3w pikseli i oferuje zaawansowane możliwości og\xf3lnego rozumienia wizualnego, wielojęzycznego OCR, precyzyjnej lokalizacji wizualnej oraz dialogu wizualnego. Jako część serii Qwen3, model ten radzi sobie z wymagającymi zadaniami multimodalnymi i obsługuje zaawansowane funkcje, takie jak wywoływanie narzędzi i kontynuacja prefiks\xf3w."},"Qwen/Qwen3-VL-32B-Thinking":{"description":"Qwen3-VL-32B-Thinking to specjalnie zoptymalizowana wersja modelu językowo-wizualnego opracowanego przez zesp\xf3ł Tongyi Qianwen z Alibaba, przeznaczona do złożonych zadań wnioskowania wizualnego. Model ten posiada wbudowany „tryb myślenia”, kt\xf3ry umożliwia generowanie szczeg\xf3łowych, pośrednich krok\xf3w wnioskowania przed udzieleniem odpowiedzi, znacznie poprawiając jego skuteczność w zadaniach wymagających wieloetapowej logiki, planowania i złożonego rozumowania. Obsługuje obrazy o wysokiej rozdzielczości na poziomie milion\xf3w pikseli, oferuje zaawansowane możliwości rozumienia wizualnego, wielojęzycznego OCR, precyzyjnej lokalizacji wizualnej i dialogu wizualnego, a także wspiera wywoływanie narzędzi i kontynuację prefiks\xf3w."},"Qwen/Qwen3-VL-8B-Instruct":{"description":"Qwen3-VL-8B-Instruct to model językowo-wizualny z serii Qwen3, opracowany na bazie Qwen3-8B-Instruct i wytrenowany na dużej ilości danych tekstowo-obrazowych. Wyr\xf3żnia się w og\xf3lnym rozumieniu wizualnym, dialogach skoncentrowanych na obrazie oraz rozpoznawaniu tekstu w wielu językach w obrazach. Nadaje się do zastosowań takich jak pytania i odpowiedzi wizualne, opisy obraz\xf3w, podążanie za multimodalnymi instrukcjami oraz wywoływanie narzędzi."},"Qwen/Qwen3-VL-8B-Thinking":{"description":"Qwen3-VL-8B-Thinking to wersja modelu Qwen3 skoncentrowana na rozumowaniu wizualnym, zoptymalizowana pod kątem złożonych zadań wymagających wieloetapowego wnioskowania. Domyślnie generuje łańcuch myślenia (thinking chain) przed udzieleniem odpowiedzi, aby zwiększyć dokładność rozumowania. Idealnie nadaje się do zastosowań wymagających głębokiej analizy, takich jak pytania i odpowiedzi wizualne czy przegląd treści obraz\xf3w z dokładną analizą."},"Qwen2-72B-Instruct":{"description":"Qwen2 to najnowsza seria modeli Qwen, obsługująca kontekst 128k. W por\xf3wnaniu do obecnie najlepszych modeli open source, Qwen2-72B znacznie przewyższa w zakresie rozumienia języka naturalnego, wiedzy, kodowania, matematyki i wielu język\xf3w."},"Qwen2-7B-Instruct":{"description":"Qwen2 to najnowsza seria modeli Qwen, kt\xf3ra przewyższa najlepsze modele open source o podobnej skali, a nawet większe. Qwen2 7B osiągnęła znaczną przewagę w wielu testach, szczeg\xf3lnie w zakresie kodowania i rozumienia języka chińskiego."},"Qwen2-VL-72B":{"description":"Qwen2-VL-72B to potężny model językowo-wizualny, wspierający przetwarzanie multimodalne obraz\xf3w i tekstu, zdolny do precyzyjnego rozpoznawania treści obraz\xf3w i generowania odpowiednich opis\xf3w lub odpowiedzi."},"Qwen2.5-14B-Instruct":{"description":"Qwen2.5-14B-Instruct to model językowy z 14 miliardami parametr\xf3w, o doskonałej wydajności, optymalizujący scenariusze w języku chińskim i wielojęzyczne, wspierający inteligentne odpowiedzi, generowanie treści i inne zastosowania."},"Qwen2.5-32B-Instruct":{"description":"Qwen2.5-32B-Instruct to model językowy z 32 miliardami parametr\xf3w, o zr\xf3wnoważonej wydajności, optymalizujący scenariusze w języku chińskim i wielojęzyczne, wspierający inteligentne odpowiedzi, generowanie treści i inne zastosowania."},"Qwen2.5-72B-Instruct":{"description":"Qwen2.5-72B-Instruct obsługuje kontekst 16k, generując długie teksty przekraczające 8K. Wspiera wywołania funkcji i bezproblemową interakcję z systemami zewnętrznymi, znacznie zwiększając elastyczność i skalowalność. Wiedza modelu znacznie wzrosła, a jego zdolności w zakresie kodowania i matematyki uległy znacznemu poprawieniu, z obsługą ponad 29 język\xf3w."},"Qwen2.5-7B-Instruct":{"description":"Qwen2.5-7B-Instruct to model językowy z 7 miliardami parametr\xf3w, wspierający wywołania funkcji i bezproblemową interakcję z systemami zewnętrznymi, znacznie zwiększając elastyczność i skalowalność. Optymalizuje scenariusze w języku chińskim i wielojęzyczne, wspierając inteligentne odpowiedzi, generowanie treści i inne zastosowania."},"Qwen2.5-Coder-14B-Instruct":{"description":"Qwen2.5-Coder-14B-Instruct to model instrukcji programowania oparty na dużych wstępnych treningach, posiadający silne zdolności rozumienia i generowania kodu, zdolny do efektywnego przetwarzania r\xf3żnych zadań programistycznych, szczeg\xf3lnie odpowiedni do inteligentnego pisania kodu, generowania skrypt\xf3w automatycznych i rozwiązywania problem\xf3w programistycznych."},"Qwen2.5-Coder-32B-Instruct":{"description":"Qwen2.5-Coder-32B-Instruct to duży model językowy zaprojektowany specjalnie do generowania kodu, rozumienia kodu i efektywnych scenariuszy rozwoju, wykorzystujący wiodącą w branży skalę 32B parametr\xf3w, zdolny do zaspokojenia r\xf3żnorodnych potrzeb programistycznych."},"Qwen3-235B":{"description":"Qwen3-235B-A22B to model MoE (ekspert mieszany), kt\xf3ry wprowadza „hybrydowy tryb rozumowania”, umożliwiający użytkownikom płynne przełączanie się między trybem myślenia a trybem bez myślenia. Obsługuje rozumienie i rozumowanie w 119 językach i dialektach oraz posiada zaawansowane możliwości wywoływania narzędzi. W testach por\xf3wnawczych obejmujących zdolności og\xf3lne, kodowanie, matematykę, wielojęzyczność, wiedzę i rozumowanie konkuruje z czołowymi modelami rynkowymi, takimi jak DeepSeek R1, OpenAI o1, o3-mini, Grok 3 oraz Google Gemini 2.5 Pro."},"Qwen3-235B-A22B-Instruct-2507-FP8":{"description":"Qwen3 235B A22B Instruct 2507: model zoptymalizowany pod kątem zaawansowanego wnioskowania i instrukcji dialogowych, z hybrydową architekturą ekspert\xf3w zapewniającą efektywność wnioskowania przy dużej liczbie parametr\xf3w."},"Qwen3-32B":{"description":"Qwen3-32B to model gęsty (Dense Model), kt\xf3ry wprowadza „hybrydowy tryb rozumowania”, umożliwiający użytkownikom płynne przełączanie się między trybem myślenia a trybem bez myślenia. Dzięki ulepszonej architekturze modelu, zwiększonej ilości danych treningowych oraz bardziej efektywnym metodom treningu, jego og\xf3lna wydajność jest por\xf3wnywalna z Qwen2.5-72B."},"SenseChat":{"description":"Podstawowa wersja modelu (V4), długość kontekstu 4K, silne zdolności og\xf3lne."},"SenseChat-128K":{"description":"Podstawowa wersja modelu (V4), długość kontekstu 128K, doskonałe wyniki w zadaniach związanych z rozumieniem i generowaniem długich tekst\xf3w."},"SenseChat-32K":{"description":"Podstawowa wersja modelu (V4), długość kontekstu 32K, elastycznie stosowana w r\xf3żnych scenariuszach."},"SenseChat-5":{"description":"Najnowsza wersja modelu (V5.5), długość kontekstu 128K, znacznie poprawione zdolności w zakresie rozumowania matematycznego, rozm\xf3w w języku angielskim, podążania za instrukcjami oraz rozumienia długich tekst\xf3w, dor\xf3wnująca GPT-4o."},"SenseChat-5-1202":{"description":"Oparty na najnowszej wersji V5.5, z wyraźnymi ulepszeniami w podstawowych zdolnościach w języku chińskim i angielskim, czacie, wiedzy ścisłej i humanistycznej, pisaniu, logice matematycznej oraz kontroli liczby sł\xf3w."},"SenseChat-5-Cantonese":{"description":"Długość kontekstu 32K, w rozumieniu rozm\xf3w w języku kantońskim przewyższa GPT-4, w wielu dziedzinach, takich jak wiedza, rozumowanie, matematyka i programowanie, dor\xf3wnuje GPT-4 Turbo."},"SenseChat-5-beta":{"description":"Częściowo lepsza wydajność niż SenseCat-5-1202"},"SenseChat-Character":{"description":"Standardowa wersja modelu, długość kontekstu 8K, wysoka szybkość reakcji."},"SenseChat-Character-Pro":{"description":"Zaawansowana wersja modelu, długość kontekstu 32K, znacznie poprawione zdolności, obsługuje rozmowy w języku chińskim i angielskim."},"SenseChat-Turbo":{"description":"Idealny do szybkich odpowiedzi i scenariuszy dostosowywania modelu."},"SenseChat-Turbo-1202":{"description":"Jest to najnowsza wersja modelu o niskiej wadze, osiągająca ponad 90% możliwości pełnego modelu, znacznie obniżając koszty wnioskowania."},"SenseChat-Vision":{"description":"Najnowsza wersja modelu (V5.5), obsługująca wiele obraz\xf3w jako wejście, w pełni optymalizuje podstawowe możliwości modelu, osiągając znaczną poprawę w rozpoznawaniu atrybut\xf3w obiekt\xf3w, relacji przestrzennych, rozpoznawaniu zdarzeń, zrozumieniu scen, rozpoznawaniu emocji, wnioskowaniu logicznym oraz generowaniu i rozumieniu tekstu."},"SenseNova-V6-5-Pro":{"description":"Dzięki kompleksowej aktualizacji danych multimodalnych, językowych i rozumowania oraz optymalizacji strategii treningowej, nowy model osiągnął znaczące ulepszenia w zakresie rozumowania multimodalnego i uniwersalnego przestrzegania instrukcji. Obsługuje kontekst o długości do 128k i wykazuje doskonałe wyniki w specjalistycznych zadaniach, takich jak OCR oraz rozpoznawanie IP w turystyce i kulturze."},"SenseNova-V6-5-Turbo":{"description":"Dzięki kompleksowej aktualizacji danych multimodalnych, językowych i rozumowania oraz optymalizacji strategii treningowej, nowy model osiągnął znaczące ulepszenia w zakresie rozumowania multimodalnego i uniwersalnego przestrzegania instrukcji. Obsługuje kontekst o długości do 128k i wykazuje doskonałe wyniki w specjalistycznych zadaniach, takich jak OCR oraz rozpoznawanie IP w turystyce i kulturze."},"SenseNova-V6-Pro":{"description":"Osiąga natywną jedność zdolności do przetwarzania obraz\xf3w, tekst\xf3w i wideo, przełamując tradycyjne ograniczenia rozdzielnych modalności, zdobywając podw\xf3jne mistrzostwo w ocenach OpenCompass i SuperCLUE."},"SenseNova-V6-Reasoner":{"description":"Łączy głębokie rozumienie wizualne i językowe, umożliwiając powolne myślenie i głęboką analizę, prezentując pełny proces myślowy."},"SenseNova-V6-Turbo":{"description":"Osiąga natywną jedność zdolności do przetwarzania obraz\xf3w, tekst\xf3w i wideo, przełamując tradycyjne ograniczenia rozdzielnych modalności, przewyższając w kluczowych wymiarach, takich jak podstawowe umiejętności multimodalne i językowe, oraz osiągając wysokie wyniki w wielu testach, wielokrotnie plasując się w czoł\xf3wce krajowej i międzynarodowej."},"Skylark2-lite-8k":{"description":"Model drugiej generacji Skylark (Skylark2) o wysokiej szybkości reakcji, odpowiedni do scenariuszy wymagających wysokiej reaktywności, wrażliwych na koszty, z mniejszymi wymaganiami co do precyzji modelu, z długością okna kontekstowego 8k."},"Skylark2-pro-32k":{"description":"Model drugiej generacji Skylark (Skylark2) o wysokiej precyzji, odpowiedni do bardziej złożonych scenariuszy generowania tekstu, takich jak generowanie treści w profesjonalnych dziedzinach, tworzenie powieści oraz tłumaczenia wysokiej jakości, z długością okna kontekstowego 32k."},"Skylark2-pro-4k":{"description":"Model drugiej generacji Skylark (Skylark2) o wysokiej precyzji, odpowiedni do bardziej złożonych scenariuszy generowania tekstu, takich jak generowanie treści w profesjonalnych dziedzinach, tworzenie powieści oraz tłumaczenia wysokiej jakości, z długością okna kontekstowego 4k."},"Skylark2-pro-character-4k":{"description":"Model drugiej generacji Skylark (Skylark2) z doskonałymi umiejętnościami w odgrywaniu r\xf3l i czatowaniu. Doskonale reaguje na prompty użytkownik\xf3w, odgrywając r\xf3żne role w naturalny spos\xf3b, idealny do budowy chatbot\xf3w, wirtualnych asystent\xf3w i obsługi klienta online, cechujący się wysoką szybkością reakcji."},"Skylark2-pro-turbo-8k":{"description":"Model drugiej generacji Skylark (Skylark2) z szybszym wnioskowaniem i niższymi kosztami, z długością okna kontekstowego 8k."},"THUDM/GLM-4-32B-0414":{"description":"GLM-4-32B-0414 to nowa generacja otwartego modelu z serii GLM, posiadająca 32 miliardy parametr\xf3w. Model ten osiąga wyniki por\xf3wnywalne z serią GPT OpenAI i serią V3/R1 DeepSeek."},"THUDM/GLM-4-9B-0414":{"description":"GLM-4-9B-0414 to mały model z serii GLM, mający 9 miliard\xf3w parametr\xf3w. Model ten dziedziczy cechy technologiczne serii GLM-4-32B, ale oferuje lżejsze opcje wdrożeniowe. Mimo mniejszych rozmiar\xf3w, GLM-4-9B-0414 nadal wykazuje doskonałe zdolności w generowaniu kodu, projektowaniu stron internetowych, generowaniu grafiki SVG i pisaniu opartym na wyszukiwaniu."},"THUDM/GLM-4.1V-9B-Thinking":{"description":"GLM-4.1V-9B-Thinking to otwarty model wizualno-językowy (VLM) opracowany wsp\xf3lnie przez Zhipu AI i Laboratorium KEG Uniwersytetu Tsinghua, zaprojektowany do obsługi złożonych zadań poznawczych wielomodalnych. Model opiera się na bazowym modelu GLM-4-9B-0414 i znacząco poprawia zdolności wnioskowania międzymodalnego oraz stabilność dzięki wprowadzeniu mechanizmu rozumowania „łańcucha myślowego” (Chain-of-Thought) oraz zastosowaniu strategii uczenia ze wzmocnieniem."},"THUDM/GLM-Z1-32B-0414":{"description":"GLM-Z1-32B-0414 to model wnioskowania z głęboką zdolnością myślenia. Model ten oparty jest na GLM-4-32B-0414, rozwinięty poprzez zimny start i rozszerzone uczenie przez wzmocnienie, a także przeszedł dalsze szkolenie w zadaniach matematycznych, kodowania i logiki. W por\xf3wnaniu do modelu bazowego, GLM-Z1-32B-0414 znacznie poprawił zdolności matematyczne i umiejętność rozwiązywania złożonych zadań."},"THUDM/GLM-Z1-9B-0414":{"description":"GLM-Z1-9B-0414 to mały model z serii GLM, mający tylko 9 miliard\xf3w parametr\xf3w, ale zachowujący tradycję otwartego źr\xf3dła, jednocześnie wykazując zdumiewające zdolności. Mimo mniejszych rozmiar\xf3w, model ten nadal osiąga doskonałe wyniki w wnioskowaniu matematycznym i og\xf3lnych zadaniach, a jego og\xf3lna wydajność jest na czołowej pozycji wśr\xf3d modeli o podobnej wielkości."},"THUDM/GLM-Z1-Rumination-32B-0414":{"description":"GLM-Z1-Rumination-32B-0414 to model głębokiego wnioskowania z zdolnością do refleksji (konkurujący z Deep Research OpenAI). W przeciwieństwie do typowych modeli głębokiego myślenia, model refleksyjny stosuje dłuższy czas głębokiego myślenia do rozwiązywania bardziej otwartych i złożonych problem\xf3w."},"THUDM/glm-4-9b-chat":{"description":"GLM-4 9B to otwarta wersja, oferująca zoptymalizowane doświadczenie dialogowe dla aplikacji konwersacyjnych."},"Tongyi-Zhiwen/QwenLong-L1-32B":{"description":"QwenLong-L1-32B to pierwszy duży model wnioskowania z długim kontekstem (LRM) wytrenowany z użyciem uczenia ze wzmocnieniem, zoptymalizowany pod kątem zadań wnioskowania na długich tekstach. Model osiąga stabilne przejście od kr\xf3tkiego do długiego kontekstu dzięki progresywnemu rozszerzaniu kontekstu w ramach uczenia ze wzmocnieniem. W siedmiu benchmarkach dotyczących pytań i odpowiedzi na długich dokumentach QwenLong-L1-32B przewyższa flagowe modele takie jak OpenAI-o3-mini i Qwen3-235B-A22B, osiągając wydajność por\xf3wnywalną z Claude-3.7-Sonnet-Thinking. Model jest szczeg\xf3lnie silny w złożonych zadaniach matematycznego, logicznego i wieloetapowego wnioskowania."},"Yi-34B-Chat":{"description":"Yi-1.5-34B, zachowując doskonałe og\xf3lne zdolności językowe oryginalnej serii modeli, znacznie poprawił zdolności logiczne i kodowania dzięki dodatkowym treningom na 500 miliardach wysokiej jakości token\xf3w."},"abab5.5-chat":{"description":"Skierowany do scenariuszy produkcyjnych, wspierający przetwarzanie złożonych zadań i efektywne generowanie tekstu, odpowiedni do zastosowań w profesjonalnych dziedzinach."},"abab5.5s-chat":{"description":"Zaprojektowany specjalnie do scenariuszy dialogowych w języku chińskim, oferujący wysokiej jakości generowanie dialog\xf3w w języku chińskim, odpowiedni do r\xf3żnych zastosowań."},"abab6.5g-chat":{"description":"Zaprojektowany specjalnie do dialog\xf3w z wielojęzycznymi postaciami, wspierający wysokiej jakości generowanie dialog\xf3w w języku angielskim i innych językach."},"abab6.5s-chat":{"description":"Odpowiedni do szerokiego zakresu zadań przetwarzania języka naturalnego, w tym generowania tekstu, system\xf3w dialogowych itp."},"abab6.5t-chat":{"description":"Optymalizowany do scenariuszy dialogowych w języku chińskim, oferujący płynne i zgodne z chińskimi zwyczajami generowanie dialog\xf3w."},"accounts/fireworks/models/deepseek-r1":{"description":"DeepSeek-R1 to zaawansowany model językowy, kt\xf3ry został zoptymalizowany dzięki uczeniu przez wzmocnienie i danym z zimnego startu, oferując doskonałe możliwości wnioskowania, matematyki i programowania."},"accounts/fireworks/models/deepseek-v3":{"description":"Potężny model językowy Mixture-of-Experts (MoE) oferowany przez Deepseek, z całkowitą liczbą parametr\xf3w wynoszącą 671 miliard\xf3w, aktywującym 37 miliard\xf3w parametr\xf3w na każdy token."},"accounts/fireworks/models/llama-v3-70b-instruct":{"description":"Model Llama 3 70B Instruct, zaprojektowany do wielojęzycznych dialog\xf3w i rozumienia języka naturalnego, przewyższa większość konkurencyjnych modeli."},"accounts/fireworks/models/llama-v3-8b-instruct":{"description":"Model Llama 3 8B Instruct, zoptymalizowany do dialog\xf3w i zadań wielojęzycznych, oferuje doskonałe i efektywne osiągi."},"accounts/fireworks/models/llama-v3-8b-instruct-hf":{"description":"Model Llama 3 8B Instruct (wersja HF), zgodny z wynikami oficjalnej implementacji, zapewnia wysoką sp\xf3jność i kompatybilność międzyplatformową."},"accounts/fireworks/models/llama-v3p1-405b-instruct":{"description":"Model Llama 3.1 405B Instruct, z ogromną liczbą parametr\xf3w, idealny do złożonych zadań i śledzenia poleceń w scenariuszach o dużym obciążeniu."},"accounts/fireworks/models/llama-v3p1-70b-instruct":{"description":"Model Llama 3.1 70B Instruct oferuje doskonałe możliwości rozumienia i generowania języka, idealny do zadań dialogowych i analitycznych."},"accounts/fireworks/models/llama-v3p1-8b-instruct":{"description":"Model Llama 3.1 8B Instruct, zoptymalizowany do wielojęzycznych dialog\xf3w, potrafi przewyższyć większość modeli open source i closed source w powszechnych standardach branżowych."},"accounts/fireworks/models/llama-v3p2-11b-vision-instruct":{"description":"Model wnioskowania wizualnego z 11B parametr\xf3w od Meta. Model zoptymalizowany do rozpoznawania wizualnego, wnioskowania obraz\xf3w, opisywania obraz\xf3w oraz odpowiadania na og\xf3lne pytania dotyczące obraz\xf3w. Model potrafi rozumieć dane wizualne, takie jak wykresy i grafiki, a dzięki generowaniu tekstowych opis\xf3w szczeg\xf3ł\xf3w obraz\xf3w, łączy wizję z językiem."},"accounts/fireworks/models/llama-v3p2-3b-instruct":{"description":"Model instruktażowy Llama 3.2 3B to lekki model wielojęzyczny zaprezentowany przez Meta. Zaprojektowany, aby poprawić wydajność, oferując znaczące usprawnienia w op\xf3źnieniu i kosztach w por\xf3wnaniu do większych modeli. Przykładowe przypadki użycia tego modelu obejmują zapytania i przepisanie sugestii oraz pomoc w pisaniu."},"accounts/fireworks/models/llama-v3p2-90b-vision-instruct":{"description":"Model wnioskowania wizualnego z 90B parametr\xf3w od Meta. Model zoptymalizowany do rozpoznawania wizualnego, wnioskowania obraz\xf3w, opisywania obraz\xf3w oraz odpowiadania na og\xf3lne pytania dotyczące obraz\xf3w. Model potrafi rozumieć dane wizualne, takie jak wykresy i grafiki, a dzięki generowaniu tekstowych opis\xf3w szczeg\xf3ł\xf3w obraz\xf3w, łączy wizję z językiem."},"accounts/fireworks/models/llama-v3p3-70b-instruct":{"description":"Llama 3.3 70B Instruct to zaktualizowana wersja Llama 3.1 70B z grudnia. Model ten został ulepszony w oparciu o Llama 3.1 70B (wydany w lipcu 2024), wzmacniając możliwości wywoływania narzędzi, wsparcie dla tekst\xf3w w wielu językach, a także umiejętności matematyczne i programistyczne. Model osiągnął wiodący w branży poziom w zakresie wnioskowania, matematyki i przestrzegania instrukcji, oferując wydajność por\xf3wnywalną z 3.1 405B, jednocześnie zapewniając znaczące korzyści w zakresie szybkości i koszt\xf3w."},"accounts/fireworks/models/mistral-small-24b-instruct-2501":{"description":"Model z 24 miliardami parametr\xf3w, oferujący zaawansowane możliwości por\xf3wnywalne z większymi modelami."},"accounts/fireworks/models/mixtral-8x22b-instruct":{"description":"Model Mixtral MoE 8x22B Instruct, z dużą liczbą parametr\xf3w i architekturą wielu ekspert\xf3w, kompleksowo wspierający efektywne przetwarzanie złożonych zadań."},"accounts/fireworks/models/mixtral-8x7b-instruct":{"description":"Model Mixtral MoE 8x7B Instruct, architektura wielu ekspert\xf3w, oferująca efektywne śledzenie i wykonanie poleceń."},"accounts/fireworks/models/mythomax-l2-13b":{"description":"Model MythoMax L2 13B, łączący nowatorskie techniki łączenia, doskonały w narracji i odgrywaniu r\xf3l."},"accounts/fireworks/models/phi-3-vision-128k-instruct":{"description":"Model Phi 3 Vision Instruct, lekki model multimodalny, zdolny do przetwarzania złożonych informacji wizualnych i tekstowych, z silnymi zdolnościami wnioskowania."},"accounts/fireworks/models/qwen-qwq-32b-preview":{"description":"Model QwQ to eksperymentalny model badawczy opracowany przez zesp\xf3ł Qwen, skoncentrowany na zwiększeniu zdolności wnioskowania AI."},"accounts/fireworks/models/qwen2-vl-72b-instruct":{"description":"Wersja 72B modelu Qwen-VL to najnowszy owoc iteracji Alibaba, reprezentujący innowacje z ostatniego roku."},"accounts/fireworks/models/qwen2p5-72b-instruct":{"description":"Qwen2.5 to seria modeli językowych opracowana przez zesp\xf3ł Qwen na chmurze Alibaba, kt\xf3ra zawiera jedynie dekodery. Modele te występują w r\xf3żnych rozmiarach, w tym 0.5B, 1.5B, 3B, 7B, 14B, 32B i 72B, i oferują dwie wersje: bazową (base) i instruktażową (instruct)."},"accounts/fireworks/models/qwen2p5-coder-32b-instruct":{"description":"Qwen2.5 Coder 32B Instruct to najnowsza wersja serii dużych modeli językowych specyficznych dla kodu wydana przez Alibaba Cloud. Model ten, oparty na Qwen2.5, został przeszkolony na 55 bilionach token\xf3w, znacznie poprawiając zdolności generowania kodu, wnioskowania i naprawy. Wzmacnia on nie tylko zdolności kodowania, ale także utrzymuje przewagę w zakresie matematyki i og\xf3lnych umiejętności. Model ten stanowi bardziej kompleksową podstawę dla rzeczywistych zastosowań, takich jak inteligentne agenty kodowe."},"accounts/yi-01-ai/models/yi-large":{"description":"Model Yi-Large, oferujący doskonałe możliwości przetwarzania wielojęzycznego, nadający się do r\xf3żnych zadań generowania i rozumienia języka."},"ai21-jamba-1.5-large":{"description":"Model wielojęzyczny z 398 miliardami parametr\xf3w (94 miliardy aktywnych), oferujący okno kontekstowe o długości 256K, wywoływanie funkcji, strukturalne wyjście i generację opartą na kontekście."},"ai21-jamba-1.5-mini":{"description":"Model wielojęzyczny z 52 miliardami parametr\xf3w (12 miliard\xf3w aktywnych), oferujący okno kontekstowe o długości 256K, wywoływanie funkcji, strukturalne wyjście i generację opartą na kontekście."},"ai21-labs/AI21-Jamba-1.5-Large":{"description":"Model wielojęzyczny o 398 miliardach parametr\xf3w (94 miliardy aktywnych), oferujący okno kontekstowe o długości 256K, wywoływanie funkcji, strukturalne wyjście oraz generowanie oparte na faktach."},"ai21-labs/AI21-Jamba-1.5-Mini":{"description":"Model wielojęzyczny o 52 miliardach parametr\xf3w (12 miliard\xf3w aktywnych), oferujący okno kontekstowe o długości 256K, wywoływanie funkcji, strukturalne wyjście oraz generowanie oparte na faktach."},"alibaba/qwen-3-14b":{"description":"Qwen3 to najnowsza generacja dużych modeli językowych z serii Qwen, oferująca kompleksowy zestaw modeli gęstych i hybrydowych ekspert\xf3w (MoE). Dzięki szerokiemu treningowi Qwen3 zapewnia przełomowe postępy w zakresie wnioskowania, przestrzegania instrukcji, zdolności agent\xf3w oraz wsparcia wielojęzycznego."},"alibaba/qwen-3-235b":{"description":"Qwen3 to najnowsza generacja dużych modeli językowych z serii Qwen, oferująca kompleksowy zestaw modeli gęstych i hybrydowych ekspert\xf3w (MoE). Dzięki szerokiemu treningowi Qwen3 zapewnia przełomowe postępy w zakresie wnioskowania, przestrzegania instrukcji, zdolności agent\xf3w oraz wsparcia wielojęzycznego."},"alibaba/qwen-3-30b":{"description":"Qwen3 to najnowsza generacja dużych modeli językowych z serii Qwen, oferująca kompleksowy zestaw modeli gęstych i hybrydowych ekspert\xf3w (MoE). Dzięki szerokiemu treningowi Qwen3 zapewnia przełomowe postępy w zakresie wnioskowania, przestrzegania instrukcji, zdolności agent\xf3w oraz wsparcia wielojęzycznego."},"alibaba/qwen-3-32b":{"description":"Qwen3 to najnowsza generacja dużych modeli językowych z serii Qwen, oferująca kompleksowy zestaw modeli gęstych i hybrydowych ekspert\xf3w (MoE). Dzięki szerokiemu treningowi Qwen3 zapewnia przełomowe postępy w zakresie wnioskowania, przestrzegania instrukcji, zdolności agent\xf3w oraz wsparcia wielojęzycznego."},"alibaba/qwen3-coder":{"description":"Qwen3-Coder-480B-A35B-Instruct to najbardziej agentowy model kodowania z serii Qwen, wyr\xf3żniający się znakomitą wydajnością w kodowaniu agentowym, korzystaniu z przeglądarki przez agenta oraz innych podstawowych zadaniach kodowania, osiągając wyniki por\xf3wnywalne z Claude Sonnet."},"amazon/nova-lite":{"description":"Bardzo niskokosztowy model multimodalny, kt\xf3ry przetwarza obrazy, wideo i tekst z niezwykłą szybkością."},"amazon/nova-micro":{"description":"Model tekstowy oferujący najniższe op\xf3źnienia przy bardzo niskich kosztach."},"amazon/nova-pro":{"description":"Wysoce kompetentny model multimodalny, oferujący optymalne połączenie dokładności, szybkości i koszt\xf3w, odpowiedni do szerokiego zakresu zadań."},"amazon/titan-embed-text-v2":{"description":"Amazon Titan Text Embeddings V2 to lekki, wydajny model wielojęzycznych osadzeń, obsługujący wymiary 1024, 512 i 256."},"anthropic.claude-3-5-sonnet-20240620-v1:0":{"description":"Claude 3.5 Sonnet podnosi standardy branżowe, przewyższając modele konkurencji oraz Claude 3 Opus, osiągając doskonałe wyniki w szerokim zakresie ocen, jednocześnie oferując szybkość i koszty na poziomie naszych modeli średniej klasy."},"anthropic.claude-3-5-sonnet-20241022-v2:0":{"description":"Claude 3.5 Sonnet podnosi standardy branżowe, przewyższając modele konkurencji oraz Claude 3 Opus, wykazując doskonałe wyniki w szerokich ocenach, jednocześnie oferując prędkość i koszty naszych modeli średniego poziomu."},"anthropic.claude-3-haiku-20240307-v1:0":{"description":"Claude 3 Haiku to najszybszy i najbardziej kompaktowy model od Anthropic, oferujący niemal natychmiastową szybkość odpowiedzi. Może szybko odpowiadać na proste zapytania i prośby. Klienci będą mogli budować płynne doświadczenia AI, kt\xf3re naśladują interakcje międzyludzkie. Claude 3 Haiku może przetwarzać obrazy i zwracać wyjścia tekstowe, z oknem kontekstowym wynoszącym 200K."},"anthropic.claude-3-opus-20240229-v1:0":{"description":"Claude 3 Opus to najpotężniejszy model AI od Anthropic, z najnowocześniejszymi osiągami w wysoko złożonych zadaniach. Może obsługiwać otwarte podpowiedzi i nieznane scenariusze, oferując doskonałą płynność i ludzkie zdolności rozumienia. Claude 3 Opus pokazuje granice możliwości generatywnej AI. Claude 3 Opus może przetwarzać obrazy i zwracać wyjścia tekstowe, z oknem kontekstowym wynoszącym 200K."},"anthropic.claude-3-sonnet-20240229-v1:0":{"description":"Claude 3 Sonnet od Anthropic osiąga idealną r\xf3wnowagę między inteligencją a szybkością — szczeg\xf3lnie odpowiedni do obciążeń roboczych w przedsiębiorstwach. Oferuje maksymalną użyteczność po niższej cenie niż konkurencja i został zaprojektowany jako niezawodny, wytrzymały model gł\xf3wny, odpowiedni do skalowalnych wdrożeń AI. Claude 3 Sonnet może przetwarzać obrazy i zwracać wyjścia tekstowe, z oknem kontekstowym wynoszącym 200K."},"anthropic.claude-instant-v1":{"description":"Szybki, ekonomiczny model, kt\xf3ry wciąż jest bardzo zdolny, może obsługiwać szereg zadań, w tym codzienne rozmowy, analizę tekstu, podsumowania i pytania dotyczące dokument\xf3w."},"anthropic.claude-v2":{"description":"Model Anthropic wykazuje wysokie zdolności w szerokim zakresie zadań, od złożonych rozm\xf3w i generowania treści kreatywnych po szczeg\xf3łowe przestrzeganie instrukcji."},"anthropic.claude-v2:1":{"description":"Zaktualizowana wersja Claude 2, z podw\xf3jnym oknem kontekstowym oraz poprawioną niezawodnością, wskaźnikiem halucynacji i dokładnością opartą na dowodach w kontekście długich dokument\xf3w i RAG."},"anthropic/claude-3-haiku":{"description":"Claude 3 Haiku to najszybszy model Anthropic, zaprojektowany do obciążeń korporacyjnych zwykle obejmujących długie podpowiedzi. Haiku potrafi szybko analizować duże ilości dokument\xf3w, takich jak raporty kwartalne, umowy czy sprawy prawne, przy kosztach stanowiących połowę innych modeli o podobnej klasie wydajności."},"anthropic/claude-3-opus":{"description":"Claude 3 Opus to najbardziej inteligentny model Anthropic, oferujący wiodącą na rynku wydajność w bardzo złożonych zadaniach. Potrafi płynnie i z ludzkim zrozumieniem radzić sobie z otwartymi podpowiedziami i nieznanymi wcześniej scenariuszami."},"anthropic/claude-3.5-haiku":{"description":"Claude 3.5 Haiku to następna generacja naszego najszybszego modelu. Oferuje podobną szybkość jak Claude 3 Haiku, ale z ulepszeniami we wszystkich zestawach umiejętności i przewyższa w wielu testach inteligencji nasz poprzedni największy model Claude 3 Opus."},"anthropic/claude-3.5-sonnet":{"description":"Claude 3.5 Sonnet osiąga idealną r\xf3wnowagę między inteligencją a szybkością — szczeg\xf3lnie dla obciążeń korporacyjnych. W por\xf3wnaniu z konkurencją oferuje potężną wydajność przy niższych kosztach i jest zaprojektowany z myślą o wysokiej trwałości w dużych wdrożeniach AI."},"anthropic/claude-3.7-sonnet":{"description":"Claude 3.7 Sonnet to pierwszy model hybrydowego wnioskowania i najbardziej inteligentny model Anthropic do tej pory. Oferuje zaawansowaną wydajność w kodowaniu, generowaniu treści, analizie danych i planowaniu, budując na fundamentach inżynierii oprogramowania i umiejętności komputerowych poprzednika Claude 3.5 Sonnet."},"anthropic/claude-opus-4":{"description":"Claude Opus 4 to najsilniejszy model Anthropic i najlepszy na świecie model kodowania, prowadzący w benchmarkach SWE-bench (72,5%) i Terminal-bench (43,2%). Zapewnia ciągłą wydajność dla długotrwałych zadań wymagających skupienia i tysięcy krok\xf3w, mogąc pracować nieprzerwanie przez wiele godzin — znacznie rozszerzając możliwości agent\xf3w AI."},"anthropic/claude-opus-4.1":{"description":"Claude Opus 4.1 to plug-and-play alternatywa dla Opus 4, oferująca doskonałą wydajność i precyzję w praktycznych zadaniach kodowania i agent\xf3w. Podnosi najnowocześniejszą wydajność kodowania do 74,5% w SWE-bench Verified i radzi sobie złożonymi, wieloetapowymi problemami z większą rygorystycznością i dbałością o szczeg\xf3ły."},"anthropic/claude-sonnet-4":{"description":"Claude Sonnet 4 to znacząca poprawa w stosunku do Sonnet 3.7, oferująca doskonałą wydajność w kodowaniu z rekordowym wynikiem 72,7% w SWE-bench. Model osiąga r\xf3wnowagę między wydajnością a efektywnością, nadaje się do zastosowań wewnętrznych i zewnętrznych oraz zapewnia większą kontrolę dzięki ulepszonej sterowalności."},"anthropic/claude-sonnet-4.5":{"description":"Claude Sonnet 4.5 to jak dotąd najbardziej inteligentny model Anthropic."},"ascend-tribe/pangu-pro-moe":{"description":"Pangu-Pro-MoE 72B-A16B to rzadki, duży model językowy o 72 miliardach parametr\xf3w i 16 miliardach aktywowanych parametr\xf3w, oparty na architekturze grupowanych ekspert\xf3w (MoGE). W fazie wyboru ekspert\xf3w model grupuje ekspert\xf3w i ogranicza aktywację token\xf3w do r\xf3wnej liczby ekspert\xf3w w każdej grupie, co zapewnia r\xf3wnomierne obciążenie ekspert\xf3w i znacznie poprawia efektywność wdrożenia modelu na platformie Ascend."},"aya":{"description":"Aya 23 to model wielojęzyczny wydany przez Cohere, wspierający 23 języki, ułatwiający r\xf3żnorodne zastosowania językowe."},"aya:35b":{"description":"Aya 23 to model wielojęzyczny wydany przez Cohere, wspierający 23 języki, ułatwiający r\xf3żnorodne zastosowania językowe."},"azure-DeepSeek-R1-0528":{"description":"Dostarczony i wdrożony przez Microsoft; model DeepSeek R1 przeszedł drobną aktualizację wersji, obecna wersja to DeepSeek-R1-0528. W najnowszej aktualizacji DeepSeek R1 znacznie poprawił głębokość wnioskowania i zdolności inferencyjne poprzez zwiększenie zasob\xf3w obliczeniowych oraz wprowadzenie optymalizacji algorytm\xf3w w fazie post-treningowej. Model ten osiąga doskonałe wyniki w testach bazowych z matematyki, programowania i logiki og\xf3lnej, a jego og\xf3lna wydajność zbliża się do czołowych modeli, takich jak O3 i Gemini 2.5 Pro."},"baichuan-m2-32b":{"description":"Baichuan M2 32B to hybrydowy model ekspertowy opracowany przez Baichuan Intelligence, charakteryzujący się zaawansowanymi zdolnościami wnioskowania."},"baichuan/baichuan2-13b-chat":{"description":"Baichuan-13B to otwarty model językowy stworzony przez Baichuan Intelligence, zawierający 13 miliard\xf3w parametr\xf3w, kt\xf3ry osiągnął najlepsze wyniki w swojej klasie w autorytatywnych benchmarkach w języku chińskim i angielskim."},"baidu/ERNIE-4.5-300B-A47B":{"description":"ERNIE-4.5-300B-A47B to duży model językowy opracowany przez firmę Baidu, oparty na hybrydowej architekturze ekspert\xf3w (MoE). Model ma 300 miliard\xf3w parametr\xf3w, ale podczas inferencji aktywuje tylko 47 miliard\xf3w parametr\xf3w na token, co zapewnia doskonałą wydajność przy efektywności obliczeniowej. Jako jeden z kluczowych modeli serii ERNIE 4.5, wykazuje znakomite zdolności w rozumieniu tekstu, generowaniu, wnioskowaniu i programowaniu. Model wykorzystuje innowacyjną metodę pretrenowania multimodalnego heterogenicznego MoE, łącząc trening tekstu i wizji, co skutecznie zwiększa jego zdolności, zwłaszcza w zakresie przestrzegania instrukcji i pamięci wiedzy o świecie."},"c4ai-aya-expanse-32b":{"description":"Aya Expanse to model wielojęzyczny o wysokiej wydajności 32B, zaprojektowany w celu wyzwania wydajności modeli jednolanguage poprzez innowacje w zakresie dostosowywania instrukcji, arbitrażu danych, treningu preferencji i łączenia modeli. Obsługuje 23 języki."},"c4ai-aya-expanse-8b":{"description":"Aya Expanse to model wielojęzyczny o wysokiej wydajności 8B, zaprojektowany w celu wyzwania wydajności modeli jednolanguage poprzez innowacje w zakresie dostosowywania instrukcji, arbitrażu danych, treningu preferencji i łączenia modeli. Obsługuje 23 języki."},"c4ai-aya-vision-32b":{"description":"Aya Vision to zaawansowany model wielomodalny, kt\xf3ry osiąga doskonałe wyniki w wielu kluczowych benchmarkach dotyczących zdolności językowych, tekstowych i obrazowych. Obsługuje 23 języki. Ta wersja z 32 miliardami parametr\xf3w koncentruje się na najnowocześniejszej wydajności wielojęzycznej."},"c4ai-aya-vision-8b":{"description":"Aya Vision to zaawansowany model wielomodalny, kt\xf3ry osiąga doskonałe wyniki w wielu kluczowych benchmarkach dotyczących zdolności językowych, tekstowych i obrazowych. Ta wersja z 8 miliardami parametr\xf3w koncentruje się na niskiej latencji i najlepszej wydajności."},"charglm-3":{"description":"CharGLM-3 zaprojektowany z myślą o odgrywaniu r\xf3l i emocjonalnym towarzyszeniu, obsługujący ultra-długą pamięć wielokrotną i spersonalizowane dialogi, z szerokim zakresem zastosowań."},"charglm-4":{"description":"CharGLM-4 zaprojektowany z myślą o odgrywaniu r\xf3l i emocjonalnym towarzyszeniu, wspierający długotrwałą pamięć i spersonalizowane rozmowy, z szerokim zakresem zastosowań."},"chatgpt-4o-latest":{"description":"ChatGPT-4o to dynamiczny model, kt\xf3ry jest na bieżąco aktualizowany, aby utrzymać najnowszą wersję. Łączy potężne zdolności rozumienia i generowania języka, co czyni go odpowiednim do zastosowań na dużą skalę, w tym obsługi klienta, edukacji i wsparcia technicznego."},"claude-2.0":{"description":"Claude 2 oferuje postępy w kluczowych możliwościach dla przedsiębiorstw, w tym wiodącą w branży kontekst 200K token\xf3w, znacznie zmniejszającą częstość występowania halucynacji modelu, systemowe podpowiedzi oraz nową funkcję testową: wywołania narzędzi."},"claude-2.1":{"description":"Claude 2 oferuje postępy w kluczowych możliwościach dla przedsiębiorstw, w tym wiodącą w branży kontekst 200K token\xf3w, znacznie zmniejszającą częstość występowania halucynacji modelu, systemowe podpowiedzi oraz nową funkcję testową: wywołania narzędzi."},"claude-3-5-haiku-20241022":{"description":"Claude 3.5 Haiku to najszybszy model następnej generacji od Anthropic. W por\xf3wnaniu do Claude 3 Haiku, Claude 3.5 Haiku wykazuje poprawę w r\xf3żnych umiejętnościach i przewyższa największy model poprzedniej generacji, Claude 3 Opus, w wielu testach inteligencji."},"claude-3-5-haiku-latest":{"description":"Claude 3.5 Haiku zapewnia szybkie odpowiedzi, idealne do lekkich zadań."},"claude-3-7-sonnet-20250219":{"description":"Claude 3.7 Sonnet to najnowszy model od Anthropic, kt\xf3ry oferuje doskonałe wyniki w szerokim zakresie zadań, w tym generowanie treści, rozumienie języka naturalnego i przestrzeganie instrukcji. Claude 3.7 Sonnet jest szybki, niezawodny i ekonomiczny, co sprawia, że jest idealny do zastosowań produkcyjnych."},"claude-3-7-sonnet-latest":{"description":"Claude 3.7 Sonnet to najnowszy, najpotężniejszy model Anthropic do obsługi wysoce złożonych zadań. Wyr\xf3żnia się doskonałą wydajnością, inteligencją, płynnością i zdolnością rozumienia."},"claude-3-haiku-20240307":{"description":"Claude 3 Haiku to najszybszy i najbardziej kompaktowy model Anthropic, zaprojektowany do osiągania niemal natychmiastowych odpowiedzi. Oferuje szybkie i dokładne wyniki w ukierunkowanych zadaniach."},"claude-3-opus-20240229":{"description":"Claude 3 Opus to najpotężniejszy model Anthropic do przetwarzania wysoce złożonych zadań. Wykazuje doskonałe osiągi w zakresie wydajności, inteligencji, płynności i zrozumienia."},"claude-3-sonnet-20240229":{"description":"Claude 3 Sonnet zapewnia idealną r\xf3wnowagę między inteligencją a szybkością dla obciążeń roboczych w przedsiębiorstwach. Oferuje maksymalną użyteczność przy niższej cenie, jest niezawodny i odpowiedni do dużych wdrożeń."},"claude-haiku-4-5-20251001":{"description":"Claude Haiku 4.5 to najszybszy i najbardziej inteligentny model Haiku firmy Anthropic, oferujący błyskawiczne działanie i zaawansowane możliwości rozumowania."},"claude-opus-4-1-20250805":{"description":"Claude Opus 4.1 to najnowszy i najpotężniejszy model Anthropic do obsługi wysoce złożonych zadań. Wyr\xf3żnia się doskonałą wydajnością, inteligencją, płynnością i zdolnością rozumienia."},"claude-opus-4-1-20250805-thinking":{"description":"Model myślenia Claude Opus 4.1, zaawansowana wersja pokazująca procesy rozumowania."},"claude-opus-4-20250514":{"description":"Claude Opus 4 to najpotężniejszy model Anthropic, zaprojektowany do obsługi wysoce złożonych zadań. Wyr\xf3żnia się doskonałymi osiągami, inteligencją, płynnością i zdolnością rozumienia."},"claude-sonnet-4-20250514":{"description":"Claude Sonnet 4 może generować niemal natychmiastowe odpowiedzi lub wydłużone, stopniowe rozważania, kt\xf3re użytkownik może wyraźnie obserwować."},"claude-sonnet-4-20250514-thinking":{"description":"Model myślenia Claude Sonnet 4 może generować niemal natychmiastowe odpowiedzi lub wydłużone, stopniowe rozważania, kt\xf3re użytkownik może wyraźnie obserwować."},"claude-sonnet-4-5-20250929":{"description":"Claude Sonnet 4.5 to jak dotąd najbardziej inteligentny model Anthropic."},"codegeex-4":{"description":"CodeGeeX-4 to potężny asystent programowania AI, obsługujący inteligentne pytania i odpowiedzi oraz uzupełnianie kodu w r\xf3żnych językach programowania, zwiększając wydajność programist\xf3w."},"codegeex4-all-9b":{"description":"CodeGeeX4-ALL-9B to model generowania kodu w wielu językach, kt\xf3ry obsługuje kompleksowe funkcje, w tym uzupełnianie i generowanie kodu, interpreter kodu, wyszukiwanie w sieci, wywołania funkcji oraz pytania i odpowiedzi na poziomie repozytori\xf3w, obejmując r\xf3żne scenariusze rozwoju oprogramowania. Jest to wiodący model generowania kodu z mniej niż 10B parametr\xf3w."},"codegemma":{"description":"CodeGemma to lekki model językowy, specjalizujący się w r\xf3żnych zadaniach programistycznych, wspierający szybkie iteracje i integrację."},"codegemma:2b":{"description":"CodeGemma to lekki model językowy, specjalizujący się w r\xf3żnych zadaniach programistycznych, wspierający szybkie iteracje i integrację."},"codellama":{"description":"Code Llama to model LLM skoncentrowany na generowaniu i dyskusji kodu, łączący wsparcie dla szerokiego zakresu język\xf3w programowania, odpowiedni do środowisk deweloperskich."},"codellama/CodeLlama-34b-Instruct-hf":{"description":"Code Llama to LLM skoncentrowany na generowaniu i omawianiu kodu, z szerokim wsparciem dla r\xf3żnych język\xf3w programowania, odpowiedni dla środowisk deweloperskich."},"codellama:13b":{"description":"Code Llama to model LLM skoncentrowany na generowaniu i dyskusji kodu, łączący wsparcie dla szerokiego zakresu język\xf3w programowania, odpowiedni do środowisk deweloperskich."},"codellama:34b":{"description":"Code Llama to model LLM skoncentrowany na generowaniu i dyskusji kodu, łączący wsparcie dla szerokiego zakresu język\xf3w programowania, odpowiedni do środowisk deweloperskich."},"codellama:70b":{"description":"Code Llama to model LLM skoncentrowany na generowaniu i dyskusji kodu, łączący wsparcie dla szerokiego zakresu język\xf3w programowania, odpowiedni do środowisk deweloperskich."},"codeqwen":{"description":"CodeQwen1.5 to duży model językowy wytrenowany na dużej ilości danych kodowych, zaprojektowany do rozwiązywania złożonych zadań programistycznych."},"codestral":{"description":"Codestral to pierwszy model kodowy Mistral AI, oferujący doskonałe wsparcie dla zadań generowania kodu."},"codestral-latest":{"description":"Codestral to nowoczesny model generacyjny skoncentrowany na generowaniu kodu, zoptymalizowany do zadań wypełniania i uzupełniania kodu."},"codex-mini-latest":{"description":"codex-mini-latest to wersja dostrojona o4-mini, specjalnie zaprojektowana do Codex CLI. Do bezpośredniego użycia przez API zalecamy rozpoczęcie od gpt-4.1."},"cogview-4":{"description":"CogView-4 to pierwszy otwartoźr\xf3dłowy model generowania obraz\xf3w tekstowych firmy Zhipu, kt\xf3ry obsługuje generowanie znak\xf3w chińskich. Model oferuje kompleksowe ulepszenia w zakresie rozumienia semantycznego, jakości generowanych obraz\xf3w oraz zdolności generowania tekstu w języku chińskim i angielskim. Obsługuje dwujęzyczne wejście w dowolnej długości i potrafi generować obrazy o dowolnej rozdzielczości w określonym zakresie."},"cohere-command-r":{"description":"Command R to skalowalny model generatywny, kt\xf3ry koncentruje się na RAG i użyciu narzędzi, aby umożliwić AI na skalę produkcyjną dla przedsiębiorstw."},"cohere-command-r-plus":{"description":"Command R+ to model zoptymalizowany pod kątem RAG, zaprojektowany do obsługi obciążeń roboczych na poziomie przedsiębiorstwa."},"cohere/Cohere-command-r":{"description":"Command R to skalowalny model generatywny zaprojektowany do zastosowań RAG i narzędziowych, umożliwiający firmom wdrożenie AI na poziomie produkcyjnym."},"cohere/Cohere-command-r-plus":{"description":"Command R+ to zaawansowany model zoptymalizowany pod kątem RAG, stworzony do obsługi obciążeń na poziomie przedsiębiorstwa."},"cohere/command-a":{"description":"Command A to najsilniejszy model Cohere, wyr\xf3żniający się w użyciu narzędzi, agentach, generowaniu wspomaganym wyszukiwaniem (RAG) i zastosowaniach wielojęzycznych. Posiada długość kontekstu 256K i działa na zaledwie dw\xf3ch GPU, oferując 150% wyższą przepustowość w por\xf3wnaniu do Command R+ 08-2024."},"cohere/command-r":{"description":"Command R to duży model językowy zoptymalizowany pod kątem interakcji konwersacyjnych i zadań z długim kontekstem. Należy do kategorii \\"skalowalnych\\" modeli, łącząc wysoką wydajność z dużą dokładnością, umożliwiając firmom przejście od proof-of-concept do produkcji."},"cohere/command-r-plus":{"description":"Command R+ to najnowszy duży model językowy Cohere, zoptymalizowany pod kątem interakcji konwersacyjnych i zadań z długim kontekstem. Jego celem jest osiągnięcie wyjątkowej wydajności, umożliwiając firmom przejście od proof-of-concept do produkcji."},"cohere/embed-v4.0":{"description":"Model umożliwiający klasyfikację tekstu, obraz\xf3w lub treści mieszanych oraz konwersję na osadzenia."},"comfyui/flux-dev":{"description":"FLUX.1 Dev – Wysokiej jakości model generowania obraz\xf3w z tekstu, generuje w 10–50 krokach, idealny do tworzenia dzieł sztuki i kreatywnych projekt\xf3w."},"comfyui/flux-kontext-dev":{"description":"FLUX.1 Kontext-dev – Model edycji obraz\xf3w, umożliwia modyfikację istniejących obraz\xf3w na podstawie poleceń tekstowych, wspiera edycję lokalną i transfer stylu."},"comfyui/flux-krea-dev":{"description":"FLUX.1 Krea-dev – Ulepszony pod względem bezpieczeństwa model generowania obraz\xf3w z tekstu, opracowany we wsp\xf3łpracy z Krea, z wbudowanym filtrem bezpieczeństwa."},"comfyui/flux-schnell":{"description":"FLUX.1 Schnell – Ekstremalnie szybki model generowania obraz\xf3w z tekstu, tworzy wysokiej jakości obrazy w zaledwie 1–4 krokach, idealny do zastosowań w czasie rzeczywistym i szybkiego prototypowania."},"comfyui/stable-diffusion-15":{"description":"Stable Diffusion 1.5 – Klasyczny model generowania obraz\xf3w z tekstu o rozdzielczości 512x512, idealny do szybkiego prototypowania i eksperyment\xf3w tw\xf3rczych."},"comfyui/stable-diffusion-35":{"description":"Stable Diffusion 3.5 – Nowej generacji model generowania obraz\xf3w z tekstu, dostępny w wersjach Large i Medium, wymaga zewnętrznego pliku kodera CLIP, oferuje doskonałą jakość obrazu i zgodność z podpowiedziami."},"comfyui/stable-diffusion-35-inclclip":{"description":"Stable Diffusion 3.5 – Wersja z wbudowanym koderem CLIP/T5, nie wymaga zewnętrznych plik\xf3w kodera, odpowiednia dla modeli takich jak sd3.5_medium_incl_clips, zużywa mniej zasob\xf3w."},"comfyui/stable-diffusion-custom":{"description":"Niestandardowy model SD do generowania obraz\xf3w z tekstu. Nazwa pliku modelu powinna brzmieć custom_sd_lobe.safetensors, a jeśli używasz VAE – custom_sd_vae_lobe.safetensors. Pliki modelu muszą być umieszczone w odpowiednim folderze zgodnie z wymaganiami Comfy."},"comfyui/stable-diffusion-custom-refiner":{"description":"Niestandardowy model SDXL do konwersji obrazu na obraz. Nazwa pliku modelu powinna brzmieć custom_sd_lobe.safetensors, a jeśli używasz VAE – custom_sd_vae_lobe.safetensors. Pliki modelu muszą być umieszczone w odpowiednim folderze zgodnie z wymaganiami Comfy."},"comfyui/stable-diffusion-refiner":{"description":"Model SDXL do konwersji obrazu na obraz, umożliwia wysokiej jakości przekształcenia obrazu, wspiera transfer stylu, naprawę obrazu i kreatywne modyfikacje."},"comfyui/stable-diffusion-xl":{"description":"Model SDXL do generowania obraz\xf3w z tekstu, obsługuje wysoką rozdzielczość 1024x1024, oferuje lepszą jakość obrazu i szczeg\xf3łowość."},"command":{"description":"Model konwersacyjny, kt\xf3ry przestrzega instrukcji, oferujący wysoką jakość i niezawodność w zadaniach językowych, a także dłuższą długość kontekstu w por\xf3wnaniu do naszych podstawowych modeli generacyjnych."},"command-a-03-2025":{"description":"Command A to nasz najsilniejszy model, kt\xf3ry do tej pory osiągnął najlepsze wyniki, doskonale sprawdzający się w zastosowaniach narzędziowych, agentowych, generacji wzbogaconej o wyszukiwanie (RAG) oraz w kontekście wielojęzycznym. Command A ma długość kontekstu 256K, działa na zaledwie dw\xf3ch GPU i w por\xf3wnaniu do Command R+ 08-2024 zwiększa wydajność o 150%."},"command-light":{"description":"Mniejsza i szybsza wersja Command, niemal r\xf3wnie potężna, ale szybsza."},"command-light-nightly":{"description":"Aby skr\xf3cić czas między wydaniami gł\xf3wnych wersji, wprowadziliśmy nocną wersję modelu Command. Dla serii command-light ta wersja nazywa się command-light-nightly. Proszę pamiętać, że command-light-nightly to najnowsza, najbardziej eksperymentalna i (możliwie) niestabilna wersja. Wersje nocne są regularnie aktualizowane i nie są zapowiadane z wyprzedzeniem, dlatego nie zaleca się ich używania w środowisku produkcyjnym."},"command-nightly":{"description":"Aby skr\xf3cić czas między wydaniami gł\xf3wnych wersji, wprowadziliśmy nocną wersję modelu Command. Dla serii Command ta wersja nazywa się command-cightly. Proszę pamiętać, że command-nightly to najnowsza, najbardziej eksperymentalna i (możliwie) niestabilna wersja. Wersje nocne są regularnie aktualizowane i nie są zapowiadane z wyprzedzeniem, dlatego nie zaleca się ich używania w środowisku produkcyjnym."},"command-r":{"description":"Command R to LLM zoptymalizowany do dialog\xf3w i zadań z długim kontekstem, szczeg\xf3lnie odpowiedni do dynamicznej interakcji i zarządzania wiedzą."},"command-r-03-2024":{"description":"Command R to model konwersacyjny, kt\xf3ry przestrzega instrukcji, oferujący wyższą jakość i niezawodność w zadaniach językowych, a także dłuższą długość kontekstu w por\xf3wnaniu do wcześniejszych modeli. Może być używany w złożonych przepływach pracy, takich jak generacja kodu, generacja wzbogacona o wyszukiwanie (RAG), korzystanie z narzędzi i agent\xf3w."},"command-r-08-2024":{"description":"command-r-08-2024 to zaktualizowana wersja modelu Command R, wydana w sierpniu 2024 roku."},"command-r-plus":{"description":"Command R+ to model językowy o wysokiej wydajności, zaprojektowany z myślą o rzeczywistych scenariuszach biznesowych i złożonych zastosowaniach."},"command-r-plus-04-2024":{"description":"Command R+ to model konwersacyjny, kt\xf3ry przestrzega instrukcji, oferujący wyższą jakość i niezawodność w zadaniach językowych, a także dłuższą długość kontekstu w por\xf3wnaniu do wcześniejszych modeli. Jest najlepiej dostosowany do złożonych przepływ\xf3w pracy RAG i wieloetapowego korzystania z narzędzi."},"command-r-plus-08-2024":{"description":"Command R+ to model konwersacyjny przestrzegający instrukcji, oferujący wyższą jakość i niezawodność w zadaniach językowych, a także dłuższy kontekst w por\xf3wnaniu do wcześniejszych modeli. Najlepiej sprawdza się w złożonych przepływach pracy RAG i wieloetapowym korzystaniu z narzędzi."},"command-r7b-12-2024":{"description":"command-r7b-12-2024 to mała i wydajna zaktualizowana wersja, wydana w grudniu 2024 roku. Doskonale sprawdza się w zadaniach wymagających złożonego rozumowania i wieloetapowego przetwarzania, takich jak RAG, korzystanie z narzędzi i agenci."},"computer-use-preview":{"description":"Model computer-use-preview to dedykowany model zaprojektowany specjalnie do „narzędzi użycia komputera”, wytrenowany do rozumienia i wykonywania zadań związanych z komputerem."},"dall-e-2":{"description":"Druga generacja modelu DALL\xb7E, obsługująca bardziej realistyczne i dokładne generowanie obraz\xf3w, o rozdzielczości czterokrotnie większej niż pierwsza generacja."},"dall-e-3":{"description":"Najnowocześniejszy model DALL\xb7E, wydany w listopadzie 2023 roku. Obsługuje bardziej realistyczne i dokładne generowanie obraz\xf3w, z lepszą zdolnością do oddawania szczeg\xf3ł\xf3w."},"databricks/dbrx-instruct":{"description":"DBRX Instruct oferuje wysoką niezawodność w przetwarzaniu poleceń, wspierając r\xf3żne branże."},"deepseek-ai/DeepSeek-OCR":{"description":"DeepSeek-OCR to model językowo-wizualny opracowany przez DeepSeek AI, skoncentrowany na optycznym rozpoznawaniu znak\xf3w (OCR) i „kontekstowej kompresji optycznej”. Model ten bada granice kompresji informacji kontekstowej z obraz\xf3w, umożliwiając efektywne przetwarzanie dokument\xf3w i konwersję ich do ustrukturyzowanych format\xf3w tekstowych, takich jak Markdown. Potrafi precyzyjnie rozpoznawać tekst w obrazach, co czyni go idealnym do cyfryzacji dokument\xf3w, ekstrakcji tekstu i przetwarzania strukturalnego."},"deepseek-ai/DeepSeek-R1":{"description":"DeepSeek-R1 to model wnioskowania napędzany uczeniem przez wzmacnianie (RL), kt\xf3ry rozwiązuje problemy z powtarzalnością i czytelnością modelu. Przed RL, DeepSeek-R1 wprowadził dane z zimnego startu, co dodatkowo zoptymalizowało wydajność wnioskowania. W zadaniach matematycznych, kodowania i wnioskowania osiąga wyniki por\xf3wnywalne z OpenAI-o1, a dzięki starannie zaprojektowanym metodom treningowym poprawia og\xf3lne efekty."},"deepseek-ai/DeepSeek-R1-0528":{"description":"DeepSeek R1 znacząco zwiększa głębokość zdolności wnioskowania i dedukcji dzięki zwiększonym zasobom obliczeniowym oraz wprowadzeniu mechanizm\xf3w optymalizacji algorytm\xf3w w trakcie dalszego treningu. Model osiąga doskonałe wyniki w r\xf3żnych benchmarkach, w tym w matematyce, programowaniu i logice og\xf3lnej. Jego og\xf3lna wydajność jest obecnie zbliżona do czołowych modeli, takich jak O3 i Gemini 2.5 Pro."},"deepseek-ai/DeepSeek-R1-0528-Qwen3-8B":{"description":"DeepSeek-R1-0528-Qwen3-8B to model uzyskany przez destylację łańcuch\xf3w myślowych z modelu DeepSeek-R1-0528 do Qwen3 8B Base. Model osiąga najnowocześniejszą (SOTA) wydajność wśr\xf3d modeli open source, przewyższając Qwen3 8B o 10% w teście AIME 2024 i osiągając poziom wydajności Qwen3-235B-thinking. Wykazuje doskonałe wyniki w matematycznym wnioskowaniu, programowaniu i logice og\xf3lnej, posiadając architekturę identyczną z Qwen3-8B, ale korzystając z tokenizera DeepSeek-R1-0528."},"deepseek-ai/DeepSeek-R1-Distill-Llama-70B":{"description":"Model destylacyjny DeepSeek-R1, optymalizujący wydajność wnioskowania dzięki uczeniu przez wzmocnienie i danym z zimnego startu, otwarty model ustanawiający nowe standardy w wielu zadaniach."},"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B":{"description":"Model destylacyjny DeepSeek-R1, optymalizujący wydajność wnioskowania dzięki uczeniu przez wzmocnienie i danym z zimnego startu, otwarty model ustanawiający nowe standardy w wielu zadaniach."},"deepseek-ai/DeepSeek-R1-Distill-Qwen-14B":{"description":"Model destylacyjny DeepSeek-R1, optymalizujący wydajność wnioskowania dzięki uczeniu przez wzmocnienie i danym z zimnego startu, otwarty model ustanawiający nowe standardy w wielu zadaniach."},"deepseek-ai/DeepSeek-R1-Distill-Qwen-32B":{"description":"DeepSeek-R1-Distill-Qwen-32B to model uzyskany przez destylację Qwen2.5-32B. Model ten został dostosowany przy użyciu 800 000 starannie wybranych pr\xf3bek wygenerowanych przez DeepSeek-R1, wykazując doskonałe osiągi w wielu dziedzinach, takich jak matematyka, programowanie i wnioskowanie. Osiągnął znakomite wyniki w wielu testach referencyjnych, w tym 94,3% dokładności w MATH-500, co pokazuje jego silne zdolności wnioskowania matematycznego."},"deepseek-ai/DeepSeek-R1-Distill-Qwen-7B":{"description":"DeepSeek-R1-Distill-Qwen-7B to model uzyskany przez destylację Qwen2.5-Math-7B. Model ten został dostosowany przy użyciu 800 000 starannie wybranych pr\xf3bek wygenerowanych przez DeepSeek-R1, wykazując doskonałe zdolności wnioskowania. Osiągnął znakomite wyniki w wielu testach referencyjnych, w tym 92,8% dokładności w MATH-500, 55,5% wskaźnika zdawalności w AIME 2024 oraz 1189 punkt\xf3w w CodeForces, demonstrując silne zdolności matematyczne i programistyczne jako model o skali 7B."},"deepseek-ai/DeepSeek-V2.5":{"description":"DeepSeek V2.5 łączy doskonałe cechy wcześniejszych wersji, wzmacniając zdolności og\xf3lne i kodowania."},"deepseek-ai/DeepSeek-V3":{"description":"DeepSeek-V3 to model językowy z 6710 miliardami parametr\xf3w, oparty na mieszanych ekspertach (MoE), wykorzystujący wielogłowicową potencjalną uwagę (MLA) oraz architekturę DeepSeekMoE, łączącą strategię r\xf3wnoważenia obciążenia bez dodatkowych strat, co optymalizuje wydajność wnioskowania i treningu. Dzięki wstępnemu treningowi na 14,8 bilionach wysokiej jakości token\xf3w oraz nadzorowanemu dostrajaniu i uczeniu przez wzmacnianie, DeepSeek-V3 przewyższa inne modele open source, zbliżając się do wiodących modeli zamkniętych."},"deepseek-ai/DeepSeek-V3.1":{"description":"Model DeepSeek V3.1 to architektura hybrydowego wnioskowania, obsługująca zar\xf3wno tryb myślenia, jak i tryb bezmyślny."},"deepseek-ai/DeepSeek-V3.1-Terminus":{"description":"DeepSeek-V3.1-Terminus to zaktualizowana wersja modelu V3.1 wydanego przez DeepSeek, zaprojektowana jako hybrydowy model językowy z agentami. Aktualizacja skupia się na naprawie zgłoszonych przez użytkownik\xf3w problem\xf3w i poprawie stabilności, zachowując jednocześnie dotychczasowe możliwości modelu. Znacząco poprawiono sp\xf3jność językową, zmniejszając mieszanie języka chińskiego i angielskiego oraz eliminując nieprawidłowe znaki. Model integruje tryb myślenia (Thinking Mode) oraz tryb bez myślenia (Non-thinking Mode), kt\xf3re użytkownicy mogą elastycznie przełączać za pomocą szablon\xf3w czatu, dostosowując się do r\xf3żnych zadań. Ważną optymalizacją jest wzmocnienie wydajności agenta kodu (Code Agent) i agenta wyszukiwania (Search Agent), co czyni je bardziej niezawodnymi w wywoływaniu narzędzi i realizacji wieloetapowych, złożonych zadań."},"deepseek-ai/DeepSeek-V3.2-Exp":{"description":"DeepSeek-V3.2-Exp to eksperymentalna wersja V3.2 wydana przez DeepSeek, stanowiąca etap przejściowy w kierunku nowej generacji architektury. Na bazie V3.1-Terminus wprowadza mechanizm rzadkiej uwagi DeepSeek (DeepSeek Sparse Attention, DSA), kt\xf3ry zwiększa efektywność trenowania i wnioskowania w kontekście długich sekwencji. Model został specjalnie zoptymalizowany pod kątem wywoływania narzędzi, rozumienia długich dokument\xf3w i wieloetapowego wnioskowania. V3.2-Exp stanowi pomost między badaniami a wdrożeniem komercyjnym i jest odpowiedni dla użytkownik\xf3w poszukujących wyższej efektywności wnioskowania w scenariuszach z dużym budżetem kontekstowym."},"deepseek-ai/deepseek-llm-67b-chat":{"description":"DeepSeek 67B to zaawansowany model przeszkolony do złożonych dialog\xf3w."},"deepseek-ai/deepseek-r1":{"description":"Najnowocześniejszy, wydajny LLM, specjalizujący się w wnioskowaniu, matematyce i programowaniu."},"deepseek-ai/deepseek-v3.1":{"description":"DeepSeek V3.1: kolejna generacja modelu inferencyjnego, poprawiająca zdolności do złożonego wnioskowania i łańcuchowego myślenia, odpowiednia do zadań wymagających dogłębnej analizy."},"deepseek-ai/deepseek-v3.1-terminus":{"description":"DeepSeek V3.1: Nowej generacji model wnioskowania, kt\xf3ry poprawia zdolność do złożonego rozumowania i myślenia łańcuchowego, idealny do zadań wymagających dogłębnej analizy."},"deepseek-ai/deepseek-vl2":{"description":"DeepSeek-VL2 to model wizualno-językowy oparty na DeepSeekMoE-27B, wykorzystujący architekturę MoE z rzadką aktywacją, osiągający doskonałe wyniki przy aktywacji jedynie 4,5 miliarda parametr\xf3w. Model ten wyr\xf3żnia się w wielu zadaniach, takich jak wizualne pytania i odpowiedzi, optyczne rozpoznawanie znak\xf3w, zrozumienie dokument\xf3w/tabel/wykres\xf3w oraz lokalizacja wizualna."},"deepseek-chat":{"description":"Nowy otwarty model łączący zdolności og\xf3lne i kodowe, kt\xf3ry nie tylko zachowuje og\xf3lne zdolności dialogowe oryginalnego modelu czatu i potężne zdolności przetwarzania kodu modelu Coder, ale także lepiej dostosowuje się do ludzkich preferencji. Ponadto, DeepSeek-V2.5 osiągnął znaczne poprawy w zadaniach pisarskich, przestrzeganiu instrukcji i innych obszarach."},"deepseek-coder-33B-instruct":{"description":"DeepSeek Coder 33B to model języka kodu, wytrenowany na 20 bilionach danych, z czego 87% to kod, a 13% to języki chiński i angielski. Model wprowadza okno o rozmiarze 16K oraz zadania uzupełniania, oferując funkcje uzupełniania kodu na poziomie projektu i wypełniania fragment\xf3w."},"deepseek-coder-v2":{"description":"DeepSeek Coder V2 to otwarty model kodowy Mixture-of-Experts, kt\xf3ry doskonale radzi sobie z zadaniami kodowymi, por\xf3wnywalny z GPT4-Turbo."},"deepseek-coder-v2:236b":{"description":"DeepSeek Coder V2 to otwarty model kodowy Mixture-of-Experts, kt\xf3ry doskonale radzi sobie z zadaniami kodowymi, por\xf3wnywalny z GPT4-Turbo."},"deepseek-r1":{"description":"DeepSeek-R1 to model wnioskowania napędzany uczeniem przez wzmacnianie (RL), kt\xf3ry rozwiązuje problemy z powtarzalnością i czytelnością modelu. Przed RL, DeepSeek-R1 wprowadził dane z zimnego startu, co dodatkowo zoptymalizowało wydajność wnioskowania. W zadaniach matematycznych, kodowania i wnioskowania osiąga wyniki por\xf3wnywalne z OpenAI-o1, a dzięki starannie zaprojektowanym metodom treningowym poprawia og\xf3lne efekty."},"deepseek-r1-0528":{"description":"Model w pełnej wersji 685B, wydany 28 maja 2025 roku. DeepSeek-R1 wykorzystuje techniki uczenia ze wzmocnieniem na dużą skalę w fazie post-treningowej, co znacznie poprawia zdolności wnioskowania modelu przy minimalnej ilości oznaczonych danych. Wysoka wydajność i zdolności w zadaniach matematycznych, kodowaniu oraz rozumowaniu języka naturalnego."},"deepseek-r1-250528":{"description":"DeepSeek R1 250528, pełna wersja modelu wnioskowania DeepSeek-R1, odpowiednia do złożonych zadań matematycznych i logicznych."},"deepseek-r1-70b-fast-online":{"description":"DeepSeek R1 70B szybka wersja, wspierająca wyszukiwanie w czasie rzeczywistym, oferująca szybszy czas reakcji przy zachowaniu wydajności modelu."},"deepseek-r1-70b-online":{"description":"DeepSeek R1 70B standardowa wersja, wspierająca wyszukiwanie w czasie rzeczywistym, odpowiednia do zadań konwersacyjnych i przetwarzania tekstu wymagających najnowszych informacji."},"deepseek-r1-distill-llama":{"description":"deepseek-r1-distill-llama to model stworzony na podstawie Llamy, uzyskany przez destylację z DeepSeek-R1."},"deepseek-r1-distill-llama-70b":{"description":"DeepSeek R1 Distill Llama 70B, model destylowany łączący og\xf3lne możliwości R1 z ekosystemem Llama."},"deepseek-r1-distill-llama-8b":{"description":"DeepSeek-R1-Distill-Llama-8B to duży model językowy oparty na Llama-3.1-8B, wykorzystujący wyniki DeepSeek R1."},"deepseek-r1-distill-qianfan-70b":{"description":"DeepSeek R1 Distill Qianfan 70B, model destylowany R1 oparty na Qianfan-70B, oferujący wysoką wydajność w korzystnej cenie."},"deepseek-r1-distill-qianfan-8b":{"description":"DeepSeek R1 Distill Qianfan 8B, model destylowany R1 oparty na Qianfan-8B, odpowiedni do średnich i małych zastosowań."},"deepseek-r1-distill-qianfan-llama-70b":{"description":"DeepSeek R1 Distill Qianfan Llama 70B, model destylowany R1 oparty na Llama-70B."},"deepseek-r1-distill-qwen":{"description":"deepseek-r1-distill-qwen to model stworzony na podstawie Qwen poprzez destylację z DeepSeek-R1."},"deepseek-r1-distill-qwen-1.5b":{"description":"DeepSeek R1 Distill Qwen 1.5B, ultralekki model destylowany R1, odpowiedni do środowisk o bardzo ograniczonych zasobach."},"deepseek-r1-distill-qwen-14b":{"description":"DeepSeek R1 Distill Qwen 14B, średniej wielkości model destylowany R1, odpowiedni do wdrożeń w r\xf3żnych scenariuszach."},"deepseek-r1-distill-qwen-32b":{"description":"DeepSeek R1 Distill Qwen 32B, model destylowany R1 oparty na Qwen-32B, zapewniający r\xf3wnowagę między wydajnością a kosztem."},"deepseek-r1-distill-qwen-7b":{"description":"DeepSeek R1 Distill Qwen 7B, lekki model destylowany R1, odpowiedni do środowisk brzegowych i prywatnych wdrożeń korporacyjnych."},"deepseek-r1-fast-online":{"description":"DeepSeek R1 pełna szybka wersja, wspierająca wyszukiwanie w czasie rzeczywistym, łącząca potężne możliwości 671 miliard\xf3w parametr\xf3w z szybszym czasem reakcji."},"deepseek-r1-online":{"description":"DeepSeek R1 pełna wersja, z 671 miliardami parametr\xf3w, wspierająca wyszukiwanie w czasie rzeczywistym, z potężniejszymi zdolnościami rozumienia i generowania."},"deepseek-reasoner":{"description":"Tryb myślenia DeepSeek V3.2. Przed wygenerowaniem ostatecznej odpowiedzi model najpierw przedstawia łańcuch rozumowania, co zwiększa dokładność końcowej odpowiedzi."},"deepseek-v2":{"description":"DeepSeek V2 to wydajny model językowy Mixture-of-Experts, odpowiedni do ekonomicznych potrzeb przetwarzania."},"deepseek-v2:236b":{"description":"DeepSeek V2 236B to model kodowy zaprojektowany przez DeepSeek, oferujący potężne możliwości generowania kodu."},"deepseek-v3":{"description":"DeepSeek-V3 to model MoE opracowany przez Hangzhou DeepSeek AI Technology Research Co., Ltd., kt\xf3ry osiągnął znakomite wyniki w wielu testach, zajmując pierwsze miejsce wśr\xf3d modeli open-source na gł\xf3wnych listach. W por\xf3wnaniu do modelu V2.5, prędkość generowania wzrosła trzykrotnie, co zapewnia użytkownikom szybsze i płynniejsze doświadczenia."},"deepseek-v3-0324":{"description":"DeepSeek-V3-0324 to model MoE z 671 miliardami parametr\xf3w, kt\xf3ry wyr\xf3żnia się w zakresie programowania i umiejętności technicznych, rozumienia kontekstu oraz przetwarzania długich tekst\xf3w."},"deepseek-v3.1":{"description":"DeepSeek-V3.1 to nowy hybrydowy model wnioskowania opracowany przez DeepSeek, obsługujący dwa tryby wnioskowania: myślenia i bezmyślny, z wyższą efektywnością myślenia niż DeepSeek-R1-0528. Dzięki optymalizacji po treningu, wykorzystanie narzędzi agenta i wydajność zadań inteligentnych agent\xf3w zostały znacznie poprawione. Obsługuje okno kontekstowe do 128k oraz maksymalną długość wyjścia do 64k token\xf3w."},"deepseek-v3.1-terminus":{"description":"DeepSeek-V3.1-Terminus to zoptymalizowana wersja dużego modelu językowego opracowana przez DeepSeek, zaprojektowana specjalnie dla urządzeń końcowych."},"deepseek-v3.1-think-250821":{"description":"DeepSeek V3.1 Think 250821, model głębokiego rozumowania odpowiadający wersji Terminus, przeznaczony do scenariuszy wymagających wysokiej wydajności."},"deepseek-v3.1:671b":{"description":"DeepSeek V3.1: kolejna generacja modelu inferencyjnego, poprawiająca zdolności do złożonego wnioskowania i łańcuchowego myślenia, odpowiednia do zadań wymagających dogłębnej analizy."},"deepseek-v3.2-exp":{"description":"deepseek-v3.2-exp wprowadza mechanizm rzadkiej uwagi, mający na celu poprawę efektywności treningu i wnioskowania podczas przetwarzania długich tekst\xf3w, przy cenie niższej niż deepseek-v3.1."},"deepseek-v3.2-think":{"description":"DeepSeek V3.2 Think, pełna wersja modelu głębokiego rozumowania, wzmocniona pod kątem długich łańcuch\xf3w wnioskowania."},"deepseek-vl2":{"description":"DeepSeek VL2, model multimodalny wspierający zrozumienie obrazu i tekstu oraz precyzyjne pytania wizualne."},"deepseek-vl2-small":{"description":"DeepSeek VL2 Small, lekka wersja multimodalna, odpowiednia do środowisk o ograniczonych zasobach i wysokiej r\xf3wnoczesności."},"deepseek/deepseek-chat-v3-0324":{"description":"DeepSeek V3 to model mieszany z 685B parametrami, będący najnowszą iteracją flagowej serii modeli czatu zespołu DeepSeek.\\n\\nDziedziczy po modelu [DeepSeek V3](/deepseek/deepseek-chat-v3) i wykazuje doskonałe wyniki w r\xf3żnych zadaniach."},"deepseek/deepseek-chat-v3-0324:free":{"description":"DeepSeek V3 to model mieszany z 685B parametrami, będący najnowszą iteracją flagowej serii modeli czatu zespołu DeepSeek.\\n\\nDziedziczy po modelu [DeepSeek V3](/deepseek/deepseek-chat-v3) i wykazuje doskonałe wyniki w r\xf3żnych zadaniach."},"deepseek/deepseek-chat-v3.1":{"description":"DeepSeek-V3.1 to duży hybrydowy model wnioskowania obsługujący długi kontekst 128K i efektywne przełączanie tryb\xf3w, osiągający doskonałą wydajność i szybkość w wywoływaniu narzędzi, generowaniu kodu oraz złożonych zadaniach wnioskowania."},"deepseek/deepseek-r1":{"description":"Model DeepSeek R1 przeszedł drobną aktualizację do wersji DeepSeek-R1-0528. W najnowszej aktualizacji DeepSeek R1 znacznie poprawił głębokość i zdolności wnioskowania dzięki zwiększonym zasobom obliczeniowym i wprowadzeniu optymalizacji algorytmicznych po treningu. Model osiąga znakomite wyniki w benchmarkach matematycznych, programistycznych i og\xf3lnej logiki, zbliżając się do czołowych modeli, takich jak O3 i Gemini 2.5 Pro."},"deepseek/deepseek-r1-0528":{"description":"DeepSeek-R1 znacząco poprawia zdolność wnioskowania modelu nawet przy minimalnej ilości oznaczonych danych. Przed wygenerowaniem ostatecznej odpowiedzi model najpierw generuje łańcuch myślowy, co zwiększa dokładność końcowej odpowiedzi."},"deepseek/deepseek-r1-0528:free":{"description":"DeepSeek-R1 znacząco poprawia zdolność wnioskowania modelu nawet przy minimalnej ilości oznaczonych danych. Przed wygenerowaniem ostatecznej odpowiedzi model najpierw generuje łańcuch myślowy, co zwiększa dokładność końcowej odpowiedzi."},"deepseek/deepseek-r1-distill-llama-70b":{"description":"DeepSeek R1 Distill Llama 70B to duży model językowy oparty na Llama3.3 70B, kt\xf3ry dzięki dostrojeniu na podstawie wynik\xf3w DeepSeek R1 osiąga konkurencyjną wydajność por\xf3wnywalną z czołowymi modelami najnowszej generacji."},"deepseek/deepseek-r1-distill-llama-8b":{"description":"DeepSeek R1 Distill Llama 8B to destylowany duży model językowy oparty na Llama-3.1-8B-Instruct, wytrenowany przy użyciu wyjścia DeepSeek R1."},"deepseek/deepseek-r1-distill-qwen-14b":{"description":"DeepSeek R1 Distill Qwen 14B to destylowany duży model językowy oparty na Qwen 2.5 14B, wytrenowany przy użyciu wyjścia DeepSeek R1. Model ten przewyższył OpenAI o1-mini w wielu testach benchmarkowych, osiągając najnowsze osiągnięcia technologiczne w dziedzinie modeli gęstych (dense models). Oto niekt\xf3re wyniki test\xf3w benchmarkowych:\\nAIME 2024 pass@1: 69.7\\nMATH-500 pass@1: 93.9\\nCodeForces Rating: 1481\\nModel ten, dostrojony na podstawie wyjścia DeepSeek R1, wykazuje konkurencyjną wydajność por\xf3wnywalną z większymi modelami na czołowej pozycji."},"deepseek/deepseek-r1-distill-qwen-32b":{"description":"DeepSeek R1 Distill Qwen 32B to destylowany duży model językowy oparty na Qwen 2.5 32B, wytrenowany przy użyciu wyjścia DeepSeek R1. Model ten przewyższył OpenAI o1-mini w wielu testach benchmarkowych, osiągając najnowsze osiągnięcia technologiczne w dziedzinie modeli gęstych (dense models). Oto niekt\xf3re wyniki test\xf3w benchmarkowych:\\nAIME 2024 pass@1: 72.6\\nMATH-500 pass@1: 94.3\\nCodeForces Rating: 1691\\nModel ten, dostrojony na podstawie wyjścia DeepSeek R1, wykazuje konkurencyjną wydajność por\xf3wnywalną z większymi modelami na czołowej pozycji."},"deepseek/deepseek-r1/community":{"description":"DeepSeek R1 to najnowszy model open source wydany przez zesp\xf3ł DeepSeek, kt\xf3ry charakteryzuje się bardzo silnymi możliwościami wnioskowania, szczeg\xf3lnie w zadaniach matematycznych, programistycznych i logicznych, osiągając poziom por\xf3wnywalny z modelem o1 OpenAI."},"deepseek/deepseek-r1:free":{"description":"DeepSeek-R1 znacznie poprawił zdolności wnioskowania modelu przy minimalnej ilości oznaczonych danych. Przed wygenerowaniem ostatecznej odpowiedzi, model najpierw wygeneruje fragment myślenia, aby zwiększyć dokładność końcowej odpowiedzi."},"deepseek/deepseek-v3":{"description":"Szybki, uniwersalny duży model językowy z ulepszonymi zdolnościami wnioskowania."},"deepseek/deepseek-v3.1-base":{"description":"DeepSeek V3.1 Base to ulepszona wersja modelu DeepSeek V3."},"deepseek/deepseek-v3/community":{"description":"DeepSeek-V3 osiągnął znaczący przełom w szybkości wnioskowania w por\xf3wnaniu do wcześniejszych modeli. Zajmuje pierwsze miejsce wśr\xf3d modeli open source i może konkurować z najnowocześniejszymi modelami zamkniętymi na świecie. DeepSeek-V3 wykorzystuje architekturę wielogłowicowej uwagi (MLA) oraz DeepSeekMoE, kt\xf3re zostały w pełni zweryfikowane w DeepSeek-V2. Ponadto, DeepSeek-V3 wprowadza pomocniczą strategię bezstratną do r\xf3wnoważenia obciążenia oraz ustala cele treningowe dla wieloetykietowego przewidywania, aby uzyskać lepszą wydajność."},"deepseek_r1":{"description":"DeepSeek-R1 to model wnioskowania napędzany uczeniem przez wzmocnienie (RL), kt\xf3ry rozwiązuje problemy z powtarzalnością i czytelnością modelu. Przed RL, DeepSeek-R1 wprowadził dane z zimnego startu, co dodatkowo zoptymalizowało wydajność wnioskowania. W zadaniach matematycznych, kodowania i wnioskowania osiąga wyniki por\xf3wnywalne z OpenAI-o1, a dzięki starannie zaprojektowanym metodom szkoleniowym poprawia og\xf3lne efekty."},"deepseek_r1_distill_llama_70b":{"description":"DeepSeek-R1-Distill-Llama-70B to model uzyskany poprzez destylację treningową z Llama-3.3-70B-Instruct. Model ten jest częścią serii DeepSeek-R1, a dzięki użyciu pr\xf3bek wygenerowanych przez DeepSeek-R1, wykazuje doskonałe wyniki w matematyce, programowaniu i wnioskowaniu."},"deepseek_r1_distill_qwen_14b":{"description":"DeepSeek-R1-Distill-Qwen-14B to model uzyskany poprzez destylację wiedzy z Qwen2.5-14B. Model ten został dostrojony przy użyciu 800 000 starannie wybranych pr\xf3bek wygenerowanych przez DeepSeek-R1, wykazując doskonałe zdolności wnioskowania."},"deepseek_r1_distill_qwen_32b":{"description":"DeepSeek-R1-Distill-Qwen-32B to model uzyskany poprzez destylację wiedzy z Qwen2.5-32B. Model ten został dostrojony przy użyciu 800 000 starannie wybranych pr\xf3bek wygenerowanych przez DeepSeek-R1, wykazując doskonałe wyniki w wielu dziedzinach, w tym matematyce, programowaniu i wnioskowaniu."},"doubao-1.5-lite-32k":{"description":"Doubao-1.5-lite to nowa generacja modelu o lekkiej konstrukcji, charakteryzująca się ekstremalną szybkością reakcji, osiągając światowy poziom zar\xf3wno w zakresie wydajności, jak i op\xf3źnienia."},"doubao-1.5-pro-256k":{"description":"Doubao-1.5-pro-256k to kompleksowa wersja ulepszona na bazie Doubao-1.5-Pro, kt\xf3ra oferuje znaczny wzrost wydajności o 10%. Obsługuje wnioskowanie w kontekście 256k, a maksymalna długość wyjścia wynosi 12k token\xf3w. Wyższa wydajność, większe okno, doskonały stosunek jakości do ceny, odpowiedni do szerszego zakresu zastosowań."},"doubao-1.5-pro-32k":{"description":"Doubao-1.5-pro to nowa generacja gł\xf3wnego modelu, kt\xf3ry oferuje kompleksowe ulepszenia wydajności, wykazując doskonałe wyniki w zakresie wiedzy, kodowania, wnioskowania i innych obszar\xf3w."},"doubao-1.5-thinking-pro":{"description":"Model głębokiego myślenia Doubao-1.5, nowa generacja, wyr\xf3żnia się w dziedzinach takich jak matematyka, programowanie, rozumowanie naukowe oraz w zadaniach og\xf3lnych, takich jak tw\xf3rcze pisanie. Osiąga lub zbliża się do poziomu czołowych graczy w branży w wielu uznawanych benchmarkach, takich jak AIME 2024, Codeforces, GPQA. Obsługuje okno kontekstowe o wielkości 128k oraz 16k wyjścia."},"doubao-1.5-thinking-pro-m":{"description":"Doubao-1.5 to nowy model głębokiego myślenia (wersja m z natywną wielomodalną zdolnością głębokiego wnioskowania), wyr\xf3żniający się w dziedzinach takich jak matematyka, programowanie, rozumowanie naukowe oraz tw\xf3rcze pisanie. Osiąga lub zbliża się do czoł\xf3wki branży na wielu prestiżowych benchmarkach, takich jak AIME 2024, Codeforces, GPQA. Obsługuje kontekst do 128k i wyjście do 16k."},"doubao-1.5-thinking-vision-pro":{"description":"Nowy model głębokiego myślenia wizualnego, oferujący zaawansowane zdolności uniwersalnego wielomodalnego rozumienia i wnioskowania, osiągając SOTA w 37 z 59 publicznych benchmark\xf3w."},"doubao-1.5-ui-tars":{"description":"Doubao-1.5-UI-TARS to natywny model agenta zaprojektowany do interakcji z graficznym interfejsem użytkownika (GUI). Dzięki zdolnościom percepcji, wnioskowania i działania na poziomie ludzkim umożliwia płynną interakcję z GUI."},"doubao-1.5-vision-lite":{"description":"Doubao-1.5-vision-lite to nowo zaktualizowany model multimodalny, kt\xf3ry obsługuje rozpoznawanie obraz\xf3w o dowolnej rozdzielczości i ekstremalnych proporcjach, wzmacniając zdolności wnioskowania wizualnego, rozpoznawania dokument\xf3w, rozumienia szczeg\xf3łowych informacji i przestrzegania instrukcji. Obsługuje okno kontekstowe 128k, maksymalna długość wyjścia to 16k token\xf3w."},"doubao-1.5-vision-pro":{"description":"Doubao-1.5-vision-pro to nowo ulepszony wielomodalny model dużej skali, obsługujący rozpoznawanie obraz\xf3w o dowolnej rozdzielczości i ekstremalnych proporcjach, wzmacniający zdolności wizualnego wnioskowania, rozpoznawania dokument\xf3w, rozumienia szczeg\xf3ł\xf3w i przestrzegania instrukcji."},"doubao-1.5-vision-pro-32k":{"description":"Doubao-1.5-vision-pro to nowo ulepszony wielomodalny model dużej skali, obsługujący rozpoznawanie obraz\xf3w o dowolnej rozdzielczości i ekstremalnych proporcjach, wzmacniający zdolności wizualnego wnioskowania, rozpoznawania dokument\xf3w, rozumienia szczeg\xf3ł\xf3w i przestrzegania instrukcji."},"doubao-lite-128k":{"description":"Oferuje niezwykle szybkie reakcje i lepszy stosunek jakości do ceny, zapewniając klientom elastyczne opcje dla r\xf3żnych scenariuszy. Obsługuje wnioskowanie i dostrajanie z kontekstem do 128k."},"doubao-lite-32k":{"description":"Oferuje niezwykle szybkie reakcje i lepszy stosunek jakości do ceny, zapewniając klientom elastyczne opcje dla r\xf3żnych scenariuszy. Obsługuje wnioskowanie i dostrajanie z kontekstem do 32k."},"doubao-lite-4k":{"description":"Oferuje niezwykle szybkie reakcje i lepszy stosunek jakości do ceny, zapewniając klientom elastyczne opcje dla r\xf3żnych scenariuszy. Obsługuje wnioskowanie i dostrajanie z kontekstem do 4k."},"doubao-pro-256k":{"description":"Najlepszy model gł\xf3wny, odpowiedni do złożonych zadań, osiągający doskonałe wyniki w scenariuszach takich jak pytania i odpowiedzi, streszczenia, tw\xf3rczość, klasyfikacja tekstu i odgrywanie r\xf3l. Obsługuje wnioskowanie i dostrajanie z kontekstem do 256k."},"doubao-pro-32k":{"description":"Najlepszy model gł\xf3wny, odpowiedni do złożonych zadań, osiągający doskonałe wyniki w scenariuszach takich jak pytania i odpowiedzi, streszczenia, tw\xf3rczość, klasyfikacja tekstu i odgrywanie r\xf3l. Obsługuje wnioskowanie i dostrajanie z kontekstem do 32k."},"doubao-seed-1.6":{"description":"Doubao-Seed-1.6 to nowy, wielomodalny model głębokiego myślenia, obsługujący trzy tryby myślenia: auto, thinking i non-thinking. W trybie non-thinking model osiąga znacznie lepsze wyniki w por\xf3wnaniu do Doubao-1.5-pro/250115. Obsługuje kontekst do 256k oraz maksymalną długość wyjścia do 16k token\xf3w."},"doubao-seed-1.6-flash":{"description":"Doubao-Seed-1.6-flash to ultraszybki model wielomodalnego głębokiego myślenia, z czasem TPOT zaledwie 10 ms; obsługuje zar\xf3wno rozumienie tekstu, jak i obrazu, z lepszymi zdolnościami tekstowymi niż poprzednia generacja lite oraz wizualnymi por\xf3wnywalnymi do modeli pro konkurencji. Obsługuje kontekst do 256k oraz maksymalną długość wyjścia do 16k token\xf3w."},"doubao-seed-1.6-lite":{"description":"Doubao-Seed-1.6-lite to nowy, multimodalny model głębokiego rozumowania, umożliwiający regulację poziomu wnioskowania (reasoning effort) w czterech trybach: Minimal, Low, Medium i High. Oferuje doskonały stosunek jakości do ceny i jest idealnym wyborem do typowych zadań, z kontekstem do 256k."},"doubao-seed-1.6-thinking":{"description":"Model Doubao-Seed-1.6-thinking ma znacznie wzmocnione zdolności myślenia, w por\xf3wnaniu do Doubao-1.5-thinking-pro osiąga dalsze ulepszenia w podstawowych umiejętnościach takich jak kodowanie, matematyka i rozumowanie logiczne, wspiera r\xf3wnież rozumienie wizualne. Obsługuje kontekst do 256k oraz maksymalną długość wyjścia do 16k token\xf3w."},"doubao-seed-1.6-vision":{"description":"Doubao-Seed-1.6-vision to wizualny model głębokiego myślenia, kt\xf3ry wykazuje silniejsze zdolności og\xf3lnego rozumienia multimodalnego i wnioskowania w scenariuszach edukacyjnych, przeglądu obraz\xf3w, inspekcji i bezpieczeństwa oraz AI w wyszukiwaniu i odpowiadaniu na pytania. Obsługuje okno kontekstowe do 256k oraz maksymalną długość wyjścia do 64k token\xf3w."},"doubao-seededit-3-0-i2i-250628":{"description":"Model generowania obraz\xf3w Doubao opracowany przez zesp\xf3ł Seed ByteDance, obsługuje wejścia tekstowe i obrazowe, oferując wysoką kontrolę i jakość generowanych obraz\xf3w. Umożliwia edycję obraz\xf3w za pomocą poleceń tekstowych, generując obrazy o rozmiarach od 512 do 1536 pikseli."},"doubao-seedream-3-0-t2i-250415":{"description":"Model generowania obraz\xf3w Seedream 3.0 opracowany przez zesp\xf3ł Seed ByteDance, obsługuje wejścia tekstowe i obrazowe, oferując wysoką kontrolę i jakość generowanych obraz\xf3w. Generuje obrazy na podstawie tekstowych wskaz\xf3wek."},"doubao-seedream-4-0-250828":{"description":"Model generowania obraz\xf3w Seedream 4.0 opracowany przez zesp\xf3ł Seed ByteDance, obsługuje wejścia tekstowe i obrazowe, oferując wysoką kontrolę i jakość generowanych obraz\xf3w. Generuje obrazy na podstawie tekstowych wskaz\xf3wek."},"doubao-vision-lite-32k":{"description":"Model Doubao-vision to wielomodalny model dużej skali opracowany przez Doubao, oferujący potężne zdolności rozumienia i wnioskowania obraz\xf3w oraz precyzyjne rozumienie poleceń. Model wykazuje silne wyniki w ekstrakcji informacji z obraz\xf3w i tekstu oraz w zadaniach wnioskowania opartych na obrazach, umożliwiając zastosowanie w bardziej złożonych i szerokich zadaniach wizualnych pytań i odpowiedzi."},"doubao-vision-pro-32k":{"description":"Model Doubao-vision to wielomodalny model dużej skali opracowany przez Doubao, oferujący potężne zdolności rozumienia i wnioskowania obraz\xf3w oraz precyzyjne rozumienie poleceń. Model wykazuje silne wyniki w ekstrakcji informacji z obraz\xf3w i tekstu oraz w zadaniach wnioskowania opartych na obrazach, umożliwiając zastosowanie w bardziej złożonych i szerokich zadaniach wizualnych pytań i odpowiedzi."},"emohaa":{"description":"Emohaa to model psychologiczny, posiadający profesjonalne umiejętności doradcze, pomagający użytkownikom zrozumieć problemy emocjonalne."},"ernie-4.5-0.3b":{"description":"ERNIE 4.5 0.3B, otwartoźr\xf3dłowy lekki model, odpowiedni do lokalnych i dostosowanych wdrożeń."},"ernie-4.5-21b-a3b":{"description":"ERNIE 4.5 21B A3B, otwartoźr\xf3dłowy model o dużej liczbie parametr\xf3w, oferujący lepsze wyniki w zadaniach rozumienia i generowania."},"ernie-4.5-300b-a47b":{"description":"ERNIE 4.5 300B A47B to model ekspertowy o ultradużej skali opracowany przez Baidu Wenxin, wyr\xf3żniający się wyjątkowymi zdolnościami wnioskowania."},"ernie-4.5-8k-preview":{"description":"ERNIE 4.5 8K Preview, model podglądowy z kontekstem 8K, przeznaczony do testowania i oceny możliwości ERNIE 4.5."},"ernie-4.5-turbo-128k":{"description":"ERNIE 4.5 Turbo 128K, wydajny model og\xf3lnego przeznaczenia, wspierający wyszukiwanie i korzystanie z narzędzi, odpowiedni do pytań, kodu i agent\xf3w."},"ernie-4.5-turbo-128k-preview":{"description":"ERNIE 4.5 Turbo 128K Preview, wersja podglądowa oferująca te same możliwości co wersja produkcyjna, odpowiednia do test\xf3w i integracji."},"ernie-4.5-turbo-32k":{"description":"ERNIE 4.5 Turbo 32K, wersja z kontekstem średniej długości, odpowiednia do pytań, wyszukiwania w bazach wiedzy i wieloetapowych rozm\xf3w."},"ernie-4.5-turbo-latest":{"description":"ERNIE 4.5 Turbo Najnowsza wersja, zoptymalizowana pod kątem og\xf3lnej wydajności, idealna jako gł\xf3wny model produkcyjny."},"ernie-4.5-turbo-vl":{"description":"ERNIE 4.5 Turbo VL, dojrzały model multimodalny, odpowiedni do zadań rozumienia i rozpoznawania obrazu i tekstu w środowisku produkcyjnym."},"ernie-4.5-turbo-vl-32k":{"description":"ERNIE 4.5 Turbo VL 32K, multimodalna wersja dla średnich i długich tekst\xf3w, odpowiednia do zintegrowanego rozumienia dokument\xf3w i obraz\xf3w."},"ernie-4.5-turbo-vl-32k-preview":{"description":"ERNIE 4.5 Turbo VL 32K Preview, wersja podglądowa multimodalna 32K, ułatwiająca ocenę zdolności rozumienia długiego kontekstu wizualnego."},"ernie-4.5-turbo-vl-latest":{"description":"ERNIE 4.5 Turbo VL Najnowsza wersja, najnowszy model multimodalny, oferujący lepsze wyniki w rozumieniu i wnioskowaniu obraz\xf3w i tekstu."},"ernie-4.5-turbo-vl-preview":{"description":"ERNIE 4.5 Turbo VL Preview, podglądowy model multimodalny, wspierający rozumienie i generowanie obraz\xf3w i tekstu, odpowiedni do wizualnych pytań i analizy treści."},"ernie-4.5-vl-28b-a3b":{"description":"ERNIE 4.5 VL 28B A3B, otwartoźr\xf3dłowy model multimodalny, wspierający zadania rozumienia i wnioskowania obraz\xf3w i tekstu."},"ernie-5.0-thinking-preview":{"description":"ERNIE 5.0 Thinking Preview, flagowy model natywnie multimodalny, wspierający tekst, obraz, dźwięk i wideo, kompleksowo ulepszony do złożonych pytań, tw\xf3rczości i agent\xf3w."},"ernie-char-8k":{"description":"ERNIE Character 8K, model dialogowy z osobowością, odpowiedni do tworzenia postaci IP i długoterminowych interakcji."},"ernie-char-fiction-8k":{"description":"ERNIE Character Fiction 8K, model osobowościowy do tworzenia powieści i fabuły, odpowiedni do generowania długich historii."},"ernie-char-fiction-8k-preview":{"description":"ERNIE Character Fiction 8K Preview, wersja podglądowa modelu do tworzenia postaci i fabuły, przeznaczona do test\xf3w i oceny funkcji."},"ernie-irag-edit":{"description":"ERNIE iRAG Edit, model edycji obrazu wspierający usuwanie, rekonstrukcję i generowanie wariant\xf3w obraz\xf3w."},"ernie-lite-8k":{"description":"ERNIE Lite 8K, lekki model og\xf3lnego przeznaczenia, odpowiedni do codziennych pytań i generowania treści przy niskich kosztach."},"ernie-lite-pro-128k":{"description":"ERNIE Lite Pro 128K, lekki i wydajny model, odpowiedni do zastosowań wrażliwych na op\xf3źnienia i koszty."},"ernie-novel-8k":{"description":"ERNIE Novel 8K, model do tworzenia długich powieści i fabuły IP, specjalizujący się w narracji wielopostaciowej i wielowątkowej."},"ernie-speed-128k":{"description":"ERNIE Speed 128K, duży model bez koszt\xf3w wejścia/wyjścia, odpowiedni do rozumienia długich tekst\xf3w i test\xf3w na dużą skalę."},"ernie-speed-8k":{"description":"ERNIE Speed 8K, darmowy i szybki model, odpowiedni do codziennych rozm\xf3w i lekkich zadań tekstowych."},"ernie-speed-pro-128k":{"description":"ERNIE Speed Pro 128K, model o wysokiej r\xf3wnoczesności i korzystnym stosunku ceny do wydajności, odpowiedni do usług online i zastosowań korporacyjnych na dużą skalę."},"ernie-tiny-8k":{"description":"ERNIE Tiny 8K, ultralekki model, odpowiedni do prostych pytań, klasyfikacji i innych niskokosztowych zadań wnioskowania."},"ernie-x1-turbo-32k":{"description":"ERNIE X1 Turbo 32K, model szybkiego rozumowania z kontekstem 32K, odpowiedni do złożonego wnioskowania i wieloetapowych rozm\xf3w."},"ernie-x1.1-preview":{"description":"ERNIE X1.1 Preview, wersja podglądowa modelu rozumowania ERNIE X1.1, odpowiednia do test\xf3w i walidacji możliwości."},"fal-ai/bytedance/seedream/v4":{"description":"Model generowania obraz\xf3w Seedream 4.0 opracowany przez zesp\xf3ł Seed ByteDance, obsługuje wejścia tekstowe i obrazowe, oferując wysoką kontrolę i jakość generowanych obraz\xf3w. Generuje obrazy na podstawie tekstowych wskaz\xf3wek."},"fal-ai/flux-kontext/dev":{"description":"Model FLUX.1 skoncentrowany na zadaniach edycji obraz\xf3w, obsługuje wejścia tekstowe i obrazowe."},"fal-ai/flux-pro/kontext":{"description":"FLUX.1 Kontext [pro] potrafi przetwarzać tekst i obrazy referencyjne jako wejście, umożliwiając płynną, celową edycję lokalną oraz złożone transformacje całych scen."},"fal-ai/flux/krea":{"description":"Flux Krea [dev] to model generowania obraz\xf3w z estetycznymi preferencjami, mający na celu tworzenie bardziej realistycznych i naturalnych obraz\xf3w."},"fal-ai/flux/schnell":{"description":"FLUX.1 [schnell] to model generowania obraz\xf3w z 12 miliardami parametr\xf3w, skoncentrowany na szybkim tworzeniu wysokiej jakości obraz\xf3w."},"fal-ai/hunyuan-image/v3":{"description":"Potężny natywny model generowania obraz\xf3w multimodalnych"},"fal-ai/imagen4/preview":{"description":"Wysokiej jakości model generowania obraz\xf3w udostępniony przez Google."},"fal-ai/nano-banana":{"description":"Nano Banana to najnowszy, najszybszy i najbardziej efektywny natywny model multimodalny Google, pozwalający na generowanie i edycję obraz\xf3w poprzez dialog."},"fal-ai/qwen-image":{"description":"Potężny model generowania obraz\xf3w zespołu Qwen, z imponującą zdolnością generowania chińskiego tekstu i r\xf3żnorodnymi stylami wizualnymi obraz\xf3w."},"fal-ai/qwen-image-edit":{"description":"Profesjonalny model edycji obraz\xf3w zespołu Qwen, wspierający edycję semantyczną i wyglądu, umożliwiający precyzyjną edycję tekstu w języku chińskim i angielskim, a także transformacje styl\xf3w, obr\xf3t obiekt\xf3w i inne wysokiej jakości edycje obraz\xf3w."},"flux-1-schnell":{"description":"Model generowania obraz\xf3w na podstawie tekstu o 12 miliardach parametr\xf3w opracowany przez Black Forest Labs, wykorzystujący technikę destylacji latentnej dyfuzji przeciwstawnej, zdolny do generowania wysokiej jakości obraz\xf3w w 1 do 4 krok\xf3w. Model osiąga wydajność por\xf3wnywalną z zamkniętymi alternatywami i jest udostępniony na licencji Apache-2.0, odpowiedni do użytku osobistego, badawczego i komercyjnego."},"flux-dev":{"description":"FLUX.1 [dev] to otwarty, dopracowany model o otwartych wagach przeznaczony do zastosowań niekomercyjnych. Zachowuje jakość obrazu i zdolność do przestrzegania instrukcji zbliżoną do wersji profesjonalnej FLUX, oferując jednocześnie wyższą efektywność działania. W por\xf3wnaniu do standardowych modeli o podobnej wielkości jest bardziej efektywny w wykorzystaniu zasob\xf3w."},"flux-kontext-max":{"description":"Najnowocześniejsze generowanie i edycja obraz\xf3w kontekstowych — łączenie tekstu i obraz\xf3w, aby uzyskać precyzyjne i sp\xf3jne rezultaty."},"flux-kontext-pro":{"description":"Najnowocześniejsze generowanie i edycja obraz\xf3w w kontekście — łączenie tekstu i obraz\xf3w w celu uzyskania precyzyjnych i sp\xf3jnych rezultat\xf3w."},"flux-merged":{"description":"Model FLUX.1-merged łączy głębokie cechy eksplorowane podczas fazy rozwojowej „DEV” z zaletami szybkiego wykonania reprezentowanymi przez „Schnell”. Dzięki temu FLUX.1-merged nie tylko przesuwa granice wydajności modelu, ale także rozszerza zakres jego zastosowań."},"flux-pro":{"description":"Wiodący komercyjny model AI do generowania obraz\xf3w — niezr\xf3wnana jakość obraz\xf3w i r\xf3żnorodność generowanych rezultat\xf3w."},"flux-pro-1.1":{"description":"Ulepszona, profesjonalna wersja modelu AI do generowania obraz\xf3w — zapewnia doskonałą jakość obraz\xf3w i precyzyjne realizowanie poleceń."},"flux-pro-1.1-ultra":{"description":"Generowanie obraz\xf3w AI o ultrawysokiej rozdzielczości — obsługa wyjścia 4 megapikseli, tworzy niezwykle wyraźne obrazy w ciągu 10 sekund."},"flux-schnell":{"description":"FLUX.1 [schnell] to obecnie najbardziej zaawansowany otwarty model o małej liczbie krok\xf3w, przewyższający konkurencję, a nawet potężne modele nie destylowane, takie jak Midjourney v6.0 i DALL\xb7E 3 (HD). Model został specjalnie dostrojony, aby zachować pełną r\xf3żnorodność wyjść z fazy wstępnego treningu. W por\xf3wnaniu z najlepszymi modelami na rynku FLUX.1 [schnell] znacząco poprawia jakość wizualną, zgodność z instrukcjami, obsługę zmian rozmiaru/proporcji, przetwarzanie czcionek oraz r\xf3żnorodność generowanych obraz\xf3w, oferując użytkownikom bogatsze i bardziej zr\xf3żnicowane doświadczenia tw\xf3rcze."},"flux.1-schnell":{"description":"FLUX.1-schnell, wydajny model generowania obraz\xf3w, odpowiedni do szybkiego tworzenia obraz\xf3w w r\xf3żnych stylach."},"gemini-1.0-pro-001":{"description":"Gemini 1.0 Pro 001 (Tuning) oferuje stabilną i dostosowywalną wydajność, co czyni go idealnym wyborem dla rozwiązań złożonych zadań."},"gemini-1.0-pro-002":{"description":"Gemini 1.0 Pro 002 (Tuning) oferuje doskonałe wsparcie multimodalne, koncentrując się na efektywnym rozwiązywaniu złożonych zadań."},"gemini-1.0-pro-latest":{"description":"Gemini 1.0 Pro to model AI o wysokiej wydajności od Google, zaprojektowany do szerokiego rozszerzania zadań."},"gemini-1.5-flash-001":{"description":"Gemini 1.5 Flash 001 to wydajny model multimodalny, wspierający szerokie zastosowania."},"gemini-1.5-flash-002":{"description":"Gemini 1.5 Flash 002 to wydajny model multimodalny, kt\xf3ry wspiera szeroką gamę zastosowań."},"gemini-1.5-flash-8b":{"description":"Gemini 1.5 Flash 8B to wydajny model multimodalny, kt\xf3ry wspiera szeroki zakres zastosowań."},"gemini-1.5-flash-8b-exp-0924":{"description":"Gemini 1.5 Flash 8B 0924 to najnowszy eksperymentalny model, kt\xf3ry wykazuje znaczące poprawy wydajności w zastosowaniach tekstowych i multimodalnych."},"gemini-1.5-flash-8b-latest":{"description":"Gemini 1.5 Flash 8B to wydajny model wielomodalny, kt\xf3ry obsługuje szeroki zakres zastosowań."},"gemini-1.5-flash-exp-0827":{"description":"Gemini 1.5 Flash 0827 oferuje zoptymalizowane możliwości przetwarzania multimodalnego, odpowiednie dla wielu złożonych scenariuszy."},"gemini-1.5-flash-latest":{"description":"Gemini 1.5 Flash to najnowszy model AI Google o wielu modalnościach, kt\xf3ry charakteryzuje się szybkim przetwarzaniem i obsługuje wejścia tekstowe, obrazowe i wideo, co czyni go odpowiednim do efektywnego rozszerzania w r\xf3żnych zadaniach."},"gemini-1.5-pro-001":{"description":"Gemini 1.5 Pro 001 to skalowalne rozwiązanie AI multimodalnego, wspierające szeroki zakres złożonych zadań."},"gemini-1.5-pro-002":{"description":"Gemini 1.5 Pro 002 to najnowszy model gotowy do produkcji, oferujący wyższą jakość wynik\xf3w, ze szczeg\xf3lnym uwzględnieniem zadań matematycznych, długich kontekst\xf3w i zadań wizualnych."},"gemini-1.5-pro-exp-0801":{"description":"Gemini 1.5 Pro 0801 oferuje doskonałe możliwości przetwarzania multimodalnego, zapewniając większą elastyczność w rozwoju aplikacji."},"gemini-1.5-pro-exp-0827":{"description":"Gemini 1.5 Pro 0827 łączy najnowsze technologie optymalizacji, oferując bardziej efektywne możliwości przetwarzania danych multimodalnych."},"gemini-1.5-pro-latest":{"description":"Gemini 1.5 Pro obsługuje do 2 milion\xf3w token\xf3w, co czyni go idealnym wyborem dla średniej wielkości modeli multimodalnych, odpowiednim do wszechstronnej obsługi złożonych zadań."},"gemini-2.0-flash":{"description":"Gemini 2.0 Flash oferuje funkcje i ulepszenia nowej generacji, w tym doskonałą prędkość, natywne korzystanie z narzędzi, generowanie multimodalne oraz okno kontekstowe o długości 1M token\xf3w."},"gemini-2.0-flash-001":{"description":"Gemini 2.0 Flash oferuje funkcje i ulepszenia nowej generacji, w tym doskonałą prędkość, natywne korzystanie z narzędzi, generowanie multimodalne oraz okno kontekstowe o długości 1M token\xf3w."},"gemini-2.0-flash-exp":{"description":"Gemini 2.0 Flash to wariant modelu, zoptymalizowany pod kątem efektywności kosztowej i niskiego op\xf3źnienia."},"gemini-2.0-flash-exp-image-generation":{"description":"Model eksperymentalny Gemini 2.0 Flash, wspierający generowanie obraz\xf3w"},"gemini-2.0-flash-lite":{"description":"Gemini 2.0 Flash to wariant modelu, zoptymalizowany pod kątem efektywności kosztowej i niskiego op\xf3źnienia."},"gemini-2.0-flash-lite-001":{"description":"Gemini 2.0 Flash to wariant modelu, zoptymalizowany pod kątem efektywności kosztowej i niskiego op\xf3źnienia."},"gemini-2.5-flash":{"description":"Gemini 2.5 Flash to najbardziej opłacalny model Google, oferujący wszechstronne funkcje."},"gemini-2.5-flash-image":{"description":"Nano Banana to najnowszy, najszybszy i najbardziej efektywny natywny model multimodalny Google, kt\xf3ry umożliwia generowanie i edycję obraz\xf3w za pomocą rozmowy."},"gemini-2.5-flash-image-preview":{"description":"Nano Banana to najnowszy, najszybszy i najbardziej wydajny natywny model multimodalny Google, kt\xf3ry pozwala generować i edytować obrazy za pomocą rozmowy."},"gemini-2.5-flash-image-preview:image":{"description":"Nano Banana to najnowszy, najszybszy i najbardziej wydajny natywny model multimodalny Google, kt\xf3ry pozwala generować i edytować obrazy za pomocą rozmowy."},"gemini-2.5-flash-image:image":{"description":"Nano Banana to najnowszy, najszybszy i najbardziej efektywny natywny model multimodalny Google, kt\xf3ry umożliwia generowanie i edycję obraz\xf3w za pomocą rozmowy."},"gemini-2.5-flash-lite":{"description":"Gemini 2.5 Flash-Lite to najmniejszy i najbardziej opłacalny model Google, zaprojektowany z myślą o szerokim zastosowaniu."},"gemini-2.5-flash-lite-preview-06-17":{"description":"Gemini 2.5 Flash-Lite Preview to najmniejszy i najbardziej opłacalny model Google, zaprojektowany z myślą o masowym zastosowaniu."},"gemini-2.5-flash-lite-preview-09-2025":{"description":"Wersja podglądowa (25 września 2025) Gemini 2.5 Flash-Lite"},"gemini-2.5-flash-preview-04-17":{"description":"Gemini 2.5 Flash Preview to najbardziej opłacalny model Google, oferujący wszechstronne funkcje."},"gemini-2.5-flash-preview-09-2025":{"description":"Wersja podglądowa (25 września 2025) Gemini 2.5 Flash"},"gemini-2.5-pro":{"description":"Gemini 2.5 Pro to najnowocześniejszy model myślowy Google, zdolny do rozumowania nad złożonymi problemami w dziedzinach kodowania, matematyki i STEM oraz analizowania dużych zbior\xf3w danych, repozytori\xf3w kodu i dokumentacji przy użyciu długiego kontekstu."},"gemini-2.5-pro-preview-03-25":{"description":"Gemini 2.5 Pro Preview to najnowocześniejszy model myślenia Google, zdolny do wnioskowania w zakresie kodu, matematyki i złożonych problem\xf3w w dziedzinie STEM, a także do analizy dużych zbior\xf3w danych, repozytori\xf3w kodu i dokument\xf3w przy użyciu długiego kontekstu."},"gemini-2.5-pro-preview-05-06":{"description":"Gemini 2.5 Pro Preview to najnowocześniejszy model myślenia Google, zdolny do wnioskowania w złożonych problemach związanych z kodem, matematyką i dziedzinami STEM, a także do analizy dużych zbior\xf3w danych, repozytori\xf3w kodu i dokument\xf3w przy użyciu długiego kontekstu."},"gemini-2.5-pro-preview-06-05":{"description":"Gemini 2.5 Pro Preview to najnowocześniejszy model myślowy Google, zdolny do rozumowania nad złożonymi problemami w dziedzinach kodowania, matematyki i STEM oraz do analizy dużych zbior\xf3w danych, repozytori\xf3w kodu i dokument\xf3w z wykorzystaniem długich kontekst\xf3w."},"gemini-3-pro-preview":{"description":"Gemini 3 Pro to najinteligentniejszy model Google, oferujący najnowocześniejsze wnioskowanie i rozumienie multimodalne, a także zaawansowane funkcje agenta i kodowania kontekstu."},"gemini-flash-latest":{"description":"Najnowsze wydanie Gemini Flash"},"gemini-flash-lite-latest":{"description":"Najnowsze wydanie Gemini Flash-Lite"},"gemini-pro-latest":{"description":"Najnowsze wydanie Gemini Pro"},"gemma-7b-it":{"description":"Gemma 7B nadaje się do przetwarzania zadań średniej i małej skali, łącząc efektywność kosztową."},"gemma2":{"description":"Gemma 2 to wydajny model wydany przez Google, obejmujący r\xf3żnorodne zastosowania, od małych aplikacji po złożone przetwarzanie danych."},"gemma2-9b-it":{"description":"Gemma 2 9B to model zoptymalizowany do specyficznych zadań i integracji narzędzi."},"gemma2:27b":{"description":"Gemma 2 to wydajny model wydany przez Google, obejmujący r\xf3żnorodne zastosowania, od małych aplikacji po złożone przetwarzanie danych."},"gemma2:2b":{"description":"Gemma 2 to wydajny model wydany przez Google, obejmujący r\xf3żnorodne zastosowania, od małych aplikacji po złożone przetwarzanie danych."},"generalv3":{"description":"Spark Pro to model dużego języka o wysokiej wydajności, zoptymalizowany do profesjonalnych dziedzin, takich jak matematyka, programowanie, medycyna i edukacja, wspierający wyszukiwanie w sieci oraz wbudowane wtyczki, takie jak pogoda i daty. Jego zoptymalizowany model wykazuje doskonałe wyniki i wysoką wydajność w skomplikowanych pytaniach o wiedzę, rozumieniu języka oraz tworzeniu zaawansowanych tekst\xf3w, co czyni go idealnym wyborem do profesjonalnych zastosowań."},"generalv3.5":{"description":"Spark3.5 Max to najbardziej wszechstronna wersja, wspierająca wyszukiwanie w sieci oraz wiele wbudowanych wtyczek. Jego kompleksowo zoptymalizowane zdolności rdzeniowe oraz funkcje ustawiania r\xf3l systemowych i wywoływania funkcji sprawiają, że wykazuje się wyjątkową wydajnością w r\xf3żnych skomplikowanych zastosowaniach."},"glm-4":{"description":"GLM-4 to stary flagowy model wydany w styczniu 2024 roku, obecnie zastąpiony przez silniejszy model GLM-4-0520."},"glm-4-0520":{"description":"GLM-4-0520 to najnowsza wersja modelu, zaprojektowana do wysoko złożonych i zr\xf3żnicowanych zadań, z doskonałymi wynikami."},"glm-4-32b-0414":{"description":"GLM-4 32B 0414, og\xf3lny model dużej skali z serii GLM, wspierający generowanie i rozumienie tekstu w wielu zadaniach."},"glm-4-9b-chat":{"description":"GLM-4-9B-Chat osiąga wysoką wydajność w zakresie semantyki, matematyki, wnioskowania, kodowania i wiedzy. Obsługuje r\xf3wnież przeglądanie stron internetowych, wykonywanie kodu, wywoływanie niestandardowych narzędzi oraz wnioskowanie na podstawie długich tekst\xf3w. Wspiera 26 język\xf3w, w tym japoński, koreański i niemiecki."},"glm-4-air":{"description":"GLM-4-Air to opłacalna wersja, kt\xf3rej wydajność jest zbliżona do GLM-4, oferująca szybkie działanie i przystępną cenę."},"glm-4-air-250414":{"description":"GLM-4-Air to wersja o wysokim stosunku jakości do ceny, o wydajności zbliżonej do GLM-4, oferująca szybkie tempo i przystępną cenę."},"glm-4-airx":{"description":"GLM-4-AirX oferuje wydajną wersję GLM-4-Air, z szybkością wnioskowania do 2,6 razy szybszą."},"glm-4-alltools":{"description":"GLM-4-AllTools to model inteligentny o wielu funkcjach, zoptymalizowany do wsparcia złożonego planowania instrukcji i wywołań narzędzi, takich jak przeglądanie sieci, interpretacja kodu i generowanie tekstu, odpowiedni do wykonywania wielu zadań."},"glm-4-flash":{"description":"GLM-4-Flash to idealny wyb\xf3r do przetwarzania prostych zadań, najszybszy i najtańszy."},"glm-4-flash-250414":{"description":"GLM-4-Flash to idealny wyb\xf3r do prostych zadań, najszybszy i darmowy."},"glm-4-flashx":{"description":"GLM-4-FlashX to ulepszona wersja Flash, charakteryzująca się niezwykle szybkim czasem wnioskowania."},"glm-4-long":{"description":"GLM-4-Long obsługuje ultra-długie wejścia tekstowe, odpowiednie do zadań pamięciowych i przetwarzania dużych dokument\xf3w."},"glm-4-plus":{"description":"GLM-4-Plus jako flagowy model o wysokiej inteligencji, posiada potężne zdolności przetwarzania długich tekst\xf3w i złożonych zadań, z og\xf3lnym wzrostem wydajności."},"glm-4.1v-thinking-flash":{"description":"Seria modeli GLM-4.1V-Thinking to najsilniejsze znane modele wizualno-językowe (VLM) na poziomie 10 miliard\xf3w parametr\xf3w, integrujące najnowocześniejsze zadania wizualno-językowe na tym poziomie, w tym rozumienie wideo, pytania i odpowiedzi na obrazach, rozwiązywanie problem\xf3w naukowych, rozpoznawanie tekstu OCR, interpretację dokument\xf3w i wykres\xf3w, agenta GUI, kodowanie front-endowe stron internetowych, grounding i inne. Wiele z tych zadań przewyższa możliwości modelu Qwen2.5-VL-72B, kt\xf3ry ma ponad 8 razy więcej parametr\xf3w. Dzięki zaawansowanym technikom uczenia ze wzmocnieniem model opanował rozumowanie łańcuchowe, co znacząco poprawia dokładność i bogactwo odpowiedzi, przewyższając tradycyjne modele bez mechanizmu thinking pod względem końcowych rezultat\xf3w i interpretowalności."},"glm-4.1v-thinking-flashx":{"description":"Seria modeli GLM-4.1V-Thinking to najsilniejsze znane modele wizualno-językowe (VLM) na poziomie 10 miliard\xf3w parametr\xf3w, integrujące najnowocześniejsze zadania wizualno-językowe na tym poziomie, w tym rozumienie wideo, pytania i odpowiedzi na obrazach, rozwiązywanie problem\xf3w naukowych, rozpoznawanie tekstu OCR, interpretację dokument\xf3w i wykres\xf3w, agenta GUI, kodowanie front-endowe stron internetowych, grounding i inne. Wiele z tych zadań przewyższa możliwości modelu Qwen2.5-VL-72B, kt\xf3ry ma ponad 8 razy więcej parametr\xf3w. Dzięki zaawansowanym technikom uczenia ze wzmocnieniem model opanował rozumowanie łańcuchowe, co znacząco poprawia dokładność i bogactwo odpowiedzi, przewyższając tradycyjne modele bez mechanizmu thinking pod względem końcowych rezultat\xf3w i interpretowalności."},"glm-4.5":{"description":"Flagowy model Zhipu, wspierający tryb myślenia, osiągający poziom SOTA wśr\xf3d modeli open source pod względem zdolności og\xf3lnych, z długością kontekstu do 128K."},"glm-4.5-air":{"description":"Lżejsza wersja GLM-4.5, łącząca wydajność i opłacalność, z możliwością elastycznego przełączania hybrydowego trybu myślenia."},"glm-4.5-airx":{"description":"Ekspresowa wersja GLM-4.5-Air, oferująca szybszy czas reakcji, zaprojektowana do zastosowań wymagających dużej skali i wysokiej prędkości."},"glm-4.5-flash":{"description":"Bezpłatna wersja GLM-4.5, wyr\xf3żniająca się doskonałą wydajnością w zadaniach inferencyjnych, kodowania i agent\xf3w."},"glm-4.5-x":{"description":"Ekspresowa wersja GLM-4.5, łącząca wysoką wydajność z prędkością generowania do 100 token\xf3w na sekundę."},"glm-4.5v":{"description":"Nowa generacja modelu do wnioskowania wizualnego firmy Zhipu oparta na architekturze MOE. Przy łącznej liczbie parametr\xf3w 106B i 12B parametr\xf3w aktywacji osiąga wyniki SOTA wśr\xf3d otwartoźr\xf3dłowych modeli multimodalnych o por\xf3wnywalnej skali na r\xf3żnych benchmarkach, obejmując typowe zadania związane z analizą obraz\xf3w, wideo, rozumieniem dokument\xf3w oraz zadaniami GUI."},"glm-4.6":{"description":"Najnowszy flagowy model Zhipu GLM-4.6 (355B) przewyższa poprzednie generacje pod względem zaawansowanego kodowania, przetwarzania długich tekst\xf3w, wnioskowania i zdolności agent\xf3w, szczeg\xf3lnie wyr\xf3wnując się z Claude Sonnet 4 w zakresie programowania, stając się czołowym modelem kodowania w kraju."},"glm-4v":{"description":"GLM-4V oferuje potężne zdolności rozumienia i wnioskowania obraz\xf3w, obsługując r\xf3żne zadania wizualne."},"glm-4v-flash":{"description":"GLM-4V-Flash koncentruje się na efektywnym zrozumieniu pojedynczego obrazu, idealny do scenariuszy szybkiej analizy obrazu, takich jak analiza obraz\xf3w w czasie rzeczywistym lub przetwarzanie partii obraz\xf3w."},"glm-4v-plus":{"description":"GLM-4V-Plus ma zdolność rozumienia treści wideo oraz wielu obraz\xf3w, odpowiedni do zadań multimodalnych."},"glm-4v-plus-0111":{"description":"GLM-4V-Plus posiada zdolność rozumienia treści wideo oraz wielu obraz\xf3w, odpowiedni do zadań multimodalnych."},"glm-z1-air":{"description":"Model wnioskowania: posiadający silne zdolności wnioskowania, odpowiedni do zadań wymagających głębokiego wnioskowania."},"glm-z1-airx":{"description":"Ekstremalne wnioskowanie: charakteryzujące się ultra szybkim tempem wnioskowania i silnymi efektami wnioskowania."},"glm-z1-flash":{"description":"Seria GLM-Z1 charakteryzuje się silnymi zdolnościami do złożonego wnioskowania, osiągając doskonałe wyniki w logice, matematyce i programowaniu."},"glm-z1-flashx":{"description":"Wysoka prędkość i niska cena: wersja wzbogacona Flash, ultra szybkie tempo inferencji i lepsza obsługa wsp\xf3łbieżności."},"glm-zero-preview":{"description":"GLM-Zero-Preview posiada silne zdolności do złożonego wnioskowania, wyr\xf3żniając się w dziedzinach takich jak wnioskowanie logiczne, matematyka i programowanie."},"google/gemini-2.0-flash":{"description":"Gemini 2.0 Flash oferuje funkcje nowej generacji i ulepszenia, w tym doskonałą szybkość, wbudowane użycie narzędzi, generowanie multimodalne oraz okno kontekstu o rozmiarze 1 miliona token\xf3w."},"google/gemini-2.0-flash-001":{"description":"Gemini 2.0 Flash oferuje funkcje i ulepszenia nowej generacji, w tym doskonałą prędkość, natywne korzystanie z narzędzi, generowanie multimodalne oraz okno kontekstowe o długości 1M token\xf3w."},"google/gemini-2.0-flash-exp:free":{"description":"Gemini 2.0 Flash Experimental to najnowszy eksperymentalny model AI Google, kt\xf3ry w por\xf3wnaniu do wcześniejszych wersji wykazuje pewne poprawy jakości, szczeg\xf3lnie w zakresie wiedzy o świecie, kodu i długiego kontekstu."},"google/gemini-2.0-flash-lite":{"description":"Gemini 2.0 Flash Lite oferuje funkcje nowej generacji i ulepszenia, w tym doskonałą szybkość, wbudowane użycie narzędzi, generowanie multimodalne oraz okno kontekstu o rozmiarze 1 miliona token\xf3w."},"google/gemini-2.5-flash":{"description":"Gemini 2.5 Flash to model myślący, oferujący doskonałe, wszechstronne możliwości. Zaprojektowany, by znaleźć r\xf3wnowagę między ceną a wydajnością, obsługuje multimodalność i okno kontekstu o rozmiarze 1 miliona token\xf3w."},"google/gemini-2.5-flash-image-preview":{"description":"Eksperymentalny model Gemini 2.5 Flash, wspierający generowanie obraz\xf3w."},"google/gemini-2.5-flash-lite":{"description":"Gemini 2.5 Flash-Lite to zr\xf3wnoważony, niskoop\xf3źnieniowy model z konfigurowalnym budżetem myślenia i łącznością narzędzi (np. Google Search grounding i wykonywanie kodu). Obsługuje multimodalne wejścia i oferuje okno kontekstu o rozmiarze 1 miliona token\xf3w."},"google/gemini-2.5-flash-preview":{"description":"Gemini 2.5 Flash to najnowocześniejszy model gł\xf3wny Google, zaprojektowany z myślą o zaawansowanym wnioskowaniu, kodowaniu, matematyce i zadaniach naukowych. Zawiera wbudowaną zdolność \'myślenia\', co pozwala mu na dostarczanie odpowiedzi z wyższą dokładnością i szczeg\xf3łowym przetwarzaniem kontekstu.\\n\\nUwaga: ten model ma dwa warianty: myślenie i niemyslenie. Ceny wyjściowe r\xf3żnią się znacznie w zależności od tego, czy zdolność myślenia jest aktywowana. Jeśli wybierzesz standardowy wariant (bez sufiksu \':thinking\'), model wyraźnie unika generowania token\xf3w myślenia.\\n\\nAby skorzystać z zdolności myślenia i otrzymać tokeny myślenia, musisz wybrać wariant \':thinking\', co spowoduje wyższe ceny wyjściowe za myślenie.\\n\\nPonadto Gemini 2.5 Flash można konfigurować za pomocą parametru \'maksymalna liczba token\xf3w do wnioskowania\', jak opisano w dokumentacji (https://openrouter.ai/docs/use-cases/reasoning-tokens#max-tokens-for-reasoning)."},"google/gemini-2.5-flash-preview:thinking":{"description":"Gemini 2.5 Flash to najnowocześniejszy model gł\xf3wny Google, zaprojektowany z myślą o zaawansowanym wnioskowaniu, kodowaniu, matematyce i zadaniach naukowych. Zawiera wbudowaną zdolność \'myślenia\', co pozwala mu na dostarczanie odpowiedzi z wyższą dokładnością i szczeg\xf3łowym przetwarzaniem kontekstu.\\n\\nUwaga: ten model ma dwa warianty: myślenie i niemyslenie. Ceny wyjściowe r\xf3żnią się znacznie w zależności od tego, czy zdolność myślenia jest aktywowana. Jeśli wybierzesz standardowy wariant (bez sufiksu \':thinking\'), model wyraźnie unika generowania token\xf3w myślenia.\\n\\nAby skorzystać z zdolności myślenia i otrzymać tokeny myślenia, musisz wybrać wariant \':thinking\', co spowoduje wyższe ceny wyjściowe za myślenie.\\n\\nPonadto Gemini 2.5 Flash można konfigurować za pomocą parametru \'maksymalna liczba token\xf3w do wnioskowania\', jak opisano w dokumentacji (https://openrouter.ai/docs/use-cases/reasoning-tokens#max-tokens-for-reasoning)."},"google/gemini-2.5-pro":{"description":"Gemini 2.5 Pro to nasz najbardziej zaawansowany model wnioskowania Gemini, zdolny do rozwiązywania złożonych problem\xf3w. Posiada okno kontekstu o rozmiarze 2 milion\xf3w token\xf3w i obsługuje multimodalne wejścia, w tym tekst, obrazy, dźwięk, wideo i dokumenty PDF."},"google/gemini-2.5-pro-preview":{"description":"Gemini 2.5 Pro Preview to najnowocześniejszy model myślowy Google, zdolny do rozumowania nad złożonymi problemami w dziedzinie kodowania, matematyki i STEM oraz do analizy dużych zbior\xf3w danych, repozytori\xf3w kodu i dokument\xf3w przy użyciu długiego kontekstu."},"google/gemini-embedding-001":{"description":"Najnowocześniejszy model osadzeń, oferujący doskonałą wydajność w zadaniach anglojęzycznych, wielojęzycznych i kodowych."},"google/gemini-flash-1.5":{"description":"Gemini 1.5 Flash oferuje zoptymalizowane możliwości przetwarzania multimodalnego, odpowiednie do r\xf3żnych złożonych scenariuszy zadań."},"google/gemini-pro-1.5":{"description":"Gemini 1.5 Pro łączy najnowsze technologie optymalizacji, oferując bardziej efektywne przetwarzanie danych multimodalnych."},"google/gemma-2-27b":{"description":"Gemma 2 to wydajny model wydany przez Google, obejmujący r\xf3żnorodne scenariusze zastosowań, od małych aplikacji po złożone przetwarzanie danych."},"google/gemma-2-27b-it":{"description":"Gemma 2 kontynuuje ideę lekkiego i wydajnego projektowania."},"google/gemma-2-2b-it":{"description":"Lekki model dostosowywania instrukcji od Google."},"google/gemma-2-9b":{"description":"Gemma 2 to wydajny model wydany przez Google, obejmujący r\xf3żnorodne scenariusze zastosowań, od małych aplikacji po złożone przetwarzanie danych."},"google/gemma-2-9b-it":{"description":"Gemma 2 to lekka seria modeli tekstowych open source od Google."},"google/gemma-2-9b-it:free":{"description":"Gemma 2 to odchudzona seria otwartych modeli tekstowych Google."},"google/gemma-2b-it":{"description":"Gemma Instruct (2B) oferuje podstawowe możliwości przetwarzania poleceń, idealne do lekkich aplikacji."},"google/gemma-3-12b-it":{"description":"Gemma 3 12B to otwarty model językowy Google, ustanawiający nowe standardy w zakresie efektywności i wydajności."},"google/gemma-3-27b-it":{"description":"Gemma 3 27B to otwarty model językowy stworzony przez Google, kt\xf3ry ustanowił nowe standardy w zakresie wydajności i efektywności."},"google/text-embedding-005":{"description":"Model osadzeń tekstowych skoncentrowany na języku angielskim, zoptymalizowany pod kątem zadań kodowania i języka angielskiego."},"google/text-multilingual-embedding-002":{"description":"Model osadzeń tekstowych wielojęzycznych, zoptymalizowany pod kątem zadań międzyjęzykowych, obsługujący wiele język\xf3w."},"gpt-3.5-turbo":{"description":"GPT 3.5 Turbo, odpowiedni do r\xf3żnych zadań generowania i rozumienia tekstu, obecnie wskazuje na gpt-3.5-turbo-0125."},"gpt-3.5-turbo-0125":{"description":"GPT 3.5 Turbo, odpowiedni do r\xf3żnych zadań generowania i rozumienia tekstu, obecnie wskazuje na gpt-3.5-turbo-0125."},"gpt-3.5-turbo-1106":{"description":"GPT 3.5 Turbo, odpowiedni do r\xf3żnych zadań generowania i rozumienia tekstu, obecnie wskazuje na gpt-3.5-turbo-0125."},"gpt-3.5-turbo-instruct":{"description":"GPT 3.5 Turbo, odpowiedni do r\xf3żnych zadań generowania i rozumienia tekstu, obecnie wskazuje na gpt-3.5-turbo-0125."},"gpt-35-turbo":{"description":"GPT 3.5 Turbo to wydajny model dostarczany przez OpenAI, idealny do obsługi zadań związanych z czatowaniem i generowaniem tekstu, wspierający r\xf3wnoległe wywołania funkcji."},"gpt-35-turbo-16k":{"description":"GPT 3.5 Turbo 16k, model do generowania tekstu o dużej pojemności, odpowiedni do bardziej złożonych zadań."},"gpt-4":{"description":"GPT-4 oferuje większe okno kontekstowe, zdolne do przetwarzania dłuższych wejść tekstowych, co czyni go odpowiednim do scenariuszy wymagających szerokiej integracji informacji i analizy danych."},"gpt-4-0125-preview":{"description":"Najnowszy model GPT-4 Turbo posiada funkcje wizualne. Teraz zapytania wizualne mogą być obsługiwane za pomocą formatu JSON i wywołań funkcji. GPT-4 Turbo to ulepszona wersja, kt\xf3ra oferuje opłacalne wsparcie dla zadań multimodalnych. Znajduje r\xf3wnowagę między dokładnością a wydajnością, co czyni go odpowiednim do aplikacji wymagających interakcji w czasie rzeczywistym."},"gpt-4-0613":{"description":"GPT-4 oferuje większe okno kontekstowe, zdolne do przetwarzania dłuższych wejść tekstowych, co czyni go odpowiednim do scenariuszy wymagających szerokiej integracji informacji i analizy danych."},"gpt-4-1106-preview":{"description":"Najnowszy model GPT-4 Turbo posiada funkcje wizualne. Teraz zapytania wizualne mogą być obsługiwane za pomocą formatu JSON i wywołań funkcji. GPT-4 Turbo to ulepszona wersja, kt\xf3ra oferuje opłacalne wsparcie dla zadań multimodalnych. Znajduje r\xf3wnowagę między dokładnością a wydajnością, co czyni go odpowiednim do aplikacji wymagających interakcji w czasie rzeczywistym."},"gpt-4-32k":{"description":"GPT-4 oferuje większe okno kontekstowe, zdolne do przetwarzania dłuższych wejść tekstowych, co czyni go odpowiednim do scenariuszy wymagających szerokiej integracji informacji i analizy danych."},"gpt-4-32k-0613":{"description":"GPT-4 oferuje większe okno kontekstowe, zdolne do przetwarzania dłuższych wejść tekstowych, co czyni go odpowiednim do scenariuszy wymagających szerokiej integracji informacji i analizy danych."},"gpt-4-turbo":{"description":"Najnowszy model GPT-4 Turbo posiada funkcje wizualne. Teraz zapytania wizualne mogą być obsługiwane za pomocą formatu JSON i wywołań funkcji. GPT-4 Turbo to ulepszona wersja, kt\xf3ra oferuje opłacalne wsparcie dla zadań multimodalnych. Znajduje r\xf3wnowagę między dokładnością a wydajnością, co czyni go odpowiednim do aplikacji wymagających interakcji w czasie rzeczywistym."},"gpt-4-turbo-2024-04-09":{"description":"Najnowszy model GPT-4 Turbo posiada funkcje wizualne. Teraz zapytania wizualne mogą być obsługiwane za pomocą formatu JSON i wywołań funkcji. GPT-4 Turbo to ulepszona wersja, kt\xf3ra oferuje opłacalne wsparcie dla zadań multimodalnych. Znajduje r\xf3wnowagę między dokładnością a wydajnością, co czyni go odpowiednim do aplikacji wymagających interakcji w czasie rzeczywistym."},"gpt-4-turbo-preview":{"description":"Najnowszy model GPT-4 Turbo posiada funkcje wizualne. Teraz zapytania wizualne mogą być obsługiwane za pomocą formatu JSON i wywołań funkcji. GPT-4 Turbo to ulepszona wersja, kt\xf3ra oferuje opłacalne wsparcie dla zadań multimodalnych. Znajduje r\xf3wnowagę między dokładnością a wydajnością, co czyni go odpowiednim do aplikacji wymagających interakcji w czasie rzeczywistym."},"gpt-4-vision-preview":{"description":"Najnowszy model GPT-4 Turbo posiada funkcje wizualne. Teraz zapytania wizualne mogą być obsługiwane za pomocą formatu JSON i wywołań funkcji. GPT-4 Turbo to ulepszona wersja, kt\xf3ra oferuje opłacalne wsparcie dla zadań multimodalnych. Znajduje r\xf3wnowagę między dokładnością a wydajnością, co czyni go odpowiednim do aplikacji wymagających interakcji w czasie rzeczywistym."},"gpt-4.1":{"description":"GPT-4.1 to nasz flagowy model do złożonych zadań. Doskonale nadaje się do rozwiązywania problem\xf3w w r\xf3żnych dziedzinach."},"gpt-4.1-mini":{"description":"GPT-4.1 mini oferuje r\xf3wnowagę między inteligencją, szybkością a kosztami, co czyni go atrakcyjnym modelem w wielu zastosowaniach."},"gpt-4.1-nano":{"description":"GPT-4.1 mini oferuje r\xf3wnowagę między inteligencją, szybkością a kosztami, co czyni go atrakcyjnym modelem w wielu zastosowaniach."},"gpt-4.5-preview":{"description":"GPT-4.5-preview to najnowszy model og\xf3lnego przeznaczenia, dysponujący rozległą wiedzą o świecie i lepszym rozumieniem intencji użytkownika. Sprawdza się w zadaniach tw\xf3rczych i planowaniu działań. Wiedza modelu jest aktualna na październik 2023 r."},"gpt-4o":{"description":"ChatGPT-4o to dynamiczny model, kt\xf3ry jest na bieżąco aktualizowany, aby utrzymać najnowszą wersję. Łączy potężne zdolności rozumienia i generowania języka, co czyni go odpowiednim do zastosowań na dużą skalę, w tym obsługi klienta, edukacji i wsparcia technicznego."},"gpt-4o-2024-05-13":{"description":"ChatGPT-4o to dynamiczny model, kt\xf3ry jest na bieżąco aktualizowany, aby utrzymać najnowszą wersję. Łączy potężne zdolności rozumienia i generowania języka, co czyni go odpowiednim do zastosowań na dużą skalę, w tym obsługi klienta, edukacji i wsparcia technicznego."},"gpt-4o-2024-08-06":{"description":"ChatGPT-4o to dynamiczny model, kt\xf3ry jest na bieżąco aktualizowany, aby utrzymać najnowszą wersję. Łączy potężne zdolności rozumienia i generowania języka, co czyni go odpowiednim do zastosowań na dużą skalę, w tym obsługi klienta, edukacji i wsparcia technicznego."},"gpt-4o-2024-11-20":{"description":"ChatGPT-4o to dynamiczny model, aktualizowany w czasie rzeczywistym, aby być zawsze na bieżąco z najnowszą wersją. Łączy potężne zdolności rozumienia i generowania języka, idealny do zastosowań w dużej skali, w tym obsłudze klienta, edukacji i wsparciu technicznym."},"gpt-4o-audio-preview":{"description":"Model GPT-4o Audio Preview, obsługujący wejście i wyjście audio."},"gpt-4o-mini":{"description":"GPT-4o mini to najnowszy model OpenAI, wprowadzony po GPT-4 Omni, obsługujący wejścia tekstowe i wizualne oraz generujący tekst. Jako ich najnowocześniejszy model w małej skali, jest znacznie tańszy niż inne niedawno wprowadzone modele, a jego cena jest o ponad 60% niższa niż GPT-3.5 Turbo. Utrzymuje najnowocześniejszą inteligencję, jednocześnie oferując znaczną wartość za pieniądze. GPT-4o mini uzyskał wynik 82% w teście MMLU i obecnie zajmuje wyższą pozycję w preferencjach czatu niż GPT-4."},"gpt-4o-mini-audio-preview":{"description":"Model GPT-4o mini Audio, obsługujący wejście i wyjście audio."},"gpt-4o-mini-realtime-preview":{"description":"Wersja na żywo GPT-4o-mini, obsługująca wejście i wyjście audio oraz tekstowe w czasie rzeczywistym."},"gpt-4o-mini-search-preview":{"description":"GPT-4o mini wersja podglądowa do wyszukiwania to model specjalnie wytrenowany do rozumienia i realizacji zapytań wyszukiwania internetowego, korzystający z API Chat Completions. Poza opłatami za tokeny, zapytania wyszukiwania internetowego są dodatkowo obciążane opłatą za każde wywołanie narzędzia."},"gpt-4o-mini-transcribe":{"description":"GPT-4o Mini Transcribe to model konwersji mowy na tekst wykorzystujący GPT-4o do transkrypcji audio. W por\xf3wnaniu z oryginalnym modelem Whisper poprawia wskaźnik błęd\xf3w sł\xf3w oraz rozpoznawanie i dokładność językową. Użyj go, aby uzyskać dokładniejsze transkrypcje."},"gpt-4o-mini-tts":{"description":"GPT-4o mini TTS to model tekstu na mowę oparty na GPT-4o mini, oferujący wysokiej jakości generowanie mowy przy niższych kosztach."},"gpt-4o-realtime-preview":{"description":"Wersja na żywo GPT-4o, obsługująca wejście i wyjście audio oraz tekstowe w czasie rzeczywistym."},"gpt-4o-realtime-preview-2024-10-01":{"description":"Wersja na żywo GPT-4o, obsługująca wejście i wyjście audio oraz tekstowe w czasie rzeczywistym."},"gpt-4o-realtime-preview-2025-06-03":{"description":"Wersja GPT-4o w czasie rzeczywistym, obsługująca jednoczesne wejście i wyjście audio oraz tekstu."},"gpt-4o-search-preview":{"description":"GPT-4o wersja podglądowa do wyszukiwania to model specjalnie wytrenowany do rozumienia i realizacji zapytań wyszukiwania internetowego, korzystający z API Chat Completions. Poza opłatami za tokeny, zapytania wyszukiwania internetowego są dodatkowo obciążane opłatą za każde wywołanie narzędzia."},"gpt-4o-transcribe":{"description":"GPT-4o Transcribe to model konwersji mowy na tekst wykorzystujący GPT-4o do transkrypcji audio. W por\xf3wnaniu z oryginalnym modelem Whisper poprawia wskaźnik błęd\xf3w sł\xf3w oraz rozpoznawanie i dokładność językową. Użyj go, aby uzyskać dokładniejsze transkrypcje."},"gpt-5":{"description":"Najlepszy model do zadań międzydziedzinowego kodowania i pośrednictwa. GPT-5 osiąga przełom w dokładności, szybkości, rozumowaniu, rozpoznawaniu kontekstu, myśleniu strukturalnym i rozwiązywaniu problem\xf3w."},"gpt-5-chat":{"description":"GPT-5 Chat to wersja zapoznawcza zoptymalizowana pod kątem scenariuszy konwersacyjnych. Obsługuje wejścia tekstowe i graficzne, generuje wyłącznie tekst, idealna do chatbot\xf3w i aplikacji opartych na konwersacyjnej sztucznej inteligencji."},"gpt-5-chat-latest":{"description":"Model GPT-5 używany w ChatGPT. Łączy potężne zdolności rozumienia i generowania języka, idealny do interakcji konwersacyjnych."},"gpt-5-codex":{"description":"GPT-5 Codex to wersja GPT-5 zoptymalizowana pod kątem zadań kodowania w środowiskach Codex lub podobnych."},"gpt-5-mini":{"description":"Szybsza i bardziej ekonomiczna wersja GPT-5, przeznaczona do jasno określonych zadań. Zapewnia szybszą reakcję przy zachowaniu wysokiej jakości wynik\xf3w."},"gpt-5-nano":{"description":"Najszybsza i najbardziej ekonomiczna wersja GPT-5. Doskonała do zastosowań wymagających szybkiej odpowiedzi i wrażliwych na koszty."},"gpt-5-pro":{"description":"GPT-5 pro wykorzystuje większą moc obliczeniową do głębszego rozumowania i konsekwentnie dostarcza lepsze odpowiedzi."},"gpt-5.1":{"description":"GPT-5.1 — flagowy model zoptymalizowany pod kątem zadań związanych z kodowaniem i agentami, oferujący konfigurowalną intensywność wnioskowania oraz dłuższy kontekst."},"gpt-5.1-chat-latest":{"description":"GPT-5.1 Chat: wariant GPT-5.1 przeznaczony do ChatGPT, idealny do zastosowań konwersacyjnych."},"gpt-5.1-codex":{"description":"GPT-5.1 Codex: wersja GPT-5.1 zoptymalizowana pod kątem zadań kodowania z udziałem agent\xf3w, dostępna w API odpowiedzi do bardziej złożonych przepływ\xf3w pracy z kodem i agentami."},"gpt-5.1-codex-mini":{"description":"GPT-5.1 Codex mini: mniejszy i tańszy wariant Codex, zoptymalizowany do zadań kodowania z udziałem agent\xf3w."},"gpt-audio":{"description":"GPT Audio to uniwersalny model konwersacyjny obsługujący wejście i wyjście audio, dostępny w API Chat Completions z obsługą audio I/O."},"gpt-image-1":{"description":"Natywny multimodalny model generowania obraz\xf3w ChatGPT."},"gpt-image-1-mini":{"description":"Tańsza wersja GPT Image 1, natywnie obsługuje wejścia tekstowe i graficzne oraz generuje obrazy jako wyjście."},"gpt-oss-120b":{"description":"Model wymaga zgłoszenia w celu uzyskania dostępu. GPT-OSS-120B to otwartoźr\xf3dłowy, wielkoskalowy model językowy opracowany przez OpenAI, oferujący zaawansowane możliwości generowania tekstu."},"gpt-oss-20b":{"description":"Model wymaga zgłoszenia w celu uzyskania dostępu. GPT-OSS-20B to otwartoźr\xf3dłowy, średniej wielkości model językowy opracowany przez OpenAI, zapewniający wydajne generowanie tekstu."},"gpt-oss:120b":{"description":"GPT-OSS 120B to duży otwarty model językowy wydany przez OpenAI, wykorzystujący technologię kwantyzacji MXFP4, przeznaczony jako model flagowy. Wymaga środowiska wielo-GPU lub wysokowydajnej stacji roboczej, oferując znakomitą wydajność w złożonym wnioskowaniu, generowaniu kodu oraz przetwarzaniu wielojęzycznym, wspierając zaawansowane wywołania funkcji i integrację narzędzi."},"gpt-oss:20b":{"description":"GPT-OSS 20B to otwartoźr\xf3dłowy duży model językowy wydany przez OpenAI, wykorzystujący technikę kwantyzacji MXFP4, przeznaczony do uruchamiania na wysokiej klasy konsumenckich GPU lub Apple Silicon Mac. Model wykazuje doskonałe wyniki w generowaniu dialog\xf3w, pisaniu kodu i zadaniach wnioskowania, obsługuje wywołania funkcji i korzystanie z narzędzi."},"gpt-realtime":{"description":"Uniwersalny model czasu rzeczywistego, obsługujący tekstowe i audio wejścia i wyjścia oraz wejścia obraz\xf3w."},"grok-2-image-1212":{"description":"Nasz najnowszy model generowania obraz\xf3w potrafi tworzyć żywe i realistyczne obrazy na podstawie tekstowych wskaz\xf3wek. Sprawdza się doskonale w marketingu, mediach społecznościowych i rozrywce."},"grok-2-vision-1212":{"description":"Model ten poprawił dokładność, przestrzeganie instrukcji oraz zdolności wielojęzyczne."},"grok-3":{"description":"Flagowy model, specjalizujący się w ekstrakcji danych, programowaniu i streszczaniu tekst\xf3w na poziomie korporacyjnym, z głęboką wiedzą w dziedzinach finans\xf3w, medycyny, prawa i nauki."},"grok-3-mini":{"description":"Lekki model, kt\xf3ry najpierw analizuje przed rozmową. Działa szybko i inteligentnie, odpowiedni do zadań logicznych nie wymagających głębokiej wiedzy dziedzinowej, z możliwością śledzenia pierwotnego toku myślenia."},"grok-4":{"description":"Nasz najnowszy i najpotężniejszy model flagowy, kt\xf3ry wyr\xf3żnia się doskonałymi wynikami w przetwarzaniu języka naturalnego, obliczeniach matematycznych i rozumowaniu — to idealny wszechstronny zawodnik."},"grok-4-0709":{"description":"Grok 4 od xAI, wyposażony w potężne zdolności rozumowania."},"grok-4-1-fast-non-reasoning":{"description":"Nowoczesny model multimodalny, zoptymalizowany specjalnie do wydajnego korzystania z narzędzi pośredniczących."},"grok-4-1-fast-reasoning":{"description":"Nowoczesny model multimodalny, zoptymalizowany specjalnie do wydajnego korzystania z narzędzi pośredniczących."},"grok-4-fast-non-reasoning":{"description":"Z radością prezentujemy Grok 4 Fast, nasz najnowszy postęp w modelach inferencyjnych o wysokiej efektywności kosztowej."},"grok-4-fast-reasoning":{"description":"Z radością prezentujemy Grok 4 Fast, nasz najnowszy postęp w modelach inferencyjnych o wysokiej efektywności kosztowej."},"grok-code-fast-1":{"description":"Z radością przedstawiamy grok-code-fast-1, szybki i ekonomiczny model inferencyjny, kt\xf3ry doskonale sprawdza się w kodowaniu agent\xf3w."},"groq/compound":{"description":"Compound to złożony system AI wspierany przez wiele dostępnych publicznie modeli w GroqCloud, kt\xf3ry inteligentnie i selektywnie wykorzystuje narzędzia do odpowiadania na zapytania użytkownik\xf3w."},"groq/compound-mini":{"description":"Compound-mini to złożony system AI wspierany przez dostępne publicznie modele w GroqCloud, kt\xf3ry inteligentnie i selektywnie wykorzystuje narzędzia do odpowiadania na zapytania użytkownik\xf3w."},"gryphe/mythomax-l2-13b":{"description":"MythoMax l2 13B to model językowy łączący kreatywność i inteligencję, zintegrowany z wieloma wiodącymi modelami."},"hunyuan-a13b":{"description":"Hunyuan to pierwszy hybrydowy model rozumowania, będący ulepszoną wersją hunyuan-standard-256K, z 80 miliardami parametr\xf3w i 13 miliardami aktywowanych. Domyślnie działa w trybie wolnego myślenia, ale obsługuje przełączanie między trybami szybkiego i wolnego myślenia za pomocą parametr\xf3w lub instrukcji; przełączanie odbywa się przez dodanie / no_think przed zapytaniem. Og\xf3lne zdolności modelu znacznie przewyższają poprzednią generację, zwłaszcza w matematyce, naukach ścisłych, rozumieniu długich tekst\xf3w i zdolnościach agenta."},"hunyuan-code":{"description":"Najnowocześniejszy model generowania kodu Hunyuan, przeszkolony na bazie 200B wysokiej jakości danych kodu, z p\xf3łrocznym treningiem na wysokiej jakości danych SFT, z wydłużonym oknem kontekstowym do 8K, zajmującym czołowe miejsca w automatycznych wskaźnikach oceny generowania kodu w pięciu językach; w ocenie jakościowej zadań kodowych w pięciu językach, osiąga wyniki w pierwszej lidze."},"hunyuan-functioncall":{"description":"Najnowocześniejszy model FunctionCall w architekturze MOE Hunyuan, przeszkolony na wysokiej jakości danych FunctionCall, z oknem kontekstowym o długości 32K, osiągający wiodące wyniki w wielu wymiarach oceny."},"hunyuan-large":{"description":"Model Hunyuan-large ma całkowitą liczbę parametr\xf3w wynoszącą około 389B, z aktywowanymi parametrami wynoszącymi około 52B, co czyni go obecnie największym i najlepiej działającym modelem MoE w architekturze Transformer w branży."},"hunyuan-large-longcontext":{"description":"Specjalizuje się w zadaniach związanych z długimi tekstami, takich jak streszczenia dokument\xf3w i pytania i odpowiedzi dotyczące dokument\xf3w, a także ma zdolność do obsługi og\xf3lnych zadań generowania tekstu. Wykazuje doskonałe wyniki w analizie i generowaniu długich tekst\xf3w, skutecznie radząc sobie z złożonymi i szczeg\xf3łowymi wymaganiami dotyczącymi przetwarzania długich treści."},"hunyuan-large-vision":{"description":"Model przeznaczony do scenariuszy rozumienia obraz\xf3w i tekstu, oparty na modelu Hunyuan Large, obsługujący dowolną rozdzielczość i wiele obraz\xf3w wraz z tekstem, generujący treści tekstowe, skupiający się na zadaniach związanych z rozumieniem obrazowo-tekstowym, z wyraźną poprawą zdolności wielojęzycznego rozumienia obraz\xf3w i tekstu."},"hunyuan-lite":{"description":"Zaktualizowana do struktury MOE, z oknem kontekstowym o długości 256k, prowadzi w wielu zestawach testowych w NLP, kodowaniu, matematyce i innych dziedzinach w por\xf3wnaniu do wielu modeli open source."},"hunyuan-lite-vision":{"description":"Najnowocześniejszy model multimodalny 7B Hunyuan, z oknem kontekstowym 32K, wspierający multimodalne dialogi w języku chińskim i angielskim, rozpoznawanie obiekt\xf3w w obrazach, zrozumienie dokument\xf3w i tabel, multimodalną matematykę itp., z wynikami w wielu wymiarach lepszymi niż modele konkurencyjne 7B."},"hunyuan-pro":{"description":"Model długiego tekstu MOE-32K o skali bilion\xf3w parametr\xf3w. Osiąga absolutnie wiodący poziom w r\xf3żnych benchmarkach, obsługując złożone instrukcje i wnioskowanie, posiadając zaawansowane umiejętności matematyczne, wspierając wywołania funkcji, z optymalizacjami w obszarach takich jak tłumaczenia wielojęzyczne, prawo finansowe i medyczne."},"hunyuan-role":{"description":"Najnowocześniejszy model odgrywania r\xf3l Hunyuan, stworzony przez oficjalne dostosowanie i trening Hunyuan, oparty na modelu Hunyuan i zestawie danych scenariuszy odgrywania r\xf3l, oferujący lepsze podstawowe wyniki w scenariuszach odgrywania r\xf3l."},"hunyuan-standard":{"description":"Zastosowano lepszą strategię routingu, jednocześnie łagodząc problemy z r\xf3wnoważeniem obciążenia i zbieżnością ekspert\xf3w. W przypadku długich tekst\xf3w wskaźnik \'znalezienia igły w stogu siana\' osiąga 99,9%. MOE-32K oferuje lepszy stosunek jakości do ceny, r\xf3wnoważąc efektywność i cenę, umożliwiając przetwarzanie długich tekst\xf3w."},"hunyuan-standard-256K":{"description":"Zastosowano lepszą strategię routingu, jednocześnie łagodząc problemy z r\xf3wnoważeniem obciążenia i zbieżnością ekspert\xf3w. W przypadku długich tekst\xf3w wskaźnik \'znalezienia igły w stogu siana\' osiąga 99,9%. MOE-256K dokonuje dalszych przełom\xf3w w długości i efektywności, znacznie rozszerzając możliwą długość wejścia."},"hunyuan-standard-vision":{"description":"Najnowocześniejszy model multimodalny Hunyuan, wspierający odpowiedzi w wielu językach, z r\xf3wnoważnymi zdolnościami w języku chińskim i angielskim."},"hunyuan-t1-20250321":{"description":"Kompleksowy model zdolności w naukach ścisłych i humanistycznych, z silną zdolnością do uchwycenia długich informacji tekstowych. Wspiera wnioskowanie w odpowiedzi na r\xf3żnorodne trudności w matematyce, logice, naukach ścisłych i kodowaniu."},"hunyuan-t1-20250403":{"description":"Zwiększenie zdolności generowania kodu na poziomie projektu; poprawa jakości pisania generowanego tekstu; ulepszenie wieloetapowego rozumienia temat\xf3w, przestrzegania instrukcji typu tob oraz rozumienia sł\xf3w; optymalizacja problem\xf3w z mieszanym użyciem uproszczonych i tradycyjnych znak\xf3w oraz mieszanym językiem chińsko-angielskim."},"hunyuan-t1-20250529":{"description":"Optymalizacja tworzenia tekst\xf3w, pisania esej\xf3w, ulepszenie umiejętności w kodowaniu frontendowym, matematyce, rozumowaniu logicznym oraz zwiększenie zdolności do przestrzegania instrukcji."},"hunyuan-t1-20250711":{"description":"Znacząca poprawa zdolności w zakresie zaawansowanej matematyki, logiki i kodowania, optymalizacja stabilności wyjścia modelu oraz zwiększenie zdolności do pracy z długimi tekstami."},"hunyuan-t1-latest":{"description":"Znacząco poprawia zdolności gł\xf3wnego modelu wolnego myślenia w zakresie zaawansowanej matematyki, złożonego wnioskowania, trudnego kodowania, przestrzegania instrukcji oraz jakości tworzenia tekst\xf3w."},"hunyuan-t1-vision-20250619":{"description":"Najnowszy model wielomodalny t1-vision Hunyuan z głębokim rozumowaniem, obsługujący natywne łańcuchy myślowe wielomodalne, z kompleksową poprawą w stosunku do poprzedniej domyślnej wersji modelu."},"hunyuan-t1-vision-20250916":{"description":"Najnowszy model głębokiego rozumienia wizualnego Hunyuan t1-vision oferuje kompleksowe ulepszenia w por\xf3wnaniu do poprzedniej wersji w zadaniach takich jak og\xf3lne pytania i odpowiedzi na podstawie obrazu i tekstu, lokalizacja wizualna, OCR, analiza wykres\xf3w, rozwiązywanie zadań ze zdjęć oraz kreatywne tworzenie na podstawie obraz\xf3w. Znacząco poprawiono r\xf3wnież obsługę języka angielskiego i język\xf3w niszowych."},"hunyuan-turbo":{"description":"Hunyuan to nowa generacja dużego modelu językowego w wersji pr\xf3bnej, wykorzystująca nową strukturę modelu mieszanych ekspert\xf3w (MoE), kt\xf3ra w por\xf3wnaniu do hunyuan-pro charakteryzuje się szybszą efektywnością wnioskowania i lepszymi wynikami."},"hunyuan-turbo-20241223":{"description":"Optymalizacja tej wersji: skalowanie danych instrukcji, znaczne zwiększenie og\xf3lnej zdolności generalizacji modelu; znaczne zwiększenie zdolności w zakresie matematyki, kodowania i rozumowania logicznego; optymalizacja zdolności związanych z rozumieniem tekstu i sł\xf3w; optymalizacja jakości generowania treści w tworzeniu tekst\xf3w."},"hunyuan-turbo-latest":{"description":"Og\xf3lna optymalizacja doświadczeń, w tym zrozumienie NLP, tworzenie tekst\xf3w, rozmowy, pytania i odpowiedzi, tłumaczenia, obszary tematyczne itp.; zwiększenie humanizacji, optymalizacja inteligencji emocjonalnej modelu; poprawa zdolności modelu do aktywnego wyjaśniania w przypadku niejasnych intencji; poprawa zdolności do rozwiązywania problem\xf3w związanych z analizą sł\xf3w; poprawa jakości i interaktywności tw\xf3rczości; poprawa doświadczeń w wielokrotnych interakcjach."},"hunyuan-turbo-vision":{"description":"Nowa generacja flagowego modelu językowo-wizualnego Hunyuan, wykorzystująca nową strukturę modelu mieszanych ekspert\xf3w (MoE), z pełnym zwiększeniem zdolności w zakresie podstawowego rozpoznawania, tworzenia treści, pytań i odpowiedzi oraz analizy i rozumowania w por\xf3wnaniu do poprzedniej generacji modeli."},"hunyuan-turbos-20250313":{"description":"Ujednolicenie stylu krok\xf3w rozwiązywania zadań matematycznych, wzmocnienie wieloetapowego zadawania pytań matematycznych. Optymalizacja stylu odpowiedzi w tworzeniu tekst\xf3w, eliminacja sztuczności AI, wzbogacenie języka."},"hunyuan-turbos-20250416":{"description":"Aktualizacja bazy pretrenowania, wzmacniająca zdolność rozumienia i przestrzegania instrukcji; w fazie dostrajania poprawa umiejętności matematycznych, programistycznych, logicznych i nauk ścisłych; podniesienie jakości tw\xf3rczości literackiej, rozumienia tekstu, dokładności tłumaczeń oraz wiedzy og\xf3lnej; wzmocnienie zdolności agent\xf3w w r\xf3żnych dziedzinach, ze szczeg\xf3lnym naciskiem na rozumienie wieloetapowych dialog\xf3w."},"hunyuan-turbos-20250604":{"description":"Ulepszona baza pretrenowania, poprawa umiejętności pisania i rozumienia tekstu, znaczne zwiększenie zdolności w kodowaniu i naukach ścisłych, ciągłe doskonalenie w realizacji złożonych poleceń."},"hunyuan-turbos-20250926":{"description":"Ulepszona jakość danych bazy pretrenowania. Optymalizacja strategii treningowej fazy post-treningowej, ciągłe podnoszenie zdolności agenta, obsługi język\xf3w angielskiego i mniejszych język\xf3w, zgodności z instrukcjami, kodowania oraz nauk ścisłych."},"hunyuan-turbos-latest":{"description":"hunyuan-TurboS to najnowsza wersja flagowego modelu Hunyuan, oferująca silniejsze zdolności myślenia i lepsze efekty doświadczenia."},"hunyuan-turbos-longtext-128k-20250325":{"description":"Specjalizuje się w zadaniach związanych z długimi tekstami, takimi jak streszczenia dokument\xf3w i pytania do dokument\xf3w, a także ma zdolność do generowania og\xf3lnych tekst\xf3w. W analizie i generowaniu długich tekst\xf3w wykazuje doskonałe wyniki, skutecznie radząc sobie z złożonymi i szczeg\xf3łowymi wymaganiami przetwarzania długich treści."},"hunyuan-turbos-role-plus":{"description":"Najnowsza wersja modelu do odgrywania r\xf3l Hunyuan, oficjalnie dostrojona przez Hunyuan, oparta na modelu Hunyuan i wzbogacona o dane scenariuszy odgrywania r\xf3l, zapewniająca lepsze podstawowe efekty w tych scenariuszach."},"hunyuan-turbos-vision":{"description":"Model przeznaczony do zadań rozumienia obraz\xf3w i tekstu, oparty na najnowszym modelu turbos Hunyuan, będący nową generacją flagowego modelu wizualno-językowego. Skupia się na zadaniach związanych z rozpoznawaniem obiekt\xf3w na obrazach, pytaniami i odpowiedziami opartymi na wiedzy, tworzeniem tekst\xf3w reklamowych, rozwiązywaniem problem\xf3w na podstawie zdjęć i innych, z kompleksową poprawą w stosunku do poprzedniej generacji."},"hunyuan-turbos-vision-20250619":{"description":"Najnowszy flagowy model wizualno-językowy turbos-vision Hunyuan, z kompleksową poprawą w zadaniach związanych z rozumieniem obraz\xf3w i tekstu, w tym rozpoznawaniem obiekt\xf3w na obrazach, pytaniami i odpowiedziami opartymi na wiedzy, tworzeniem tekst\xf3w reklamowych, rozwiązywaniem problem\xf3w na podstawie zdjęć, w por\xf3wnaniu do poprzedniej domyślnej wersji modelu."},"hunyuan-vision":{"description":"Najnowocześniejszy model multimodalny Hunyuan, wspierający generowanie treści tekstowych na podstawie obraz\xf3w i tekstu."},"image-01":{"description":"Nowy model generowania obraz\xf3w o delikatnej jakości wizualnej, wspierający generację obraz\xf3w na podstawie tekstu oraz obraz\xf3w na podstawie obraz\xf3w."},"image-01-live":{"description":"Model generowania obraz\xf3w o delikatnej jakości wizualnej, wspierający generację obraz\xf3w na podstawie tekstu z możliwością ustawienia stylu."},"imagen-4.0-fast-generate-001":{"description":"Imagen — czwarta generacja serii modeli tekst-na-obraz, wersja Fast"},"imagen-4.0-generate-001":{"description":"Seria modeli Imagen czwartej generacji do tworzenia obraz\xf3w na podstawie tekstu"},"imagen-4.0-generate-preview-06-06":{"description":"Czwarta generacja modeli Imagen do generowania obraz\xf3w z tekstu."},"imagen-4.0-ultra-generate-001":{"description":"Imagen — seria modeli przekształcających tekst w obraz czwartej generacji, wersja Ultra"},"imagen-4.0-ultra-generate-preview-06-06":{"description":"Wersja Ultra czwartej generacji modeli Imagen do generowania obraz\xf3w z tekstu."},"inception/mercury-coder-small":{"description":"Mercury Coder Small to idealny wyb\xf3r do generowania, debugowania i refaktoryzacji kodu, oferujący minimalne op\xf3źnienia."},"inclusionAI/Ling-1T":{"description":"Ling-1T to flagowy model bez rozumowania (non-thinking) z serii „Ling 2.0”, posiadający 1 bilion parametr\xf3w og\xf3lnych i około 50 miliard\xf3w aktywnych parametr\xf3w na token. Zbudowany na architekturze Ling 2.0, Ling-1T ma na celu przesunięcie granic efektywnego wnioskowania i skalowalnej kognicji. Ling-1T-base został wytrenowany na ponad 20 bilionach wysokiej jakości, intensywnie rozumujących token\xf3w."},"inclusionAI/Ling-flash-2.0":{"description":"Ling-flash-2.0 to trzeci model z serii architektury Ling 2.0 wydany przez zesp\xf3ł Bailing z Ant Group. Jest to model hybrydowy ekspert\xf3w (MoE) o łącznej liczbie parametr\xf3w 100 miliard\xf3w, z aktywacją jedynie 6,1 miliarda parametr\xf3w na token (48 miliard\xf3w bez uwzględnienia wektor\xf3w osadzeń). Jako lekka konfiguracja modelu, Ling-flash-2.0 wykazuje w wielu autorytatywnych testach wydajność por\xf3wnywalną lub przewyższającą modele gęste (Dense) o wielkości 40 miliard\xf3w parametr\xf3w oraz większe modele MoE. Model ten ma na celu eksplorację efektywnych ścieżek w kontekście powszechnego przekonania, że „duży model to duża liczba parametr\xf3w”, poprzez zaawansowany projekt architektury i strategię treningową."},"inclusionAI/Ling-mini-2.0":{"description":"Ling-mini-2.0 to mały, wysokowydajny duży model językowy oparty na architekturze MoE. Posiada 16 miliard\xf3w parametr\xf3w, ale aktywuje tylko 1,4 miliarda na token (789 milion\xf3w bez osadzeń), co zapewnia bardzo wysoką szybkość generowania. Dzięki efektywnemu projektowi MoE i dużej, wysokiej jakości bazie treningowej, mimo niskiej liczby aktywowanych parametr\xf3w, Ling-mini-2.0 osiąga w zadaniach downstream wydajność por\xf3wnywalną z najlepszymi modelami gęstymi poniżej 10 miliard\xf3w parametr\xf3w oraz większymi modelami MoE."},"inclusionAI/Ring-1T":{"description":"Ring-1T to otwartoźr\xf3dłowy model myślenia o skali biliona parametr\xf3w, opracowany przez zesp\xf3ł Bailing. Bazuje na architekturze Ling 2.0 i modelu bazowym Ling-1T-base, z 1 bilionem parametr\xf3w og\xf3lnych i 50 miliardami aktywnych parametr\xf3w. Obsługuje kontekst do 128K i został zoptymalizowany za pomocą skalowalnego, weryfikowalnego uczenia przez wzmocnienie z nagrodą."},"inclusionAI/Ring-flash-2.0":{"description":"Ring-flash-2.0 to wysoko wydajny model myślenia głęboko zoptymalizowany na bazie Ling-flash-2.0-base. Wykorzystuje architekturę hybrydowych ekspert\xf3w (MoE) z łączną liczbą parametr\xf3w 100 miliard\xf3w, aktywując podczas inferencji tylko 6,1 miliarda parametr\xf3w. Model rozwiązuje problem niestabilności treningu MoE w uczeniu ze wzmocnieniem (RL) dzięki autorskiej metodzie icepop, co pozwala na ciągłe zwiększanie zdolności do złożonego wnioskowania podczas długotrwałego treningu. Ring-flash-2.0 osiągnął znaczące przełomy w trudnych benchmarkach, takich jak konkursy matematyczne, generowanie kodu i rozumowanie logiczne. Jego wydajność przewyższa najlepsze modele gęste poniżej 40 miliard\xf3w parametr\xf3w i jest por\xf3wnywalna z większymi otwartoźr\xf3dłowymi modelami MoE oraz zamkniętymi modelami myślenia o wysokiej wydajności. Choć skupiony na złożonym wnioskowaniu, model dobrze radzi sobie także z zadaniami kreatywnego pisania. Dzięki efektywnej architekturze Ring-flash-2.0 oferuje wysoką wydajność przy szybkim inferowaniu, co znacząco obniża koszty wdrożenia modeli myślenia w środowiskach o dużej r\xf3wnoczesności."},"internlm/internlm2_5-7b-chat":{"description":"InternLM2.5 oferuje inteligentne rozwiązania dialogowe w r\xf3żnych scenariuszach."},"internlm2.5-latest":{"description":"Nasza najnowsza seria modeli, charakteryzująca się doskonałymi osiągami wnioskowania, obsługująca długość kontekstu do 1M oraz lepsze możliwości śledzenia instrukcji i wywoływania narzędzi."},"internlm3-latest":{"description":"Nasza najnowsza seria modeli, charakteryzująca się doskonałą wydajnością wnioskowania, prowadzi wśr\xf3d modeli open-source o podobnej skali. Domyślnie wskazuje na naszą najnowszą wersję modelu InternLM3."},"internvl2.5-38b-mpo":{"description":"InternVL2.5 38B MPO, multimodalny model wstępnie wytrenowany, wspierający złożone zadania wnioskowania obraz-tekst."},"internvl2.5-latest":{"description":"Wersja InternVL2.5, kt\xf3rą nadal utrzymujemy, charakteryzuje się doskonałą i stabilną wydajnością. Domyślnie wskazuje na nasz najnowszy model z serii InternVL2.5, obecnie wskazuje na internvl2.5-78b."},"internvl3-14b":{"description":"InternVL3 14B, średniej wielkości model multimodalny, zapewniający r\xf3wnowagę między wydajnością a kosztem."},"internvl3-1b":{"description":"InternVL3 1B, lekki model multimodalny, odpowiedni do wdrożeń w środowiskach o ograniczonych zasobach."},"internvl3-38b":{"description":"InternVL3 38B, duży otwartoźr\xf3dłowy model multimodalny, odpowiedni do zadań wymagających wysokiej precyzji w rozumieniu obraz\xf3w i tekstu."},"internvl3-latest":{"description":"Nasz najnowszy model multimodalny, kt\xf3ry ma silniejsze zdolności rozumienia tekstu i obraz\xf3w oraz długoterminowego rozumienia obraz\xf3w, osiągający wyniki por\xf3wnywalne z najlepszymi modelami zamkniętymi. Domyślnie wskazuje na nasz najnowszy model z serii InternVL, obecnie wskazuje na internvl3-78b."},"irag-1.0":{"description":"ERNIE iRAG, model generowania wspomaganego wyszukiwaniem obraz\xf3w, wspierający wyszukiwanie obrazem, wyszukiwanie obraz-tekst i generowanie treści."},"jamba-large":{"description":"Nasz najsilniejszy i najbardziej zaawansowany model, zaprojektowany do obsługi złożonych zadań na poziomie przedsiębiorstw, oferujący doskonałą wydajność."},"jamba-mini":{"description":"Najbardziej efektywny model w swojej klasie, łączący szybkość z jakością, o mniejszych rozmiarach."},"jina-deepsearch-v1":{"description":"Głębokie wyszukiwanie łączy wyszukiwanie w sieci, czytanie i wnioskowanie, umożliwiając kompleksowe badania. Możesz to traktować jako agenta, kt\xf3ry przyjmuje Twoje zadania badawcze - przeprowadza szerokie poszukiwania i wielokrotne iteracje, zanim poda odpowiedź. Proces ten obejmuje ciągłe badania, wnioskowanie i rozwiązywanie problem\xf3w z r\xf3żnych perspektyw. To zasadniczo r\xf3żni się od standardowych dużych modeli, kt\xf3re generują odpowiedzi bezpośrednio z wstępnie wytrenowanych danych oraz od tradycyjnych system\xf3w RAG, kt\xf3re polegają na jednorazowym powierzchownym wyszukiwaniu."},"kimi-k2":{"description":"Kimi-K2 to podstawowy model architektury MoE opracowany przez Moonshot AI, wyposażony w potężne zdolności kodowania i agenta, z łączną liczbą parametr\xf3w 1 biliona i 32 miliardami aktywowanych parametr\xf3w. W testach wydajności w zakresie og\xf3lnej wiedzy, programowania, matematyki i zadań agenta model K2 przewyższa inne popularne otwarte modele."},"kimi-k2-0711-preview":{"description":"kimi-k2 to podstawowy model architektury MoE o potężnych zdolnościach kodowania i agenta, z łączną liczbą parametr\xf3w 1T i 32B aktywowanych parametr\xf3w. W testach wydajności na benchmarkach obejmujących og\xf3lne rozumowanie, programowanie, matematykę i agent\xf3w model K2 przewyższa inne popularne modele open source."},"kimi-k2-0905-preview":{"description":"Model kimi-k2-0905-preview obsługuje długość kontekstu do 256k, oferując silniejsze zdolności Agentic Coding, bardziej estetyczny i praktyczny kod frontendowy oraz lepsze rozumienie kontekstu."},"kimi-k2-instruct":{"description":"Kimi K2 Instruct, oficjalny model wnioskowania Kimi, wspierający długi kontekst, kodowanie, pytania i inne scenariusze."},"kimi-k2-turbo-preview":{"description":"kimi-k2 to bazowy model z architekturą MoE, dysponujący wyjątkowymi możliwościami w zakresie kodowania i agent\xf3w, z łączną liczbą parametr\xf3w 1T oraz 32B parametr\xf3w aktywacyjnych. W standardowych testach wydajności (benchmarkach) dla gł\xf3wnych kategorii takich jak wnioskowanie z wiedzy og\xf3lnej, programowanie, matematyka i agenty, model K2 przewyższa inne popularne otwarte modele."},"kimi-k2:1t":{"description":"Kimi K2 to duży, hybrydowy model ekspertowy (MoE) języka opracowany przez AI z Ciemnej Strony Księżyca, posiadający 1 bilion parametr\xf3w og\xf3łem oraz 32 miliardy aktywowanych parametr\xf3w na pojedyncze przejście w prz\xf3d. Model jest zoptymalizowany pod kątem zdolności agentowych, w tym zaawansowanego korzystania z narzędzi, wnioskowania i syntezy kodu."},"kimi-latest":{"description":"Produkt Kimi Smart Assistant korzysta z najnowszego modelu Kimi, kt\xf3ry może zawierać cechy jeszcze niestabilne. Obsługuje zrozumienie obraz\xf3w i automatycznie wybiera model 8k/32k/128k jako model rozliczeniowy w zależności od długości kontekstu żądania."},"kimi-thinking-preview":{"description":"Model kimi-thinking-preview dostarczany przez Moon’s Dark Side to multimodalny model myślenia z umiejętnościami og\xf3lnego i głębokiego rozumowania, kt\xf3ry pomaga rozwiązywać bardziej złożone i trudniejsze problemy."},"learnlm-1.5-pro-experimental":{"description":"LearnLM to eksperymentalny model językowy, specyficzny dla zadań, przeszkolony zgodnie z zasadami nauki o uczeniu się, kt\xf3ry może przestrzegać systemowych instrukcji w scenariuszach nauczania i uczenia się, pełniąc rolę eksperta mentora."},"learnlm-2.0-flash-experimental":{"description":"LearnLM to eksperymentalny model językowy, specyficzny dla zadań, przeszkolony zgodnie z zasadami nauki o uczeniu się, kt\xf3ry może przestrzegać systemowych instrukcji w scenariuszach nauczania i uczenia się, pełniąc rolę eksperta mentora."},"lite":{"description":"Spark Lite to lekki model językowy o dużej skali, charakteryzujący się niezwykle niskim op\xf3źnieniem i wysoką wydajnością przetwarzania, całkowicie darmowy i otwarty, wspierający funkcje wyszukiwania w czasie rzeczywistym. Jego cechy szybkiej reakcji sprawiają, że doskonale sprawdza się w zastosowaniach inferencyjnych na urządzeniach o niskiej mocy obliczeniowej oraz w dostosowywaniu modeli, oferując użytkownikom znakomity stosunek koszt\xf3w do korzyści oraz inteligentne doświadczenie, szczeg\xf3lnie w kontekście pytań i odpowiedzi, generowania treści oraz wyszukiwania."},"llama-3.1-70b-versatile":{"description":"Llama 3.1 70B oferuje potężne możliwości wnioskowania AI, odpowiednie do złożonych zastosowań, wspierające ogromne przetwarzanie obliczeniowe przy zachowaniu efektywności i dokładności."},"llama-3.1-8b-instant":{"description":"Llama 3.1 8B to model o wysokiej wydajności, oferujący szybkie możliwości generowania tekstu, idealny do zastosowań wymagających dużej efektywności i opłacalności."},"llama-3.1-instruct":{"description":"Model Llama 3.1 zoptymalizowany do rozm\xf3w przewyższa wiele istniejących open-source modeli czatowych w standardowych testach branżowych."},"llama-3.2-11b-vision-instruct":{"description":"Wyjątkowe zdolności wnioskowania wizualnego na obrazach o wysokiej rozdzielczości, idealne do zastosowań związanych ze zrozumieniem wizualnym."},"llama-3.2-11b-vision-preview":{"description":"Llama 3.2 jest zaprojektowana do obsługi zadań łączących dane wizualne i tekstowe. Wykazuje doskonałe wyniki w zadaniach takich jak opisywanie obraz\xf3w i wizualne pytania i odpowiedzi, przekraczając przepaść między generowaniem języka a wnioskowaniem wizualnym."},"llama-3.2-90b-vision-instruct":{"description":"Zaawansowane zdolności wnioskowania obraz\xf3w dla zastosowań w agentach zrozumienia wizualnego."},"llama-3.2-90b-vision-preview":{"description":"Llama 3.2 jest zaprojektowana do obsługi zadań łączących dane wizualne i tekstowe. Wykazuje doskonałe wyniki w zadaniach takich jak opisywanie obraz\xf3w i wizualne pytania i odpowiedzi, przekraczając przepaść między generowaniem języka a wnioskowaniem wizualnym."},"llama-3.2-vision-instruct":{"description":"Model Llama 3.2-Vision zoptymalizowany jest do rozpoznawania wizualnego, wnioskowania na podstawie obraz\xf3w, opisywania obraz\xf3w oraz odpowiadania na typowe pytania związane z obrazami."},"llama-3.3-70b":{"description":"Llama 3.3 70B: średnio-duży model Llama, łączący zdolności wnioskowania z wysoką przepustowością."},"llama-3.3-70b-versatile":{"description":"Meta Llama 3.3 to wielojęzyczny model językowy (LLM) 70B, pretrenowany i dostosowany do poleceń. Model Llama 3.3, dostosowany do poleceń, jest zoptymalizowany do zastosowań w dialogach wielojęzycznych i przewyższa wiele dostępnych modeli czatu, zar\xf3wno open source, jak i zamkniętych, w popularnych branżowych benchmarkach."},"llama-3.3-instruct":{"description":"Model Llama 3.3 zoptymalizowany do rozm\xf3w, kt\xf3ry w standardowych testach branżowych przewyższa wiele istniejących modeli czatowych o otwartym kodzie."},"llama-4-scout-17b-16e-instruct":{"description":"Llama 4 Scout: wysokowydajny model z serii Llama, zaprojektowany do zastosowań wymagających dużej przepustowości i niskich op\xf3źnień."},"llama3-70b-8192":{"description":"Meta Llama 3 70B oferuje niezr\xf3wnane możliwości przetwarzania złożoności, dostosowane do projekt\xf3w o wysokich wymaganiach."},"llama3-8b-8192":{"description":"Meta Llama 3 8B zapewnia wysoką jakość wydajności wnioskowania, odpowiednią do r\xf3żnych zastosowań."},"llama3-groq-70b-8192-tool-use-preview":{"description":"Llama 3 Groq 70B Tool Use oferuje potężne możliwości wywoływania narzędzi, wspierając efektywne przetwarzanie złożonych zadań."},"llama3-groq-8b-8192-tool-use-preview":{"description":"Llama 3 Groq 8B Tool Use to model zoptymalizowany do efektywnego korzystania z narzędzi, wspierający szybkie obliczenia r\xf3wnoległe."},"llama3.1":{"description":"Llama 3.1 to wiodący model wydany przez Meta, obsługujący do 405B parametr\xf3w, mogący być stosowany w złożonych dialogach, tłumaczeniach wielojęzycznych i analizie danych."},"llama3.1-8b":{"description":"Llama 3.1 8B: lekka i niskolatencyjna wersja modelu Llama, odpowiednia do lekkich zadań inferencyjnych i interaktywnych online."},"llama3.1:405b":{"description":"Llama 3.1 to wiodący model wydany przez Meta, obsługujący do 405B parametr\xf3w, mogący być stosowany w złożonych dialogach, tłumaczeniach wielojęzycznych i analizie danych."},"llama3.1:70b":{"description":"Llama 3.1 to wiodący model wydany przez Meta, obsługujący do 405B parametr\xf3w, mogący być stosowany w złożonych dialogach, tłumaczeniach wielojęzycznych i analizie danych."},"llava":{"description":"LLaVA to multimodalny model łączący kodery wizualne i Vicunę, przeznaczony do silnego rozumienia wizualnego i językowego."},"llava-v1.5-7b-4096-preview":{"description":"LLaVA 1.5 7B oferuje zintegrowane możliwości przetwarzania wizualnego, generując złożone wyjścia na podstawie informacji wizualnych."},"llava:13b":{"description":"LLaVA to multimodalny model łączący kodery wizualne i Vicunę, przeznaczony do silnego rozumienia wizualnego i językowego."},"llava:34b":{"description":"LLaVA to multimodalny model łączący kodery wizualne i Vicunę, przeznaczony do silnego rozumienia wizualnego i językowego."},"magistral-medium-latest":{"description":"Magistral Medium 1.2 to zaawansowany model inferencyjny z obsługą wizualną, wydany przez Mistral AI we wrześniu 2025 roku."},"magistral-small-2509":{"description":"Magistral Small 1.2 to otwartoźr\xf3dłowy, kompaktowy model inferencyjny z obsługą wizualną, wydany przez Mistral AI we wrześniu 2025 roku."},"mathstral":{"description":"MathΣtral zaprojektowany do badań naukowych i wnioskowania matematycznego, oferujący efektywne możliwości obliczeniowe i interpretację wynik\xf3w."},"max-32k":{"description":"Spark Max 32K jest wyposażony w dużą zdolność przetwarzania kontekstu, oferując silniejsze zrozumienie kontekstu i zdolności logicznego wnioskowania, obsługując teksty o długości do 32K token\xf3w, co czyni go odpowiednim do czytania długich dokument\xf3w, prywatnych pytań i odpowiedzi oraz innych scenariuszy."},"megrez-3b-instruct":{"description":"Megrez 3B Instruct to kompaktowy i wydajny model opracowany przez Wuwen Xinqiong."},"meituan/longcat-flash-chat":{"description":"Longcat Flash Chat to otwartoźr\xf3dłowy model bazowy od Meituan, zoptymalizowany pod kątem interakcji dialogowych i zadań agentowych, wyr\xf3żniający się w scenariuszach wymagających użycia narzędzi i złożonych wieloetapowych konwersacji."},"meta-llama-3-70b-instruct":{"description":"Potężny model z 70 miliardami parametr\xf3w, doskonały w rozumowaniu, kodowaniu i szerokich zastosowaniach językowych."},"meta-llama-3-8b-instruct":{"description":"Wszechstronny model z 8 miliardami parametr\xf3w, zoptymalizowany do zadań dialogowych i generacji tekstu."},"meta-llama-3.1-405b-instruct":{"description":"Modele tekstowe Llama 3.1 dostosowane do instrukcji, zoptymalizowane do wielojęzycznych przypadk\xf3w użycia dialogowego, przewyższają wiele dostępnych modeli open source i zamkniętych w powszechnych benchmarkach branżowych."},"meta-llama-3.1-70b-instruct":{"description":"Modele tekstowe Llama 3.1 dostosowane do instrukcji, zoptymalizowane do wielojęzycznych przypadk\xf3w użycia dialogowego, przewyższają wiele dostępnych modeli open source i zamkniętych w powszechnych benchmarkach branżowych."},"meta-llama-3.1-8b-instruct":{"description":"Modele tekstowe Llama 3.1 dostosowane do instrukcji, zoptymalizowane do wielojęzycznych przypadk\xf3w użycia dialogowego, przewyższają wiele dostępnych modeli open source i zamkniętych w powszechnych benchmarkach branżowych."},"meta-llama/Llama-2-13b-chat-hf":{"description":"LLaMA-2 Chat (13B) oferuje doskonałe możliwości przetwarzania języka i znakomite doświadczenie interakcji."},"meta-llama/Llama-2-70b-hf":{"description":"LLaMA-2 oferuje doskonałe zdolności przetwarzania języka i znakomite doświadczenie interakcyjne."},"meta-llama/Llama-3-70b-chat-hf":{"description":"LLaMA-3 Chat (70B) to potężny model czatu, wspierający złożone potrzeby dialogowe."},"meta-llama/Llama-3-8b-chat-hf":{"description":"LLaMA-3 Chat (8B) oferuje wsparcie dla wielu język\xf3w, obejmując bogatą wiedzę z r\xf3żnych dziedzin."},"meta-llama/Llama-3.2-11B-Vision-Instruct-Turbo":{"description":"LLaMA 3.2 zaprojektowana do przetwarzania zadań łączących dane wizualne i tekstowe. Doskonała w zadaniach takich jak opisywanie obraz\xf3w i wizualne pytania odpowiedzi, przekracza granice między generowaniem języka a wnioskowaniem wizualnym."},"meta-llama/Llama-3.2-3B-Instruct-Turbo":{"description":"LLaMA 3.2 zaprojektowana do przetwarzania zadań łączących dane wizualne i tekstowe. Doskonała w zadaniach takich jak opisywanie obraz\xf3w i wizualne pytania odpowiedzi, przekracza granice między generowaniem języka a wnioskowaniem wizualnym."},"meta-llama/Llama-3.2-90B-Vision-Instruct-Turbo":{"description":"LLaMA 3.2 zaprojektowana do przetwarzania zadań łączących dane wizualne i tekstowe. Doskonała w zadaniach takich jak opisywanie obraz\xf3w i wizualne pytania odpowiedzi, przekracza granice między generowaniem języka a wnioskowaniem wizualnym."},"meta-llama/Llama-3.3-70B-Instruct-Turbo":{"description":"Meta Llama 3.3 to wielojęzyczny model językowy (LLM) o skali 70B (wejście/wyjście tekstowe), będący modelem generacyjnym wstępnie wytrenowanym i dostosowanym do instrukcji. Model Llama 3.3 dostosowany do instrukcji jest zoptymalizowany pod kątem zastosowań w dialogach wielojęzycznych i przewyższa wiele dostępnych modeli open-source i zamkniętych w popularnych testach branżowych."},"meta-llama/Llama-Vision-Free":{"description":"LLaMA 3.2 zaprojektowana do przetwarzania zadań łączących dane wizualne i tekstowe. Doskonała w zadaniach takich jak opisywanie obraz\xf3w i wizualne pytania odpowiedzi, przekracza granice między generowaniem języka a wnioskowaniem wizualnym."},"meta-llama/Meta-Llama-3-70B-Instruct-Lite":{"description":"Llama 3 70B Instruct Lite jest idealny do środowisk wymagających wysokiej wydajności i niskiego op\xf3źnienia."},"meta-llama/Meta-Llama-3-70B-Instruct-Turbo":{"description":"Llama 3 70B Instruct Turbo oferuje doskonałe możliwości rozumienia i generowania języka, idealny do najbardziej wymagających zadań obliczeniowych."},"meta-llama/Meta-Llama-3-8B-Instruct-Lite":{"description":"Llama 3 8B Instruct Lite jest dostosowany do środowisk z ograniczonymi zasobami, oferując doskonałą r\xf3wnowagę wydajności."},"meta-llama/Meta-Llama-3-8B-Instruct-Turbo":{"description":"Llama 3 8B Instruct Turbo to wydajny model językowy, wspierający szeroki zakres zastosowań."},"meta-llama/Meta-Llama-3.1-405B-Instruct":{"description":"LLaMA 3.1 405B to potężny model do wstępnego uczenia się i dostosowywania instrukcji."},"meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo":{"description":"Model Llama 3.1 Turbo 405B oferuje ogromną pojemność kontekstową dla przetwarzania dużych danych, wyr\xf3żniając się w zastosowaniach sztucznej inteligencji o dużej skali."},"meta-llama/Meta-Llama-3.1-70B":{"description":"Llama 3.1 to wiodący model wydany przez Meta, wspierający do 405B parametr\xf3w, mogący być stosowany w złożonych rozmowach, tłumaczeniach wielojęzycznych i analizie danych."},"meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo":{"description":"Model Llama 3.1 70B został starannie dostosowany do aplikacji o dużym obciążeniu, kwantyzowany do FP8, co zapewnia wyższą wydajność obliczeniową i dokładność, gwarantując doskonałe osiągi w złożonych scenariuszach."},"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo":{"description":"Model Llama 3.1 8B wykorzystuje kwantyzację FP8, obsługując do 131,072 kontekstowych token\xf3w, wyr\xf3żniając się wśr\xf3d modeli open source, idealny do złożonych zadań, przewyższający wiele branżowych standard\xf3w."},"meta-llama/llama-3-70b-instruct":{"description":"Llama 3 70B Instruct zoptymalizowano do wysokiej jakości dialog\xf3w, osiągając znakomite wyniki w r\xf3żnych ocenach ludzkich."},"meta-llama/llama-3-8b-instruct":{"description":"Llama 3 8B Instruct zoptymalizowano do wysokiej jakości scenariuszy dialogowych, osiągając lepsze wyniki niż wiele modeli zamkniętych."},"meta-llama/llama-3.1-70b-instruct":{"description":"Llama 3.1 70B Instruct zaprojektowano z myślą o wysokiej jakości dialogach, osiągając znakomite wyniki w ocenach ludzkich, szczeg\xf3lnie w scenariuszach o wysokiej interakcji."},"meta-llama/llama-3.1-8b-instruct":{"description":"Llama 3.1 8B Instruct to najnowsza wersja wydana przez Meta, zoptymalizowana do wysokiej jakości scenariuszy dialogowych, przewyższająca wiele wiodących modeli zamkniętych."},"meta-llama/llama-3.1-8b-instruct:free":{"description":"LLaMA 3.1 oferuje wsparcie dla wielu język\xf3w i jest jednym z wiodących modeli generacyjnych w branży."},"meta-llama/llama-3.2-11b-vision-instruct":{"description":"LLaMA 3.2 jest zaprojektowana do przetwarzania zadań łączących dane wizualne i tekstowe. Wykazuje doskonałe wyniki w zadaniach takich jak opisywanie obraz\xf3w i wizualne pytania i odpowiedzi, przekraczając granice między generowaniem języka a wnioskowaniem wizualnym."},"meta-llama/llama-3.2-3b-instruct":{"description":"meta-llama/llama-3.2-3b-instruct"},"meta-llama/llama-3.2-90b-vision-instruct":{"description":"LLaMA 3.2 jest zaprojektowana do przetwarzania zadań łączących dane wizualne i tekstowe. Wykazuje doskonałe wyniki w zadaniach takich jak opisywanie obraz\xf3w i wizualne pytania i odpowiedzi, przekraczając granice między generowaniem języka a wnioskowaniem wizualnym."},"meta-llama/llama-3.3-70b-instruct":{"description":"Llama 3.3 to najnowocześniejszy wielojęzyczny, otwarty model językowy z serii Llama, kt\xf3ry oferuje wydajność por\xf3wnywalną z modelem 405B przy bardzo niskich kosztach. Opiera się na strukturze Transformer i poprawia użyteczność oraz bezpieczeństwo dzięki nadzorowanemu dostrajaniu (SFT) i uczeniu ze wzmocnieniem na podstawie ludzkich opinii (RLHF). Jego wersja dostosowana do instrukcji jest zoptymalizowana do wielojęzycznych rozm\xf3w i w wielu branżowych benchmarkach przewyższa wiele otwartych i zamkniętych modeli czatu. Data graniczna wiedzy to grudzień 2023."},"meta-llama/llama-3.3-70b-instruct:free":{"description":"Llama 3.3 to najnowocześniejszy wielojęzyczny, otwarty model językowy z serii Llama, kt\xf3ry oferuje wydajność por\xf3wnywalną z modelem 405B przy bardzo niskich kosztach. Opiera się na strukturze Transformer i poprawia użyteczność oraz bezpieczeństwo dzięki nadzorowanemu dostrajaniu (SFT) i uczeniu ze wzmocnieniem na podstawie ludzkich opinii (RLHF). Jego wersja dostosowana do instrukcji jest zoptymalizowana do wielojęzycznych rozm\xf3w i w wielu branżowych benchmarkach przewyższa wiele otwartych i zamkniętych modeli czatu. Data graniczna wiedzy to grudzień 2023."},"meta.llama3-1-405b-instruct-v1:0":{"description":"Meta Llama 3.1 405B Instruct to największy i najpotężniejszy model w rodzinie modeli Llama 3.1 Instruct. Jest to wysoko zaawansowany model do dialog\xf3w, wnioskowania i generowania danych, kt\xf3ry może być r\xf3wnież używany jako podstawa do specjalistycznego, ciągłego wstępnego szkolenia lub dostosowywania w określonych dziedzinach. Llama 3.1 oferuje wielojęzyczne duże modele językowe (LLM), kt\xf3re są zestawem wstępnie wytrenowanych, dostosowanych do instrukcji modeli generacyjnych, obejmujących rozmiary 8B, 70B i 405B (wejście/wyjście tekstowe). Modele tekstowe Llama 3.1 dostosowane do instrukcji (8B, 70B, 405B) zostały zoptymalizowane do zastosowań w wielojęzycznych dialogach i przewyższają wiele dostępnych modeli czatu open source w powszechnych testach branżowych. Llama 3.1 jest zaprojektowana do użytku komercyjnego i badawczego w wielu językach. Modele tekstowe dostosowane do instrukcji nadają się do czatu w stylu asystenta, podczas gdy modele wstępnie wytrenowane mogą być dostosowane do r\xf3żnych zadań generowania języka naturalnego. Modele Llama 3.1 wspierają r\xf3wnież wykorzystanie ich wyjść do poprawy innych modeli, w tym generowania danych syntetycznych i udoskonalania. Llama 3.1 jest modelem językowym autoregresywnym opartym na zoptymalizowanej architekturze transformatora. Dostosowane wersje wykorzystują nadzorowane dostosowywanie (SFT) oraz uczenie się ze wzmocnieniem z ludzkim feedbackiem (RLHF), aby odpowiadać ludzkim preferencjom dotyczącym pomocności i bezpieczeństwa."},"meta.llama3-1-70b-instruct-v1:0":{"description":"Zaktualizowana wersja Meta Llama 3.1 70B Instruct, obejmująca rozszerzone 128K długości kontekstu, wielojęzyczność i poprawione zdolności wnioskowania. Llama 3.1 oferuje wielojęzyczne modele językowe (LLMs) jako zestaw wstępnie wytrenowanych, dostosowanych do instrukcji modeli generacyjnych, w tym rozmiar\xf3w 8B, 70B i 405B (wejście/wyjście tekstowe). Modele tekstowe Llama 3.1 dostosowane do instrukcji (8B, 70B, 405B) są zoptymalizowane do zastosowań w dialogach wielojęzycznych i przewyższają wiele dostępnych modeli czatu w powszechnych testach branżowych. Llama 3.1 jest przeznaczona do zastosowań komercyjnych i badawczych w wielu językach. Modele tekstowe dostosowane do instrukcji są odpowiednie do czatu podobnego do asystenta, podczas gdy modele wstępnie wytrenowane mogą być dostosowane do r\xf3żnych zadań generowania języka naturalnego. Modele Llama 3.1 wspierają r\xf3wnież wykorzystanie wynik\xf3w ich modeli do poprawy innych modeli, w tym generowania danych syntetycznych i rafinacji. Llama 3.1 jest modelem językowym autoregresywnym, wykorzystującym zoptymalizowaną architekturę transformatora. Wersje dostosowane wykorzystują nadzorowane dostrajanie (SFT) i uczenie się ze wzmocnieniem z ludzkim feedbackiem (RLHF), aby dostosować się do ludzkich preferencji dotyczących pomocności i bezpieczeństwa."},"meta.llama3-1-8b-instruct-v1:0":{"description":"Zaktualizowana wersja Meta Llama 3.1 8B Instruct, obejmująca rozszerzone 128K długości kontekstu, wielojęzyczność i poprawione zdolności wnioskowania. Llama 3.1 oferuje wielojęzyczne modele językowe (LLMs) jako zestaw wstępnie wytrenowanych, dostosowanych do instrukcji modeli generacyjnych, w tym rozmiar\xf3w 8B, 70B i 405B (wejście/wyjście tekstowe). Modele tekstowe Llama 3.1 dostosowane do instrukcji (8B, 70B, 405B) są zoptymalizowane do zastosowań w dialogach wielojęzycznych i przewyższają wiele dostępnych modeli czatu w powszechnych testach branżowych. Llama 3.1 jest przeznaczona do zastosowań komercyjnych i badawczych w wielu językach. Modele tekstowe dostosowane do instrukcji są odpowiednie do czatu podobnego do asystenta, podczas gdy modele wstępnie wytrenowane mogą być dostosowane do r\xf3żnych zadań generowania języka naturalnego. Modele Llama 3.1 wspierają r\xf3wnież wykorzystanie wynik\xf3w ich modeli do poprawy innych modeli, w tym generowania danych syntetycznych i rafinacji. Llama 3.1 jest modelem językowym autoregresywnym, wykorzystującym zoptymalizowaną architekturę transformatora. Wersje dostosowane wykorzystują nadzorowane dostrajanie (SFT) i uczenie się ze wzmocnieniem z ludzkim feedbackiem (RLHF), aby dostosować się do ludzkich preferencji dotyczących pomocności i bezpieczeństwa."},"meta.llama3-70b-instruct-v1:0":{"description":"Meta Llama 3 to otwarty duży model językowy (LLM) skierowany do deweloper\xf3w, badaczy i przedsiębiorstw, mający na celu pomoc w budowaniu, eksperymentowaniu i odpowiedzialnym rozwijaniu ich pomysł\xf3w na generatywną sztuczną inteligencję. Jako część podstawowego systemu innowacji globalnej społeczności, jest idealny do tworzenia treści, AI do dialog\xf3w, rozumienia języka, badań i zastosowań biznesowych."},"meta.llama3-8b-instruct-v1:0":{"description":"Meta Llama 3 to otwarty duży model językowy (LLM) skierowany do deweloper\xf3w, badaczy i przedsiębiorstw, mający na celu pomoc w budowaniu, eksperymentowaniu i odpowiedzialnym rozwijaniu ich pomysł\xf3w na generatywną sztuczną inteligencję. Jako część podstawowego systemu innowacji globalnej społeczności, jest idealny dla urządzeń o ograniczonej mocy obliczeniowej i zasobach, a także dla szybszego czasu szkolenia."},"meta/Llama-3.2-11B-Vision-Instruct":{"description":"Wysokiej jakości zdolności wnioskowania obrazowego na obrazach o wysokiej rozdzielczości, idealne do zastosowań związanych z rozumieniem wizualnym."},"meta/Llama-3.2-90B-Vision-Instruct":{"description":"Zaawansowane zdolności wnioskowania obrazowego przeznaczone do zastosowań agent\xf3w rozumienia wizualnego."},"meta/Llama-3.3-70B-Instruct":{"description":"Llama 3.3 to najnowocześniejszy wielojęzyczny, otwarty model językowy z serii Llama, oferujący wydajność por\xf3wnywalną z modelem 405B przy bardzo niskich kosztach. Opiera się na architekturze Transformer i jest ulepszony przez nadzorowane dostrajanie (SFT) oraz uczenie ze wzmocnieniem na podstawie opinii ludzi (RLHF). Wersja dostrojona pod kątem instrukcji jest zoptymalizowana do wielojęzycznych dialog\xf3w i przewyższa wiele otwartych i zamkniętych modeli czatu w licznych branżowych benchmarkach. Data odcięcia wiedzy: grudzień 2023."},"meta/Meta-Llama-3-70B-Instruct":{"description":"Potężny model o 70 miliardach parametr\xf3w, wyr\xf3żniający się wnioskowaniem, kodowaniem i szerokim zastosowaniem językowym."},"meta/Meta-Llama-3-8B-Instruct":{"description":"Wszechstronny model o 8 miliardach parametr\xf3w, zoptymalizowany do zadań dialogowych i generowania tekstu."},"meta/Meta-Llama-3.1-405B-Instruct":{"description":"Model tekstowy Llama 3.1 dostrojony pod kątem instrukcji, zoptymalizowany do wielojęzycznych zastosowań dialogowych, osiągający doskonałe wyniki w wielu dostępnych otwartych i zamkniętych modelach czatu na popularnych branżowych benchmarkach."},"meta/Meta-Llama-3.1-70B-Instruct":{"description":"Model tekstowy Llama 3.1 dostrojony pod kątem instrukcji, zoptymalizowany do wielojęzycznych zastosowań dialogowych, osiągający doskonałe wyniki w wielu dostępnych otwartych i zamkniętych modelach czatu na popularnych branżowych benchmarkach."},"meta/Meta-Llama-3.1-8B-Instruct":{"description":"Model tekstowy Llama 3.1 dostrojony pod kątem instrukcji, zoptymalizowany do wielojęzycznych zastosowań dialogowych, osiągający doskonałe wyniki w wielu dostępnych otwartych i zamkniętych modelach czatu na popularnych branżowych benchmarkach."},"meta/llama-3-70b":{"description":"Model open source o 70 miliardach parametr\xf3w, starannie dostrojony przez Meta do cel\xf3w przestrzegania instrukcji. Obsługiwany przez Groq na ich niestandardowym sprzęcie LPU, zapewnia szybkie i wydajne wnioskowanie."},"meta/llama-3-8b":{"description":"Model open source o 8 miliardach parametr\xf3w, starannie dostrojony przez Meta do cel\xf3w przestrzegania instrukcji. Obsługiwany przez Groq na ich niestandardowym sprzęcie LPU, zapewnia szybkie i wydajne wnioskowanie."},"meta/llama-3.1-405b-instruct":{"description":"Zaawansowany LLM, wspierający generowanie danych syntetycznych, destylację wiedzy i wnioskowanie, odpowiedni do chatbot\xf3w, programowania i zadań w określonych dziedzinach."},"meta/llama-3.1-70b":{"description":"Zaktualizowana wersja Meta Llama 3 70B Instruct, obejmująca rozszerzoną długość kontekstu 128K, wsparcie wielojęzyczne i ulepszone zdolności wnioskowania."},"meta/llama-3.1-70b-instruct":{"description":"Umożliwia złożone rozmowy, posiadając doskonałe zrozumienie kontekstu, zdolności wnioskowania i generowania tekstu."},"meta/llama-3.1-8b":{"description":"Llama 3.1 8B obsługuje okno kontekstu 128K, co czyni go idealnym wyborem do interfejs\xf3w rozm\xf3w na żywo i analizy danych, oferując jednocześnie znaczące oszczędności koszt\xf3w w por\xf3wnaniu z większymi modelami. Obsługiwany przez Groq na ich niestandardowym sprzęcie LPU, zapewnia szybkie i wydajne wnioskowanie."},"meta/llama-3.1-8b-instruct":{"description":"Zaawansowany, nowoczesny model, posiadający zrozumienie języka, doskonałe zdolności wnioskowania i generowania tekstu."},"meta/llama-3.2-11b":{"description":"Model generujący wnioskowania obrazowe dostosowany do instrukcji (wejście tekst + obraz / wyjście tekst), zoptymalizowany pod kątem rozpoznawania wizualnego, wnioskowania obrazowego, generowania podpis\xf3w i odpowiadania na og\xf3lne pytania dotyczące obraz\xf3w."},"meta/llama-3.2-11b-vision-instruct":{"description":"Nowoczesny model wizualno-językowy, specjalizujący się w wysokiej jakości wnioskowaniu z obraz\xf3w."},"meta/llama-3.2-1b":{"description":"Model tylko tekstowy, wspierający zastosowania na urządzeniach, takie jak wielojęzyczne lokalne wyszukiwanie wiedzy, streszczanie i przepisywanie."},"meta/llama-3.2-1b-instruct":{"description":"Zaawansowany, nowoczesny mały model językowy, posiadający zrozumienie języka, doskonałe zdolności wnioskowania i generowania tekstu."},"meta/llama-3.2-3b":{"description":"Model tylko tekstowy, starannie dostrojony do wspierania zastosowań na urządzeniach, takich jak wielojęzyczne lokalne wyszukiwanie wiedzy, streszczanie i przepisywanie."},"meta/llama-3.2-3b-instruct":{"description":"Zaawansowany, nowoczesny mały model językowy, posiadający zrozumienie języka, doskonałe zdolności wnioskowania i generowania tekstu."},"meta/llama-3.2-90b":{"description":"Model generujący wnioskowania obrazowe dostosowany do instrukcji (wejście tekst + obraz / wyjście tekst), zoptymalizowany pod kątem rozpoznawania wizualnego, wnioskowania obrazowego, generowania podpis\xf3w i odpowiadania na og\xf3lne pytania dotyczące obraz\xf3w."},"meta/llama-3.2-90b-vision-instruct":{"description":"Nowoczesny model wizualno-językowy, specjalizujący się w wysokiej jakości wnioskowaniu z obraz\xf3w."},"meta/llama-3.3-70b":{"description":"Idealne połączenie wydajności i efektywności. Model wspiera wysokowydajne AI konwersacyjne, zaprojektowany do tworzenia treści, zastosowań korporacyjnych i badań, oferując zaawansowane zdolności rozumienia języka, w tym streszczanie tekstu, klasyfikację, analizę sentymentu i generowanie kodu."},"meta/llama-3.3-70b-instruct":{"description":"Zaawansowany LLM, specjalizujący się w wnioskowaniu, matematyce, zdrowym rozsądku i wywoływaniu funkcji."},"meta/llama-4-maverick":{"description":"Zestaw modeli Llama 4 to natywne modele AI multimodalne, wspierające tekst i doświadczenia multimodalne. Modele te wykorzystują architekturę hybrydowych ekspert\xf3w, oferując wiodącą w branży wydajność w rozumieniu tekstu i obraz\xf3w. Llama 4 Maverick to model o 17 miliardach parametr\xf3w z 128 ekspertami. Dostarczany przez DeepInfra."},"meta/llama-4-scout":{"description":"Zestaw modeli Llama 4 to natywne modele AI multimodalne, wspierające tekst i doświadczenia multimodalne. Modele te wykorzystują architekturę hybrydowych ekspert\xf3w, oferując wiodącą w branży wydajność w rozumieniu tekstu i obraz\xf3w. Llama 4 Scout to model o 17 miliardach parametr\xf3w z 16 ekspertami. Dostarczany przez DeepInfra."},"microsoft/Phi-3-medium-128k-instruct":{"description":"Ten sam model Phi-3-medium, ale z większym rozmiarem kontekstu, odpowiedni do RAG lub nielicznych podpowiedzi."},"microsoft/Phi-3-medium-4k-instruct":{"description":"Model o 14 miliardach parametr\xf3w, lepszej jakości niż Phi-3-mini, skoncentrowany na wysokiej jakości i danych wymagających intensywnego wnioskowania."},"microsoft/Phi-3-mini-128k-instruct":{"description":"Ten sam model Phi-3-mini, ale z większym rozmiarem kontekstu, odpowiedni do RAG lub nielicznych podpowiedzi."},"microsoft/Phi-3-mini-4k-instruct":{"description":"Najmniejszy członek rodziny Phi-3, zoptymalizowany pod kątem jakości i niskich op\xf3źnień."},"microsoft/Phi-3-small-128k-instruct":{"description":"Ten sam model Phi-3-small, ale z większym rozmiarem kontekstu, odpowiedni do RAG lub nielicznych podpowiedzi."},"microsoft/Phi-3-small-8k-instruct":{"description":"Model o 7 miliardach parametr\xf3w, lepszej jakości niż Phi-3-mini, skoncentrowany na wysokiej jakości i danych wymagających intensywnego wnioskowania."},"microsoft/Phi-3.5-mini-instruct":{"description":"Zaktualizowana wersja modelu Phi-3-mini."},"microsoft/Phi-3.5-vision-instruct":{"description":"Zaktualizowana wersja modelu Phi-3-vision."},"microsoft/WizardLM-2-8x22B":{"description":"WizardLM 2 to model językowy oferowany przez Microsoft AI, kt\xf3ry wyr\xf3żnia się w złożonych rozmowach, wielojęzyczności, wnioskowaniu i jako inteligentny asystent."},"microsoft/wizardlm-2-8x22b":{"description":"WizardLM-2 8x22B to najnowocześniejszy model Wizard od Microsoftu, wykazujący niezwykle konkurencyjne osiągi."},"minicpm-v":{"description":"MiniCPM-V to nowa generacja multimodalnego dużego modelu wydanego przez OpenBMB, kt\xf3ry posiada doskonałe zdolności rozpoznawania OCR oraz zrozumienia multimodalnego, wspierając szeroki zakres zastosowań."},"minimax-m2":{"description":"MiniMax M2 to wydajny duży model językowy stworzony z myślą o kodowaniu i zautomatyzowanych przepływach pracy."},"minimax/minimax-m2":{"description":"Stworzony z myślą o wydajnym kodowaniu i przepływach pracy agent\xf3w."},"minimaxai/minimax-m2":{"description":"MiniMax-M2 to kompaktowy, szybki i ekonomiczny model MoE (Mixture of Experts) z 230 miliardami całkowitych parametr\xf3w i 10 miliardami aktywnych parametr\xf3w, zaprojektowany z myślą o najwyższej wydajności w zadaniach kodowania i agentowych, przy jednoczesnym zachowaniu silnej inteligencji og\xf3lnej. Model ten doskonale sprawdza się w edycji wielu plik\xf3w, zamkniętej pętli kodowanie-uruchamianie-naprawa, testowaniu i weryfikacji poprawek oraz w złożonych, długich łańcuchach narzędziowych, co czyni go idealnym wyborem dla przepływ\xf3w pracy deweloper\xf3w."},"ministral-3b-latest":{"description":"Ministral 3B to czołowy model brzegowy Mistrala."},"ministral-8b-latest":{"description":"Ministral 8B to opłacalny model brzegowy Mistrala."},"mistral":{"description":"Mistral to model 7B wydany przez Mistral AI, odpowiedni do zmiennych potrzeb przetwarzania języka."},"mistral-ai/Mistral-Large-2411":{"description":"Flagowy model Mistral, odpowiedni do zadań wymagających dużej mocy obliczeniowej lub wysoko wyspecjalizowanych, takich jak generowanie tekstu syntetycznego, generowanie kodu, RAG lub agent\xf3w."},"mistral-ai/Mistral-Nemo":{"description":"Mistral Nemo to nowoczesny model językowy (LLM) oferujący najlepsze w swojej klasie zdolności wnioskowania, wiedzy o świecie i kodowania."},"mistral-ai/mistral-small-2503":{"description":"Mistral Small jest przeznaczony do wszelkich zadań językowych wymagających wysokiej wydajności i niskich op\xf3źnień."},"mistral-large":{"description":"Mixtral Large to flagowy model Mistral, łączący zdolności generowania kodu, matematyki i wnioskowania, wspierający kontekst o długości 128k."},"mistral-large-instruct":{"description":"Mistral-Large-Instruct-2407 to zaawansowany gęsty model językowy o dużym rozmiarze (LLM) z 123 miliardami parametr\xf3w, posiadający najnowocześniejsze zdolności wnioskowania, wiedzy i kodowania."},"mistral-large-latest":{"description":"Mistral Large to flagowy model, doskonały w zadaniach wielojęzycznych, złożonym wnioskowaniu i generowaniu kodu, idealny do zaawansowanych zastosowań."},"mistral-medium-latest":{"description":"Mistral Medium 3 oferuje najnowocześniejszą wydajność przy kosztach 8 razy niższych, a także zasadniczo upraszcza wdrożenia w przedsiębiorstwach."},"mistral-nemo":{"description":"Mistral Nemo, opracowany przez Mistral AI i NVIDIA, to model 12B o wysokiej wydajności."},"mistral-nemo-instruct":{"description":"Duży model językowy (LLM) Mistral-Nemo-Instruct-2407 to wersja dostosowana do poleceń modelu Mistral-Nemo-Base-2407."},"mistral-small":{"description":"Mistral Small może być używany w każdym zadaniu opartym na języku, kt\xf3re wymaga wysokiej wydajności i niskiej latencji."},"mistral-small-latest":{"description":"Mistral Small to opcja o wysokiej efektywności kosztowej, szybka i niezawodna, odpowiednia do tłumaczeń, podsumowań i analizy sentymentu."},"mistral/codestral":{"description":"Mistral Codestral 25.01 to najnowocześniejszy model kodowania, zoptymalizowany pod kątem niskich op\xf3źnień i wysokiej częstotliwości zastosowań. Obsługuje ponad 80 język\xf3w programowania i wyr\xf3żnia się w zadaniach takich jak wypełnianie środkowe (FIM), korekta kodu i generowanie test\xf3w."},"mistral/codestral-embed":{"description":"Model osadzeń kodu, kt\xf3ry można osadzić w bazach danych i repozytoriach kodu, wspierający asystent\xf3w kodowania."},"mistral/devstral-small":{"description":"Devstral to agentowy duży model językowy do zadań inżynierii oprogramowania, idealny jako agent inżynierii oprogramowania."},"mistral/magistral-medium":{"description":"Złożone myślenie wspierane głębokim zrozumieniem, z przejrzystym rozumowaniem, kt\xf3re można śledzić i weryfikować. Model utrzymuje wysoką wierność rozumowania w wielu językach, nawet przy zmianie języka w trakcie zadania."},"mistral/magistral-small":{"description":"Złożone myślenie wspierane głębokim zrozumieniem, z przejrzystym rozumowaniem, kt\xf3re można śledzić i weryfikować. Model utrzymuje wysoką wierność rozumowania w wielu językach, nawet przy zmianie języka w trakcie zadania."},"mistral/ministral-3b":{"description":"Kompaktowy, wydajny model do zadań na urządzeniach, takich jak inteligentni asystenci i lokalna analiza, oferujący niskie op\xf3źnienia."},"mistral/ministral-8b":{"description":"Mocniejszy model z szybszym i bardziej pamięciooszczędnym wnioskowaniem, idealny do złożonych przepływ\xf3w pracy i wymagających zastosowań brzegowych."},"mistral/mistral-embed":{"description":"Uniwersalny model osadzeń tekstowych do wyszukiwania semantycznego, podobieństwa, klastrowania i przepływ\xf3w pracy RAG."},"mistral/mistral-large":{"description":"Mistral Large to idealny wyb\xf3r do złożonych zadań wymagających dużej mocy wnioskowania lub wysokiej specjalizacji — takich jak generowanie tekstu syntetycznego, generowanie kodu, RAG lub agenci."},"mistral/mistral-small":{"description":"Mistral Small to idealny wyb\xf3r do prostych zadań, kt\xf3re można przetwarzać hurtowo — takich jak klasyfikacja, obsługa klienta czy generowanie tekstu. Oferuje doskonałą wydajność w przystępnej cenie."},"mistral/mixtral-8x22b-instruct":{"description":"Model 8x22b Instruct. 8x22b to otwarty model hybrydowych ekspert\xf3w obsługiwany przez Mistral."},"mistral/pixtral-12b":{"description":"Model 12B z umiejętnościami rozumienia obraz\xf3w oraz tekstu."},"mistral/pixtral-large":{"description":"Pixtral Large to drugi model w naszej rodzinie multimodalnej, prezentujący zaawansowany poziom rozumienia obraz\xf3w. Model potrafi rozumieć dokumenty, wykresy i obrazy naturalne, zachowując jednocześnie wiodące zdolności rozumienia tekstu Mistral Large 2."},"mistralai/Mistral-7B-Instruct-v0.1":{"description":"Mistral (7B) Instruct jest znany z wysokiej wydajności, idealny do r\xf3żnorodnych zadań językowych."},"mistralai/Mistral-7B-Instruct-v0.2":{"description":"Mistral 7B to model dostosowany na żądanie, oferujący zoptymalizowane odpowiedzi na zadania."},"mistralai/Mistral-7B-Instruct-v0.3":{"description":"Mistral (7B) Instruct v0.3 oferuje efektywne możliwości obliczeniowe i rozumienia języka naturalnego, idealne do szerokiego zakresu zastosowań."},"mistralai/Mistral-7B-v0.1":{"description":"Mistral 7B to kompaktowy, ale wysokowydajny model, dobrze radzący sobie z przetwarzaniem wsadowym i prostymi zadaniami, takimi jak klasyfikacja i generowanie tekstu, z dobrą zdolnością wnioskowania."},"mistralai/Mixtral-8x22B-Instruct-v0.1":{"description":"Mixtral-8x22B Instruct (141B) to super duży model językowy, wspierający ekstremalne wymagania przetwarzania."},"mistralai/Mixtral-8x7B-Instruct-v0.1":{"description":"Mixtral 8x7B to wstępnie wytrenowany model rzadkiego mieszania ekspert\xf3w, przeznaczony do og\xf3lnych zadań tekstowych."},"mistralai/Mixtral-8x7B-v0.1":{"description":"Mixtral 8x7B to model sparsity expert, kt\xf3ry korzysta z wielu parametr\xf3w, aby zwiększyć prędkość wnioskowania, idealny do przetwarzania zadań wielojęzycznych i generowania kodu."},"mistralai/mistral-nemo":{"description":"Mistral Nemo to model z 7,3 miliardami parametr\xf3w, wspierający wiele język\xf3w i wysoką wydajność programowania."},"mixtral":{"description":"Mixtral to model ekspercki Mistral AI, z otwartymi wagami, oferujący wsparcie w generowaniu kodu i rozumieniu języka."},"mixtral-8x7b-32768":{"description":"Mixtral 8x7B oferuje wysoką tolerancję na błędy w obliczeniach r\xf3wnoległych, odpowiednią do złożonych zadań."},"mixtral:8x22b":{"description":"Mixtral to model ekspercki Mistral AI, z otwartymi wagami, oferujący wsparcie w generowaniu kodu i rozumieniu języka."},"moonshot-v1-128k":{"description":"Moonshot V1 128K to model o zdolności przetwarzania kontekstu o ultra-długiej długości, odpowiedni do generowania bardzo długich tekst\xf3w, spełniający wymagania złożonych zadań generacyjnych, zdolny do przetwarzania treści do 128 000 token\xf3w, idealny do zastosowań w badaniach, akademickich i generowaniu dużych dokument\xf3w."},"moonshot-v1-128k-vision-preview":{"description":"Model wizualny Kimi (w tym moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-preview itp.) potrafi rozumieć treść obraz\xf3w, w tym teksty na obrazach, kolory obraz\xf3w i kształty obiekt\xf3w."},"moonshot-v1-32k":{"description":"Moonshot V1 32K oferuje zdolność przetwarzania kontekstu o średniej długości, zdolną do przetwarzania 32 768 token\xf3w, szczeg\xf3lnie odpowiednią do generowania r\xf3żnych długich dokument\xf3w i złożonych dialog\xf3w, stosowaną w tworzeniu treści, generowaniu raport\xf3w i systemach dialogowych."},"moonshot-v1-32k-vision-preview":{"description":"Model wizualny Kimi (w tym moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-preview itp.) potrafi rozumieć treść obraz\xf3w, w tym teksty na obrazach, kolory obraz\xf3w i kształty obiekt\xf3w."},"moonshot-v1-8k":{"description":"Moonshot V1 8K zaprojektowany do generowania kr\xf3tkich tekst\xf3w, charakteryzuje się wydajnością przetwarzania, zdolny do przetwarzania 8 192 token\xf3w, idealny do kr\xf3tkich dialog\xf3w, notatek i szybkiego generowania treści."},"moonshot-v1-8k-vision-preview":{"description":"Model wizualny Kimi (w tym moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-preview itp.) potrafi rozumieć treść obraz\xf3w, w tym teksty na obrazach, kolory obraz\xf3w i kształty obiekt\xf3w."},"moonshot-v1-auto":{"description":"Moonshot V1 Auto może wybierać odpowiedni model w zależności od liczby token\xf3w zajmowanych przez bieżący kontekst."},"moonshotai/Kimi-Dev-72B":{"description":"Kimi-Dev-72B to otwarty model kodu źr\xf3dłowego, zoptymalizowany za pomocą zaawansowanego uczenia ze wzmocnieniem, zdolny do generowania stabilnych, gotowych do produkcji poprawek. Model osiągnął nowy rekord 60,4% na SWE-bench Verified, ustanawiając nowy standard w zadaniach automatyzacji inżynierii oprogramowania, takich jak naprawa błęd\xf3w i przegląd kodu."},"moonshotai/Kimi-K2-Instruct-0905":{"description":"Kimi K2-Instruct-0905 to najnowsza i najpotężniejsza wersja Kimi K2. Jest to zaawansowany model językowy typu Mixture of Experts (MoE) z 1 bilionem parametr\xf3w og\xf3łem i 32 miliardami aktywowanych parametr\xf3w. Gł\xf3wne cechy modelu to: wzmocniona inteligencja kodowania agent\xf3w, kt\xf3ra wykazuje znaczącą poprawę wydajności w publicznych testach por\xf3wnawczych oraz w rzeczywistych zadaniach kodowania agent\xf3w; ulepszone doświadczenie kodowania front-end, z postępami zar\xf3wno w estetyce, jak i funkcjonalności programowania front-endowego."},"moonshotai/kimi-k2":{"description":"Kimi K2 to duży model językowy hybrydowych ekspert\xf3w (MoE) opracowany przez Moonshot AI, z 1 bilionem parametr\xf3w łącznie i 32 miliardami aktywnych parametr\xf3w na pojedyncze przejście. Model jest zoptymalizowany pod kątem zdolności agentowych, w tym zaawansowanego użycia narzędzi, wnioskowania i syntezy kodu."},"moonshotai/kimi-k2-0905":{"description":"Model kimi-k2-0905-preview obsługuje długość kontekstu do 256k, oferując silniejsze zdolności Agentic Coding, bardziej estetyczny i praktyczny kod frontendowy oraz lepsze rozumienie kontekstu."},"moonshotai/kimi-k2-instruct-0905":{"description":"Model kimi-k2-0905-preview obsługuje długość kontekstu do 256k, oferując silniejsze zdolności Agentic Coding, bardziej estetyczny i praktyczny kod frontendowy oraz lepsze rozumienie kontekstu."},"morph/morph-v3-fast":{"description":"Morph oferuje specjalistyczny model AI, kt\xf3ry szybko stosuje zmiany kodu sugerowane przez najnowocześniejsze modele, takie jak Claude czy GPT-4o, do istniejących plik\xf3w kodu — SZYBKOŚĆ ponad 4500 token\xf3w/sekundę. Działa jako ostatni krok w przepływie pracy kodowania AI. Obsługuje 16k token\xf3w wejściowych i 16k token\xf3w wyjściowych."},"morph/morph-v3-large":{"description":"Morph oferuje specjalistyczny model AI, kt\xf3ry stosuje zmiany kodu sugerowane przez najnowocześniejsze modele, takie jak Claude czy GPT-4o, do istniejących plik\xf3w kodu — SZYBKOŚĆ ponad 2500 token\xf3w/sekundę. Działa jako ostatni krok w przepływie pracy kodowania AI. Obsługuje 16k token\xf3w wejściowych i 16k token\xf3w wyjściowych."},"nousresearch/hermes-2-pro-llama-3-8b":{"description":"Hermes 2 Pro Llama 3 8B to ulepszona wersja Nous Hermes 2, zawierająca najnowsze wewnętrznie opracowane zbiory danych."},"nvidia/Llama-3.1-Nemotron-70B-Instruct-HF":{"description":"Llama 3.1 Nemotron 70B to dostosowany przez NVIDIA duży model językowy, mający na celu zwiększenie użyteczności odpowiedzi generowanych przez LLM w odpowiedzi na zapytania użytkownik\xf3w. Model ten osiągnął doskonałe wyniki w testach benchmarkowych, takich jak Arena Hard, AlpacaEval 2 LC i GPT-4-Turbo MT-Bench, zajmując pierwsze miejsce we wszystkich trzech automatycznych testach do 1 października 2024 roku. Model został przeszkolony przy użyciu RLHF (szczeg\xf3lnie REINFORCE), Llama-3.1-Nemotron-70B-Reward i HelpSteer2-Preference na bazie modelu Llama-3.1-70B-Instruct."},"nvidia/llama-3.1-nemotron-51b-instruct":{"description":"Unikalny model językowy, oferujący niezr\xf3wnaną dokładność i wydajność."},"nvidia/llama-3.1-nemotron-70b-instruct":{"description":"Llama-3.1-Nemotron-70B-Instruct to dostosowany przez NVIDIA duży model językowy, zaprojektowany w celu zwiększenia użyteczności odpowiedzi generowanych przez LLM."},"o1":{"description":"Skupia się na zaawansowanym wnioskowaniu i rozwiązywaniu złożonych problem\xf3w, w tym zadań matematycznych i naukowych. Doskonale nadaje się do aplikacji wymagających głębokiego zrozumienia kontekstu i zarządzania procesami."},"o1-mini":{"description":"o1-mini to szybki i ekonomiczny model wnioskowania zaprojektowany z myślą o programowaniu, matematyce i zastosowaniach naukowych. Model ten ma kontekst 128K i datę graniczną wiedzy z października 2023 roku."},"o1-preview":{"description":"Skoncentrowany na zaawansowanym wnioskowaniu i rozwiązywaniu złożonych problem\xf3w, w tym zadań matematycznych i naukowych. Doskonale nadaje się do zastosowań wymagających głębokiego zrozumienia kontekstu i autonomicznych przepływ\xf3w pracy."},"o1-pro":{"description":"Modele z serii o1 są trenowane z wykorzystaniem uczenia ze wzmocnieniem, potrafią myśleć przed udzieleniem odpowiedzi i wykonywać złożone zadania rozumowania. Model o1-pro wykorzystuje więcej zasob\xf3w obliczeniowych, aby prowadzić głębsze rozważania i stale dostarczać lepsze odpowiedzi."},"o3":{"description":"o3 to wszechstronny i potężny model, kt\xf3ry doskonale sprawdza się w wielu dziedzinach. Ustanawia nowe standardy w zadaniach matematycznych, naukowych, programistycznych i wizualnych. Jest r\xf3wnież biegły w pisaniu technicznym i przestrzeganiu instrukcji. Użytkownicy mogą go wykorzystać do analizy tekst\xf3w, kod\xf3w i obraz\xf3w, rozwiązując złożone problemy wieloetapowe."},"o3-2025-04-16":{"description":"o3 to nowy model rozumowania OpenAI, obsługujący wejścia tekstowo-obrazowe i generujący tekst, przeznaczony do złożonych zadań wymagających szerokiej wiedzy og\xf3lnej."},"o3-deep-research":{"description":"o3-deep-research to nasz najbardziej zaawansowany model głębokich badań, zaprojektowany specjalnie do obsługi złożonych, wieloetapowych zadań badawczych. Potrafi wyszukiwać i integrować informacje z internetu, a także uzyskiwać dostęp do Twoich własnych danych i wykorzystywać je za pośrednictwem łącznika MCP."},"o3-mini":{"description":"o3-mini to nasz najnowszy mały model wnioskowania, kt\xf3ry oferuje wysoką inteligencję przy tych samych kosztach i celach op\xf3źnienia co o1-mini."},"o3-pro":{"description":"Model o3-pro wykorzystuje większą moc obliczeniową do głębszego myślenia i zawsze dostarcza lepsze odpowiedzi, dostępny wyłącznie przez API Responses."},"o3-pro-2025-06-10":{"description":"o3 Pro to nowy model rozumowania OpenAI, obsługujący wejścia tekstowo-obrazowe i generujący tekst, przeznaczony do złożonych zadań wymagających szerokiej wiedzy og\xf3lnej."},"o4-mini":{"description":"o4-mini to nasz najnowszy mały model z serii o. Został zoptymalizowany do szybkiego i efektywnego wnioskowania, osiągając wysoką wydajność i efektywność w zadaniach kodowania i wizualnych."},"o4-mini-2025-04-16":{"description":"o4-mini to model rozumowania OpenAI, obsługujący wejścia tekstowo-obrazowe i generujący tekst, przeznaczony do złożonych zadań wymagających szerokiej wiedzy og\xf3lnej. Model posiada kontekst o długości 200 tys. token\xf3w."},"o4-mini-deep-research":{"description":"o4-mini-deep-research to nasz szybszy i bardziej przystępny cenowo model głębokich badań — idealny do obsługi złożonych, wieloetapowych zadań badawczych. Potrafi wyszukiwać i integrować informacje z internetu, a także uzyskiwać dostęp do Twoich własnych danych i wykorzystywać je za pośrednictwem łącznika MCP."},"open-codestral-mamba":{"description":"Codestral Mamba to model językowy Mamba 2 skoncentrowany na generowaniu kodu, oferujący silne wsparcie dla zaawansowanych zadań kodowania i wnioskowania."},"open-mistral-7b":{"description":"Mistral 7B to kompaktowy, ale wydajny model, doskonały do przetwarzania wsadowego i prostych zadań, takich jak klasyfikacja i generowanie tekstu, z dobrą wydajnością wnioskowania."},"open-mistral-nemo":{"description":"Mistral Nemo to model 12B opracowany we wsp\xf3łpracy z Nvidia, oferujący doskonałe możliwości wnioskowania i kodowania, łatwy do integracji i zastąpienia."},"open-mixtral-8x22b":{"description":"Mixtral 8x22B to większy model eksperta, skoncentrowany na złożonych zadaniach, oferujący doskonałe możliwości wnioskowania i wyższą przepustowość."},"open-mixtral-8x7b":{"description":"Mixtral 8x7B to model rzadkiego eksperta, kt\xf3ry wykorzystuje wiele parametr\xf3w do zwiększenia prędkości wnioskowania, odpowiedni do przetwarzania zadań wielojęzycznych i generowania kodu."},"openai/gpt-3.5-turbo":{"description":"Najbardziej kompetentny i opłacalny model z serii GPT-3.5 od OpenAI, zoptymalizowany pod kątem czatu, ale r\xf3wnież dobrze radzący sobie z tradycyjnymi zadaniami uzupełniania."},"openai/gpt-3.5-turbo-instruct":{"description":"Model o zdolnościach podobnych do modeli z ery GPT-3, kompatybilny z tradycyjnymi punktami końcowymi uzupełniania, a nie czatu."},"openai/gpt-4-turbo":{"description":"gpt-4-turbo od OpenAI posiada szeroką wiedzę og\xf3lną i specjalistyczną, umożliwiającą wykonywanie złożonych instrukcji w języku naturalnym i precyzyjne rozwiązywanie trudnych problem\xf3w. Data zakończenia wiedzy to kwiecień 2023, a okno kontekstu wynosi 128 000 token\xf3w."},"openai/gpt-4.1":{"description":"GPT 4.1 to flagowy model OpenAI, przeznaczony do złożonych zadań. Doskonale nadaje się do rozwiązywania problem\xf3w międzydziedzinowych."},"openai/gpt-4.1-mini":{"description":"GPT 4.1 mini osiąga r\xf3wnowagę między inteligencją, szybkością i kosztami, czyniąc go atrakcyjnym modelem dla wielu zastosowań."},"openai/gpt-4.1-nano":{"description":"GPT-4.1 nano to najszybszy i najbardziej opłacalny model GPT 4.1."},"openai/gpt-4o":{"description":"GPT-4o od OpenAI posiada szeroką wiedzę og\xf3lną i specjalistyczną, umożliwiającą wykonywanie złożonych instrukcji w języku naturalnym i precyzyjne rozwiązywanie trudnych problem\xf3w. Oferuje wydajność por\xf3wnywalną z GPT-4 Turbo, ale z szybszym i tańszym API."},"openai/gpt-4o-mini":{"description":"GPT-4o mini od OpenAI to ich najbardziej zaawansowany i opłacalny mały model. Jest multimodalny (przyjmuje tekst lub obrazy i generuje tekst) oraz inteligentniejszy niż gpt-3.5-turbo, zachowując podobną szybkość."},"openai/gpt-5":{"description":"GPT-5 to flagowy model językowy OpenAI, wyr\xf3żniający się w złożonym wnioskowaniu, szerokiej wiedzy o świecie, zadaniach intensywnie kodujących i wieloetapowych zadaniach agentowych."},"openai/gpt-5-mini":{"description":"GPT-5 mini to model zoptymalizowany pod kątem koszt\xf3w, oferujący doskonałą wydajność w zadaniach wnioskowania i czatu. Zapewnia najlepszą r\xf3wnowagę między szybkością, kosztami i możliwościami."},"openai/gpt-5-nano":{"description":"GPT-5 nano to model o wysokiej przepustowości, doskonały w prostych zadaniach instrukcyjnych lub klasyfikacyjnych."},"openai/gpt-oss-120b":{"description":"Niezwykle kompetentny, uniwersalny duży model językowy z potężnymi i kontrolowanymi zdolnościami wnioskowania."},"openai/gpt-oss-20b":{"description":"Kompaktowy model językowy z otwartym kodem, zoptymalizowany pod kątem niskich op\xf3źnień i środowisk o ograniczonych zasobach, w tym wdrożeń lokalnych i brzegowych."},"openai/o1":{"description":"o1 od OpenAI to flagowy model wnioskowania, zaprojektowany do złożonych problem\xf3w wymagających głębokiego myślenia. Zapewnia potężne zdolności wnioskowania i wyższą dokładność w złożonych, wieloetapowych zadaniach."},"openai/o1-mini":{"description":"o1-mini to szybki i ekonomiczny model wnioskowania zaprojektowany z myślą o programowaniu, matematyce i zastosowaniach naukowych. Model ten ma kontekst 128K i datę graniczną wiedzy z października 2023 roku."},"openai/o1-preview":{"description":"o1 to nowy model wnioskowania OpenAI, odpowiedni do złożonych zadań wymagających szerokiej wiedzy og\xf3lnej. Model ten ma kontekst 128K i datę graniczną wiedzy z października 2023 roku."},"openai/o3":{"description":"o3 od OpenAI to najsilniejszy model wnioskowania, ustanawiający nowe standardy w kodowaniu, matematyce, nauce i percepcji wizualnej. Doskonale radzi sobie ze złożonymi zapytaniami wymagającymi wieloaspektowej analizy, z wyjątkowymi zdolnościami w analizie obraz\xf3w, wykres\xf3w i graf\xf3w."},"openai/o3-mini":{"description":"o3-mini to najnowszy mały model wnioskowania OpenAI, oferujący wysoką inteligencję przy tych samych celach kosztowych i op\xf3źnieniowych co o1-mini."},"openai/o3-mini-high":{"description":"o3-mini w wersji o wysokim poziomie rozumowania, oferujący wysoką inteligencję przy tych samych kosztach i celach op\xf3źnienia co o1-mini."},"openai/o4-mini":{"description":"o4-mini od OpenAI oferuje szybkie i opłacalne wnioskowanie z doskonałą wydajnością w swojej klasie, szczeg\xf3lnie w zadaniach matematycznych (najlepsze wyniki w benchmarku AIME), kodowaniu i zadaniach wizualnych."},"openai/o4-mini-high":{"description":"o4-mini w wersji o wysokim poziomie wnioskowania, zoptymalizowany do szybkiego i efektywnego wnioskowania, osiągający wysoką wydajność i efektywność w zadaniach kodowania i wizualnych."},"openai/text-embedding-3-large":{"description":"Najbardziej kompetentny model osadzeń OpenAI, odpowiedni do zadań w języku angielskim i innych językach."},"openai/text-embedding-3-small":{"description":"Ulepszona, bardziej wydajna wersja modelu osadzeń ada od OpenAI."},"openai/text-embedding-ada-002":{"description":"Tradycyjny model osadzeń tekstowych od OpenAI."},"openrouter/auto":{"description":"W zależności od długości kontekstu, tematu i złożoności, Twoje zapytanie zostanie wysłane do Llama 3 70B Instruct, Claude 3.5 Sonnet (samoregulacja) lub GPT-4o."},"perplexity/sonar":{"description":"Lekki produkt Perplexity z funkcją wyszukiwania, szybszy i tańszy niż Sonar Pro."},"perplexity/sonar-pro":{"description":"Flagowy produkt Perplexity z funkcją wyszukiwania, obsługujący zaawansowane zapytania i działania następcze."},"perplexity/sonar-reasoning":{"description":"Model skoncentrowany na wnioskowaniu, generujący łańcuchy myślowe (CoT) w odpowiedziach, oferujący szczeg\xf3łowe wyjaśnienia z funkcją wyszukiwania."},"perplexity/sonar-reasoning-pro":{"description":"Zaawansowany model skoncentrowany na wnioskowaniu, generujący łańcuchy myślowe (CoT) w odpowiedziach, oferujący ulepszone możliwości wyszukiwania i wielokrotne zapytania wyszukiwania na każde żądanie."},"phi3":{"description":"Phi-3 to lekki model otwarty wydany przez Microsoft, odpowiedni do efektywnej integracji i dużej skali wnioskowania wiedzy."},"phi3:14b":{"description":"Phi-3 to lekki model otwarty wydany przez Microsoft, odpowiedni do efektywnej integracji i dużej skali wnioskowania wiedzy."},"pixtral-12b-2409":{"description":"Model Pixtral wykazuje silne zdolności w zadaniach związanych z analizą wykres\xf3w i zrozumieniem obraz\xf3w, pytaniami dokumentowymi, wielomodalnym rozumowaniem i przestrzeganiem instrukcji, zdolny do przyjmowania obraz\xf3w w naturalnej rozdzielczości i proporcjach, a także do przetwarzania dowolnej liczby obraz\xf3w w długim oknie kontekstowym o długości do 128K token\xf3w."},"pixtral-large-latest":{"description":"Pixtral Large to otwarty model wielomodalny z 124 miliardami parametr\xf3w, zbudowany na bazie Mistral Large 2. To nasz drugi model w rodzinie wielomodalnej, kt\xf3ry wykazuje zaawansowane zdolności rozumienia obraz\xf3w."},"pro-128k":{"description":"Spark Pro 128K jest wyposażony w wyjątkową zdolność przetwarzania kontekstu, mogąc obsługiwać do 128K informacji kontekstowych, co czyni go idealnym do analizy całościowej i długoterminowego przetwarzania logicznych powiązań w długich treściach, zapewniając płynność i sp\xf3jność logiczną oraz r\xf3żnorodne wsparcie cytat\xf3w w złożonej komunikacji tekstowej."},"pro-deepseek-r1":{"description":"Model przeznaczony do usług dedykowanych dla przedsiębiorstw, obsługujący usługi r\xf3wnoległe."},"pro-deepseek-v3":{"description":"Model przeznaczony do usług dedykowanych dla przedsiębiorstw, obsługujący usługi r\xf3wnoległe."},"qianfan-70b":{"description":"Qianfan 70B, duży chiński model językowy, odpowiedni do generowania treści wysokiej jakości i złożonych zadań wnioskowania."},"qianfan-8b":{"description":"Qianfan 8B, średniej wielkości uniwersalny model, idealny do generowania tekstu i scenariuszy pytań i odpowiedzi z r\xf3wnowagą między kosztem a wydajnością."},"qianfan-agent-intent-32k":{"description":"Qianfan Agent Intent 32K, model do rozpoznawania intencji i orkiestracji agent\xf3w, obsługujący scenariusze z długim kontekstem."},"qianfan-agent-lite-8k":{"description":"Qianfan Agent Lite 8K, lekki model agenta, odpowiedni do niskokosztowych, wieloetapowych dialog\xf3w i orkiestracji proces\xf3w biznesowych."},"qianfan-agent-speed-32k":{"description":"Qianfan Agent Speed 32K, model agenta o wysokiej przepustowości, idealny do dużych, wielozadaniowych aplikacji agentowych."},"qianfan-agent-speed-8k":{"description":"Qianfan Agent Speed 8K, model agenta o wysokiej r\xf3wnoległości, przeznaczony do kr\xf3tkich dialog\xf3w i szybkich odpowiedzi."},"qianfan-check-vl":{"description":"Qianfan Check VL, multimodalny model do moderacji i wykrywania treści, wspierający zgodność i rozpoznawanie obraz\xf3w i tekstu."},"qianfan-composition":{"description":"Qianfan Composition, multimodalny model tw\xf3rczy, obsługujący zintegrowane rozumienie i generowanie obraz\xf3w i tekstu."},"qianfan-engcard-vl":{"description":"Qianfan EngCard VL, multimodalny model rozpoznawania skoncentrowany na scenariuszach w języku angielskim."},"qianfan-lightning-128b-a19b":{"description":"Qianfan Lightning 128B A19B, wydajny chiński model og\xf3lnego przeznaczenia, odpowiedni do złożonych pytań i dużych zadań wnioskowania."},"qianfan-llama-vl-8b":{"description":"Qianfan Llama VL 8B, multimodalny model oparty na Llama, przeznaczony do og\xf3lnych zadań rozumienia obraz\xf3w i tekstu."},"qianfan-multipicocr":{"description":"Qianfan MultiPicOCR, model OCR dla wielu obraz\xf3w, obsługujący wykrywanie i rozpoznawanie tekstu na wielu zdjęciach."},"qianfan-qi-vl":{"description":"Qianfan QI VL, multimodalny model pytań i odpowiedzi, wspierający precyzyjne wyszukiwanie i odpowiedzi w złożonych scenariuszach obrazowo-tekstowych."},"qianfan-singlepicocr":{"description":"Qianfan SinglePicOCR, model OCR dla pojedynczego obrazu, zapewniający wysoką precyzję rozpoznawania znak\xf3w."},"qianfan-vl-70b":{"description":"Qianfan VL 70B, duży model językowo-wizualny, odpowiedni do złożonych zadań rozumienia obraz\xf3w i tekstu."},"qianfan-vl-8b":{"description":"Qianfan VL 8B, lekki model językowo-wizualny, idealny do codziennych pytań i analiz obrazowo-tekstowych."},"qvq-72b-preview":{"description":"Model QVQ jest eksperymentalnym modelem badawczym opracowanym przez zesp\xf3ł Qwen, skoncentrowanym na zwiększeniu zdolności w zakresie rozumowania wizualnego, szczeg\xf3lnie w dziedzinie rozumowania matematycznego."},"qvq-max":{"description":"Model wizualnego wnioskowania Tongyi Qianwen QVQ, obsługujący wejścia wizualne i generujący łańcuchy myślowe, wykazujący silne zdolności w matematyce, programowaniu, analizie wizualnej, tw\xf3rczości oraz zadaniach og\xf3lnych."},"qvq-plus":{"description":"Model wnioskowania wizualnego. Obsługuje wejścia wizualne oraz generowanie łańcuch\xf3w myślowych. Wersja plus po modelu qvq-max, charakteryzuje się szybszym wnioskowaniem oraz lepszą r\xf3wnowagą między efektywnością a kosztami w por\xf3wnaniu do qvq-max."},"qwen-3-32b":{"description":"Qwen 3 32B: model z serii Qwen, kt\xf3ry doskonale sprawdza się w zadaniach wielojęzycznych i programistycznych, odpowiedni do średnioskalowej produkcji."},"qwen-3-coder-480b":{"description":"Qwen 3 Coder 480B: model z długim kontekstem, zaprojektowany do generowania kodu i realizacji złożonych zadań programistycznych."},"qwen-coder-plus":{"description":"Model kodowania Tongyi Qianwen."},"qwen-coder-turbo":{"description":"Model kodowania Tongyi Qianwen."},"qwen-coder-turbo-latest":{"description":"Model kodowania Qwen."},"qwen-flash":{"description":"Seria Tongyi Qianwen to najszybsze i najtańsze modele, odpowiednie do prostych zadań."},"qwen-image":{"description":"Qwen-Image jest uniwersalnym modelem generowania obraz\xf3w, obsługującym wiele styl\xf3w artystycznych, a w szczeg\xf3lności znakomicie radzącym sobie z renderowaniem złożonego tekstu, zwłaszcza tekstu w języku chińskim i angielskim. Model obsługuje układy wielowierszowe, generowanie tekstu na poziomie akapitu oraz odwzorowywanie drobnych detali, co pozwala na tworzenie złożonych projekt\xf3w łączących obraz i tekst."},"qwen-image-edit":{"description":"Qwen Image Edit to model generujący obrazy na podstawie obraz\xf3w i tekstu, umożliwiający edycję i modyfikację obraz\xf3w zgodnie z podanymi wskaz\xf3wkami. Potrafi precyzyjnie dostosować i kreatywnie przekształcić oryginalny obraz zgodnie z potrzebami użytkownika."},"qwen-long":{"description":"Qwen to ultra-duży model językowy, kt\xf3ry obsługuje długie konteksty tekstowe oraz funkcje dialogowe oparte na długich dokumentach i wielu dokumentach."},"qwen-math-plus":{"description":"Model matematyczny Tongyi Qianwen, specjalnie zaprojektowany do rozwiązywania zadań matematycznych."},"qwen-math-plus-latest":{"description":"Model matematyczny Qwen, stworzony specjalnie do rozwiązywania problem\xf3w matematycznych."},"qwen-math-turbo":{"description":"Model matematyczny Tongyi Qianwen, specjalnie zaprojektowany do rozwiązywania zadań matematycznych."},"qwen-math-turbo-latest":{"description":"Model matematyczny Qwen, stworzony specjalnie do rozwiązywania problem\xf3w matematycznych."},"qwen-max":{"description":"Qwen Max to model językowy o skali miliardowej, obsługujący chiński, angielski i inne języki. Aktualna wersja API modelu na bazie Qwen 2.5."},"qwen-omni-turbo":{"description":"Modele z serii Qwen-Omni obsługują dane wejściowe w r\xf3żnych modalnościach, w tym wideo, audio, obrazy i tekst, oraz generują wyjścia w postaci audio i tekstu."},"qwen-plus":{"description":"Qwen Plus to ulepszona wersja ogromnego modelu językowego, wspierająca r\xf3żne języki, w tym chiński i angielski."},"qwen-turbo":{"description":"通义千问 Turbo nie będzie już aktualizowany; zaleca się zastąpienie go modelem 通义千问 Flash. 通义千问 to model językowy o bardzo dużej skali, obsługujący wejścia w języku chińskim, angielskim i innych językach."},"qwen-vl-chat-v1":{"description":"Qwen VL obsługuje elastyczne interakcje, w tym wiele obraz\xf3w, wielokrotne pytania i odpowiedzi oraz zdolności tw\xf3rcze."},"qwen-vl-max":{"description":"Nadzwyczajny, bardzo duży model wizualno-językowy Tongyi Qianwen. W por\xf3wnaniu z wersją wzmocnioną, ponownie poprawia zdolności wnioskowania wizualnego i przestrzegania instrukcji, oferując wyższy poziom percepcji i poznania wizualnego."},"qwen-vl-max-latest":{"description":"Model wizualno-językowy Qwen o ultra dużej skali. W por\xf3wnaniu do wersji rozszerzonej, ponownie zwiększa zdolności wnioskowania wizualnego i przestrzegania instrukcji, oferując wyższy poziom percepcji wizualnej i poznawczej."},"qwen-vl-ocr":{"description":"Tongyi Qianwen OCR to specjalistyczny model do ekstrakcji tekstu, skoncentrowany na rozpoznawaniu tekstu w dokumentach, tabelach, zadaniach testowych i pismach odręcznych. Potrafi rozpoznawać wiele język\xf3w, w tym chiński, angielski, francuski, japoński, koreański, niemiecki, rosyjski, włoski, wietnamski i arabski."},"qwen-vl-plus":{"description":"Wzmocniona wersja dużego modelu wizualno-językowego Tongyi Qianwen. Znacząco poprawia zdolność rozpoznawania detali i tekstu, obsługuje obrazy o rozdzielczości przekraczającej milion pikseli oraz dowolnych proporcjach."},"qwen-vl-plus-latest":{"description":"Wersja rozszerzona modelu wizualno-językowego Qwen. Znacząco poprawia zdolność rozpoznawania szczeg\xf3ł\xf3w i tekstu, obsługuje obrazy o rozdzielczości przekraczającej milion pikseli oraz dowolnych proporcjach."},"qwen-vl-v1":{"description":"Model wstępnie wytrenowany, zainicjowany przez model językowy Qwen-7B, dodający model obrazowy, z rozdzielczością wejściową obrazu wynoszącą 448."},"qwen/qwen-2-7b-instruct":{"description":"Qwen2 to nowa seria dużych modeli językowych Qwen. Qwen2 7B to model oparty na transformatorze, kt\xf3ry wykazuje doskonałe wyniki w zakresie rozumienia języka, zdolności wielojęzycznych, programowania, matematyki i wnioskowania."},"qwen/qwen-2-7b-instruct:free":{"description":"Qwen2 to nowa seria dużych modeli językowych, charakteryzująca się silniejszymi zdolnościami rozumienia i generowania."},"qwen/qwen-2-vl-72b-instruct":{"description":"Qwen2-VL to najnowsza iteracja modelu Qwen-VL, kt\xf3ra osiągnęła najnowocześniejsze wyniki w testach benchmarkowych dotyczących rozumienia wizualnego, w tym MathVista, DocVQA, RealWorldQA i MTVQA. Qwen2-VL potrafi rozumieć filmy trwające ponad 20 minut, umożliwiając wysokiej jakości pytania i odpowiedzi, dialogi oraz tworzenie treści oparte na wideo. Posiada r\xf3wnież zdolności do złożonego wnioskowania i podejmowania decyzji, co pozwala na integrację z urządzeniami mobilnymi, robotami itp., aby automatycznie działać na podstawie środowiska wizualnego i instrukcji tekstowych. Opr\xf3cz angielskiego i chińskiego, Qwen2-VL teraz wspiera r\xf3wnież rozumienie tekstu w r\xf3żnych językach w obrazach, w tym większości język\xf3w europejskich, japońskiego, koreańskiego, arabskiego i wietnamskiego."},"qwen/qwen-2.5-72b-instruct":{"description":"Qwen2.5-72B-Instruct to jeden z najnowszych modeli dużych język\xf3w wydanych przez Alibaba Cloud. Model 72B wykazuje znaczną poprawę w obszarach kodowania i matematyki. Model ten oferuje wsparcie dla wielu język\xf3w, obejmując ponad 29 język\xf3w, w tym chiński i angielski. Model znacząco poprawił zdolność do podążania za instrukcjami, rozumienia danych strukturalnych oraz generowania strukturalnych wynik\xf3w (szczeg\xf3lnie JSON)."},"qwen/qwen2.5-32b-instruct":{"description":"Qwen2.5-32B-Instruct to jeden z najnowszych modeli dużych język\xf3w wydanych przez Alibaba Cloud. Model 32B wykazuje znaczną poprawę w obszarach kodowania i matematyki. Model ten oferuje wsparcie dla wielu język\xf3w, obejmując ponad 29 język\xf3w, w tym chiński i angielski. Model znacząco poprawił zdolność do podążania za instrukcjami, rozumienia danych strukturalnych oraz generowania strukturalnych wynik\xf3w (szczeg\xf3lnie JSON)."},"qwen/qwen2.5-7b-instruct":{"description":"LLM skierowany na język chiński i angielski, skoncentrowany na języku, programowaniu, matematyce, wnioskowaniu i innych dziedzinach."},"qwen/qwen2.5-coder-32b-instruct":{"description":"Zaawansowany LLM, wspierający generowanie kodu, wnioskowanie i naprawę, obejmujący gł\xf3wne języki programowania."},"qwen/qwen2.5-coder-7b-instruct":{"description":"Potężny średniej wielkości model kodu, wspierający długość kontekstu 32K, specjalizujący się w programowaniu wielojęzycznym."},"qwen/qwen3-14b":{"description":"Qwen3-14B to gęsty model językowy o 14 miliardach parametr\xf3w w serii Qwen3, zaprojektowany z myślą o złożonym wnioskowaniu i efektywnych dialogach. Obsługuje płynne przełączanie między trybem \'myślenia\' używanym do matematyki, programowania i wnioskowania logicznego a trybem \'nie-myślenia\' stosowanym w og\xf3lnych rozmowach. Model został dostosowany do przestrzegania instrukcji, użycia narzędzi agenta, tw\xf3rczego pisania oraz wielojęzycznych zadań w ponad 100 językach i dialektach. Obsługuje natywnie 32K token\xf3w kontekstu i może być rozszerzany do 131K token\xf3w za pomocą YaRN."},"qwen/qwen3-14b:free":{"description":"Qwen3-14B to gęsty model językowy o 14 miliardach parametr\xf3w w serii Qwen3, zaprojektowany z myślą o złożonym wnioskowaniu i efektywnych dialogach. Obsługuje płynne przełączanie między trybem \'myślenia\' używanym do matematyki, programowania i wnioskowania logicznego a trybem \'nie-myślenia\' stosowanym w og\xf3lnych rozmowach. Model został dostosowany do przestrzegania instrukcji, użycia narzędzi agenta, tw\xf3rczego pisania oraz wielojęzycznych zadań w ponad 100 językach i dialektach. Obsługuje natywnie 32K token\xf3w kontekstu i może być rozszerzany do 131K token\xf3w za pomocą YaRN."},"qwen/qwen3-235b-a22b":{"description":"Qwen3-235B-A22B to model mieszanki ekspert\xf3w (MoE) o 235 miliardach parametr\xf3w opracowany przez Qwen, aktywujący 22 miliardy parametr\xf3w przy każdym przejściu do przodu. Obsługuje płynne przełączanie między trybem \'myślenia\' używanym do złożonego wnioskowania, matematyki i zadań kodowania a trybem \'nie-myślenia\' stosowanym w og\xf3lnych rozmowach. Model wykazuje silne zdolności w zakresie wnioskowania, wsparcia wielojęzycznego (ponad 100 język\xf3w i dialekt\xf3w), zaawansowanego przestrzegania instrukcji oraz wywoływania narzędzi agenta. Obsługuje natywnie okno kontekstu 32K token\xf3w i może być rozszerzany do 131K token\xf3w za pomocą YaRN."},"qwen/qwen3-235b-a22b:free":{"description":"Qwen3-235B-A22B to model mieszanki ekspert\xf3w (MoE) o 235 miliardach parametr\xf3w opracowany przez Qwen, aktywujący 22 miliardy parametr\xf3w przy każdym przejściu do przodu. Obsługuje płynne przełączanie między trybem \'myślenia\' używanym do złożonego wnioskowania, matematyki i zadań kodowania a trybem \'nie-myślenia\' stosowanym w og\xf3lnych rozmowach. Model wykazuje silne zdolności w zakresie wnioskowania, wsparcia wielojęzycznego (ponad 100 język\xf3w i dialekt\xf3w), zaawansowanego przestrzegania instrukcji oraz wywoływania narzędzi agenta. Obsługuje natywnie okno kontekstu 32K token\xf3w i może być rozszerzany do 131K token\xf3w za pomocą YaRN."},"qwen/qwen3-30b-a3b":{"description":"Qwen3 to najnowsza generacja serii dużych modeli językowych Qwen, charakteryzująca się architekturą gęstą i mieszanką ekspert\xf3w (MoE), kt\xf3ra doskonale radzi sobie w zakresie wnioskowania, wsparcia wielojęzycznego i zaawansowanych zadań agenta. Jego unikalna zdolność do płynnego przełączania się między trybem myślenia w złożonym wnioskowaniu a trybem nie-myślenia w efektywnych dialogach zapewnia wszechstronność i wysoką jakość wydajności.\\n\\nQwen3 znacząco przewyższa wcześniejsze modele, takie jak QwQ i Qwen2.5, oferując doskonałe umiejętności w zakresie matematyki, kodowania, wnioskowania og\xf3lnego, tw\xf3rczego pisania i interaktywnych dialog\xf3w. Wariant Qwen3-30B-A3B zawiera 30,5 miliarda parametr\xf3w (3,3 miliarda aktywowanych parametr\xf3w), 48 warstw, 128 ekspert\xf3w (aktywowano 8 dla każdego zadania) i obsługuje kontekst do 131K token\xf3w (z użyciem YaRN), ustanawiając nowy standard dla modeli open source."},"qwen/qwen3-30b-a3b:free":{"description":"Qwen3 to najnowsza generacja serii dużych modeli językowych Qwen, charakteryzująca się architekturą gęstą i mieszanką ekspert\xf3w (MoE), kt\xf3ra doskonale radzi sobie w zakresie wnioskowania, wsparcia wielojęzycznego i zaawansowanych zadań agenta. Jego unikalna zdolność do płynnego przełączania się między trybem myślenia w złożonym wnioskowaniu a trybem nie-myślenia w efektywnych dialogach zapewnia wszechstronność i wysoką jakość wydajności.\\n\\nQwen3 znacząco przewyższa wcześniejsze modele, takie jak QwQ i Qwen2.5, oferując doskonałe umiejętności w zakresie matematyki, kodowania, wnioskowania og\xf3lnego, tw\xf3rczego pisania i interaktywnych dialog\xf3w. Wariant Qwen3-30B-A3B zawiera 30,5 miliarda parametr\xf3w (3,3 miliarda aktywowanych parametr\xf3w), 48 warstw, 128 ekspert\xf3w (aktywowano 8 dla każdego zadania) i obsługuje kontekst do 131K token\xf3w (z użyciem YaRN), ustanawiając nowy standard dla modeli open source."},"qwen/qwen3-32b":{"description":"Qwen3-32B to gęsty model językowy o 32 miliardach parametr\xf3w w serii Qwen3, zoptymalizowany pod kątem złożonego wnioskowania i efektywnych dialog\xf3w. Obsługuje płynne przełączanie między trybem \'myślenia\' używanym do matematyki, kodowania i wnioskowania logicznego a trybem \'nie-myślenia\' stosowanym w szybszych, og\xf3lnych rozmowach. Model wykazuje silną wydajność w przestrzeganiu instrukcji, użyciu narzędzi agenta, tw\xf3rczym pisaniu oraz wielojęzycznych zadań w ponad 100 językach i dialektach. Obsługuje natywnie 32K token\xf3w kontekstu i może być rozszerzany do 131K token\xf3w za pomocą YaRN."},"qwen/qwen3-32b:free":{"description":"Qwen3-32B to gęsty model językowy o 32 miliardach parametr\xf3w w serii Qwen3, zoptymalizowany pod kątem złożonego wnioskowania i efektywnych dialog\xf3w. Obsługuje płynne przełączanie między trybem \'myślenia\' używanym do matematyki, kodowania i wnioskowania logicznego a trybem \'nie-myślenia\' stosowanym w szybszych, og\xf3lnych rozmowach. Model wykazuje silną wydajność w przestrzeganiu instrukcji, użyciu narzędzi agenta, tw\xf3rczym pisaniu oraz wielojęzycznych zadań w ponad 100 językach i dialektach. Obsługuje natywnie 32K token\xf3w kontekstu i może być rozszerzany do 131K token\xf3w za pomocą YaRN."},"qwen/qwen3-8b:free":{"description":"Qwen3-8B to gęsty model językowy o 8 miliardach parametr\xf3w w serii Qwen3, zaprojektowany z myślą o zadaniach wymagających intensywnego wnioskowania i efektywnych dialogach. Obsługuje płynne przełączanie między trybem \'myślenia\' używanym do matematyki, kodowania i wnioskowania logicznego a trybem \'nie-myślenia\' stosowanym w og\xf3lnych rozmowach. Model został dostosowany do przestrzegania instrukcji, integracji agenta, tw\xf3rczego pisania oraz wielojęzycznego użycia w ponad 100 językach i dialektach. Obsługuje natywnie okno kontekstu 32K token\xf3w i może być rozszerzany do 131K token\xf3w za pomocą YaRN."},"qwen2":{"description":"Qwen2 to nowa generacja dużego modelu językowego Alibaba, wspierająca r\xf3żnorodne potrzeby aplikacyjne dzięki doskonałej wydajności."},"qwen2.5":{"description":"Qwen2.5 to nowa generacja dużego modelu językowego Alibaba, kt\xf3ry wspiera r\xf3żnorodne potrzeby aplikacyjne dzięki doskonałej wydajności."},"qwen2.5-14b-instruct":{"description":"Model Qwen 2.5 o skali 14B, udostępniony na zasadzie open source."},"qwen2.5-14b-instruct-1m":{"description":"Model o skali 72B, udostępniony przez Tongyi Qianwen 2.5."},"qwen2.5-32b-instruct":{"description":"Model Qwen 2.5 o skali 32B, udostępniony na zasadzie open source."},"qwen2.5-72b-instruct":{"description":"Model Qwen 2.5 o skali 72B, udostępniony na zasadzie open source."},"qwen2.5-7b-instruct":{"description":"Qwen2.5 7B Instruct, dojrzały model open-source do instrukcji, odpowiedni do dialog\xf3w i generowania w r\xf3żnych scenariuszach."},"qwen2.5-coder-1.5b-instruct":{"description":"Otwarta wersja modelu kodowania Qwen."},"qwen2.5-coder-14b-instruct":{"description":"Otwarta wersja modelu kodowania Tongyi Qianwen."},"qwen2.5-coder-32b-instruct":{"description":"Otwarta wersja modelu kodowania Qwen."},"qwen2.5-coder-7b-instruct":{"description":"Otwarta wersja modelu kodowania Qwen."},"qwen2.5-coder-instruct":{"description":"Qwen2.5-Coder to najnowszy model językowy o dużym rozmiarze z serii Qwen, specjalnie przeznaczony do obsługi kodu (wcześniej znany jako CodeQwen)."},"qwen2.5-instruct":{"description":"Qwen2.5 to najnowsza seria modeli językowych Qwen. W przypadku Qwen2.5 wydaliśmy wiele podstawowych modeli językowych oraz modeli językowych dostosowanych do instrukcji, z zakresem parametr\xf3w od 500 milion\xf3w do 7,2 miliarda."},"qwen2.5-math-1.5b-instruct":{"description":"Model Qwen-Math ma silne umiejętności rozwiązywania problem\xf3w matematycznych."},"qwen2.5-math-72b-instruct":{"description":"Model Qwen-Math, kt\xf3ry ma silne zdolności rozwiązywania problem\xf3w matematycznych."},"qwen2.5-math-7b-instruct":{"description":"Model Qwen-Math, kt\xf3ry ma silne zdolności rozwiązywania problem\xf3w matematycznych."},"qwen2.5-omni-7b":{"description":"Model serii Qwen-Omni obsługuje wprowadzanie danych w r\xf3żnych modalnościach, w tym wideo, audio, obrazy i tekst, oraz generuje audio i tekst."},"qwen2.5-vl-32b-instruct":{"description":"Qwen2.5 VL 32B Instruct, multimodalny model open-source, odpowiedni do wdrożeń prywatnych i zastosowań w wielu scenariuszach."},"qwen2.5-vl-72b-instruct":{"description":"Zwiększona zdolność do podążania za instrukcjami, matematyki, rozwiązywania problem\xf3w i kodowania, poprawiona zdolność do rozpoznawania obiekt\xf3w, wsparcie dla r\xf3żnych format\xf3w do precyzyjnego lokalizowania element\xf3w wizualnych, zdolność do rozumienia długich plik\xf3w wideo (do 10 minut) oraz lokalizowania moment\xf3w zdarzeń w czasie rzeczywistym, zdolność do rozumienia kolejności czasowej i szybkości, wsparcie dla operacji na systemach OS lub Mobile, silna zdolność do ekstrakcji kluczowych informacji i generowania wyjścia w formacie JSON. Ta wersja to wersja 72B, najsilniejsza w tej serii."},"qwen2.5-vl-7b-instruct":{"description":"Qwen2.5 VL 7B Instruct, lekki multimodalny model, łączący niskie koszty wdrożenia z dobrą zdolnością rozpoznawania."},"qwen2.5-vl-instruct":{"description":"Qwen2.5-VL to najnowsza wersja modelu wizualno-lingwistycznego rodziny Qwen."},"qwen2.5:0.5b":{"description":"Qwen2.5 to nowa generacja dużego modelu językowego Alibaba, kt\xf3ry wspiera r\xf3żnorodne potrzeby aplikacyjne dzięki doskonałej wydajności."},"qwen2.5:1.5b":{"description":"Qwen2.5 to nowa generacja dużego modelu językowego Alibaba, kt\xf3ry wspiera r\xf3żnorodne potrzeby aplikacyjne dzięki doskonałej wydajności."},"qwen2.5:72b":{"description":"Qwen2.5 to nowa generacja dużego modelu językowego Alibaba, kt\xf3ry wspiera r\xf3żnorodne potrzeby aplikacyjne dzięki doskonałej wydajności."},"qwen2:0.5b":{"description":"Qwen2 to nowa generacja dużego modelu językowego Alibaba, wspierająca r\xf3żnorodne potrzeby aplikacyjne dzięki doskonałej wydajności."},"qwen2:1.5b":{"description":"Qwen2 to nowa generacja dużego modelu językowego Alibaba, wspierająca r\xf3żnorodne potrzeby aplikacyjne dzięki doskonałej wydajności."},"qwen2:72b":{"description":"Qwen2 to nowa generacja dużego modelu językowego Alibaba, wspierająca r\xf3żnorodne potrzeby aplikacyjne dzięki doskonałej wydajności."},"qwen3":{"description":"Qwen3 to nowa generacja dużego modelu językowego od Alibaba, kt\xf3ry wspiera r\xf3żnorodne potrzeby aplikacyjne dzięki doskonałej wydajności."},"qwen3-0.6b":{"description":"Qwen3 0.6B, model podstawowy, odpowiedni do prostych zadań wnioskowania i środowisk o bardzo ograniczonych zasobach."},"qwen3-1.7b":{"description":"Qwen3 1.7B, ultralekki model, łatwy do wdrożenia na urządzeniach brzegowych i końcowych."},"qwen3-14b":{"description":"Qwen3 14B, model średniej wielkości, odpowiedni do wielojęzycznych pytań i generowania tekstu."},"qwen3-235b-a22b":{"description":"Qwen3 235B A22B, uniwersalny duży model, przeznaczony do r\xf3żnorodnych złożonych zadań."},"qwen3-235b-a22b-instruct-2507":{"description":"Qwen3 235B A22B Instruct 2507, flagowy model instrukcji og\xf3lnego przeznaczenia, odpowiedni do generowania i wnioskowania."},"qwen3-235b-a22b-thinking-2507":{"description":"Qwen3 235B A22B Thinking 2507, model do głębokiego wnioskowania na dużą skalę, przeznaczony do trudnych zadań logicznych."},"qwen3-30b-a3b":{"description":"Qwen3 30B A3B, średnio-duży model og\xf3lnego przeznaczenia, zapewniający r\xf3wnowagę między kosztem a wydajnością."},"qwen3-30b-a3b-instruct-2507":{"description":"Qwen3 30B A3B Instruct 2507, średnio-duży model instrukcji, odpowiedni do generowania wysokiej jakości treści i pytań."},"qwen3-30b-a3b-thinking-2507":{"description":"Qwen3 30B A3B Thinking 2507, średnio-duży model do wnioskowania, łączący precyzję z efektywnością kosztową."},"qwen3-32b":{"description":"Qwen3 32B, odpowiedni do og\xf3lnych zadań wymagających większych zdolności rozumienia."},"qwen3-4b":{"description":"Qwen3 4B, odpowiedni do małych i średnich aplikacji oraz lokalnych scenariuszy wnioskowania."},"qwen3-8b":{"description":"Qwen3 8B, lekki model, elastyczny w wdrożeniu, odpowiedni do zastosowań o wysokiej r\xf3wnoległości."},"qwen3-coder-30b-a3b-instruct":{"description":"Otwartoźr\xf3dłowa wersja modelu kodowania Tongyi Qianwen. Najnowszy qwen3-coder-30b-a3b-instruct to model generowania kodu oparty na Qwen3, wyposażony w zaawansowane możliwości agenta kodującego, doskonale radzący sobie z wywoływaniem narzędzi i interakcją ze środowiskiem, umożliwiający autonomiczne programowanie i łączący doskonałe umiejętności kodowania z og\xf3lnymi zdolnościami."},"qwen3-coder-480b-a35b-instruct":{"description":"Qwen3 Coder 480B A35B Instruct, flagowy model kodowania, obsługujący programowanie w wielu językach i złożone rozumienie kodu."},"qwen3-coder-flash":{"description":"Model kodowania Tongyi Qianwen. Najnowsza seria modeli Qwen3-Coder oparta na Qwen3 to modele generujące kod, posiadające potężne zdolności agenta kodującego, biegłe w wywoływaniu narzędzi i interakcji ze środowiskiem, umożliwiające autonomiczne programowanie, łącząc doskonałe umiejętności kodowania z uniwersalnymi zdolnościami."},"qwen3-coder-plus":{"description":"Model kodowania Tongyi Qianwen. Najnowsza seria modeli Qwen3-Coder oparta na Qwen3 to modele generujące kod, posiadające potężne zdolności agenta kodującego, biegłe w wywoływaniu narzędzi i interakcji ze środowiskiem, umożliwiające autonomiczne programowanie, łącząc doskonałe umiejętności kodowania z uniwersalnymi zdolnościami."},"qwen3-coder:480b":{"description":"Wysokowydajny model długiego kontekstu od Alibaba, zoptymalizowany pod kątem zadań agenta i kodowania."},"qwen3-max":{"description":"Model serii Tongyi Qianwen 3 Max, kt\xf3ry w por\xf3wnaniu do serii 2.5 oferuje znacznie ulepszone zdolności og\xf3lne, w tym rozumienie tekstu w języku chińskim i angielskim, zdolność do wykonywania złożonych instrukcji, zadania otwarte o charakterze subiektywnym, wielojęzyczność oraz wywoływanie narzędzi; model cechuje się mniejszą halucynacją wiedzy. Najnowsza wersja qwen3-max, w por\xf3wnaniu do wersji podglądowej qwen3-max-preview, została specjalnie ulepszona w zakresie programowania agent\xf3w i wywoływania narzędzi. Wydany oficjalny model osiąga poziom SOTA w swojej dziedzinie i jest dostosowany do bardziej złożonych scenariuszy zastosowań agent\xf3w."},"qwen3-max-preview":{"description":"Najbardziej zaawansowany model z serii Tongyi Qianwen, odpowiedni do złożonych, wieloetapowych zadań. Wersja podglądowa obsługuje już rozumowanie."},"qwen3-next-80b-a3b-instruct":{"description":"Nowa generacja otwartego modelu bez trybu myślenia oparta na Qwen3, kt\xf3ra w por\xf3wnaniu z poprzednią wersją (Tongyi Qianwen 3-235B-A22B-Instruct-2507) cechuje się lepszym rozumieniem tekstu w języku chińskim, wzmocnionymi zdolnościami wnioskowania logicznego oraz lepszą wydajnością w zadaniach generowania tekstu."},"qwen3-next-80b-a3b-thinking":{"description":"Qwen3 Next 80B A3B Thinking, flagowa wersja modelu do wnioskowania, przeznaczona do złożonych zadań."},"qwen3-omni-flash":{"description":"Model Qwen-Omni obsługuje wejścia w r\xf3żnych modalnościach, takich jak tekst, obraz, dźwięk i wideo, generując odpowiedzi w formie tekstu lub mowy. Oferuje r\xf3żnorodne, naturalnie brzmiące głosy, wspiera wiele język\xf3w i dialekt\xf3w, i znajduje zastosowanie w takich obszarach jak tworzenie tekst\xf3w, rozpoznawanie obraz\xf3w czy asystenci głosowi."},"qwen3-vl-235b-a22b-instruct":{"description":"Qwen3 VL 235B A22B Instruct, flagowy model multimodalny, przeznaczony do zaawansowanego rozumienia i tw\xf3rczości."},"qwen3-vl-235b-a22b-thinking":{"description":"Qwen3 VL 235B A22B Thinking, flagowa wersja do głębokiego wnioskowania, przeznaczona do złożonych zadań multimodalnych i planowania."},"qwen3-vl-30b-a3b-instruct":{"description":"Qwen3 VL 30B A3B Instruct, duży model multimodalny, łączący precyzję z wydajnością wnioskowania."},"qwen3-vl-30b-a3b-thinking":{"description":"Qwen3 VL 30B A3B Thinking, wersja do głębokiego wnioskowania dla złożonych zadań multimodalnych."},"qwen3-vl-32b-instruct":{"description":"Qwen3 VL 32B Instruct, multimodalny model dostrojony do instrukcji, odpowiedni do wysokiej jakości pytań obrazowo-tekstowych i tw\xf3rczości."},"qwen3-vl-32b-thinking":{"description":"Qwen3 VL 32B Thinking, wersja do głębokiego multimodalnego wnioskowania, wzmacniająca złożone analizy i długie łańcuchy logiczne."},"qwen3-vl-8b-instruct":{"description":"Qwen3 VL 8B Instruct, lekki model multimodalny, odpowiedni do codziennych pytań wizualnych i integracji aplikacji."},"qwen3-vl-8b-thinking":{"description":"Qwen3 VL 8B Thinking, multimodalny model łańcucha myślenia, odpowiedni do szczeg\xf3łowego wnioskowania na podstawie informacji wizualnych."},"qwen3-vl-flash":{"description":"Qwen3 VL Flash: lekka, szybka wersja do wnioskowania, idealna do zastosowań wrażliwych na op\xf3źnienia lub wymagających obsługi dużej liczby żądań."},"qwen3-vl-plus":{"description":"Tongyi Qianwen VL to model generujący tekst z umiejętnością rozumienia wizualnego (obraz\xf3w). Potrafi nie tylko wykonywać OCR (rozpoznawanie tekstu na obrazach), ale także podsumowywać i wnioskować, na przykład wyodrębniać atrybuty z fotografii produkt\xf3w czy rozwiązywać zadania na podstawie ilustracji."},"qwq":{"description":"QwQ to eksperymentalny model badawczy, skoncentrowany na zwiększeniu zdolności wnioskowania AI."},"qwq-32b":{"description":"Model inferency QwQ, oparty na modelu Qwen2.5-32B, został znacznie ulepszony dzięki uczeniu przez wzmocnienie, co zwiększa jego zdolności inferencyjne. Kluczowe wskaźniki modelu, takie jak matematyczny kod i inne (AIME 24/25, LiveCodeBench), oraz niekt\xf3re og\xf3lne wskaźniki (IFEval, LiveBench itp.) osiągają poziom pełnej wersji DeepSeek-R1, a wszystkie wskaźniki znacznie przewyższają te, kt\xf3re są oparte na Qwen2.5-32B, w tym DeepSeek-R1-Distill-Qwen-32B."},"qwq-32b-preview":{"description":"Model QwQ to eksperymentalny model badawczy opracowany przez zesp\xf3ł Qwen, skoncentrowany na zwiększeniu zdolności wnioskowania AI."},"qwq-plus":{"description":"Model wnioskowania QwQ oparty na modelu Qwen2.5, znacznie poprawiony dzięki uczeniu ze wzmocnieniem. Kluczowe wskaźniki modelu w matematyce i kodowaniu (AIME 24/25, LiveCodeBench) oraz niekt\xf3re wskaźniki og\xf3lne (IFEval, LiveBench itp.) osiągają poziom pełnej wersji DeepSeek-R1."},"qwq_32b":{"description":"Model wnioskowania średniej wielkości z serii Qwen. W por\xf3wnaniu do tradycyjnych modeli dostosowanych do instrukcji, QwQ, posiadający zdolności myślenia i wnioskowania, może znacznie poprawić wydajność w zadaniach końcowych, zwłaszcza w rozwiązywaniu trudnych problem\xf3w."},"r1-1776":{"description":"R1-1776 to wersja modelu DeepSeek R1, kt\xf3ra została poddana dalszemu treningowi, aby dostarczać nieocenzurowane, bezstronne informacje faktograficzne."},"solar-mini":{"description":"Solar Mini to kompaktowy LLM, kt\xf3ry przewyższa GPT-3.5, posiadając potężne zdolności wielojęzyczne, wspierając angielski i koreański, oferując efektywne i zgrabne rozwiązania."},"solar-mini-ja":{"description":"Solar Mini (Ja) rozszerza możliwości Solar Mini, koncentrując się na języku japońskim, jednocześnie zachowując wysoką efektywność i doskonałe osiągi w użyciu angielskiego i koreańskiego."},"solar-pro":{"description":"Solar Pro to model LLM o wysokiej inteligencji wydany przez Upstage, koncentrujący się na zdolności do przestrzegania instrukcji na pojedynczym GPU, osiągając wynik IFEval powyżej 80. Obecnie wspiera język angielski, a wersja oficjalna planowana jest na listopad 2024, z rozszerzeniem wsparcia językowego i długości kontekstu."},"sonar":{"description":"Lekki produkt wyszukiwania oparty na kontekście, szybszy i tańszy niż Sonar Pro."},"sonar-deep-research":{"description":"Deep Research przeprowadza kompleksowe badania na poziomie eksperckim i łączy je w dostępne, praktyczne raporty."},"sonar-pro":{"description":"Zaawansowany produkt wyszukiwania wspierający kontekst wyszukiwania, oferujący zaawansowane zapytania i śledzenie."},"sonar-reasoning":{"description":"Nowy produkt API wspierany przez model wnioskowania DeepSeek."},"sonar-reasoning-pro":{"description":"Nowy produkt API wspierany przez model wnioskowania DeepSeek."},"stable-diffusion-3-medium":{"description":"Najnowszy duży model generowania obraz\xf3w na podstawie tekstu wydany przez Stability AI. Ta wersja zachowuje zalety poprzednich generacji, jednocześnie znacząco poprawiając jakość obrazu, rozumienie tekstu i r\xf3żnorodność styl\xf3w. Potrafi dokładniej interpretować złożone naturalne polecenia i generować bardziej precyzyjne oraz zr\xf3żnicowane obrazy."},"stable-diffusion-3.5-large":{"description":"stable-diffusion-3.5-large to model multimodalnego dyfuzyjnego transformera (MMDiT) do generowania obraz\xf3w na podstawie tekstu, wyposażony w 800 milion\xf3w parametr\xf3w. Charakteryzuje się doskonałą jakością obrazu i zgodnością z poleceniami, wspiera generowanie obraz\xf3w o rozdzielczości do 1 miliona pikseli i działa efektywnie na standardowym sprzęcie konsumenckim."},"stable-diffusion-3.5-large-turbo":{"description":"stable-diffusion-3.5-large-turbo to model oparty na stable-diffusion-3.5-large, wykorzystujący technikę destylacji dyfuzji przeciwstawnej (ADD), oferujący wyższą szybkość działania."},"stable-diffusion-v1.5":{"description":"stable-diffusion-v1.5 to model zainicjowany wagami ze stable-diffusion-v1.2 i dostrojony przez 595 tysięcy krok\xf3w na zbiorze \\"laion-aesthetics v2 5+\\" w rozdzielczości 512x512, z redukcją warunkowania tekstowego o 10% w celu poprawy pr\xf3bkowania bez klasyfikatora."},"stable-diffusion-xl":{"description":"stable-diffusion-xl wprowadza znaczące ulepszenia w por\xf3wnaniu do wersji v1.5 i osiąga efekty por\xf3wnywalne z najlepszymi otwartymi modelami generacji obraz\xf3w, takimi jak midjourney. Kluczowe ulepszenia obejmują: trzykrotnie większy unet backbone, dodanie modułu refinacji poprawiającego jakość generowanych obraz\xf3w oraz bardziej efektywne techniki treningowe."},"stable-diffusion-xl-base-1.0":{"description":"Duży model generowania obraz\xf3w na podstawie tekstu opracowany i udostępniony przez Stability AI, wyr\xf3żniający się czołowymi zdolnościami tw\xf3rczymi. Posiada doskonałe zdolności rozumienia instrukcji i wspiera definiowanie treści za pomocą odwrotnych prompt\xf3w."},"step-1-128k":{"description":"R\xf3wnoważy wydajność i koszty, odpowiedni do og\xf3lnych scenariuszy."},"step-1-256k":{"description":"Posiada zdolność przetwarzania ultra długiego kontekstu, szczeg\xf3lnie odpowiedni do analizy długich dokument\xf3w."},"step-1-32k":{"description":"Obsługuje średniej długości dialogi, odpowiedni do r\xf3żnych zastosowań."},"step-1-8k":{"description":"Mały model, odpowiedni do lekkich zadań."},"step-1-flash":{"description":"Model o wysokiej prędkości, odpowiedni do dialog\xf3w w czasie rzeczywistym."},"step-1.5v-mini":{"description":"Ten model ma potężne zdolności rozumienia wideo."},"step-1o-turbo-vision":{"description":"Model ten ma potężne zdolności rozumienia obraz\xf3w, w dziedzinie matematyki i kodowania przewyższa 1o. Model jest mniejszy niż 1o, a prędkość wyjścia jest szybsza."},"step-1o-vision-32k":{"description":"Ten model ma potężne zdolności rozumienia obraz\xf3w. W por\xf3wnaniu do modeli z serii step-1v, oferuje lepsze osiągi wizualne."},"step-1v-32k":{"description":"Obsługuje wejścia wizualne, wzmacniając doświadczenie interakcji multimodalnych."},"step-1v-8k":{"description":"Mały model wizualny, odpowiedni do podstawowych zadań związanych z tekstem i obrazem."},"step-1x-edit":{"description":"Model skoncentrowany na zadaniach edycji obraz\xf3w, potrafiący modyfikować i wzmacniać obrazy na podstawie dostarczonych przez użytkownika obraz\xf3w i opis\xf3w tekstowych. Obsługuje r\xf3żne formaty wejściowe, w tym opisy tekstowe i obrazy przykładowe. Model rozumie intencje użytkownika i generuje zgodne z nimi wyniki edycji obraz\xf3w."},"step-1x-medium":{"description":"Model o silnych zdolnościach generowania obraz\xf3w, obsługujący wejścia w postaci opis\xf3w tekstowych. Posiada natywną obsługę języka chińskiego, co pozwala lepiej rozumieć i przetwarzać chińskie opisy tekstowe, dokładniej uchwycić ich znaczenie i przekształcić je w cechy obrazu, umożliwiając precyzyjne generowanie obraz\xf3w. Model generuje obrazy o wysokiej rozdzielczości i jakości oraz posiada pewne zdolności transferu stylu."},"step-2-16k":{"description":"Obsługuje interakcje z dużą ilością kontekstu, idealny do złożonych scenariuszy dialogowych."},"step-2-16k-exp":{"description":"Eksperymentalna wersja modelu step-2, zawierająca najnowsze funkcje, aktualizacje w trybie ciągłym. Nie zaleca się używania w produkcji."},"step-2-mini":{"description":"Model oparty na nowej generacji własnej architektury Attention MFA, osiągający podobne wyniki jak step1 przy bardzo niskich kosztach, jednocześnie zapewniając wyższą przepustowość i szybszy czas reakcji. Potrafi obsługiwać og\xf3lne zadania, a w zakresie umiejętności kodowania ma szczeg\xf3lne zdolności."},"step-2x-large":{"description":"Nowa generacja modelu Step Star, skoncentrowana na generowaniu obraz\xf3w na podstawie tekstu. Model tworzy obrazy o bardziej realistycznej fakturze i lepszych zdolnościach generowania tekstu w języku chińskim i angielskim."},"step-3":{"description":"Model posiada zaawansowane zdolności percepcji wzrokowej i złożonego wnioskowania. Potrafi z wysoką precyzją realizować międzydziedzinowe zrozumienie skomplikowanej wiedzy, przeprowadzać analizę łączącą informacje matematyczne i wizualne oraz rozwiązywać r\xf3żnorodne problemy związane z analizą wizualną w życiu codziennym."},"step-r1-v-mini":{"description":"Model ten to potężny model wnioskowania z zdolnościami rozumienia obraz\xf3w, zdolny do przetwarzania informacji wizualnych i tekstowych, generując tekst po głębokim przemyśleniu. Model ten wyr\xf3żnia się w dziedzinie wnioskowania wizualnego, a także posiada pierwszorzędne zdolności wnioskowania matematycznego, kodowania i tekstu. Długość kontekstu wynosi 100k."},"step3":{"description":"Step3 to multimodalny model opracowany przez StepStar, charakteryzujący się zaawansowanymi zdolnościami rozumienia obrazu."},"stepfun-ai/step3":{"description":"Step3 to zaawansowany multimodalny model wnioskowania wydany przez StepFun (阶跃星辰). Został zbudowany na architekturze Mixture of Experts (MoE) z łączną liczbą 321 mld parametr\xf3w i 38 mld parametr\xf3w aktywacji. Model ma konstrukcję end-to-end, zaprojektowaną tak, aby minimalizować koszty dekodowania, jednocześnie zapewniając najwyższą wydajność w zadaniach wnioskowania wizualno-językowego. Dzięki wsp\xf3łdziałaniu mechanizm\xf3w Multi-Matrix Factorized Attention (MFA) i Attention-FFN Decoupling (AFD), Step3 zachowuje znakomitą efektywność zar\xf3wno na akceleratorach klasy flagowej, jak i na urządzeniach o niższej wydajności. W fazie pretrenowania Step3 przetworzył ponad 20 bilion\xf3w token\xf3w tekstowych oraz 4 biliony token\xf3w mieszanych tekstowo-obrazowych, obejmujących ponad dziesięć język\xf3w. Model osiągnął czołowe wyniki wśr\xf3d modeli open-source na wielu benchmarkach, w tym w zadaniach z zakresu matematyki, programowania i multimodalu."},"taichu_llm":{"description":"Model językowy TaiChu charakteryzuje się wyjątkową zdolnością rozumienia języka oraz umiejętnościami w zakresie tworzenia tekst\xf3w, odpowiadania na pytania, programowania, obliczeń matematycznych, wnioskowania logicznego, analizy emocji i streszczenia tekstu. Innowacyjnie łączy wstępne uczenie się na dużych zbiorach danych z bogatą wiedzą z wielu źr\xf3deł, stale doskonaląc technologię algorytmiczną i nieustannie przyswajając nową wiedzę z zakresu słownictwa, struktury, gramatyki i semantyki z ogromnych zbior\xf3w danych tekstowych, co prowadzi do ciągłej ewolucji modelu. Umożliwia użytkownikom łatwiejszy dostęp do informacji i usług oraz bardziej inteligentne doświadczenia."},"taichu_o1":{"description":"taichu_o1 to nowa generacja modelu wnioskowania, kt\xf3ra poprzez interakcje multimodalne i uczenie przez wzmocnienie realizuje łańcuchy myślenia przypominające ludzkie, wspierając złożone symulacje decyzji, jednocześnie prezentując ścieżki myślenia modelu przy zachowaniu wysokiej precyzji wynik\xf3w, odpowiednia do analizy strategii i głębokiego myślenia."},"taichu_vl":{"description":"Łączy zdolności rozumienia obraz\xf3w, transferu wiedzy i logicznego wnioskowania, wyr\xf3żniając się w dziedzinie pytań i odpowiedzi na podstawie tekstu i obraz\xf3w."},"tencent/Hunyuan-A13B-Instruct":{"description":"Hunyuan-A13B-Instruct ma 80 miliard\xf3w parametr\xf3w, a aktywacja 13 miliard\xf3w parametr\xf3w pozwala mu konkurować z większymi modelami. Wspiera hybrydowe wnioskowanie „szybkiego myślenia/powolnego myślenia”; stabilne rozumienie długich tekst\xf3w; potwierdzona przewaga zdolności agenta w testach BFCL-v3 i τ-Bench; dzięki połączeniu GQA i wielu format\xf3w kwantyzacji zapewnia efektywne wnioskowanie."},"tencent/Hunyuan-MT-7B":{"description":"Model tłumaczeniowy Hunyuan (Hunyuan Translation Model) składa się z modelu Hunyuan-MT-7B oraz modelu zintegrowanego Hunyuan-MT-Chimera. Hunyuan-MT-7B to lekki model tłumaczeniowy z 7 miliardami parametr\xf3w, przeznaczony do tłumaczenia tekstu źr\xf3dłowego na język docelowy. Obsługuje tłumaczenia między 33 językami oraz 5 językami mniejszości narodowych w Chinach. W międzynarodowym konkursie tłumaczenia maszynowego WMT25 model ten zdobył pierwsze miejsce w 30 z 31 kategorii językowych, w kt\xf3rych brał udział, co świadczy o jego wyjątkowej skuteczności. Tencent Hunyuan opracował kompleksowy paradygmat treningowy obejmujący pretrening, nadzorowane dostrajanie, wzmocnienie tłumaczenia i integrację, co pozwoliło osiągnąć wiodącą wydajność wśr\xf3d modeli o podobnej skali. Model cechuje się wysoką efektywnością obliczeniową i łatwością wdrożenia, co czyni go odpowiednim do wielu zastosowań."},"text-embedding-3-large":{"description":"Najpotężniejszy model wektoryzacji, odpowiedni do zadań w języku angielskim i innych językach."},"text-embedding-3-small":{"description":"Nowej generacji model Embedding, efektywny i ekonomiczny, odpowiedni do wyszukiwania wiedzy, aplikacji RAG i innych scenariuszy."},"thudm/glm-4-32b":{"description":"GLM-4-32B-0414 to dwujęzyczny (chińsko-angielski) model językowy o otwartych wagach 32B, zoptymalizowany do generowania kodu, wywołań funkcji i zadań agentowych. Został wstępnie wytrenowany na 15T wysokiej jakości danych i danych do ponownego wnioskowania, a następnie udoskonalony przy użyciu dostosowania do preferencji ludzkich, pr\xf3bkowania odrzucającego i uczenia przez wzmocnienie. Model wykazuje doskonałe wyniki w złożonym wnioskowaniu, generowaniu artefakt\xf3w i zadaniach związanych z wyjściem strukturalnym, osiągając wyniki por\xf3wnywalne z GPT-4o i DeepSeek-V3-0324 w wielu testach por\xf3wnawczych."},"thudm/glm-4-32b:free":{"description":"GLM-4-32B-0414 to dwujęzyczny (chińsko-angielski) model językowy o otwartych wagach 32B, zoptymalizowany do generowania kodu, wywołań funkcji i zadań agentowych. Został wstępnie wytrenowany na 15T wysokiej jakości danych i danych do ponownego wnioskowania, a następnie udoskonalony przy użyciu dostosowania do preferencji ludzkich, pr\xf3bkowania odrzucającego i uczenia przez wzmocnienie. Model wykazuje doskonałe wyniki w złożonym wnioskowaniu, generowaniu artefakt\xf3w i zadaniach związanych z wyjściem strukturalnym, osiągając wyniki por\xf3wnywalne z GPT-4o i DeepSeek-V3-0324 w wielu testach por\xf3wnawczych."},"thudm/glm-4-9b-chat":{"description":"Otwarta wersja najnowszej generacji modelu pretrenowanego GLM-4 wydanego przez Zhipu AI."},"thudm/glm-z1-32b":{"description":"GLM-Z1-32B-0414 to wzmocniona wariant wnioskowania GLM-4-32B, zaprojektowana do rozwiązywania głębokich problem\xf3w matematycznych, logicznych i związanych z kodem. Wykorzystuje rozszerzone uczenie przez wzmocnienie (specyficzne dla zadań i oparte na og\xf3lnych preferencjach par) w celu poprawy wydajności w złożonych zadaniach wieloetapowych. W por\xf3wnaniu do podstawowego modelu GLM-4-32B, Z1 znacznie poprawia zdolności w zakresie wnioskowania strukturalnego i formalnego.\\n\\nModel wspiera wymuszanie krok\xf3w \'myślenia\' poprzez inżynierię podpowiedzi i zapewnia poprawioną sp\xf3jność dla długich format\xf3w wyjściowych. Jest zoptymalizowany pod kątem przepływ\xf3w pracy agent\xf3w i wspiera długi kontekst (przez YaRN), wywołania narzędzi JSON oraz konfiguracje drobnoziarnistego pr\xf3bkowania dla stabilnego wnioskowania. Idealny do przypadk\xf3w użycia wymagających przemyślanego, wieloetapowego wnioskowania lub formalnych dedukcji."},"thudm/glm-z1-rumination-32b":{"description":"THUDM: GLM Z1 Rumination 32B to model głębokiego wnioskowania o 32 miliardach parametr\xf3w w serii GLM-4-Z1, zoptymalizowany do złożonych, otwartych zadań wymagających długotrwałego myślenia. Opiera się na glm-4-32b-0414, dodając dodatkowe etapy uczenia przez wzmocnienie i strategie wieloetapowego dostosowania, wprowadzając zdolność \'refleksji\' mającą na celu symulację rozszerzonego przetwarzania poznawczego. Obejmuje to iteracyjne wnioskowanie, analizy wielokrokowe i wzbogacone narzędziami przepływy pracy, takie jak wyszukiwanie, pobieranie i syntezę z uwzględnieniem cytat\xf3w.\\n\\nModel doskonale sprawdza się w pisaniu badawczym, analizie por\xf3wnawczej i złożonych pytaniach i odpowiedziach. Obsługuje wywołania funkcji dla prymityw\xf3w wyszukiwania i nawigacji (`search`, `click`, `open`, `finish`), co umożliwia jego użycie w agentowych przepływach pracy. Zachowanie refleksyjne kształtowane jest przez wieloetapową kontrolę cykliczną z nagrodami opartymi na regułach i mechanizmem op\xf3źnionych decyzji, a także na głębokich ramach badawczych, takich jak wewnętrzny stos dostosowujący OpenAI. Ten wariant jest odpowiedni dla scenariuszy wymagających głębokości, a nie szybkości."},"tngtech/deepseek-r1t-chimera:free":{"description":"DeepSeek-R1T-Chimera powstał poprzez połączenie DeepSeek-R1 i DeepSeek-V3 (0324), łącząc zdolności wnioskowania R1 z poprawą efektywności token\xf3w V3. Opiera się na architekturze DeepSeek-MoE Transformer i został zoptymalizowany do og\xf3lnych zadań generowania tekstu.\\n\\nModel łączy w sobie wagi wstępnie wytrenowane z dw\xf3ch źr\xf3dłowych modeli, aby zr\xf3wnoważyć wydajność wnioskowania, efektywności i przestrzegania instrukcji. Został wydany na licencji MIT, z zamiarem użycia w badaniach i zastosowaniach komercyjnych."},"togethercomputer/StripedHyena-Nous-7B":{"description":"StripedHyena Nous (7B) oferuje zwiększoną moc obliczeniową dzięki efektywnym strategiom i architekturze modelu."},"tts-1":{"description":"Najnowocześniejszy model tekstu na mowę, zoptymalizowany pod kątem szybkości w scenariuszach w czasie rzeczywistym."},"tts-1-hd":{"description":"Najnowocześniejszy model tekstu na mowę, zoptymalizowany pod kątem jakości."},"upstage/SOLAR-10.7B-Instruct-v1.0":{"description":"Upstage SOLAR Instruct v1 (11B) jest przeznaczony do precyzyjnych zadań poleceniowych, oferując doskonałe możliwości przetwarzania języka."},"us.anthropic.claude-3-5-sonnet-20241022-v2:0":{"description":"Claude 3.5 Sonnet podnosi standardy branżowe, przewyższając modele konkurencji oraz Claude 3 Opus, osiągając doskonałe wyniki w szerokim zakresie ocen, przy zachowaniu prędkości i koszt\xf3w naszych modeli średniego poziomu."},"us.anthropic.claude-3-7-sonnet-20250219-v1:0":{"description":"Claude 3.7 sonet to najszybszy model następnej generacji od Anthropic. W por\xf3wnaniu do Claude 3 Haiku, Claude 3.7 Sonet wykazuje poprawę w r\xf3żnych umiejętnościach i przewyższa największy model poprzedniej generacji, Claude 3 Opus, w wielu testach inteligencji."},"us.anthropic.claude-haiku-4-5-20251001-v1:0":{"description":"Claude Haiku 4.5 to najszybszy i najbardziej inteligentny model Haiku firmy Anthropic, oferujący błyskawiczne działanie i zaawansowane możliwości rozumowania."},"us.anthropic.claude-sonnet-4-5-20250929-v1:0":{"description":"Claude Sonnet 4.5 to jak dotąd najbardziej zaawansowany model stworzony przez firmę Anthropic."},"v0-1.0-md":{"description":"Model v0-1.0-md to starsza wersja modelu udostępniana przez API v0"},"v0-1.5-lg":{"description":"Model v0-1.5-lg jest przeznaczony do zaawansowanych zadań myślenia lub rozumowania"},"v0-1.5-md":{"description":"Model v0-1.5-md jest odpowiedni do codziennych zadań i generowania interfejsu użytkownika (UI)"},"vercel/v0-1.0-md":{"description":"Dostęp do modelu stojącego za v0 do generowania, naprawiania i optymalizacji nowoczesnych aplikacji webowych, z rozumowaniem specyficznym dla framework\xf3w i aktualną wiedzą."},"vercel/v0-1.5-md":{"description":"Dostęp do modelu stojącego za v0 do generowania, naprawiania i optymalizacji nowoczesnych aplikacji webowych, z rozumowaniem specyficznym dla framework\xf3w i aktualną wiedzą."},"wan2.2-t2i-flash":{"description":"Wersja ekspresowa Wanxiang 2.2, najnowszy model. Kompleksowo ulepszony pod względem kreatywności, stabilności i realizmu, generuje szybko i oferuje wysoką opłacalność."},"wan2.2-t2i-plus":{"description":"Profesjonalna wersja Wanxiang 2.2, najnowszy model. Kompleksowo ulepszony pod względem kreatywności, stabilności i realizmu, generuje obrazy o bogatych detalach."},"wanx-v1":{"description":"Podstawowy model generowania obraz\xf3w na podstawie tekstu. Odpowiada uniwersalnemu modelowi 1.0 na oficjalnej stronie Tongyi Wanxiang."},"wanx2.0-t2i-turbo":{"description":"Specjalizuje się w realistycznych portretach, oferuje średnią prędkość i niskie koszty. Odpowiada ekspresowemu modelowi 2.0 na oficjalnej stronie Tongyi Wanxiang."},"wanx2.1-t2i-plus":{"description":"Wersja z kompleksowymi ulepszeniami. Generuje obrazy o bogatszych detalach, z nieco wolniejszą prędkością. Odpowiada profesjonalnemu modelowi 2.1 na oficjalnej stronie Tongyi Wanxiang."},"wanx2.1-t2i-turbo":{"description":"Wersja z kompleksowymi ulepszeniami. Generuje szybko, oferuje wszechstronne efekty i wysoką opłacalność. Odpowiada ekspresowemu modelowi 2.1 na oficjalnej stronie Tongyi Wanxiang."},"whisper-1":{"description":"Uniwersalny model rozpoznawania mowy, obsługujący wielojęzyczne rozpoznawanie mowy, tłumaczenie mowy oraz identyfikację języka."},"wizardlm2":{"description":"WizardLM 2 to model językowy dostarczany przez Microsoft AI, kt\xf3ry wyr\xf3żnia się w złożonych dialogach, wielojęzyczności, wnioskowaniu i inteligentnych asystentach."},"wizardlm2:8x22b":{"description":"WizardLM 2 to model językowy dostarczany przez Microsoft AI, kt\xf3ry wyr\xf3żnia się w złożonych dialogach, wielojęzyczności, wnioskowaniu i inteligentnych asystentach."},"x-ai/grok-4-fast":{"description":"Z radością przedstawiamy Grok 4 Fast — nasze najnowsze osiągnięcie w dziedzinie modeli wnioskowania zoptymalizowanych pod względem koszt\xf3w."},"x-ai/grok-code-fast-1":{"description":"Z dumą prezentujemy grok-code-fast-1 — szybki i ekonomiczny model wnioskowania, kt\xf3ry doskonale sprawdza się w kodowaniu przez agent\xf3w."},"x1":{"description":"Model Spark X1 zostanie dalej ulepszony, osiągając wyniki w zadaniach og\xf3lnych, takich jak rozumowanie, generowanie tekstu i rozumienie języka, kt\xf3re będą por\xf3wnywalne z OpenAI o1 i DeepSeek R1."},"xai/grok-2":{"description":"Grok 2 to nowoczesny model językowy o zaawansowanych zdolnościach wnioskowania. Wyr\xf3żnia się w czacie, kodowaniu i wnioskowaniu, przewyższając Claude 3.5 Sonnet i GPT-4-Turbo na liście LMSYS."},"xai/grok-2-vision":{"description":"Model wizualny Grok 2 doskonale radzi sobie z zadaniami opartymi na wizji, oferując najnowocześniejszą wydajność w wizualnym wnioskowaniu matematycznym (MathVista) i pytaniach opartych na dokumentach (DocVQA). Potrafi przetwarzać r\xf3żnorodne informacje wizualne, w tym dokumenty, wykresy, diagramy, zrzuty ekranu i zdjęcia."},"xai/grok-3":{"description":"Flagowy model xAI, doskonały w zastosowaniach korporacyjnych, takich jak ekstrakcja danych, kodowanie i streszczanie tekstu. Posiada głęboką wiedzę dziedzinową w finansach, opiece zdrowotnej, prawie i nauce."},"xai/grok-3-fast":{"description":"Flagowy model xAI, doskonały w zastosowaniach korporacyjnych, takich jak ekstrakcja danych, kodowanie i streszczanie tekstu. Wersja szybka działa na szybszej infrastrukturze, oferując znacznie kr\xf3tsze czasy odpowiedzi. Zwiększona szybkość wiąże się z wyższym kosztem na token wyjściowy."},"xai/grok-3-mini":{"description":"Lekki model xAI, kt\xf3ry myśli przed odpowiedzią. Idealny do prostych lub logicznych zadań, kt\xf3re nie wymagają głębokiej wiedzy dziedzinowej. Dostępne są surowe ścieżki myślowe."},"xai/grok-3-mini-fast":{"description":"Lekki model xAI, kt\xf3ry myśli przed odpowiedzią. Idealny do prostych lub logicznych zadań, kt\xf3re nie wymagają głębokiej wiedzy dziedzinowej. Dostępne są surowe ścieżki myślowe. Wersja szybka działa na szybszej infrastrukturze, oferując znacznie kr\xf3tsze czasy odpowiedzi. Zwiększona szybkość wiąże się z wyższym kosztem na token wyjściowy."},"xai/grok-4":{"description":"Najnowszy i najlepszy flagowy model xAI, oferujący niezr\xf3wnaną wydajność w języku naturalnym, matematyce i wnioskowaniu — idealny wszechstronny zawodnik."},"yi-large":{"description":"Nowy model z miliardami parametr\xf3w, oferujący niezwykłe możliwości w zakresie pytań i generowania tekstu."},"yi-large-fc":{"description":"Model yi-large z wzmocnioną zdolnością do wywołań narzędzi, odpowiedni do r\xf3żnych scenariuszy biznesowych wymagających budowy agent\xf3w lub workflow."},"yi-large-preview":{"description":"Wersja wstępna, zaleca się korzystanie z yi-large (nowa wersja)."},"yi-large-rag":{"description":"Zaawansowana usługa oparta na modelu yi-large, łącząca techniki wyszukiwania i generowania, oferująca precyzyjne odpowiedzi oraz usługi wyszukiwania informacji w czasie rzeczywistym."},"yi-large-turbo":{"description":"Model o doskonałym stosunku jakości do ceny, z doskonałymi osiągami. Wysokiej precyzji optymalizacja w oparciu o wydajność, szybkość wnioskowania i koszty."},"yi-lightning":{"description":"Najnowocześniejszy model o wysokiej wydajności, zapewniający wysoką jakość wyjściową przy znacznie zwiększonej prędkości wnioskowania."},"yi-lightning-lite":{"description":"Lekka wersja, zaleca się użycie yi-lightning."},"yi-medium":{"description":"Model średniej wielkości, zr\xf3wnoważony pod względem możliwości i koszt\xf3w. Głęboko zoptymalizowana zdolność do przestrzegania poleceń."},"yi-medium-200k":{"description":"Okno kontekstowe o długości 200K, oferujące głębokie zrozumienie i generowanie długich tekst\xf3w."},"yi-spark":{"description":"Mały, ale potężny, lekki model o wysokiej prędkości. Oferuje wzmocnione możliwości obliczeń matematycznych i pisania kodu."},"yi-vision":{"description":"Model do złożonych zadań wizualnych, oferujący wysoką wydajność w zakresie rozumienia i analizy obraz\xf3w."},"yi-vision-v2":{"description":"Model do złożonych zadań wizualnych, oferujący wysokowydajną zdolność rozumienia i analizy na podstawie wielu obraz\xf3w."},"z-ai/glm-4.6":{"description":"GLM-4.6 to najnowszy flagowy model od Zhipu AI, kt\xf3ry znacząco przewyższa poprzednie wersje w zakresie zaawansowanego kodowania, przetwarzania długich tekst\xf3w, wnioskowania i zdolności agentowych."},"zai-org/GLM-4.5":{"description":"GLM-4.5 to podstawowy model zaprojektowany specjalnie do zastosowań agentowych, wykorzystujący architekturę mieszanych ekspert\xf3w (Mixture-of-Experts). Model jest głęboko zoptymalizowany pod kątem wywoływania narzędzi, przeglądania stron internetowych, inżynierii oprogramowania i programowania frontendowego, wspierając bezproblemową integrację z inteligentnymi agentami kodu takimi jak Claude Code i Roo Code. GLM-4.5 stosuje hybrydowy tryb wnioskowania, dostosowując się do złożonych i codziennych scenariuszy użycia."},"zai-org/GLM-4.5-Air":{"description":"GLM-4.5-Air to podstawowy model zaprojektowany specjalnie do zastosowań agentowych, wykorzystujący architekturę mieszanych ekspert\xf3w (Mixture-of-Experts). Model jest głęboko zoptymalizowany pod kątem wywoływania narzędzi, przeglądania stron internetowych, inżynierii oprogramowania i programowania frontendowego, wspierając bezproblemową integrację z inteligentnymi agentami kodu takimi jak Claude Code i Roo Code. GLM-4.5 stosuje hybrydowy tryb wnioskowania, dostosowując się do złożonych i codziennych scenariuszy użycia."},"zai-org/GLM-4.5V":{"description":"GLM-4.5V to najnowszej generacji model wizualno‑językowy (VLM) wydany przez Zhipu AI. Model zbudowano na flagowym modelu tekstowym GLM-4.5-Air, kt\xf3ry dysponuje 106 mld parametr\xf3w łącznie oraz 12 mld parametr\xf3w aktywacyjnych. Wykorzystuje architekturę Mixture-of-Experts (MoE) i został zaprojektowany, by przy niższych kosztach inferencji osiągać znakomitą wydajność. GLM-4.5V technicznie kontynuuje podejście GLM-4.1V-Thinking i wprowadza innowacje takie jak tr\xf3jwymiarowe obrotowe kodowanie pozycji (3D‑RoPE), co znacząco poprawia postrzeganie i wnioskowanie dotyczące relacji przestrzennych w 3D. Dzięki optymalizacjom w fazach pretrenowania, nadzorowanego dostrajania i uczenia przez wzmocnienie model potrafi przetwarzać obrazy, filmy i długie dokumenty, osiągając czołowe wyniki wśr\xf3d otwartoźr\xf3dłowych modeli w 41 publicznych benchmarkach multimodalnych. Dodatkowo model zyskał przełącznik „trybu myślenia”, kt\xf3ry pozwala użytkownikom elastycznie wybierać między szybką odpowiedzią a głębokim rozumowaniem, aby zr\xf3wnoważyć efektywność i skuteczność."},"zai-org/GLM-4.6":{"description":"W por\xf3wnaniu do GLM-4.5, GLM-4.6 wprowadza wiele kluczowych ulepszeń. Okno kontekstowe zostało rozszerzone z 128K do 200K token\xf3w, co pozwala modelowi radzić sobie z bardziej złożonymi zadaniami agenta. Model osiągnął wyższe wyniki w benchmarkach kodu oraz wykazał lepszą wydajność w rzeczywistych zastosowaniach takich jak Claude Code, Cline, Roo Code i Kilo Code, w tym poprawę w generowaniu wizualnie dopracowanych stron frontendowych. GLM-4.6 wykazuje wyraźny wzrost wydajności inferencyjnej i wspiera użycie narzędzi podczas inferencji, co przekłada się na silniejsze zdolności og\xf3lne. Model lepiej radzi sobie z użyciem narzędzi i agentami opartymi na wyszukiwaniu oraz jest bardziej efektywnie integrowany w ramach architektury agent\xf3w. W pisaniu model lepiej odpowiada ludzkim preferencjom pod względem stylu i czytelności oraz zachowuje się bardziej naturalnie w scenariuszach odgrywania r\xf3l."},"zai/glm-4.5":{"description":"Seria modeli GLM-4.5 to podstawowe modele zaprojektowane specjalnie dla agent\xf3w. Flagowy GLM-4.5 integruje 355 miliard\xf3w parametr\xf3w łącznie (32 miliardy aktywnych), łącząc zdolności wnioskowania, kodowania i agent\xf3w do rozwiązywania złożonych wymagań aplikacji. Jako system hybrydowego wnioskowania oferuje podw\xf3jne tryby operacyjne."},"zai/glm-4.5-air":{"description":"GLM-4.5 i GLM-4.5-Air to nasze najnowsze flagowe modele, zaprojektowane jako podstawowe modele dla zastosowań agentowych. Oba wykorzystują architekturę hybrydowych ekspert\xf3w (MoE). GLM-4.5 ma 355 miliard\xf3w parametr\xf3w łącznie i 32 miliardy aktywnych na pojedyncze przejście, podczas gdy GLM-4.5-Air ma uproszczoną konstrukcję z 106 miliardami parametr\xf3w łącznie i 12 miliardami aktywnych."},"zai/glm-4.5v":{"description":"GLM-4.5V zbudowany jest na bazie GLM-4.5-Air, dziedzicząc zweryfikowane technologie GLM-4.1V-Thinking, jednocześnie skutecznie skalując się dzięki potężnej architekturze MoE z 106 miliardami parametr\xf3w."}}')}}]);