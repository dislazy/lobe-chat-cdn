"use strict";(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[72593],{72593:e=>{e.exports=JSON.parse('{"01-ai/yi-1.5-34b-chat":{"description":"Cero Uno, el \xfaltimo modelo de ajuste fino de c\xf3digo abierto, cuenta con 34 mil millones de par\xe1metros, con ajuste fino que admite m\xfaltiples escenarios de conversaci\xf3n y datos de entrenamiento de alta calidad, alineados con las preferencias humanas."},"01-ai/yi-1.5-9b-chat":{"description":"Cero Uno, el \xfaltimo modelo de ajuste fino de c\xf3digo abierto, cuenta con 9 mil millones de par\xe1metros, con ajuste fino que admite m\xfaltiples escenarios de conversaci\xf3n y datos de entrenamiento de alta calidad, alineados con las preferencias humanas."},"360/deepseek-r1":{"description":"【Versi\xf3n desplegada de 360】DeepSeek-R1 utiliza t\xe9cnicas de aprendizaje por refuerzo a gran escala en la fase de post-entrenamiento, mejorando enormemente la capacidad de inferencia del modelo con muy pocos datos etiquetados. En tareas de matem\xe1ticas, c\xf3digo y razonamiento en lenguaje natural, su rendimiento es comparable al de la versi\xf3n oficial de OpenAI o1."},"360gpt-pro":{"description":"360GPT Pro, como un miembro importante de la serie de modelos de IA de 360, satisface diversas aplicaciones de procesamiento de lenguaje natural con su eficiente capacidad de manejo de textos, soportando la comprensi\xf3n de textos largos y funciones de di\xe1logo en m\xfaltiples turnos."},"360gpt-pro-trans":{"description":"Modelo especializado en traducci\xf3n, optimizado con un ajuste fino profundo, con resultados de traducci\xf3n l\xedderes."},"360gpt-turbo":{"description":"360GPT Turbo ofrece potentes capacidades de c\xe1lculo y di\xe1logo, con una excelente comprensi\xf3n sem\xe1ntica y eficiencia de generaci\xf3n, siendo la soluci\xf3n ideal para empresas y desarrolladores como asistente inteligente."},"360gpt-turbo-responsibility-8k":{"description":"360GPT Turbo Responsibility 8K enfatiza la seguridad sem\xe1ntica y la responsabilidad, dise\xf1ado espec\xedficamente para aplicaciones que requieren altos est\xe1ndares de seguridad de contenido, asegurando la precisi\xf3n y robustez de la experiencia del usuario."},"360gpt2-o1":{"description":"360gpt2-o1 utiliza la b\xfasqueda en \xe1rbol para construir cadenas de pensamiento e introduce un mecanismo de reflexi\xf3n, entrenado mediante aprendizaje por refuerzo, lo que le permite tener la capacidad de auto-reflexi\xf3n y correcci\xf3n de errores."},"360gpt2-pro":{"description":"360GPT2 Pro es un modelo avanzado de procesamiento de lenguaje natural lanzado por la empresa 360, con una excelente capacidad de generaci\xf3n y comprensi\xf3n de textos, destac\xe1ndose especialmente en la generaci\xf3n y creaci\xf3n de contenido, capaz de manejar tareas complejas de conversi\xf3n de lenguaje y representaci\xf3n de roles."},"360zhinao2-o1":{"description":"360zhinao2-o1 utiliza b\xfasqueda en \xe1rbol para construir cadenas de pensamiento e introduce un mecanismo de reflexi\xf3n, entrenando el modelo con aprendizaje por refuerzo, lo que le confiere la capacidad de auto-reflexi\xf3n y correcci\xf3n de errores."},"4.0Ultra":{"description":"Spark4.0 Ultra es la versi\xf3n m\xe1s poderosa de la serie de modelos grandes de Xinghuo, mejorando la comprensi\xf3n y capacidad de resumen de contenido textual al actualizar la conexi\xf3n de b\xfasqueda en l\xednea. Es una soluci\xf3n integral para mejorar la productividad en la oficina y responder con precisi\xf3n a las necesidades, siendo un producto inteligente l\xedder en la industria."},"AnimeSharp":{"description":"AnimeSharp (tambi\xe9n conocido como “4x‑AnimeSharp”) es un modelo de superresoluci\xf3n de c\xf3digo abierto desarrollado por Kim2091 basado en la arquitectura ESRGAN, enfocado en la ampliaci\xf3n y el afilado de im\xe1genes con estilo anime. Fue renombrado en febrero de 2022 desde “4x-TextSharpV1”, originalmente tambi\xe9n aplicable a im\xe1genes de texto, pero con un rendimiento significativamente optimizado para contenido anime."},"Baichuan2-Turbo":{"description":"Utiliza tecnolog\xeda de b\xfasqueda mejorada para lograr un enlace completo entre el gran modelo y el conocimiento del dominio, as\xed como el conocimiento de toda la red. Soporta la carga de documentos en PDF, Word y otros formatos, as\xed como la entrada de URL, proporcionando informaci\xf3n oportuna y completa, con resultados precisos y profesionales."},"Baichuan3-Turbo":{"description":"Optimizado para escenarios de alta frecuencia empresarial, con mejoras significativas en el rendimiento y una excelente relaci\xf3n calidad-precio. En comparaci\xf3n con el modelo Baichuan2, la creaci\xf3n de contenido mejora un 20%, las preguntas y respuestas de conocimiento un 17%, y la capacidad de interpretaci\xf3n de roles un 40%. En general, su rendimiento es superior al de GPT-3.5."},"Baichuan3-Turbo-128k":{"description":"Con una ventana de contexto ultra larga de 128K, optimizado para escenarios de alta frecuencia empresarial, con mejoras significativas en el rendimiento y una excelente relaci\xf3n calidad-precio. En comparaci\xf3n con el modelo Baichuan2, la creaci\xf3n de contenido mejora un 20%, las preguntas y respuestas de conocimiento un 17%, y la capacidad de interpretaci\xf3n de roles un 40%. En general, su rendimiento es superior al de GPT-3.5."},"Baichuan4":{"description":"El modelo tiene la mejor capacidad en el pa\xeds, superando a los modelos principales extranjeros en tareas en chino como enciclopedias, textos largos y creaci\xf3n generativa. Tambi\xe9n cuenta con capacidades multimodales l\xedderes en la industria, destac\xe1ndose en m\xfaltiples evaluaciones de referencia autorizadas."},"Baichuan4-Air":{"description":"El modelo m\xe1s potente del pa\xeds, superando a los modelos principales extranjeros en tareas en chino como enciclopedias, textos largos y creaci\xf3n generativa. Tambi\xe9n cuenta con capacidades multimodales l\xedderes en la industria, destac\xe1ndose en m\xfaltiples evaluaciones de referencia."},"Baichuan4-Turbo":{"description":"El modelo m\xe1s potente del pa\xeds, superando a los modelos principales extranjeros en tareas en chino como enciclopedias, textos largos y creaci\xf3n generativa. Tambi\xe9n cuenta con capacidades multimodales l\xedderes en la industria, destac\xe1ndose en m\xfaltiples evaluaciones de referencia."},"ByteDance-Seed/Seed-OSS-36B-Instruct":{"description":"Seed-OSS es una serie de modelos de lenguaje grandes de c\xf3digo abierto desarrollados por el equipo Seed de ByteDance, dise\xf1ados espec\xedficamente para un potente manejo de contextos largos, razonamiento, agentes inteligentes y capacidades generales. Dentro de esta serie, Seed-OSS-36B-Instruct es un modelo afinado por instrucciones con 36 mil millones de par\xe1metros, que soporta de forma nativa contextos ultra largos, permitiendo procesar grandes vol\xfamenes de documentos o complejas bases de c\xf3digo de una sola vez. Este modelo est\xe1 especialmente optimizado para tareas de razonamiento, generaci\xf3n de c\xf3digo y agentes (como el uso de herramientas), manteniendo un equilibrio y una capacidad general sobresaliente. Una caracter\xedstica destacada de este modelo es la funci\xf3n \\"Presupuesto de Pensamiento\\" (Thinking Budget), que permite a los usuarios ajustar de manera flexible la longitud del razonamiento seg\xfan sus necesidades, mejorando as\xed la eficiencia en aplicaciones pr\xe1cticas."},"DeepSeek-R1":{"description":"LLM eficiente de \xfaltima generaci\xf3n, experto en razonamiento, matem\xe1ticas y programaci\xf3n."},"DeepSeek-R1-Distill-Llama-70B":{"description":"DeepSeek R1, el modelo m\xe1s grande e inteligente del conjunto DeepSeek, ha sido destilado en la arquitectura Llama 70B. Basado en pruebas de referencia y evaluaciones humanas, este modelo es m\xe1s inteligente que el Llama 70B original, destac\xe1ndose especialmente en tareas que requieren precisi\xf3n matem\xe1tica y factual."},"DeepSeek-R1-Distill-Qwen-1.5B":{"description":"El modelo de destilaci\xf3n DeepSeek-R1 basado en Qwen2.5-Math-1.5B optimiza el rendimiento de inferencia mediante aprendizaje por refuerzo y datos de arranque en fr\xedo, actualizando el est\xe1ndar de m\xfaltiples tareas en modelos de c\xf3digo abierto."},"DeepSeek-R1-Distill-Qwen-14B":{"description":"El modelo de destilaci\xf3n DeepSeek-R1 basado en Qwen2.5-14B optimiza el rendimiento de inferencia mediante aprendizaje por refuerzo y datos de arranque en fr\xedo, actualizando el est\xe1ndar de m\xfaltiples tareas en modelos de c\xf3digo abierto."},"DeepSeek-R1-Distill-Qwen-32B":{"description":"La serie DeepSeek-R1 optimiza el rendimiento de inferencia mediante aprendizaje por refuerzo y datos de arranque en fr\xedo, actualizando el est\xe1ndar de m\xfaltiples tareas en modelos de c\xf3digo abierto, superando el nivel de OpenAI-o1-mini."},"DeepSeek-R1-Distill-Qwen-7B":{"description":"El modelo de destilaci\xf3n DeepSeek-R1 basado en Qwen2.5-Math-7B optimiza el rendimiento de inferencia mediante aprendizaje por refuerzo y datos de arranque en fr\xedo, actualizando el est\xe1ndar de m\xfaltiples tareas en modelos de c\xf3digo abierto."},"DeepSeek-V3":{"description":"DeepSeek-V3 es un modelo MoE desarrollado internamente por la empresa DeepSeek. Los resultados de DeepSeek-V3 en m\xfaltiples evaluaciones superan a otros modelos de c\xf3digo abierto como Qwen2.5-72B y Llama-3.1-405B, y su rendimiento es comparable al de los modelos cerrados de primer nivel mundial como GPT-4o y Claude-3.5-Sonnet."},"DeepSeek-V3-1":{"description":"DeepSeek V3.1: modelo de inferencia de pr\xf3xima generaci\xf3n, mejora la capacidad de razonamiento complejo y pensamiento en cadena, adecuado para tareas que requieren an\xe1lisis profundo."},"DeepSeek-V3-Fast":{"description":"Proveedor del modelo: plataforma sophnet. DeepSeek V3 Fast es la versi\xf3n de alta velocidad y alto TPS de DeepSeek V3 0324, completamente sin cuantificaci\xf3n, con mayor capacidad en c\xf3digo y matem\xe1ticas, \xa1y respuesta m\xe1s r\xe1pida!"},"DeepSeek-V3.1":{"description":"DeepSeek-V3.1 en modo no reflexivo; DeepSeek-V3.1 es un nuevo modelo h\xedbrido de razonamiento lanzado por DeepSeek, que soporta dos modos de razonamiento: reflexivo y no reflexivo, con una eficiencia de pensamiento superior a DeepSeek-R1-0528. Tras una optimizaci\xf3n post-entrenamiento, el uso de herramientas por agentes y el desempe\xf1o en tareas de agentes inteligentes han mejorado significativamente."},"DeepSeek-V3.1-Fast":{"description":"DeepSeek V3.1 Fast es la versi\xf3n de alta TPS y alta velocidad del DeepSeek V3.1. Modo h\xedbrido de pensamiento: mediante la modificaci\xf3n de la plantilla de chat, un solo modelo puede soportar simult\xe1neamente modos reflexivo y no reflexivo. Llamadas a herramientas m\xe1s inteligentes: gracias a la optimizaci\xf3n post-entrenamiento, el modelo mejora notablemente su desempe\xf1o en el uso de herramientas y tareas de agentes."},"DeepSeek-V3.1-Think":{"description":"DeepSeek-V3.1 en modo reflexivo; DeepSeek-V3.1 es un nuevo modelo h\xedbrido de razonamiento lanzado por DeepSeek, que soporta dos modos de razonamiento: reflexivo y no reflexivo, con una eficiencia de pensamiento superior a DeepSeek-R1-0528. Tras una optimizaci\xf3n post-entrenamiento, el uso de herramientas por agentes y el desempe\xf1o en tareas de agentes inteligentes han mejorado significativamente."},"DeepSeek-V3.2-Exp":{"description":"DeepSeek V3.2 es el \xfaltimo modelo general lanzado por DeepSeek, que soporta una arquitectura de inferencia h\xedbrida y cuenta con capacidades de agente m\xe1s potentes."},"DeepSeek-V3.2-Exp-Think":{"description":"Modo de pensamiento de DeepSeek V3.2. Antes de proporcionar la respuesta final, el modelo genera una cadena de razonamiento para mejorar la precisi\xf3n de la respuesta."},"Doubao-lite-128k":{"description":"Doubao-lite ofrece una velocidad de respuesta excepcional y una mejor relaci\xf3n calidad-precio, proporcionando opciones m\xe1s flexibles para diferentes escenarios de los clientes. Soporta inferencia y ajuste fino con una ventana de contexto de 128k."},"Doubao-lite-32k":{"description":"Doubao-lite ofrece una velocidad de respuesta excepcional y una mejor relaci\xf3n calidad-precio, proporcionando opciones m\xe1s flexibles para diferentes escenarios de los clientes. Soporta inferencia y ajuste fino con una ventana de contexto de 32k."},"Doubao-lite-4k":{"description":"Doubao-lite ofrece una velocidad de respuesta excepcional y una mejor relaci\xf3n calidad-precio, proporcionando opciones m\xe1s flexibles para diferentes escenarios de los clientes. Soporta inferencia y ajuste fino con una ventana de contexto de 4k."},"Doubao-pro-128k":{"description":"El modelo principal con mejor rendimiento, adecuado para tareas complejas, con excelentes resultados en preguntas de referencia, res\xfamenes, creaci\xf3n, clasificaci\xf3n de texto, juegos de rol y otros escenarios. Soporta inferencia y ajuste fino con una ventana de contexto de 128k."},"Doubao-pro-32k":{"description":"El modelo principal con mejor rendimiento, adecuado para tareas complejas, con excelentes resultados en preguntas de referencia, res\xfamenes, creaci\xf3n, clasificaci\xf3n de texto, juegos de rol y otros escenarios. Soporta inferencia y ajuste fino con una ventana de contexto de 32k."},"Doubao-pro-4k":{"description":"El modelo principal con mejor rendimiento, adecuado para tareas complejas, con excelentes resultados en preguntas de referencia, res\xfamenes, creaci\xf3n, clasificaci\xf3n de texto, juegos de rol y otros escenarios. Soporta inferencia y ajuste fino con una ventana de contexto de 4k."},"DreamO":{"description":"DreamO es un modelo de generaci\xf3n de im\xe1genes personalizado de c\xf3digo abierto desarrollado conjuntamente por ByteDance y la Universidad de Pek\xedn, dise\xf1ado para soportar generaci\xf3n de im\xe1genes multitarea mediante una arquitectura unificada. Utiliza un m\xe9todo eficiente de modelado combinado para generar im\xe1genes altamente coherentes y personalizadas seg\xfan m\xfaltiples condiciones especificadas por el usuario, como identidad, sujeto, estilo y fondo."},"ERNIE-3.5-128K":{"description":"Modelo de lenguaje a gran escala de primera l\xednea desarrollado por Baidu, que abarca una vasta cantidad de corpus en chino y en ingl\xe9s, con potentes capacidades generales que pueden satisfacer la mayor\xeda de los requisitos de preguntas y respuestas en di\xe1logos, generaci\xf3n de contenido y aplicaciones de plugins; soporta la integraci\xf3n autom\xe1tica con el plugin de b\xfasqueda de Baidu, garantizando la actualidad de la informaci\xf3n en las respuestas."},"ERNIE-3.5-8K":{"description":"Modelo de lenguaje a gran escala de primera l\xednea desarrollado por Baidu, que abarca una vasta cantidad de corpus en chino y en ingl\xe9s, con potentes capacidades generales que pueden satisfacer la mayor\xeda de los requisitos de preguntas y respuestas en di\xe1logos, generaci\xf3n de contenido y aplicaciones de plugins; soporta la integraci\xf3n autom\xe1tica con el plugin de b\xfasqueda de Baidu, garantizando la actualidad de la informaci\xf3n en las respuestas."},"ERNIE-3.5-8K-Preview":{"description":"Modelo de lenguaje a gran escala de primera l\xednea desarrollado por Baidu, que abarca una vasta cantidad de corpus en chino y en ingl\xe9s, con potentes capacidades generales que pueden satisfacer la mayor\xeda de los requisitos de preguntas y respuestas en di\xe1logos, generaci\xf3n de contenido y aplicaciones de plugins; soporta la integraci\xf3n autom\xe1tica con el plugin de b\xfasqueda de Baidu, garantizando la actualidad de la informaci\xf3n en las respuestas."},"ERNIE-4.0-8K-Latest":{"description":"Modelo de lenguaje a gran escala ultra avanzado desarrollado por Baidu, que ha logrado una actualizaci\xf3n completa de las capacidades del modelo en comparaci\xf3n con ERNIE 3.5, siendo ampliamente aplicable a escenarios de tareas complejas en diversos campos; soporta la integraci\xf3n autom\xe1tica con el plugin de b\xfasqueda de Baidu, garantizando la actualidad de la informaci\xf3n en las respuestas."},"ERNIE-4.0-8K-Preview":{"description":"Modelo de lenguaje a gran escala ultra avanzado desarrollado por Baidu, que ha logrado una actualizaci\xf3n completa de las capacidades del modelo en comparaci\xf3n con ERNIE 3.5, siendo ampliamente aplicable a escenarios de tareas complejas en diversos campos; soporta la integraci\xf3n autom\xe1tica con el plugin de b\xfasqueda de Baidu, garantizando la actualidad de la informaci\xf3n en las respuestas."},"ERNIE-4.0-Turbo-8K-Latest":{"description":"Modelo de lenguaje a gran escala desarrollado por Baidu, con un rendimiento general excepcional, ampliamente aplicable a escenas complejas en diversos campos; soporta la conexi\xf3n autom\xe1tica al complemento de b\xfasqueda de Baidu, garantizando la actualidad de la informaci\xf3n de las preguntas y respuestas. En comparaci\xf3n con ERNIE 4.0, tiene un rendimiento superior."},"ERNIE-4.0-Turbo-8K-Preview":{"description":"Modelo de lenguaje a gran escala ultra avanzado desarrollado por Baidu, con un rendimiento excepcional en efectos generales, siendo ampliamente aplicable a escenarios de tareas complejas en diversos campos; soporta la integraci\xf3n autom\xe1tica con el plugin de b\xfasqueda de Baidu, garantizando la actualidad de la informaci\xf3n en las respuestas. En comparaci\xf3n con ERNIE 4.0, ofrece un rendimiento superior."},"ERNIE-Character-8K":{"description":"Modelo de lenguaje vertical desarrollado por Baidu, adecuado para aplicaciones como NPC en juegos, di\xe1logos de servicio al cliente, y juegos de rol conversacionales, con un estilo de personaje m\xe1s distintivo y coherente, y una mayor capacidad de seguir instrucciones, adem\xe1s de un rendimiento de inferencia superior."},"ERNIE-Lite-Pro-128K":{"description":"Modelo de lenguaje ligero desarrollado por Baidu, que combina un excelente rendimiento del modelo con una alta eficiencia de inferencia, superando a ERNIE Lite, adecuado para su uso en tarjetas de aceleraci\xf3n de IA de bajo consumo."},"ERNIE-Speed-128K":{"description":"Modelo de lenguaje de alto rendimiento desarrollado por Baidu, lanzado en 2024, con capacidades generales excepcionales, adecuado como modelo base para ajustes finos, manejando mejor problemas en escenarios espec\xedficos, y con un rendimiento de inferencia excelente."},"ERNIE-Speed-Pro-128K":{"description":"Modelo de lenguaje de alto rendimiento desarrollado por Baidu, lanzado en 2024, con capacidades generales excepcionales, superando a ERNIE Speed, adecuado como modelo base para ajustes finos, manejando mejor problemas en escenarios espec\xedficos, y con un rendimiento de inferencia excelente."},"FLUX-1.1-pro":{"description":"FLUX.1.1 Pro"},"FLUX.1-Kontext-dev":{"description":"FLUX.1-Kontext-dev es un modelo multimodal de generaci\xf3n y edici\xf3n de im\xe1genes desarrollado por Black Forest Labs, basado en la arquitectura Rectified Flow Transformer, con una escala de 12 mil millones de par\xe1metros. Se especializa en generar, reconstruir, mejorar o editar im\xe1genes bajo condiciones contextuales dadas. Combina las ventajas de generaci\xf3n controlada de modelos de difusi\xf3n con la capacidad de modelado contextual de Transformers, soportando salidas de alta calidad y aplic\xe1ndose ampliamente en tareas como restauraci\xf3n de im\xe1genes, completado y reconstrucci\xf3n de escenas visuales."},"FLUX.1-Kontext-pro":{"description":"FLUX.1 Kontext [pro]"},"FLUX.1-dev":{"description":"FLUX.1-dev es un modelo multimodal de lenguaje (MLLM) de c\xf3digo abierto desarrollado por Black Forest Labs, optimizado para tareas de texto e imagen, integrando capacidades de comprensi\xf3n y generaci\xf3n tanto visual como textual. Est\xe1 basado en avanzados modelos de lenguaje grande (como Mistral-7B) y mediante un codificador visual cuidadosamente dise\xf1ado y un ajuste fino por etapas con instrucciones, logra procesamiento colaborativo de texto e imagen y razonamiento para tareas complejas."},"Gryphe/MythoMax-L2-13b":{"description":"MythoMax-L2 (13B) es un modelo innovador, adecuado para aplicaciones en m\xfaltiples campos y tareas complejas."},"HelloMeme":{"description":"HelloMeme es una herramienta de IA que puede generar autom\xe1ticamente memes, GIFs o videos cortos basados en las im\xe1genes o acciones que proporciones. No requiere conocimientos de dibujo o programaci\xf3n; solo necesitas preparar una imagen de referencia y la herramienta te ayudar\xe1 a crear contenido atractivo, divertido y con estilo coherente."},"HiDream-I1-Full":{"description":"HiDream-E1-Full es un modelo de edici\xf3n de im\xe1genes multimodal de c\xf3digo abierto lanzado por HiDream.ai, basado en la avanzada arquitectura Diffusion Transformer y potenciado con una fuerte capacidad de comprensi\xf3n del lenguaje (incorporando LLaMA 3.1-8B-Instruct). Soporta generaci\xf3n de im\xe1genes, transferencia de estilo, edici\xf3n local y redibujo de contenido mediante instrucciones en lenguaje natural, con excelentes habilidades de comprensi\xf3n y ejecuci\xf3n texto-imagen."},"HunyuanDiT-v1.2-Diffusers-Distilled":{"description":"hunyuandit-v1.2-distilled es un modelo ligero de generaci\xf3n de im\xe1genes a partir de texto, optimizado mediante destilaci\xf3n para generar im\xe1genes de alta calidad r\xe1pidamente, especialmente adecuado para entornos con recursos limitados y tareas de generaci\xf3n en tiempo real."},"InstantCharacter":{"description":"InstantCharacter es un modelo de generaci\xf3n de personajes personalizados sin necesidad de ajuste fino, lanzado por el equipo de IA de Tencent en 2025, dise\xf1ado para lograr generaci\xf3n consistente y de alta fidelidad en m\xfaltiples escenarios. El modelo permite modelar un personaje bas\xe1ndose \xfanicamente en una imagen de referencia y transferirlo de forma flexible a diversos estilos, acciones y fondos."},"InternVL2-8B":{"description":"InternVL2-8B es un potente modelo de lenguaje visual, que admite el procesamiento multimodal de im\xe1genes y texto, capaz de identificar con precisi\xf3n el contenido de las im\xe1genes y generar descripciones o respuestas relacionadas."},"InternVL2.5-26B":{"description":"InternVL2.5-26B es un potente modelo de lenguaje visual, que admite el procesamiento multimodal de im\xe1genes y texto, capaz de identificar con precisi\xf3n el contenido de las im\xe1genes y generar descripciones o respuestas relacionadas."},"Kolors":{"description":"Kolors es un modelo de generaci\xf3n de im\xe1genes a partir de texto desarrollado por el equipo Kolors de Kuaishou. Entrenado con miles de millones de par\xe1metros, destaca en calidad visual, comprensi\xf3n sem\xe1ntica del chino y renderizado de texto."},"Kwai-Kolors/Kolors":{"description":"Kolors es un modelo de generaci\xf3n de im\xe1genes a partir de texto a gran escala basado en difusi\xf3n latente, desarrollado por el equipo Kolors de Kuaishou. Entrenado con miles de millones de pares texto-imagen, muestra ventajas significativas en calidad visual, precisi\xf3n sem\xe1ntica compleja y renderizado de caracteres en chino e ingl\xe9s. Soporta entradas en ambos idiomas y sobresale en la comprensi\xf3n y generaci\xf3n de contenido espec\xedfico en chino."},"Kwaipilot/KAT-Dev":{"description":"KAT-Dev (32B) es un modelo de c\xf3digo abierto con 32 mil millones de par\xe1metros, dise\xf1ado espec\xedficamente para tareas de ingenier\xeda de software. En la prueba de referencia SWE-Bench Verified, alcanz\xf3 una tasa de resoluci\xf3n del 62,4 %, situ\xe1ndose en el quinto lugar entre todos los modelos de c\xf3digo abierto de diferentes tama\xf1os. El modelo ha sido optimizado a trav\xe9s de m\xfaltiples etapas, incluyendo entrenamiento intermedio, ajuste fino supervisado (SFT) y aprendizaje por refuerzo (RL), con el objetivo de ofrecer un s\xf3lido soporte para tareas complejas de programaci\xf3n como autocompletado de c\xf3digo, correcci\xf3n de errores y revisi\xf3n de c\xf3digo."},"Llama-3.2-11B-Vision-Instruct":{"description":"Capacidad de razonamiento de im\xe1genes excepcional en im\xe1genes de alta resoluci\xf3n, adecuada para aplicaciones de comprensi\xf3n visual."},"Llama-3.2-90B-Vision-Instruct\\t":{"description":"Capacidad avanzada de razonamiento de im\xe1genes para aplicaciones de agentes de comprensi\xf3n visual."},"Meta-Llama-3-3-70B-Instruct":{"description":"Llama 3.3 70B: modelo Transformer de gran versatilidad, adecuado para tareas de di\xe1logo y generaci\xf3n."},"Meta-Llama-3.1-405B-Instruct":{"description":"Modelo de texto ajustado por instrucciones de Llama 3.1, optimizado para casos de uso de di\xe1logos multiling\xfces, que se destaca en muchos modelos de chat de c\xf3digo abierto y cerrados en benchmarks de la industria comunes."},"Meta-Llama-3.1-70B-Instruct":{"description":"Modelo de texto ajustado por instrucciones de Llama 3.1, optimizado para casos de uso de di\xe1logos multiling\xfces, que se destaca en muchos modelos de chat de c\xf3digo abierto y cerrados en benchmarks de la industria comunes."},"Meta-Llama-3.1-8B-Instruct":{"description":"Modelo de texto ajustado por instrucciones de Llama 3.1, optimizado para casos de uso de di\xe1logos multiling\xfces, que se destaca en muchos modelos de chat de c\xf3digo abierto y cerrados en benchmarks de la industria comunes."},"Meta-Llama-3.2-1B-Instruct":{"description":"Modelo de lenguaje peque\xf1o de \xfaltima generaci\xf3n, con comprensi\xf3n del lenguaje, excelente capacidad de razonamiento y generaci\xf3n de texto."},"Meta-Llama-3.2-3B-Instruct":{"description":"Modelo de lenguaje peque\xf1o de \xfaltima generaci\xf3n, con comprensi\xf3n del lenguaje, excelente capacidad de razonamiento y generaci\xf3n de texto."},"Meta-Llama-3.3-70B-Instruct":{"description":"Llama 3.3 es el modelo de lenguaje de c\xf3digo abierto multiling\xfce m\xe1s avanzado de la serie Llama, que ofrece un rendimiento comparable al modelo de 405B a un costo extremadamente bajo. Basado en la estructura Transformer, y mejorado en utilidad y seguridad a trav\xe9s de ajuste fino supervisado (SFT) y aprendizaje por refuerzo con retroalimentaci\xf3n humana (RLHF). Su versi\xf3n ajustada por instrucciones est\xe1 optimizada para di\xe1logos multiling\xfces, superando a muchos modelos de chat de c\xf3digo abierto y cerrados en m\xfaltiples benchmarks de la industria. La fecha l\xedmite de conocimiento es diciembre de 2023."},"Meta-Llama-4-Maverick-17B-128E-Instruct-FP8":{"description":"Llama 4 Maverick: modelo a gran escala basado en Mixture-of-Experts, que ofrece una estrategia eficiente de activaci\xf3n de expertos para un rendimiento sobresaliente en inferencia."},"MiniMax-M1":{"description":"Modelo de inferencia de desarrollo propio completamente nuevo. L\xedder mundial: 80K cadenas de pensamiento x 1M de entradas, con un rendimiento comparable a los modelos m\xe1s avanzados del extranjero."},"MiniMax-M2":{"description":"Dise\xf1ado espec\xedficamente para una codificaci\xf3n eficiente y flujos de trabajo con agentes."},"MiniMax-Text-01":{"description":"En la serie de modelos MiniMax-01, hemos realizado una innovaci\xf3n audaz: la implementaci\xf3n a gran escala del mecanismo de atenci\xf3n lineal, donde la arquitectura Transformer tradicional ya no es la \xfanica opci\xf3n. Este modelo tiene una cantidad de par\xe1metros de hasta 456 mil millones, con 45.9 mil millones por activaci\xf3n. El rendimiento general del modelo es comparable a los mejores modelos internacionales, y puede manejar de manera eficiente contextos de hasta 4 millones de tokens, que es 32 veces m\xe1s que GPT-4o y 20 veces m\xe1s que Claude-3.5-Sonnet."},"MiniMaxAI/MiniMax-M1-80k":{"description":"MiniMax-M1 es un modelo de inferencia de atenci\xf3n mixta a gran escala con pesos de c\xf3digo abierto, que cuenta con 456 mil millones de par\xe1metros, activando aproximadamente 45.9 mil millones de par\xe1metros por token. El modelo soporta de forma nativa contextos ultra largos de hasta 1 mill\xf3n de tokens y, gracias a su mecanismo de atenci\xf3n rel\xe1mpago, reduce en un 75 % las operaciones de punto flotante en tareas de generaci\xf3n de 100 mil tokens en comparaci\xf3n con DeepSeek R1. Adem\xe1s, MiniMax-M1 utiliza una arquitectura MoE (Mezcla de Expertos), combinando el algoritmo CISPO y un dise\xf1o de atenci\xf3n mixta para un entrenamiento eficiente mediante aprendizaje reforzado, logrando un rendimiento l\xedder en la industria en inferencia con entradas largas y escenarios reales de ingenier\xeda de software."},"MiniMaxAI/MiniMax-M2":{"description":"MiniMax-M2 redefine la eficiencia para los agentes inteligentes. Es un modelo MoE compacto, r\xe1pido y rentable, con un total de 230 mil millones de par\xe1metros y 10 mil millones de par\xe1metros activos. Est\xe1 dise\xf1ado para ofrecer un rendimiento de primer nivel en tareas de codificaci\xf3n y agentes, manteniendo al mismo tiempo una inteligencia general s\xf3lida. Con solo 10 mil millones de par\xe1metros activos, MiniMax-M2 ofrece un rendimiento comparable al de modelos a gran escala, lo que lo convierte en una opci\xf3n ideal para aplicaciones de alta eficiencia."},"Moonshot-Kimi-K2-Instruct":{"description":"Con un total de 1 bill\xf3n de par\xe1metros y 32 mil millones de par\xe1metros activados, este modelo no reflexivo alcanza niveles de vanguardia en conocimiento avanzado, matem\xe1ticas y codificaci\xf3n, destacando en tareas generales de agentes. Optimizado para tareas de agentes, no solo responde preguntas sino que tambi\xe9n puede actuar. Ideal para conversaciones improvisadas, chat general y experiencias de agentes, es un modelo de nivel reflexivo que no requiere largos tiempos de pensamiento."},"NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO":{"description":"Nous Hermes 2 - Mixtral 8x7B-DPO (46.7B) es un modelo de instrucciones de alta precisi\xf3n, adecuado para c\xe1lculos complejos."},"OmniConsistency":{"description":"OmniConsistency mejora la consistencia de estilo y la capacidad de generalizaci\xf3n en tareas de imagen a imagen mediante la introducci\xf3n de grandes Diffusion Transformers (DiTs) y datos estilizados emparejados, evitando la degradaci\xf3n del estilo."},"Phi-3-medium-128k-instruct":{"description":"El mismo modelo Phi-3-medium, pero con un tama\xf1o de contexto m\xe1s grande para RAG o indicaciones de pocos disparos."},"Phi-3-medium-4k-instruct":{"description":"Un modelo de 14B par\xe1metros, que demuestra mejor calidad que Phi-3-mini, con un enfoque en datos densos de razonamiento de alta calidad."},"Phi-3-mini-128k-instruct":{"description":"El mismo modelo Phi-3-mini, pero con un tama\xf1o de contexto m\xe1s grande para RAG o indicaciones de pocos disparos."},"Phi-3-mini-4k-instruct":{"description":"El miembro m\xe1s peque\xf1o de la familia Phi-3. Optimizado tanto para calidad como para baja latencia."},"Phi-3-small-128k-instruct":{"description":"El mismo modelo Phi-3-small, pero con un tama\xf1o de contexto m\xe1s grande para RAG o indicaciones de pocos disparos."},"Phi-3-small-8k-instruct":{"description":"Un modelo de 7B par\xe1metros, que demuestra mejor calidad que Phi-3-mini, con un enfoque en datos densos de razonamiento de alta calidad."},"Phi-3.5-mini-instruct":{"description":"Versi\xf3n actualizada del modelo Phi-3-mini."},"Phi-3.5-vision-instrust":{"description":"Versi\xf3n actualizada del modelo Phi-3-vision."},"Pro/Qwen/Qwen2-7B-Instruct":{"description":"Qwen2-7B-Instruct es un modelo de lenguaje a gran escala de ajuste fino por instrucciones dentro de la serie Qwen2, con un tama\xf1o de par\xe1metros de 7B. Este modelo se basa en la arquitectura Transformer, utilizando funciones de activaci\xf3n SwiGLU, sesgos de atenci\xf3n QKV y atenci\xf3n de consulta agrupada, entre otras t\xe9cnicas. Es capaz de manejar entradas a gran escala. Este modelo ha destacado en m\xfaltiples pruebas de referencia en comprensi\xf3n del lenguaje, generaci\xf3n, capacidad multiling\xfce, codificaci\xf3n, matem\xe1ticas y razonamiento, superando a la mayor\xeda de los modelos de c\xf3digo abierto y mostrando competitividad comparable a modelos propietarios en ciertas tareas. Qwen2-7B-Instruct ha mostrado mejoras significativas en m\xfaltiples evaluaciones en comparaci\xf3n con Qwen1.5-7B-Chat."},"Pro/Qwen/Qwen2.5-7B-Instruct":{"description":"Qwen2.5-7B-Instruct es uno de los \xfaltimos modelos de lenguaje a gran escala lanzados por Alibaba Cloud. Este modelo de 7B ha mejorado significativamente en \xe1reas como codificaci\xf3n y matem\xe1ticas. Tambi\xe9n ofrece soporte multiling\xfce, abarcando m\xe1s de 29 idiomas, incluidos chino e ingl\xe9s. El modelo ha mostrado mejoras significativas en el seguimiento de instrucciones, comprensi\xf3n de datos estructurados y generaci\xf3n de salidas estructuradas (especialmente JSON)."},"Pro/Qwen/Qwen2.5-Coder-7B-Instruct":{"description":"Qwen2.5-Coder-7B-Instruct es la \xfaltima versi\xf3n de la serie de modelos de lenguaje a gran escala espec\xedficos para c\xf3digo lanzada por Alibaba Cloud. Este modelo, basado en Qwen2.5, ha mejorado significativamente la generaci\xf3n, razonamiento y reparaci\xf3n de c\xf3digo a trav\xe9s de un entrenamiento con 55 billones de tokens. No solo ha mejorado la capacidad de codificaci\xf3n, sino que tambi\xe9n ha mantenido ventajas en habilidades matem\xe1ticas y generales. El modelo proporciona una base m\xe1s completa para aplicaciones pr\xe1cticas como agentes de c\xf3digo."},"Pro/Qwen/Qwen2.5-VL-7B-Instruct":{"description":"Qwen2.5-VL es el nuevo miembro de la serie Qwen, con potentes capacidades de comprensi\xf3n visual. Puede analizar texto, gr\xe1ficos y dise\xf1os en im\xe1genes, comprender videos largos y capturar eventos. Es capaz de razonar, manipular herramientas, admitir el posicionamiento de objetos en m\xfaltiples formatos y generar salidas estructuradas. Optimiza la resoluci\xf3n din\xe1mica y la tasa de cuadros para la comprensi\xf3n de videos, adem\xe1s de mejorar la eficiencia del codificador visual."},"Pro/THUDM/GLM-4.1V-9B-Thinking":{"description":"GLM-4.1V-9B-Thinking es un modelo de lenguaje visual (VLM) de c\xf3digo abierto lanzado conjuntamente por Zhipu AI y el laboratorio KEG de la Universidad de Tsinghua, dise\xf1ado espec\xedficamente para manejar tareas cognitivas multimodales complejas. Este modelo se basa en el modelo base GLM-4-9B-0414 y mejora significativamente su capacidad y estabilidad de razonamiento multimodal mediante la introducci\xf3n del mecanismo de razonamiento \\"Cadena de Pensamiento\\" (Chain-of-Thought) y la adopci\xf3n de estrategias de aprendizaje reforzado."},"Pro/THUDM/glm-4-9b-chat":{"description":"GLM-4-9B-Chat es la versi\xf3n de c\xf3digo abierto de la serie de modelos preentrenados GLM-4 lanzada por Zhipu AI. Este modelo destaca en sem\xe1ntica, matem\xe1ticas, razonamiento, c\xf3digo y conocimiento. Adem\xe1s de soportar di\xe1logos de m\xfaltiples turnos, GLM-4-9B-Chat tambi\xe9n cuenta con funciones avanzadas como navegaci\xf3n web, ejecuci\xf3n de c\xf3digo, llamadas a herramientas personalizadas (Function Call) y razonamiento de textos largos. El modelo admite 26 idiomas, incluidos chino, ingl\xe9s, japon\xe9s, coreano y alem\xe1n. En m\xfaltiples pruebas de referencia, GLM-4-9B-Chat ha demostrado un rendimiento excepcional, como AlignBench-v2, MT-Bench, MMLU y C-Eval. Este modelo admite una longitud de contexto m\xe1xima de 128K, adecuado para investigaci\xf3n acad\xe9mica y aplicaciones comerciales."},"Pro/deepseek-ai/DeepSeek-R1":{"description":"DeepSeek-R1 es un modelo de inferencia impulsado por aprendizaje por refuerzo (RL) que aborda problemas de repetitividad y legibilidad en el modelo. Antes del RL, DeepSeek-R1 introdujo datos de arranque en fr\xedo, optimizando a\xfan m\xe1s el rendimiento de inferencia. Se desempe\xf1a de manera comparable a OpenAI-o1 en tareas matem\xe1ticas, de c\xf3digo e inferencia, y mejora el rendimiento general a trav\xe9s de m\xe9todos de entrenamiento cuidadosamente dise\xf1ados."},"Pro/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B":{"description":"DeepSeek-R1-Distill-Qwen-7B es un modelo obtenido mediante destilaci\xf3n de conocimiento basado en Qwen2.5-Math-7B. Este modelo se ha ajustado utilizando 800.000 muestras seleccionadas generadas por DeepSeek-R1, demostrando una excelente capacidad de razonamiento. Ha mostrado un rendimiento sobresaliente en m\xfaltiples pruebas de referencia, alcanzando un 92,8% de precisi\xf3n en MATH-500, un 55,5% de tasa de aprobaci\xf3n en AIME 2024 y una puntuaci\xf3n de 1189 en CodeForces, lo que demuestra una fuerte capacidad matem\xe1tica y de programaci\xf3n para un modelo de escala 7B."},"Pro/deepseek-ai/DeepSeek-V3":{"description":"DeepSeek-V3 es un modelo de lenguaje de expertos mixtos (MoE) con 671 mil millones de par\xe1metros, que utiliza atenci\xf3n potencial de m\xfaltiples cabezas (MLA) y la arquitectura DeepSeekMoE, combinando estrategias de balanceo de carga sin p\xe9rdidas auxiliares para optimizar la eficiencia de inferencia y entrenamiento. Preentrenado en 14.8 billones de tokens de alta calidad, y ajustado mediante supervisi\xf3n y aprendizaje por refuerzo, DeepSeek-V3 supera a otros modelos de c\xf3digo abierto y se acerca a los modelos cerrados l\xedderes."},"Pro/deepseek-ai/DeepSeek-V3.1-Terminus":{"description":"DeepSeek-V3.1-Terminus es una versi\xf3n actualizada del modelo V3.1 lanzado por DeepSeek, posicionada como un modelo de lenguaje grande con agentes h\xedbridos. Esta actualizaci\xf3n mantiene las capacidades originales del modelo, enfoc\xe1ndose en corregir problemas reportados por los usuarios y mejorar la estabilidad. Mejora significativamente la coherencia del lenguaje, reduciendo la mezcla de chino e ingl\xe9s y la aparici\xf3n de caracteres an\xf3malos. El modelo integra el “Modo de pensamiento” y el “Modo sin pensamiento”, permitiendo a los usuarios cambiar flexiblemente mediante plantillas de chat para adaptarse a diferentes tareas. Como optimizaci\xf3n importante, V3.1-Terminus mejora el rendimiento del agente de c\xf3digo y del agente de b\xfasqueda, haci\xe9ndolos m\xe1s confiables en la invocaci\xf3n de herramientas y en la ejecuci\xf3n de tareas complejas de m\xfaltiples pasos."},"Pro/deepseek-ai/DeepSeek-V3.2-Exp":{"description":"DeepSeek-V3.2-Exp es una versi\xf3n experimental lanzada por DeepSeek como un paso intermedio hacia una arquitectura de pr\xf3xima generaci\xf3n. Basado en V3.1-Terminus, introduce el mecanismo de Atenci\xf3n Dispersa de DeepSeek (DeepSeek Sparse Attention, DSA) para mejorar la eficiencia en el entrenamiento e inferencia con contextos largos. Ha sido especialmente optimizado para la invocaci\xf3n de herramientas, la comprensi\xf3n de documentos extensos y el razonamiento en m\xfaltiples pasos. V3.2-Exp act\xfaa como un puente entre la investigaci\xf3n y la producci\xf3n, ideal para usuarios que buscan explorar una mayor eficiencia de razonamiento en escenarios con presupuestos de contexto elevados."},"Pro/moonshotai/Kimi-K2-Instruct-0905":{"description":"Kimi K2-Instruct-0905 es la versi\xf3n m\xe1s reciente y potente de Kimi K2. Es un modelo de lenguaje de expertos mixtos (MoE) de primer nivel, con un total de un bill\xf3n de par\xe1metros y 32 mil millones de par\xe1metros activados. Las principales caracter\xedsticas de este modelo incluyen: inteligencia mejorada para agentes de codificaci\xf3n, mostrando un rendimiento notable en pruebas de referencia p\xfablicas y en tareas reales de agentes de codificaci\xf3n; y una experiencia mejorada en la codificaci\xf3n frontend, con avances tanto en la est\xe9tica como en la funcionalidad de la programaci\xf3n frontend."},"QwQ-32B-Preview":{"description":"QwQ-32B-Preview es un modelo de procesamiento de lenguaje natural innovador, capaz de manejar de manera eficiente tareas complejas de generaci\xf3n de di\xe1logos y comprensi\xf3n del contexto."},"Qwen/QVQ-72B-Preview":{"description":"QVQ-72B-Preview es un modelo de investigaci\xf3n desarrollado por el equipo de Qwen, enfocado en la capacidad de razonamiento visual, que tiene ventajas \xfanicas en la comprensi\xf3n de escenas complejas y en la resoluci\xf3n de problemas matem\xe1ticos relacionados con la visi\xf3n."},"Qwen/QwQ-32B":{"description":"QwQ es el modelo de inferencia de la serie Qwen. A diferencia de los modelos tradicionales de ajuste por instrucciones, QwQ posee habilidades de pensamiento e inferencia, lo que le permite lograr un rendimiento significativamente mejorado en tareas posteriores, especialmente en la resoluci\xf3n de problemas dif\xedciles. QwQ-32B es un modelo de inferencia de tama\xf1o mediano que puede competir en rendimiento con los modelos de inferencia m\xe1s avanzados (como DeepSeek-R1, o1-mini). Este modelo utiliza tecnolog\xedas como RoPE, SwiGLU, RMSNorm y sesgo de atenci\xf3n QKV, y cuenta con una estructura de red de 64 capas y 40 cabezas de atenci\xf3n Q (en la arquitectura GQA, KV es de 8)."},"Qwen/QwQ-32B-Preview":{"description":"QwQ-32B-Preview es el \xfaltimo modelo de investigaci\xf3n experimental de Qwen, enfocado en mejorar la capacidad de razonamiento de la IA. A trav\xe9s de la exploraci\xf3n de mecanismos complejos como la mezcla de lenguajes y el razonamiento recursivo, sus principales ventajas incluyen una poderosa capacidad de an\xe1lisis de razonamiento, as\xed como habilidades matem\xe1ticas y de programaci\xf3n. Sin embargo, tambi\xe9n presenta problemas de cambio de idioma, ciclos de razonamiento, consideraciones de seguridad y diferencias en otras capacidades."},"Qwen/Qwen-Image":{"description":"Qwen-Image es un modelo base de generaci\xf3n de im\xe1genes desarrollado por el equipo Tongyi Qianwen de Alibaba, con 20 mil millones de par\xe1metros. Este modelo ha logrado avances significativos en la representaci\xf3n compleja de texto y la edici\xf3n precisa de im\xe1genes, destac\xe1ndose especialmente en la generaci\xf3n de im\xe1genes con texto en chino e ingl\xe9s de alta fidelidad. Qwen-Image no solo puede manejar dise\xf1os de m\xfaltiples l\xedneas y textos a nivel de p\xe1rrafo, sino que tambi\xe9n mantiene la coherencia tipogr\xe1fica y la armon\xeda contextual al generar im\xe1genes. Adem\xe1s de su sobresaliente capacidad de renderizado de texto, el modelo admite una amplia gama de estilos art\xedsticos, desde fotograf\xeda realista hasta est\xe9tica de anime, adapt\xe1ndose con flexibilidad a diversas necesidades creativas. Tambi\xe9n posee potentes capacidades de edici\xf3n y comprensi\xf3n de im\xe1genes, incluyendo transferencia de estilo, adici\xf3n y eliminaci\xf3n de objetos, mejora de detalles, edici\xf3n de texto e incluso manipulaci\xf3n de posturas humanas. Su objetivo es convertirse en un modelo base integral para la creaci\xf3n y procesamiento visual inteligente que integre lenguaje, dise\xf1o y contenido visual."},"Qwen/Qwen-Image-Edit-2509":{"description":"Qwen-Image-Edit-2509 es la versi\xf3n m\xe1s reciente de edici\xf3n de im\xe1genes del modelo Qwen-Image, lanzado por el equipo Tongyi Qianwen de Alibaba. Este modelo ha sido entrenado en profundidad sobre la base del modelo Qwen-Image de 20 mil millones de par\xe1metros, extendiendo con \xe9xito su capacidad \xfanica de renderizado de texto al \xe1mbito de la edici\xf3n de im\xe1genes, logrando una edici\xf3n precisa del texto dentro de las im\xe1genes. Qwen-Image-Edit adopta una arquitectura innovadora que env\xeda la imagen de entrada simult\xe1neamente a Qwen2.5-VL (para el control sem\xe1ntico visual) y al codificador VAE (para el control de la apariencia visual), lo que le otorga una capacidad de edici\xf3n dual tanto sem\xe1ntica como visual. Esto significa que no solo permite ediciones locales de apariencia como agregar, eliminar o modificar elementos, sino tambi\xe9n ediciones sem\xe1nticas visuales avanzadas que requieren coherencia sem\xe1ntica, como la creaci\xf3n de propiedad intelectual (IP) o la transferencia de estilo. El modelo ha demostrado un rendimiento de vanguardia (SOTA) en m\xfaltiples pruebas de referencia p\xfablicas, consolid\xe1ndose como un potente modelo base para la edici\xf3n de im\xe1genes."},"Qwen/Qwen2-72B-Instruct":{"description":"Qwen2 es un modelo de lenguaje general avanzado, que soporta m\xfaltiples tipos de instrucciones."},"Qwen/Qwen2-7B-Instruct":{"description":"Qwen2-72B-Instruct es un modelo de lenguaje a gran escala de ajuste fino por instrucciones dentro de la serie Qwen2, con un tama\xf1o de par\xe1metros de 72B. Este modelo se basa en la arquitectura Transformer, utilizando funciones de activaci\xf3n SwiGLU, sesgos de atenci\xf3n QKV y atenci\xf3n de consulta agrupada, entre otras t\xe9cnicas. Es capaz de manejar entradas a gran escala. Este modelo ha destacado en m\xfaltiples pruebas de referencia en comprensi\xf3n del lenguaje, generaci\xf3n, capacidad multiling\xfce, codificaci\xf3n, matem\xe1ticas y razonamiento, superando a la mayor\xeda de los modelos de c\xf3digo abierto y mostrando competitividad comparable a modelos propietarios en ciertas tareas."},"Qwen/Qwen2-VL-72B-Instruct":{"description":"Qwen2-VL es la \xfaltima iteraci\xf3n del modelo Qwen-VL, alcanzando un rendimiento de vanguardia en pruebas de comprensi\xf3n visual."},"Qwen/Qwen2.5-14B-Instruct":{"description":"Qwen2.5 es una nueva serie de modelos de lenguaje a gran escala, dise\xf1ada para optimizar el procesamiento de tareas de instrucci\xf3n."},"Qwen/Qwen2.5-32B-Instruct":{"description":"Qwen2.5 es una nueva serie de modelos de lenguaje a gran escala, dise\xf1ada para optimizar el procesamiento de tareas de instrucci\xf3n."},"Qwen/Qwen2.5-72B-Instruct":{"description":"Modelo de lenguaje de gran escala desarrollado por el equipo de Tongyi Qianwen de Alibaba Cloud"},"Qwen/Qwen2.5-72B-Instruct-128K":{"description":"Qwen2.5 es una nueva serie de grandes modelos de lenguaje, con capacidades de comprensi\xf3n y generaci\xf3n m\xe1s fuertes."},"Qwen/Qwen2.5-72B-Instruct-Turbo":{"description":"Qwen2.5 es una nueva serie de grandes modelos de lenguaje, dise\xf1ada para optimizar el manejo de tareas instructivas."},"Qwen/Qwen2.5-7B-Instruct":{"description":"Qwen2.5 es una nueva serie de modelos de lenguaje a gran escala, dise\xf1ada para optimizar el procesamiento de tareas de instrucci\xf3n."},"Qwen/Qwen2.5-7B-Instruct-Turbo":{"description":"Qwen2.5 es una nueva serie de grandes modelos de lenguaje, dise\xf1ada para optimizar el manejo de tareas instructivas."},"Qwen/Qwen2.5-Coder-32B-Instruct":{"description":"Qwen2.5-Coder se centra en la escritura de c\xf3digo."},"Qwen/Qwen2.5-Coder-7B-Instruct":{"description":"Qwen2.5-Coder-7B-Instruct es la \xfaltima versi\xf3n de la serie de modelos de lenguaje a gran escala espec\xedficos para c\xf3digo lanzada por Alibaba Cloud. Este modelo, basado en Qwen2.5, ha mejorado significativamente la generaci\xf3n, razonamiento y reparaci\xf3n de c\xf3digo a trav\xe9s de un entrenamiento con 55 billones de tokens. No solo ha mejorado la capacidad de codificaci\xf3n, sino que tambi\xe9n ha mantenido ventajas en habilidades matem\xe1ticas y generales. El modelo proporciona una base m\xe1s completa para aplicaciones pr\xe1cticas como agentes de c\xf3digo."},"Qwen/Qwen2.5-VL-32B-Instruct":{"description":"Qwen2.5-VL-32B-Instruct es un modelo multimodal avanzado desarrollado por el equipo Tongyi Qianwen, que forma parte de la serie Qwen2.5-VL. Este modelo no solo domina el reconocimiento de objetos comunes, sino que tambi\xe9n puede analizar texto, gr\xe1ficos, iconos, diagramas y dise\xf1os en im\xe1genes. Funciona como un agente visual inteligente capaz de razonar y manipular herramientas din\xe1micamente, con habilidades para operar computadoras y dispositivos m\xf3viles. Adem\xe1s, el modelo puede localizar con precisi\xf3n objetos en im\xe1genes y generar salidas estructuradas para documentos como facturas y tablas. En comparaci\xf3n con su predecesor Qwen2-VL, esta versi\xf3n ha mejorado significativamente sus capacidades matem\xe1ticas y de resoluci\xf3n de problemas mediante aprendizaje por refuerzo, y su estilo de respuesta se ha optimizado para adaptarse mejor a las preferencias humanas."},"Qwen/Qwen2.5-VL-72B-Instruct":{"description":"Qwen2.5-VL es el modelo de lenguaje visual de la serie Qwen2.5. Este modelo presenta mejoras significativas en m\xfaltiples aspectos: posee una mayor capacidad de comprensi\xf3n visual, pudiendo reconocer objetos comunes, analizar texto, gr\xe1ficos y dise\xf1os; como agente visual puede razonar y guiar din\xe1micamente el uso de herramientas; soporta la comprensi\xf3n de videos largos de m\xe1s de 1 hora capturando eventos clave; es capaz de localizar objetos en im\xe1genes con precisi\xf3n generando cuadros delimitadores o puntos; y admite la generaci\xf3n de salidas estructuradas, especialmente \xfatil para datos escaneados como facturas o tablas."},"Qwen/Qwen3-14B":{"description":"Qwen3 es un nuevo modelo de Tongyi Qianwen de pr\xf3xima generaci\xf3n con capacidades significativamente mejoradas, alcanzando niveles l\xedderes en la industria en razonamiento, general, agente y m\xfaltiples idiomas, y admite el cambio de modo de pensamiento."},"Qwen/Qwen3-235B-A22B":{"description":"Qwen3 es un nuevo modelo de Tongyi Qianwen de pr\xf3xima generaci\xf3n con capacidades significativamente mejoradas, alcanzando niveles l\xedderes en la industria en razonamiento, general, agente y m\xfaltiples idiomas, y admite el cambio de modo de pensamiento."},"Qwen/Qwen3-235B-A22B-Instruct-2507":{"description":"Qwen3-235B-A22B-Instruct-2507 es un modelo de lenguaje grande h\xedbrido experto (MoE) de nivel insignia desarrollado por el equipo Tongyi Qianwen de Alibaba Cloud. Cuenta con 235 mil millones de par\xe1metros totales y activa 22 mil millones por inferencia. Es una versi\xf3n actualizada del modo no reflexivo Qwen3-235B-A22B, enfocada en mejorar significativamente el cumplimiento de instrucciones, razonamiento l\xf3gico, comprensi\xf3n textual, matem\xe1ticas, ciencias, programaci\xf3n y uso de herramientas. Adem\xe1s, ampl\xeda la cobertura de conocimientos multiling\xfces y mejora la alineaci\xf3n con las preferencias del usuario en tareas subjetivas y abiertas para generar textos m\xe1s \xfatiles y de alta calidad."},"Qwen/Qwen3-235B-A22B-Thinking-2507":{"description":"Qwen3-235B-A22B-Thinking-2507 es un modelo de lenguaje grande de la serie Qwen3 desarrollado por el equipo Tongyi Qianwen de Alibaba, especializado en tareas complejas de razonamiento avanzado. Basado en arquitectura MoE, cuenta con 235 mil millones de par\xe1metros totales y activa aproximadamente 22 mil millones por token, mejorando la eficiencia computacional sin sacrificar rendimiento. Como modelo dedicado al “pensamiento”, destaca en razonamiento l\xf3gico, matem\xe1ticas, ciencias, programaci\xf3n y pruebas acad\xe9micas que requieren conocimiento experto, alcanzando niveles l\xedderes en modelos reflexivos de c\xf3digo abierto. Tambi\xe9n mejora capacidades generales como cumplimiento de instrucciones, uso de herramientas y generaci\xf3n de texto, y soporta nativamente comprensi\xf3n de contexto largo de hasta 256K tokens, ideal para escenarios que requieren razonamiento profundo y manejo de documentos extensos."},"Qwen/Qwen3-30B-A3B":{"description":"Qwen3 es un nuevo modelo de Tongyi Qianwen de pr\xf3xima generaci\xf3n con capacidades significativamente mejoradas, alcanzando niveles l\xedderes en la industria en razonamiento, general, agente y m\xfaltiples idiomas, y admite el cambio de modo de pensamiento."},"Qwen/Qwen3-30B-A3B-Instruct-2507":{"description":"Qwen3-30B-A3B-Instruct-2507 es una versi\xf3n actualizada del modelo Qwen3-30B-A3B en modo no reflexivo. Es un modelo de expertos mixtos (MoE) con un total de 30.5 mil millones de par\xe1metros y 3.3 mil millones de par\xe1metros activados. El modelo ha mejorado significativamente en varios aspectos, incluyendo el seguimiento de instrucciones, razonamiento l\xf3gico, comprensi\xf3n de texto, matem\xe1ticas, ciencias, codificaci\xf3n y uso de herramientas. Adem\xe1s, ha logrado avances sustanciales en la cobertura de conocimientos multiling\xfces de cola larga y se alinea mejor con las preferencias del usuario en tareas subjetivas y abiertas, generando respuestas m\xe1s \xfatiles y textos de mayor calidad. Tambi\xe9n se ha mejorado la capacidad de comprensi\xf3n de textos largos hasta 256K. Este modelo solo soporta el modo no reflexivo y no genera etiquetas `<think></think>` en su salida."},"Qwen/Qwen3-30B-A3B-Thinking-2507":{"description":"Qwen3-30B-A3B-Thinking-2507 es el \xfaltimo modelo de pensamiento de la serie Qwen3, publicado por el equipo Tongyi Qianwen de Alibaba. Como un modelo Mixture of Experts (MoE) con 30.500 millones de par\xe1metros en total y 3.300 millones de par\xe1metros activados, est\xe1 enfocado en mejorar la capacidad de abordar tareas complejas. Este modelo muestra mejoras significativas en razonamiento l\xf3gico, matem\xe1ticas, ciencias, programaci\xf3n y en evaluaciones acad\xe9micas que requieren conocimientos humanos especializados. Al mismo tiempo, presenta avances notables en capacidades generales como el cumplimiento de instrucciones, el uso de herramientas, la generaci\xf3n de texto y la alineaci\xf3n con las preferencias humanas. El modelo soporta de forma nativa la comprensi\xf3n de contextos largos de 256K tokens y puede ampliarse hasta 1 mill\xf3n de tokens. Esta versi\xf3n est\xe1 dise\xf1ada espec\xedficamente para el “modo de pensamiento”, con el objetivo de resolver tareas altamente complejas mediante razonamientos detallados y paso a paso; asimismo, sus capacidades como agente (Agent) tambi\xe9n resultan sobresalientes."},"Qwen/Qwen3-32B":{"description":"Qwen3 es un nuevo modelo de Tongyi Qianwen de pr\xf3xima generaci\xf3n con capacidades significativamente mejoradas, alcanzando niveles l\xedderes en la industria en razonamiento, general, agente y m\xfaltiples idiomas, y admite el cambio de modo de pensamiento."},"Qwen/Qwen3-8B":{"description":"Qwen3 es un nuevo modelo de Tongyi Qianwen de pr\xf3xima generaci\xf3n con capacidades significativamente mejoradas, alcanzando niveles l\xedderes en la industria en razonamiento, general, agente y m\xfaltiples idiomas, y admite el cambio de modo de pensamiento."},"Qwen/Qwen3-Coder-30B-A3B-Instruct":{"description":"Qwen3-Coder-30B-A3B-Instruct es un modelo de c\xf3digo de la serie Qwen3 desarrollado por el equipo Tongyi Qianwen (通义千问) de Alibaba. Como un modelo depurado y optimizado, mantiene un alto rendimiento y eficiencia a la vez que se centra en mejorar la capacidad de procesamiento de c\xf3digo. Este modelo muestra una ventaja de rendimiento notable frente a otros modelos de c\xf3digo abierto en tareas complejas como la programaci\xf3n agente (Agentic Coding), la automatizaci\xf3n de operaciones en navegadores y la invocaci\xf3n de herramientas. Soporta de forma nativa contextos largos de 256K tokens y puede ampliarse hasta 1M tokens, lo que le permite entender y gestionar mejor repositorios de c\xf3digo a escala. Adem\xe1s, proporciona un s\xf3lido soporte de codificaci\xf3n por agentes para plataformas como Qwen Code y CLINE, y est\xe1 dise\xf1ado con un formato espec\xedfico para llamadas a funciones."},"Qwen/Qwen3-Coder-480B-A35B-Instruct":{"description":"Qwen3-Coder-480B-A35B-Instruct es un modelo de c\xf3digo publicado por Alibaba, hasta la fecha el m\xe1s capaz en t\xe9rminos de agencia (agentic). Es un modelo de expertos mixtos (MoE) con 480 000 millones de par\xe1metros en total y 35 000 millones de par\xe1metros de activaci\xf3n, que logra un equilibrio entre eficiencia y rendimiento. El modelo admite de forma nativa una longitud de contexto de 256K (aprox. 260 000) tokens y puede ampliarse hasta 1 000 000 tokens mediante m\xe9todos de extrapolaci\xf3n como YaRN, lo que le permite manejar bases de c\xf3digo a gran escala y tareas de programaci\xf3n complejas. Qwen3-Coder est\xe1 dise\xf1ado para flujos de trabajo de codificaci\xf3n orientados a agentes: no solo genera c\xf3digo, sino que puede interactuar de forma aut\xf3noma con herramientas y entornos de desarrollo para resolver problemas de programaci\xf3n complejos. En m\xfaltiples pruebas de referencia de tareas de codificaci\xf3n y de agente, este modelo ha alcanzado un nivel superior entre los modelos de c\xf3digo abierto, y su rendimiento puede compararse con el de modelos l\xedderes como Claude Sonnet 4."},"Qwen/Qwen3-Next-80B-A3B-Instruct":{"description":"Qwen3-Next-80B-A3B-Instruct es un modelo base de pr\xf3xima generaci\xf3n lanzado por el equipo Tongyi Qianwen de Alibaba. Est\xe1 basado en la nueva arquitectura Qwen3-Next, dise\xf1ada para lograr una eficiencia extrema en entrenamiento e inferencia. Este modelo utiliza un innovador mecanismo de atenci\xf3n h\xedbrida (Gated DeltaNet y Gated Attention), una estructura de expertos mixtos altamente dispersos (MoE) y m\xfaltiples optimizaciones para la estabilidad del entrenamiento. Como un modelo disperso con un total de 80 mil millones de par\xe1metros, solo activa alrededor de 3 mil millones durante la inferencia, reduciendo significativamente el costo computacional. En tareas de contexto largo que superan los 32K tokens, su rendimiento de inferencia es m\xe1s de 10 veces superior al modelo Qwen3-32B. Esta versi\xf3n est\xe1 afinada para instrucciones, dise\xf1ada para tareas generales y no soporta el modo de cadena de pensamiento (Thinking). En cuanto a rendimiento, es comparable al modelo insignia Qwen3-235B en algunas pruebas de referencia, mostrando ventajas claras en tareas de contexto ultra largo."},"Qwen/Qwen3-Next-80B-A3B-Thinking":{"description":"Qwen3-Next-80B-A3B-Thinking es un modelo base de pr\xf3xima generaci\xf3n lanzado por el equipo Tongyi Qianwen de Alibaba, dise\xf1ado espec\xedficamente para tareas complejas de razonamiento. Basado en la innovadora arquitectura Qwen3-Next, que integra mecanismos de atenci\xf3n h\xedbrida (Gated DeltaNet y Gated Attention) y una estructura de expertos mixtos altamente dispersos (MoE), busca alcanzar una eficiencia extrema en entrenamiento e inferencia. Como modelo disperso con 80 mil millones de par\xe1metros totales, solo activa alrededor de 3 mil millones durante la inferencia, reduciendo considerablemente el costo computacional. En tareas de contexto largo que superan los 32K tokens, su rendimiento es m\xe1s de 10 veces superior al modelo Qwen3-32B. Esta versi\xf3n “Thinking” est\xe1 optimizada para ejecutar tareas complejas de m\xfaltiples pasos como demostraciones matem\xe1ticas, s\xedntesis de c\xf3digo, an\xe1lisis l\xf3gico y planificaci\xf3n, y por defecto produce el proceso de razonamiento en forma estructurada de “cadena de pensamiento”. En rendimiento, supera no solo a modelos m\xe1s costosos como Qwen3-32B-Thinking, sino tambi\xe9n a Gemini-2.5-Flash-Thinking en m\xfaltiples benchmarks."},"Qwen/Qwen3-Omni-30B-A3B-Captioner":{"description":"Qwen3-Omni-30B-A3B-Captioner es un modelo de lenguaje visual (VLM) de la serie Qwen3 del equipo Qwen de Alibaba. Est\xe1 dise\xf1ado para generar descripciones de im\xe1genes de alta calidad, detalladas y precisas. Basado en una arquitectura de expertos mixtos (MoE) con un total de 30 mil millones de par\xe1metros, el modelo puede comprender profundamente el contenido visual y convertirlo en descripciones textuales naturales y fluidas. Destaca en la captura de detalles visuales, comprensi\xf3n de escenas, reconocimiento de objetos y razonamiento relacional, siendo ideal para aplicaciones que requieren una comprensi\xf3n precisa de im\xe1genes y generaci\xf3n de descripciones."},"Qwen/Qwen3-Omni-30B-A3B-Instruct":{"description":"Qwen3-Omni-30B-A3B-Instruct es parte de la \xfaltima serie Qwen3 del equipo Qwen de Alibaba. Es un modelo de expertos mixtos (MoE) con 30 mil millones de par\xe1metros totales y 3 mil millones de par\xe1metros activos, que mantiene un alto rendimiento mientras reduce los costos de inferencia. Entrenado con datos de alta calidad, multifuente y multiling\xfces, posee una gran capacidad general y admite entradas multimodales, incluyendo texto, im\xe1genes, audio y video, permitiendo la comprensi\xf3n y generaci\xf3n de contenido entre modalidades."},"Qwen/Qwen3-Omni-30B-A3B-Thinking":{"description":"Qwen3-Omni-30B-A3B-Thinking es el componente central \\"pensante\\" (Thinker) del modelo multimodal Qwen3-Omni. Est\xe1 dise\xf1ado para procesar entradas multimodales como texto, audio, im\xe1genes y video, y realizar razonamientos complejos en cadena. Como el cerebro del sistema de inferencia, este modelo unifica todas las entradas en un espacio de representaci\xf3n com\xfan, logrando una comprensi\xf3n profunda y razonamiento complejo entre modalidades. Basado en una arquitectura de expertos mixtos (MoE), cuenta con 30 mil millones de par\xe1metros totales y 3 mil millones de par\xe1metros activos, optimizando la eficiencia computacional sin sacrificar capacidad de razonamiento."},"Qwen/Qwen3-VL-235B-A22B-Instruct":{"description":"Qwen3-VL-235B-A22B-Instruct es un modelo de ajuste fino basado en instrucciones de gran escala de la serie Qwen3-VL. Basado en una arquitectura de expertos mixtos (MoE), ofrece una capacidad sobresaliente de comprensi\xf3n y generaci\xf3n multimodal, con soporte nativo para contextos de hasta 256K, ideal para servicios multimodales de nivel de producci\xf3n con alta concurrencia."},"Qwen/Qwen3-VL-235B-A22B-Thinking":{"description":"Qwen3-VL-235B-A22B-Thinking es la versi\xf3n insignia de razonamiento de la serie Qwen3-VL, especialmente optimizada para el razonamiento multimodal complejo, el razonamiento con contextos largos y la interacci\xf3n con agentes inteligentes. Es adecuada para escenarios empresariales que requieren razonamiento profundo y capacidades avanzadas de inferencia visual."},"Qwen/Qwen3-VL-30B-A3B-Instruct":{"description":"Qwen3-VL-30B-A3B-Instruct es una versi\xf3n de ajuste fino basada en instrucciones de la serie Qwen3-VL, con potentes capacidades de comprensi\xf3n y generaci\xf3n visual-ling\xfc\xedstica. Soporta de forma nativa contextos de hasta 256K, siendo ideal para di\xe1logos multimodales y tareas de generaci\xf3n condicionada por im\xe1genes."},"Qwen/Qwen3-VL-30B-A3B-Thinking":{"description":"Qwen3-VL-30B-A3B-Thinking es la versi\xf3n mejorada para razonamiento (Thinking) de Qwen3-VL, optimizada para tareas de razonamiento multimodal, conversi\xf3n de im\xe1genes a c\xf3digo y comprensi\xf3n visual compleja. Soporta contextos de hasta 256K y posee una capacidad mejorada de razonamiento en cadena."},"Qwen/Qwen3-VL-32B-Instruct":{"description":"Qwen3-VL-32B-Instruct es un modelo de lenguaje visual desarrollado por el equipo Qwen de Alibaba, que ha alcanzado un rendimiento SOTA l\xedder en m\xfaltiples pruebas de referencia de lenguaje visual. Admite im\xe1genes de alta resoluci\xf3n a nivel de megap\xedxeles y posee una potente capacidad de comprensi\xf3n visual general, OCR multiling\xfce, localizaci\xf3n visual de alta precisi\xf3n y di\xe1logo visual. Como parte de la serie Qwen3, este modelo puede manejar tareas multimodales complejas y admite funciones avanzadas como llamadas a herramientas y generaci\xf3n de texto con prefijos."},"Qwen/Qwen3-VL-32B-Thinking":{"description":"Qwen3-VL-32B-Thinking es una versi\xf3n optimizada del modelo de lenguaje visual de la serie Qwen3 del equipo Qwen de Alibaba, dise\xf1ada espec\xedficamente para tareas de razonamiento visual complejo. Incorpora un \\"modo de pensamiento\\" que le permite generar pasos intermedios detallados antes de responder, mejorando significativamente su rendimiento en tareas que requieren l\xf3gica multietapa, planificaci\xf3n y razonamiento complejo. Admite im\xe1genes de alta resoluci\xf3n a nivel de megap\xedxeles, y cuenta con s\xf3lidas capacidades de comprensi\xf3n visual general, OCR multiling\xfce, localizaci\xf3n visual precisa y di\xe1logo visual, adem\xe1s de funciones como llamadas a herramientas y generaci\xf3n con prefijos."},"Qwen/Qwen3-VL-8B-Instruct":{"description":"Qwen3-VL-8B-Instruct es un modelo de lenguaje visual de la serie Qwen3, desarrollado a partir de Qwen3-8B-Instruct y entrenado con grandes vol\xfamenes de datos de texto e imagen. Se especializa en comprensi\xf3n visual general, di\xe1logos centrados en lo visual y reconocimiento multiling\xfce de texto en im\xe1genes. Es adecuado para tareas como preguntas y respuestas visuales, descripci\xf3n de im\xe1genes, seguimiento de instrucciones multimodales y activaci\xf3n de herramientas."},"Qwen/Qwen3-VL-8B-Thinking":{"description":"Qwen3-VL-8B-Thinking es la versi\xf3n de razonamiento visual de la serie Qwen3, optimizada para tareas complejas de razonamiento en m\xfaltiples pasos. Por defecto, genera una cadena de pensamiento antes de responder, con el fin de mejorar la precisi\xf3n del razonamiento. Es ideal para escenarios que requieren razonamiento profundo, como preguntas y respuestas visuales complejas o an\xe1lisis detallado del contenido de im\xe1genes."},"Qwen2-72B-Instruct":{"description":"Qwen2 es la \xfaltima serie del modelo Qwen, que admite un contexto de 128k. En comparaci\xf3n con los modelos de c\xf3digo abierto m\xe1s \xf3ptimos actuales, Qwen2-72B supera significativamente a los modelos l\xedderes actuales en comprensi\xf3n del lenguaje natural, conocimiento, c\xf3digo, matem\xe1ticas y capacidades multiling\xfces."},"Qwen2-7B-Instruct":{"description":"Qwen2 es la \xfaltima serie del modelo Qwen, capaz de superar a los modelos de c\xf3digo abierto de tama\xf1o equivalente e incluso a modelos de mayor tama\xf1o. Qwen2 7B ha logrado ventajas significativas en m\xfaltiples evaluaciones, especialmente en comprensi\xf3n de c\xf3digo y chino."},"Qwen2-VL-72B":{"description":"Qwen2-VL-72B es un potente modelo de lenguaje visual que admite el procesamiento multimodal de im\xe1genes y texto, capaz de identificar con precisi\xf3n el contenido de las im\xe1genes y generar descripciones o respuestas relacionadas."},"Qwen2.5-14B-Instruct":{"description":"Qwen2.5-14B-Instruct es un modelo de lenguaje grande de 14 mil millones de par\xe1metros, con un rendimiento excelente, optimizado para escenarios en chino y multiling\xfces, que admite aplicaciones de preguntas y respuestas inteligentes, generaci\xf3n de contenido, entre otros."},"Qwen2.5-32B-Instruct":{"description":"Qwen2.5-32B-Instruct es un modelo de lenguaje grande de 32 mil millones de par\xe1metros, con un rendimiento equilibrado, optimizado para escenarios en chino y multiling\xfces, que admite aplicaciones de preguntas y respuestas inteligentes, generaci\xf3n de contenido, entre otros."},"Qwen2.5-72B-Instruct":{"description":"Qwen2.5-72B-Instruct admite un contexto de 16k, generando textos largos de m\xe1s de 8K. Soporta llamadas a funciones e interacci\xf3n sin problemas con sistemas externos, lo que mejora enormemente la flexibilidad y escalabilidad. El conocimiento del modelo ha aumentado significativamente, y se ha mejorado considerablemente la capacidad de codificaci\xf3n y matem\xe1ticas, con soporte para m\xe1s de 29 idiomas."},"Qwen2.5-7B-Instruct":{"description":"Qwen2.5-7B-Instruct es un modelo de lenguaje grande de 7 mil millones de par\xe1metros, que admite llamadas a funciones e interacci\xf3n sin problemas con sistemas externos, mejorando enormemente la flexibilidad y escalabilidad. Optimizado para escenarios en chino y multiling\xfces, admite aplicaciones de preguntas y respuestas inteligentes, generaci\xf3n de contenido, entre otros."},"Qwen2.5-Coder-14B-Instruct":{"description":"Qwen2.5-Coder-14B-Instruct es un modelo de instrucciones de programaci\xf3n basado en un preentrenamiento a gran escala, con una potente capacidad de comprensi\xf3n y generaci\xf3n de c\xf3digo, capaz de manejar eficientemente diversas tareas de programaci\xf3n, especialmente adecuado para la escritura inteligente de c\xf3digo, generaci\xf3n de scripts automatizados y resoluci\xf3n de problemas de programaci\xf3n."},"Qwen2.5-Coder-32B-Instruct":{"description":"Qwen2.5-Coder-32B-Instruct es un modelo de lenguaje grande dise\xf1ado espec\xedficamente para la generaci\xf3n de c\xf3digo, comprensi\xf3n de c\xf3digo y escenarios de desarrollo eficiente, con una escala de 32B par\xe1metros, l\xedder en la industria, capaz de satisfacer diversas necesidades de programaci\xf3n."},"Qwen3-235B":{"description":"Qwen3-235B-A22B es un modelo MoE (modelo de expertos mixtos) que introduce el “modo de razonamiento mixto”, permitiendo a los usuarios cambiar sin problemas entre el “modo reflexivo” y el “modo no reflexivo”. Soporta la comprensi\xf3n y el razonamiento en 119 idiomas y dialectos, y cuenta con una potente capacidad de invocaci\xf3n de herramientas. En pruebas de referencia que eval\xfaan capacidades generales, c\xf3digo y matem\xe1ticas, multiling\xfcismo, conocimiento y razonamiento, compite con los principales modelos del mercado como DeepSeek R1, OpenAI o1, o3-mini, Grok 3 y Google Gemini 2.5 Pro."},"Qwen3-235B-A22B-Instruct-2507-FP8":{"description":"Qwen3 235B A22B Instruct 2507: modelo optimizado para razonamiento avanzado e instrucciones de di\xe1logo, con arquitectura de expertos mixtos para mantener la eficiencia en inferencia con gran cantidad de par\xe1metros."},"Qwen3-32B":{"description":"Qwen3-32B es un modelo denso (Dense Model) que introduce el “modo de razonamiento mixto”, permitiendo a los usuarios cambiar sin problemas entre el “modo reflexivo” y el “modo no reflexivo”. Gracias a mejoras en la arquitectura del modelo, aumento de datos de entrenamiento y m\xe9todos de entrenamiento m\xe1s eficientes, su rendimiento general es comparable al de Qwen2.5-72B."},"SenseChat":{"description":"Modelo de versi\xf3n b\xe1sica (V4), longitud de contexto de 4K, con potentes capacidades generales."},"SenseChat-128K":{"description":"Modelo de versi\xf3n b\xe1sica (V4), longitud de contexto de 128K, se destaca en tareas de comprensi\xf3n y generaci\xf3n de textos largos."},"SenseChat-32K":{"description":"Modelo de versi\xf3n b\xe1sica (V4), longitud de contexto de 32K, aplicable de manera flexible en diversos escenarios."},"SenseChat-5":{"description":"Modelo de \xfaltima versi\xf3n (V5.5), longitud de contexto de 128K, con capacidades significativamente mejoradas en razonamiento matem\xe1tico, di\xe1logos en ingl\xe9s, seguimiento de instrucciones y comprensi\xf3n de textos largos, comparable a GPT-4o."},"SenseChat-5-1202":{"description":"Basado en la versi\xf3n m\xe1s reciente V5.5, con mejoras significativas en capacidades b\xe1sicas en chino e ingl\xe9s, chat, conocimientos cient\xedficos y human\xedsticos, redacci\xf3n, l\xf3gica matem\xe1tica y control de longitud de texto."},"SenseChat-5-Cantonese":{"description":"Longitud de contexto de 32K, supera a GPT-4 en la comprensi\xf3n de di\xe1logos en canton\xe9s, siendo comparable a GPT-4 Turbo en m\xfaltiples \xe1reas como conocimiento, razonamiento, matem\xe1ticas y programaci\xf3n."},"SenseChat-5-beta":{"description":"Rendimiento superior en algunos aspectos en comparaci\xf3n con SenseCat-5-1202"},"SenseChat-Character":{"description":"Modelo est\xe1ndar, longitud de contexto de 8K, alta velocidad de respuesta."},"SenseChat-Character-Pro":{"description":"Modelo de versi\xf3n avanzada, longitud de contexto de 32K, con capacidades completamente mejoradas, admite di\xe1logos en chino/ingl\xe9s."},"SenseChat-Turbo":{"description":"Adecuado para preguntas r\xe1pidas y escenarios de ajuste fino del modelo."},"SenseChat-Turbo-1202":{"description":"Es la \xfaltima versi\xf3n ligera del modelo, alcanzando m\xe1s del 90% de la capacidad del modelo completo, reduciendo significativamente el costo de inferencia."},"SenseChat-Vision":{"description":"La \xfaltima versi\xf3n del modelo (V5.5) admite la entrada de m\xfaltiples im\xe1genes, logrando una optimizaci\xf3n completa de las capacidades b\xe1sicas del modelo, con mejoras significativas en el reconocimiento de atributos de objetos, relaciones espaciales, reconocimiento de eventos de acci\xf3n, comprensi\xf3n de escenas, reconocimiento de emociones, razonamiento l\xf3gico y comprensi\xf3n y generaci\xf3n de texto."},"SenseNova-V6-5-Pro":{"description":"Mediante una actualizaci\xf3n integral de datos multimodales, ling\xfc\xedsticos y de razonamiento, junto con la optimizaci\xf3n de estrategias de entrenamiento, el nuevo modelo ha logrado mejoras significativas en el razonamiento multimodal y la capacidad de seguimiento de instrucciones generalizadas. Soporta una ventana de contexto de hasta 128k y destaca en tareas especializadas como OCR y reconocimiento de IP en turismo y cultura."},"SenseNova-V6-5-Turbo":{"description":"Mediante una actualizaci\xf3n integral de datos multimodales, ling\xfc\xedsticos y de razonamiento, junto con la optimizaci\xf3n de estrategias de entrenamiento, el nuevo modelo ha logrado mejoras significativas en el razonamiento multimodal y la capacidad de seguimiento de instrucciones generalizadas. Soporta una ventana de contexto de hasta 128k y destaca en tareas especializadas como OCR y reconocimiento de IP en turismo y cultura."},"SenseNova-V6-Pro":{"description":"Logra una unificaci\xf3n nativa de capacidades de imagen, texto y video, superando las limitaciones tradicionales de la multimodalidad discreta, y ha ganado el doble campeonato en las evaluaciones de OpenCompass y SuperCLUE."},"SenseNova-V6-Reasoner":{"description":"Equilibra el razonamiento profundo visual y ling\xfc\xedstico, logrando un pensamiento lento y un razonamiento profundo, presentando un proceso completo de cadena de pensamiento."},"SenseNova-V6-Turbo":{"description":"Logra una unificaci\xf3n nativa de capacidades de imagen, texto y video, superando las limitaciones tradicionales de la multimodalidad discreta, liderando en dimensiones clave como capacidades multimodales y ling\xfc\xedsticas, combinando literatura y ciencia, y ocupando repetidamente el nivel de la primera divisi\xf3n en m\xfaltiples evaluaciones tanto nacionales como internacionales."},"Skylark2-lite-8k":{"description":"El modelo de segunda generaci\xf3n Skaylark (Skylark), el modelo Skylark2-lite, tiene una alta velocidad de respuesta, adecuado para escenarios donde se requiere alta inmediatez, sensibilidad de costos y baja necesidad de precisi\xf3n del modelo, con una longitud de ventana de contexto de 8k."},"Skylark2-pro-32k":{"description":"El modelo de segunda generaci\xf3n Skaylark (Skylark), la versi\xf3n Skylark2-pro, cuenta con una alta precisi\xf3n, adecuada para escenarios de generaci\xf3n de texto m\xe1s complejos, como redacci\xf3n de copy en campos especializados, creaci\xf3n de novelas y traducciones de alta calidad, con una longitud de ventana de contexto de 32k."},"Skylark2-pro-4k":{"description":"El modelo de segunda generaci\xf3n Skaylark (Skylark), el modelo Skylark2-pro, tiene una alta precisi\xf3n, adecuado para escenarios de generaci\xf3n de texto m\xe1s complejos, como redacci\xf3n de copy en campos especializados, creaci\xf3n de novelas y traducciones de alta calidad, con una longitud de ventana de contexto de 4k."},"Skylark2-pro-character-4k":{"description":"El modelo de segunda generaci\xf3n Skaylark (Skylark), el modelo Skylark2-pro-character, presenta habilidades excepcionales para el juego de roles y la conversaci\xf3n, destac\xe1ndose en interpretar diversos roles seg\xfan las solicitudes del usuario, con un contenido conversacional natural y fluido, ideal para la construcci\xf3n de chatbots, asistentes virtuales y servicios al cliente en l\xednea, con una alta velocidad de respuesta."},"Skylark2-pro-turbo-8k":{"description":"El modelo de segunda generaci\xf3n Skaylark (Skylark), Skylark2-pro-turbo-8k, ofrece una inferencia m\xe1s r\xe1pida y costos m\xe1s bajos, con una longitud de ventana de contexto de 8k."},"THUDM/GLM-4-32B-0414":{"description":"GLM-4-32B-0414 es el nuevo modelo de c\xf3digo abierto de la serie GLM, con 32 mil millones de par\xe1metros. Su rendimiento es comparable a las series GPT de OpenAI y V3/R1 de DeepSeek."},"THUDM/GLM-4-9B-0414":{"description":"GLM-4-9B-0414 es un modelo peque\xf1o de la serie GLM, con 9 mil millones de par\xe1metros. Este modelo hereda las caracter\xedsticas t\xe9cnicas de la serie GLM-4-32B, pero ofrece opciones de implementaci\xf3n m\xe1s ligeras. A pesar de su menor tama\xf1o, GLM-4-9B-0414 sigue mostrando habilidades sobresalientes en tareas de generaci\xf3n de c\xf3digo, dise\xf1o web, generaci\xf3n de gr\xe1ficos SVG y redacci\xf3n basada en b\xfasqueda."},"THUDM/GLM-4.1V-9B-Thinking":{"description":"GLM-4.1V-9B-Thinking es un modelo de lenguaje visual (VLM) de c\xf3digo abierto lanzado conjuntamente por Zhipu AI y el laboratorio KEG de la Universidad de Tsinghua, dise\xf1ado espec\xedficamente para manejar tareas cognitivas multimodales complejas. Este modelo se basa en el modelo base GLM-4-9B-0414 y mejora significativamente su capacidad y estabilidad de razonamiento multimodal mediante la introducci\xf3n del mecanismo de razonamiento \\"Cadena de Pensamiento\\" (Chain-of-Thought) y la adopci\xf3n de estrategias de aprendizaje reforzado."},"THUDM/GLM-Z1-32B-0414":{"description":"GLM-Z1-32B-0414 es un modelo de inferencia con capacidad de pensamiento profundo. Este modelo se desarroll\xf3 a partir de GLM-4-32B-0414 mediante un arranque en fr\xedo y aprendizaje por refuerzo ampliado, y se entren\xf3 adicionalmente en tareas de matem\xe1ticas, c\xf3digo y l\xf3gica. En comparaci\xf3n con el modelo base, GLM-Z1-32B-0414 mejora significativamente la capacidad matem\xe1tica y la habilidad para resolver tareas complejas."},"THUDM/GLM-Z1-9B-0414":{"description":"GLM-Z1-9B-0414 es un modelo peque\xf1o de la serie GLM, con solo 9 mil millones de par\xe1metros, pero que muestra una capacidad sorprendente manteniendo la tradici\xf3n de c\xf3digo abierto. A pesar de su menor tama\xf1o, este modelo sigue destacando en razonamiento matem\xe1tico y tareas generales, con un rendimiento general que se encuentra entre los mejores en modelos de c\xf3digo abierto de tama\xf1o similar."},"THUDM/GLM-Z1-Rumination-32B-0414":{"description":"GLM-Z1-Rumination-32B-0414 es un modelo de inferencia profunda con capacidad de reflexi\xf3n (en comparaci\xf3n con la investigaci\xf3n profunda de OpenAI). A diferencia de los modelos t\xedpicos de pensamiento profundo, el modelo de reflexi\xf3n utiliza un tiempo de reflexi\xf3n m\xe1s prolongado para resolver problemas m\xe1s abiertos y complejos."},"THUDM/glm-4-9b-chat":{"description":"GLM-4 9B es una versi\xf3n de c\xf3digo abierto, que proporciona una experiencia de conversaci\xf3n optimizada para aplicaciones de di\xe1logo."},"Tongyi-Zhiwen/QwenLong-L1-32B":{"description":"QwenLong-L1-32B es el primer modelo de razonamiento a gran escala con contexto largo entrenado mediante aprendizaje reforzado (LRM), optimizado para tareas de razonamiento con textos extensos. Utiliza un marco de aprendizaje reforzado con expansi\xf3n progresiva de contexto, logrando una transici\xf3n estable de contexto corto a largo. En siete pruebas de referencia de preguntas y respuestas con documentos de contexto largo, QwenLong-L1-32B supera a modelos insignia como OpenAI-o3-mini y Qwen3-235B-A22B, con un rendimiento comparable a Claude-3.7-Sonnet-Thinking. Destaca en razonamiento matem\xe1tico, l\xf3gico y de m\xfaltiples saltos."},"Yi-34B-Chat":{"description":"Yi-1.5-34B, manteniendo la excelente capacidad de lenguaje general de la serie original, ha mejorado significativamente la l\xf3gica matem\xe1tica y la capacidad de codificaci\xf3n mediante un entrenamiento incremental de 500 mil millones de tokens de alta calidad."},"abab5.5-chat":{"description":"Orientado a escenarios de productividad, admite el procesamiento de tareas complejas y la generaci\xf3n eficiente de texto, adecuado para aplicaciones en campos profesionales."},"abab5.5s-chat":{"description":"Dise\xf1ado para escenarios de di\xe1logo de personajes en chino, ofrece capacidades de generaci\xf3n de di\xe1logos de alta calidad en chino, adecuado para diversas aplicaciones."},"abab6.5g-chat":{"description":"Dise\xf1ado para di\xe1logos de personajes multiling\xfces, admite generaci\xf3n de di\xe1logos de alta calidad en ingl\xe9s y otros idiomas."},"abab6.5s-chat":{"description":"Adecuado para una amplia gama de tareas de procesamiento de lenguaje natural, incluyendo generaci\xf3n de texto, sistemas de di\xe1logo, etc."},"abab6.5t-chat":{"description":"Optimizado para escenarios de di\xe1logo de personajes en chino, ofrece capacidades de generaci\xf3n de di\xe1logos fluidos y acordes con las expresiones chinas."},"accounts/fireworks/models/deepseek-r1":{"description":"DeepSeek-R1 es un modelo de lenguaje grande de \xfaltima generaci\xf3n, optimizado mediante aprendizaje por refuerzo y datos de arranque en fr\xedo, con un rendimiento excepcional en razonamiento, matem\xe1ticas y programaci\xf3n."},"accounts/fireworks/models/deepseek-v3":{"description":"Modelo de lenguaje potente de Deepseek, basado en Mixture-of-Experts (MoE), con un total de 671B de par\xe1metros, activando 37B de par\xe1metros por cada token."},"accounts/fireworks/models/llama-v3-70b-instruct":{"description":"El modelo de instrucciones Llama 3 70B est\xe1 optimizado para di\xe1logos multiling\xfces y comprensi\xf3n del lenguaje natural, superando el rendimiento de la mayor\xeda de los modelos competidores."},"accounts/fireworks/models/llama-v3-8b-instruct":{"description":"El modelo de instrucciones Llama 3 8B est\xe1 optimizado para di\xe1logos y tareas multiling\xfces, ofreciendo un rendimiento excepcional y eficiente."},"accounts/fireworks/models/llama-v3-8b-instruct-hf":{"description":"El modelo de instrucciones Llama 3 8B (versi\xf3n HF) es consistente con los resultados de la implementaci\xf3n oficial, ofreciendo alta consistencia y compatibilidad multiplataforma."},"accounts/fireworks/models/llama-v3p1-405b-instruct":{"description":"El modelo de instrucciones Llama 3.1 405B, con par\xe1metros de gran escala, es adecuado para tareas complejas y seguimiento de instrucciones en escenarios de alta carga."},"accounts/fireworks/models/llama-v3p1-70b-instruct":{"description":"El modelo de instrucciones Llama 3.1 70B ofrece una capacidad excepcional de comprensi\xf3n y generaci\xf3n de lenguaje, siendo la elecci\xf3n ideal para tareas de di\xe1logo y an\xe1lisis."},"accounts/fireworks/models/llama-v3p1-8b-instruct":{"description":"El modelo de instrucciones Llama 3.1 8B est\xe1 optimizado para di\xe1logos multiling\xfces, capaz de superar la mayor\xeda de los modelos de c\xf3digo abierto y cerrado en est\xe1ndares de la industria."},"accounts/fireworks/models/llama-v3p2-11b-vision-instruct":{"description":"Modelo de razonamiento de im\xe1genes de 11B par\xe1metros ajustado por Meta. Este modelo est\xe1 optimizado para el reconocimiento visual, razonamiento de im\xe1genes, descripci\xf3n de im\xe1genes y respuestas a preguntas generales sobre im\xe1genes. Puede entender datos visuales, como gr\xe1ficos y diagramas, y cerrar la brecha entre la visi\xf3n y el lenguaje generando descripciones textuales de los detalles de las im\xe1genes."},"accounts/fireworks/models/llama-v3p2-3b-instruct":{"description":"El modelo de instrucciones Llama 3.2 3B es un modelo multiling\xfce ligero lanzado por Meta. Est\xe1 dise\xf1ado para mejorar la eficiencia, ofreciendo mejoras significativas en latencia y costos en comparaci\xf3n con modelos m\xe1s grandes. Ejemplos de uso de este modelo incluyen consultas, reescritura de indicaciones y asistencia en la escritura."},"accounts/fireworks/models/llama-v3p2-90b-vision-instruct":{"description":"Modelo de razonamiento de im\xe1genes de 90B par\xe1metros ajustado por Meta. Este modelo est\xe1 optimizado para el reconocimiento visual, razonamiento de im\xe1genes, descripci\xf3n de im\xe1genes y respuestas a preguntas generales sobre im\xe1genes. Puede entender datos visuales, como gr\xe1ficos y diagramas, y cerrar la brecha entre la visi\xf3n y el lenguaje generando descripciones textuales de los detalles de las im\xe1genes."},"accounts/fireworks/models/llama-v3p3-70b-instruct":{"description":"Llama 3.3 70B Instruct es la versi\xf3n actualizada de diciembre de Llama 3.1 70B. Este modelo ha sido mejorado sobre la base de Llama 3.1 70B (lanzado en julio de 2024), mejorando la invocaci\xf3n de herramientas, el soporte de texto multiling\xfce, as\xed como las capacidades matem\xe1ticas y de programaci\xf3n. El modelo alcanza niveles de liderazgo en la industria en razonamiento, matem\xe1ticas y cumplimiento de instrucciones, y puede ofrecer un rendimiento similar al de 3.1 405B, al tiempo que presenta ventajas significativas en velocidad y costo."},"accounts/fireworks/models/mistral-small-24b-instruct-2501":{"description":"Modelo de 24B par\xe1metros, con capacidades de vanguardia comparables a modelos m\xe1s grandes."},"accounts/fireworks/models/mixtral-8x22b-instruct":{"description":"El modelo de instrucciones Mixtral MoE 8x22B, con par\xe1metros a gran escala y arquitectura de m\xfaltiples expertos, soporta de manera integral el procesamiento eficiente de tareas complejas."},"accounts/fireworks/models/mixtral-8x7b-instruct":{"description":"El modelo de instrucciones Mixtral MoE 8x7B, con una arquitectura de m\xfaltiples expertos, ofrece un seguimiento y ejecuci\xf3n de instrucciones eficientes."},"accounts/fireworks/models/mythomax-l2-13b":{"description":"El modelo MythoMax L2 13B combina t\xe9cnicas de fusi\xf3n innovadoras, destac\xe1ndose en narraci\xf3n y juegos de rol."},"accounts/fireworks/models/phi-3-vision-128k-instruct":{"description":"El modelo de instrucciones Phi 3 Vision es un modelo multimodal ligero, capaz de manejar informaci\xf3n visual y textual compleja, con una fuerte capacidad de razonamiento."},"accounts/fireworks/models/qwen-qwq-32b-preview":{"description":"El modelo QwQ es un modelo de investigaci\xf3n experimental desarrollado por el equipo de Qwen, enfocado en mejorar la capacidad de razonamiento de la IA."},"accounts/fireworks/models/qwen2-vl-72b-instruct":{"description":"La versi\xf3n de 72B del modelo Qwen-VL es el resultado de la \xfaltima iteraci\xf3n de Alibaba, representando casi un a\xf1o de innovaci\xf3n."},"accounts/fireworks/models/qwen2p5-72b-instruct":{"description":"Qwen2.5 es una serie de modelos de lenguaje solo decodificadores desarrollados por el equipo Qwen de Alibaba Cloud. Estos modelos ofrecen diferentes tama\xf1os, incluidos 0.5B, 1.5B, 3B, 7B, 14B, 32B y 72B, y tienen variantes base y de instrucciones."},"accounts/fireworks/models/qwen2p5-coder-32b-instruct":{"description":"Qwen2.5 Coder 32B Instruct es la \xfaltima versi\xf3n de la serie de modelos de lenguaje a gran escala espec\xedficos para c\xf3digo lanzada por Alibaba Cloud. Este modelo, basado en Qwen2.5, ha mejorado significativamente la generaci\xf3n, razonamiento y reparaci\xf3n de c\xf3digo a trav\xe9s de un entrenamiento con 55 billones de tokens. No solo ha mejorado la capacidad de codificaci\xf3n, sino que tambi\xe9n ha mantenido ventajas en habilidades matem\xe1ticas y generales. El modelo proporciona una base m\xe1s completa para aplicaciones pr\xe1cticas como agentes de c\xf3digo."},"accounts/yi-01-ai/models/yi-large":{"description":"El modelo Yi-Large ofrece una capacidad de procesamiento multiling\xfce excepcional, adecuado para diversas tareas de generaci\xf3n y comprensi\xf3n de lenguaje."},"ai21-jamba-1.5-large":{"description":"Un modelo multiling\xfce de 398B par\xe1metros (94B activos), que ofrece una ventana de contexto larga de 256K, llamada a funciones, salida estructurada y generaci\xf3n fundamentada."},"ai21-jamba-1.5-mini":{"description":"Un modelo multiling\xfce de 52B par\xe1metros (12B activos), que ofrece una ventana de contexto larga de 256K, llamada a funciones, salida estructurada y generaci\xf3n fundamentada."},"ai21-labs/AI21-Jamba-1.5-Large":{"description":"Un modelo multiling\xfce de 398 mil millones de par\xe1metros (94 mil millones activos), que ofrece una ventana de contexto larga de 256K, llamadas a funciones, salida estructurada y generaci\xf3n basada en hechos."},"ai21-labs/AI21-Jamba-1.5-Mini":{"description":"Un modelo multiling\xfce de 52 mil millones de par\xe1metros (12 mil millones activos), que ofrece una ventana de contexto larga de 256K, llamadas a funciones, salida estructurada y generaci\xf3n basada en hechos."},"alibaba/qwen-3-14b":{"description":"Qwen3 es la \xfaltima generaci\xf3n de modelos de lenguaje a gran escala de la serie Qwen, que ofrece un conjunto completo de modelos densos y de expertos mixtos (MoE). Basado en un entrenamiento extenso, Qwen3 proporciona avances revolucionarios en razonamiento, cumplimiento de instrucciones, capacidades de agente y soporte multiling\xfce."},"alibaba/qwen-3-235b":{"description":"Qwen3 es la \xfaltima generaci\xf3n de modelos de lenguaje a gran escala de la serie Qwen, que ofrece un conjunto completo de modelos densos y de expertos mixtos (MoE). Basado en un entrenamiento extenso, Qwen3 proporciona avances revolucionarios en razonamiento, cumplimiento de instrucciones, capacidades de agente y soporte multiling\xfce."},"alibaba/qwen-3-30b":{"description":"Qwen3 es la \xfaltima generaci\xf3n de modelos de lenguaje a gran escala de la serie Qwen, que ofrece un conjunto completo de modelos densos y de expertos mixtos (MoE). Basado en un entrenamiento extenso, Qwen3 proporciona avances revolucionarios en razonamiento, cumplimiento de instrucciones, capacidades de agente y soporte multiling\xfce."},"alibaba/qwen-3-32b":{"description":"Qwen3 es la \xfaltima generaci\xf3n de modelos de lenguaje a gran escala de la serie Qwen, que ofrece un conjunto completo de modelos densos y de expertos mixtos (MoE). Basado en un entrenamiento extenso, Qwen3 proporciona avances revolucionarios en razonamiento, cumplimiento de instrucciones, capacidades de agente y soporte multiling\xfce."},"alibaba/qwen3-coder":{"description":"Qwen3-Coder-480B-A35B-Instruct es el modelo de c\xf3digo m\xe1s orientado a agentes de Qwen, con un rendimiento destacado en codificaci\xf3n de agentes, uso de navegadores de agentes y otras tareas b\xe1sicas de codificaci\xf3n, alcanzando resultados comparables a Claude Sonnet."},"amazon/nova-lite":{"description":"Un modelo multimodal de muy bajo costo que procesa entradas de im\xe1genes, videos y texto a una velocidad extremadamente r\xe1pida."},"amazon/nova-micro":{"description":"Un modelo solo de texto que ofrece respuestas con la latencia m\xe1s baja a un costo muy reducido."},"amazon/nova-pro":{"description":"Un modelo multimodal altamente competente que ofrece la mejor combinaci\xf3n de precisi\xf3n, velocidad y costo, adecuado para una amplia gama de tareas."},"amazon/titan-embed-text-v2":{"description":"Amazon Titan Text Embeddings V2 es un modelo de incrustaciones multiling\xfce ligero y eficiente, compatible con dimensiones de 1024, 512 y 256."},"anthropic.claude-3-5-sonnet-20240620-v1:0":{"description":"Claude 3.5 Sonnet eleva el est\xe1ndar de la industria, superando a modelos competidores y a Claude 3 Opus, destac\xe1ndose en evaluaciones amplias, mientras mantiene la velocidad y costo de nuestros modelos de nivel medio."},"anthropic.claude-3-5-sonnet-20241022-v2:0":{"description":"Claude 3.5 Sonnet ha elevado los est\xe1ndares de la industria, superando el rendimiento de modelos competidores y de Claude 3 Opus, destac\xe1ndose en evaluaciones amplias, mientras mantiene la velocidad y el costo de nuestros modelos de nivel medio."},"anthropic.claude-3-haiku-20240307-v1:0":{"description":"Claude 3 Haiku es el modelo m\xe1s r\xe1pido y compacto de Anthropic, ofreciendo una velocidad de respuesta casi instant\xe1nea. Puede responder r\xe1pidamente a consultas y solicitudes simples. Los clientes podr\xe1n construir experiencias de IA sin costuras que imiten la interacci\xf3n humana. Claude 3 Haiku puede manejar im\xe1genes y devolver salidas de texto, con una ventana de contexto de 200K."},"anthropic.claude-3-opus-20240229-v1:0":{"description":"Claude 3 Opus es el modelo de IA m\xe1s potente de Anthropic, con un rendimiento de vanguardia en tareas altamente complejas. Puede manejar indicaciones abiertas y escenarios no vistos, con una fluidez y comprensi\xf3n humana excepcionales. Claude 3 Opus muestra la vanguardia de las posibilidades de la IA generativa. Claude 3 Opus puede manejar im\xe1genes y devolver salidas de texto, con una ventana de contexto de 200K."},"anthropic.claude-3-sonnet-20240229-v1:0":{"description":"Claude 3 Sonnet de Anthropic logra un equilibrio ideal entre inteligencia y velocidad, especialmente adecuado para cargas de trabajo empresariales. Ofrece la m\xe1xima utilidad a un costo inferior al de los competidores, dise\xf1ado para ser un modelo confiable y duradero, apto para implementaciones de IA a gran escala. Claude 3 Sonnet puede manejar im\xe1genes y devolver salidas de texto, con una ventana de contexto de 200K."},"anthropic.claude-instant-v1":{"description":"Un modelo r\xe1pido, econ\xf3mico y a\xfan muy capaz, que puede manejar una variedad de tareas, incluyendo conversaciones cotidianas, an\xe1lisis de texto, res\xfamenes y preguntas y respuestas de documentos."},"anthropic.claude-v2":{"description":"Anthropic muestra un modelo con alta capacidad en una amplia gama de tareas, desde di\xe1logos complejos y generaci\xf3n de contenido creativo hasta el seguimiento detallado de instrucciones."},"anthropic.claude-v2:1":{"description":"La versi\xf3n actualizada de Claude 2, con el doble de ventana de contexto, as\xed como mejoras en la fiabilidad, tasa de alucinaciones y precisi\xf3n basada en evidencia en contextos de documentos largos y RAG."},"anthropic/claude-3-haiku":{"description":"Claude 3 Haiku es el modelo m\xe1s r\xe1pido de Anthropic hasta la fecha, dise\xf1ado para cargas de trabajo empresariales que suelen involucrar indicaciones largas. Haiku puede analizar r\xe1pidamente grandes vol\xfamenes de documentos, como informes trimestrales, contratos o casos legales, a la mitad del costo de otros modelos de su clase."},"anthropic/claude-3-opus":{"description":"Claude 3 Opus es el modelo m\xe1s inteligente de Anthropic, con un rendimiento l\xedder en el mercado en tareas altamente complejas. Navega indicaciones abiertas y escenarios in\xe9ditos con fluidez excepcional y comprensi\xf3n humana."},"anthropic/claude-3.5-haiku":{"description":"Claude 3.5 Haiku es la siguiente generaci\xf3n de nuestro modelo m\xe1s r\xe1pido. Con una velocidad similar a Claude 3 Haiku, Claude 3.5 Haiku mejora en cada conjunto de habilidades y supera a nuestro modelo m\xe1s grande anterior, Claude 3 Opus, en muchas pruebas de referencia de inteligencia."},"anthropic/claude-3.5-sonnet":{"description":"Claude 3.5 Sonnet logra un equilibrio ideal entre inteligencia y velocidad, especialmente para cargas de trabajo empresariales. Ofrece un rendimiento potente a menor costo en comparaci\xf3n con productos similares y est\xe1 dise\xf1ado para alta durabilidad en implementaciones de IA a gran escala."},"anthropic/claude-3.7-sonnet":{"description":"Claude 3.7 Sonnet es el primer modelo de razonamiento h\xedbrido y el m\xe1s inteligente de Anthropic hasta la fecha. Ofrece un rendimiento de vanguardia en codificaci\xf3n, generaci\xf3n de contenido, an\xe1lisis de datos y tareas de planificaci\xf3n, construido sobre las capacidades de ingenier\xeda de software y computaci\xf3n de su predecesor Claude 3.5 Sonnet."},"anthropic/claude-opus-4":{"description":"Claude Opus 4 es el modelo m\xe1s potente de Anthropic y el mejor modelo de codificaci\xf3n del mundo, liderando en SWE-bench (72.5%) y Terminal-bench (43.2%). Proporciona rendimiento sostenido para tareas a largo plazo que requieren esfuerzo concentrado y miles de pasos, capaz de trabajar continuamente durante horas, ampliando significativamente las capacidades de los agentes de IA."},"anthropic/claude-opus-4.1":{"description":"Claude Opus 4.1 es una alternativa plug-and-play a Opus 4, que ofrece un rendimiento y precisi\xf3n excepcionales para tareas pr\xe1cticas de codificaci\xf3n y agentes. Eleva el rendimiento de codificaci\xf3n de vanguardia a un 74.5% verificado en SWE-bench y maneja problemas complejos de m\xfaltiples pasos con mayor rigor y atenci\xf3n al detalle."},"anthropic/claude-sonnet-4":{"description":"Claude Sonnet 4 mejora significativamente las capacidades l\xedderes de Sonnet 3.7, destac\xe1ndose en codificaci\xf3n con un rendimiento de vanguardia del 72.7% en SWE-bench. El modelo equilibra rendimiento y eficiencia, adecuado para casos de uso internos y externos, y ofrece mayor control mediante una mejor capacidad de control."},"anthropic/claude-sonnet-4.5":{"description":"Claude Sonnet 4.5 es el modelo m\xe1s inteligente de Anthropic hasta la fecha."},"ascend-tribe/pangu-pro-moe":{"description":"Pangu-Pro-MoE 72B-A16B es un modelo de lenguaje grande disperso con 72 mil millones de par\xe1metros y 16 mil millones de par\xe1metros activados. Est\xe1 basado en la arquitectura de expertos mixtos agrupados (MoGE), que agrupa expertos durante la selecci\xf3n y restringe la activaci\xf3n de un n\xfamero igual de expertos por grupo para cada token, logrando un balance de carga entre expertos y mejorando significativamente la eficiencia de despliegue en la plataforma Ascend."},"aya":{"description":"Aya 23 es un modelo multiling\xfce lanzado por Cohere, que admite 23 idiomas, facilitando aplicaciones de lenguaje diversas."},"aya:35b":{"description":"Aya 23 es un modelo multiling\xfce lanzado por Cohere, que admite 23 idiomas, facilitando aplicaciones de lenguaje diversas."},"azure-DeepSeek-R1-0528":{"description":"Desplegado y proporcionado por Microsoft; el modelo DeepSeek R1 ha recibido una actualizaci\xf3n menor, la versi\xf3n actual es DeepSeek-R1-0528. En la \xfaltima actualizaci\xf3n, DeepSeek R1 ha mejorado significativamente la profundidad de inferencia y la capacidad de deducci\xf3n mediante el aumento de recursos computacionales y la introducci\xf3n de mecanismos de optimizaci\xf3n algor\xedtmica en la fase posterior al entrenamiento. Este modelo destaca en m\xfaltiples pruebas de referencia en matem\xe1ticas, programaci\xf3n y l\xf3gica general, y su rendimiento general se acerca a modelos l\xedderes como O3 y Gemini 2.5 Pro."},"baichuan-m2-32b":{"description":"Baichuan M2 32B es un modelo de expertos mixto desarrollado por Baichuan Intelligence, con potentes capacidades de razonamiento."},"baichuan/baichuan2-13b-chat":{"description":"Baichuan-13B es un modelo de lenguaje de gran escala de c\xf3digo abierto y comercializable desarrollado por Baichuan Intelligence, que cuenta con 13 mil millones de par\xe1metros y ha logrado los mejores resultados en benchmarks autorizados en chino e ingl\xe9s."},"baidu/ERNIE-4.5-300B-A47B":{"description":"ERNIE-4.5-300B-A47B es un modelo de lenguaje grande desarrollado por Baidu basado en la arquitectura de expertos mixtos (MoE). Cuenta con un total de 300 mil millones de par\xe1metros, pero durante la inferencia solo activa 47 mil millones por token, equilibrando un rendimiento potente con eficiencia computacional. Como uno de los modelos centrales de la serie ERNIE 4.5, destaca en tareas de comprensi\xf3n, generaci\xf3n, razonamiento y programaci\xf3n de texto. Emplea un innovador m\xe9todo de preentrenamiento multimodal heterog\xe9neo MoE, que combina entrenamiento conjunto de texto y visi\xf3n, mejorando la capacidad integral del modelo, especialmente en el seguimiento de instrucciones y la memoria de conocimientos del mundo."},"c4ai-aya-expanse-32b":{"description":"Aya Expanse es un modelo multiling\xfce de alto rendimiento de 32B, dise\xf1ado para desafiar el rendimiento de los modelos monoling\xfces a trav\xe9s de innovaciones en ajuste por instrucciones, arbitraje de datos, entrenamiento de preferencias y fusi\xf3n de modelos. Soporta 23 idiomas."},"c4ai-aya-expanse-8b":{"description":"Aya Expanse es un modelo multiling\xfce de alto rendimiento de 8B, dise\xf1ado para desafiar el rendimiento de los modelos monoling\xfces a trav\xe9s de innovaciones en ajuste por instrucciones, arbitraje de datos, entrenamiento de preferencias y fusi\xf3n de modelos. Soporta 23 idiomas."},"c4ai-aya-vision-32b":{"description":"Aya Vision es un modelo multimodal de \xfaltima generaci\xf3n, que destaca en m\xfaltiples benchmarks clave de capacidades ling\xfc\xedsticas, textuales y visuales. Soporta 23 idiomas. Esta versi\xf3n de 32B se centra en el rendimiento multiling\xfce de vanguardia."},"c4ai-aya-vision-8b":{"description":"Aya Vision es un modelo multimodal de \xfaltima generaci\xf3n, que destaca en m\xfaltiples benchmarks clave de capacidades ling\xfc\xedsticas, textuales y visuales. Esta versi\xf3n de 8B se centra en baja latencia y rendimiento \xf3ptimo."},"charglm-3":{"description":"CharGLM-3 est\xe1 dise\xf1ado para juegos de rol y acompa\xf1amiento emocional, soportando memoria de m\xfaltiples rondas y di\xe1logos personalizados, con aplicaciones amplias."},"charglm-4":{"description":"CharGLM-4 est\xe1 dise\xf1ado para el juego de roles y la compa\xf1\xeda emocional, soportando memoria de m\xfaltiples turnos de larga duraci\xf3n y di\xe1logos personalizados, con aplicaciones amplias."},"chatgpt-4o-latest":{"description":"ChatGPT-4o es un modelo din\xe1mico que se actualiza en tiempo real para mantener la versi\xf3n m\xe1s actual. Combina una poderosa comprensi\xf3n y generaci\xf3n de lenguaje, adecuado para aplicaciones a gran escala, incluyendo servicio al cliente, educaci\xf3n y soporte t\xe9cnico."},"claude-2.0":{"description":"Claude 2 ofrece avances en capacidades clave para empresas, incluyendo un contexto l\xedder en la industria de 200K tokens, una reducci\xf3n significativa en la tasa de alucinaciones del modelo, indicaciones del sistema y una nueva funci\xf3n de prueba: llamadas a herramientas."},"claude-2.1":{"description":"Claude 2 ofrece avances en capacidades clave para empresas, incluyendo un contexto l\xedder en la industria de 200K tokens, una reducci\xf3n significativa en la tasa de alucinaciones del modelo, indicaciones del sistema y una nueva funci\xf3n de prueba: llamadas a herramientas."},"claude-3-5-haiku-20241022":{"description":"Claude 3.5 Haiku es el modelo de pr\xf3xima generaci\xf3n m\xe1s r\xe1pido de Anthropic. En comparaci\xf3n con Claude 3 Haiku, Claude 3.5 Haiku ha mejorado en todas las habilidades y ha superado al modelo m\xe1s grande de la generaci\xf3n anterior, Claude 3 Opus, en muchas pruebas de referencia de inteligencia."},"claude-3-5-haiku-latest":{"description":"Claude 3.5 Haiku ofrece respuestas r\xe1pidas, ideal para tareas ligeras."},"claude-3-7-sonnet-20250219":{"description":"Claude 3.7 Sonnet es el modelo de IA m\xe1s potente de Anthropic, con un rendimiento de vanguardia en tareas altamente complejas. Puede manejar indicaciones abiertas y escenarios no vistos, con una fluidez y comprensi\xf3n humana excepcionales. Claude 3.7 Sonnet muestra la vanguardia de las posibilidades de la IA generativa."},"claude-3-7-sonnet-latest":{"description":"Claude 3.7 Sonnet es el modelo m\xe1s potente y reciente de Anthropic para manejar tareas altamente complejas. Destaca en rendimiento, inteligencia, fluidez y comprensi\xf3n."},"claude-3-haiku-20240307":{"description":"Claude 3 Haiku es el modelo m\xe1s r\xe1pido y compacto de Anthropic, dise\xf1ado para lograr respuestas casi instant\xe1neas. Tiene un rendimiento de orientaci\xf3n r\xe1pido y preciso."},"claude-3-opus-20240229":{"description":"Claude 3 Opus es el modelo m\xe1s potente de Anthropic para manejar tareas altamente complejas. Destaca en rendimiento, inteligencia, fluidez y comprensi\xf3n."},"claude-3-sonnet-20240229":{"description":"Claude 3 Sonnet proporciona un equilibrio ideal entre inteligencia y velocidad para cargas de trabajo empresariales. Ofrece la m\xe1xima utilidad a un costo m\xe1s bajo, siendo fiable y adecuado para implementaciones a gran escala."},"claude-haiku-4-5-20251001":{"description":"Claude Haiku 4.5 es el modelo Haiku m\xe1s r\xe1pido e inteligente de Anthropic, con una velocidad rel\xe1mpago y una capacidad de razonamiento ampliada."},"claude-opus-4-1-20250805":{"description":"Claude Opus 4.1 es el modelo m\xe1s potente y reciente de Anthropic para manejar tareas altamente complejas. Sobresale en rendimiento, inteligencia, fluidez y comprensi\xf3n."},"claude-opus-4-1-20250805-thinking":{"description":"Modelo de pensamiento Claude Opus 4.1, una versi\xf3n avanzada que puede mostrar su proceso de razonamiento."},"claude-opus-4-20250514":{"description":"Claude Opus 4 es el modelo m\xe1s potente de Anthropic para manejar tareas altamente complejas. Se destaca en rendimiento, inteligencia, fluidez y comprensi\xf3n."},"claude-sonnet-4-20250514":{"description":"Claude Sonnet 4 puede generar respuestas casi instant\xe1neas o un pensamiento prolongado paso a paso, permitiendo a los usuarios ver claramente estos procesos."},"claude-sonnet-4-20250514-thinking":{"description":"Modelo de pensamiento Claude Sonnet 4 que puede generar respuestas casi instant\xe1neas o un pensamiento prolongado paso a paso, permitiendo a los usuarios ver claramente estos procesos."},"claude-sonnet-4-5-20250929":{"description":"Claude Sonnet 4.5 es el modelo m\xe1s inteligente de Anthropic hasta la fecha."},"codegeex-4":{"description":"CodeGeeX-4 es un potente asistente de programaci\xf3n AI, que admite preguntas y respuestas inteligentes y autocompletado de c\xf3digo en varios lenguajes de programaci\xf3n, mejorando la eficiencia del desarrollo."},"codegeex4-all-9b":{"description":"CodeGeeX4-ALL-9B es un modelo de generaci\xf3n de c\xf3digo multiling\xfce, que admite funciones completas, incluyendo autocompletado y generaci\xf3n de c\xf3digo, int\xe9rprete de c\xf3digo, b\xfasqueda en la web, llamadas a funciones y preguntas y respuestas de c\xf3digo a nivel de repositorio, cubriendo diversos escenarios de desarrollo de software. Es un modelo de generaci\xf3n de c\xf3digo de primer nivel con menos de 10B de par\xe1metros."},"codegemma":{"description":"CodeGemma es un modelo de lenguaje ligero especializado en diversas tareas de programaci\xf3n, que admite iteraciones r\xe1pidas e integraci\xf3n."},"codegemma:2b":{"description":"CodeGemma es un modelo de lenguaje ligero especializado en diversas tareas de programaci\xf3n, que admite iteraciones r\xe1pidas e integraci\xf3n."},"codellama":{"description":"Code Llama es un LLM enfocado en la generaci\xf3n y discusi\xf3n de c\xf3digo, combinando un amplio soporte para lenguajes de programaci\xf3n, adecuado para entornos de desarrolladores."},"codellama/CodeLlama-34b-Instruct-hf":{"description":"Code Llama es un LLM enfocado en la generaci\xf3n y discusi\xf3n de c\xf3digo, que combina un amplio soporte para lenguajes de programaci\xf3n, adecuado para entornos de desarrolladores."},"codellama:13b":{"description":"Code Llama es un LLM enfocado en la generaci\xf3n y discusi\xf3n de c\xf3digo, combinando un amplio soporte para lenguajes de programaci\xf3n, adecuado para entornos de desarrolladores."},"codellama:34b":{"description":"Code Llama es un LLM enfocado en la generaci\xf3n y discusi\xf3n de c\xf3digo, combinando un amplio soporte para lenguajes de programaci\xf3n, adecuado para entornos de desarrolladores."},"codellama:70b":{"description":"Code Llama es un LLM enfocado en la generaci\xf3n y discusi\xf3n de c\xf3digo, combinando un amplio soporte para lenguajes de programaci\xf3n, adecuado para entornos de desarrolladores."},"codeqwen":{"description":"CodeQwen1.5 es un modelo de lenguaje a gran escala entrenado con una gran cantidad de datos de c\xf3digo, dise\xf1ado para resolver tareas de programaci\xf3n complejas."},"codestral":{"description":"Codestral es el primer modelo de c\xf3digo de Mistral AI, que proporciona un excelente soporte para tareas de generaci\xf3n de c\xf3digo."},"codestral-latest":{"description":"Codestral es un modelo generativo de vanguardia enfocado en la generaci\xf3n de c\xf3digo, optimizado para tareas de completado de c\xf3digo y relleno intermedio."},"codex-mini-latest":{"description":"codex-mini-latest es una versi\xf3n ajustada de o4-mini, dise\xf1ada espec\xedficamente para Codex CLI. Para uso directo a trav\xe9s de la API, recomendamos comenzar con gpt-4.1."},"cogview-4":{"description":"CogView-4 es el primer modelo de generaci\xf3n de im\xe1genes a partir de texto de c\xf3digo abierto de Zhipu que admite la generaci\xf3n de caracteres chinos. Ofrece mejoras integrales en la comprensi\xf3n sem\xe1ntica, la calidad de generaci\xf3n de im\xe1genes y la capacidad de generar texto en chino e ingl\xe9s. Soporta entradas biling\xfces en chino e ingl\xe9s de cualquier longitud y puede generar im\xe1genes en cualquier resoluci\xf3n dentro del rango especificado."},"cohere-command-r":{"description":"Command R es un modelo generativo escalable dirigido a RAG y uso de herramientas para habilitar IA a escala de producci\xf3n para empresas."},"cohere-command-r-plus":{"description":"Command R+ es un modelo optimizado para RAG de \xfaltima generaci\xf3n dise\xf1ado para abordar cargas de trabajo de nivel empresarial."},"cohere/Cohere-command-r":{"description":"Command R es un modelo generativo escalable dise\xf1ado para su uso con RAG y herramientas, que permite a las empresas implementar IA de nivel productivo."},"cohere/Cohere-command-r-plus":{"description":"Command R+ es un modelo optimizado de \xfaltima generaci\xf3n para RAG, dise\xf1ado para manejar cargas de trabajo empresariales."},"cohere/command-a":{"description":"Command A es el modelo m\xe1s potente de Cohere hasta la fecha, sobresaliendo en uso de herramientas, agentes, generaci\xf3n mejorada por recuperaci\xf3n (RAG) y casos multiling\xfces. Con una longitud de contexto de 256K, funciona con solo dos GPU y ofrece un rendimiento 150% superior en comparaci\xf3n con Command R+ 08-2024."},"cohere/command-r":{"description":"Command R es un modelo de lenguaje grande optimizado para interacciones conversacionales y tareas de contexto largo. Se posiciona en la categor\xeda \\"escalable\\", equilibrando alto rendimiento y precisi\xf3n para permitir que las empresas avancen m\xe1s all\xe1 de la prueba de concepto hacia la producci\xf3n."},"cohere/command-r-plus":{"description":"Command R+ es el modelo de lenguaje grande m\xe1s reciente de Cohere, optimizado para interacciones conversacionales y tareas de contexto largo. Su objetivo es ofrecer un rendimiento excepcional para que las empresas puedan superar la prueba de concepto y pasar a producci\xf3n."},"cohere/embed-v4.0":{"description":"Un modelo que permite clasificar texto, im\xe1genes o contenido mixto o convertirlos en incrustaciones."},"comfyui/flux-dev":{"description":"FLUX.1 Dev - Modelo de generaci\xf3n de im\xe1genes a partir de texto de alta calidad, genera en 10-50 pasos, ideal para creaciones art\xedsticas y obras de alta calidad"},"comfyui/flux-kontext-dev":{"description":"FLUX.1 Kontext-dev - Modelo de edici\xf3n de im\xe1genes, permite modificar im\xe1genes existentes mediante instrucciones de texto, compatible con ediciones parciales y transferencia de estilo"},"comfyui/flux-krea-dev":{"description":"FLUX.1 Krea-dev - Modelo de generaci\xf3n de im\xe1genes con seguridad mejorada, desarrollado en colaboraci\xf3n con Krea, incluye filtros de seguridad integrados"},"comfyui/flux-schnell":{"description":"FLUX.1 Schnell - Modelo ultrarr\xe1pido de generaci\xf3n de im\xe1genes a partir de texto, genera im\xe1genes de alta calidad en solo 1-4 pasos, ideal para aplicaciones en tiempo real y creaci\xf3n r\xe1pida de prototipos"},"comfyui/stable-diffusion-15":{"description":"Modelo Stable Diffusion 1.5 de generaci\xf3n de im\xe1genes a partir de texto, cl\xe1sico con resoluci\xf3n de 512x512, ideal para prototipos r\xe1pidos y experimentaci\xf3n creativa"},"comfyui/stable-diffusion-35":{"description":"Modelo de nueva generaci\xf3n Stable Diffusion 3.5 para generaci\xf3n de im\xe1genes a partir de texto, disponible en versiones Large y Medium, requiere archivo externo del codificador CLIP, ofrece excelente calidad de imagen y precisi\xf3n en la interpretaci\xf3n de los prompts"},"comfyui/stable-diffusion-35-inclclip":{"description":"Versi\xf3n de Stable Diffusion 3.5 con codificadores CLIP/T5 integrados, no requiere archivos externos, compatible con modelos como sd3.5_medium_incl_clips, con menor consumo de recursos"},"comfyui/stable-diffusion-custom":{"description":"Modelo personalizado de generaci\xf3n de im\xe1genes SD, el archivo del modelo debe llamarse custom_sd_lobe.safetensors; si se utiliza VAE, debe llamarse custom_sd_vae_lobe.safetensors. Los archivos del modelo deben colocarse en la carpeta correspondiente seg\xfan los requisitos de Comfy"},"comfyui/stable-diffusion-custom-refiner":{"description":"Modelo personalizado SDXL de conversi\xf3n de imagen a imagen, el archivo del modelo debe llamarse custom_sd_lobe.safetensors; si se utiliza VAE, debe llamarse custom_sd_vae_lobe.safetensors. Los archivos del modelo deben colocarse en la carpeta correspondiente seg\xfan los requisitos de Comfy"},"comfyui/stable-diffusion-refiner":{"description":"Modelo SDXL de conversi\xf3n de imagen a imagen, transforma im\xe1genes de entrada en im\xe1genes de alta calidad, compatible con transferencia de estilo, restauraci\xf3n de im\xe1genes y transformaciones creativas"},"comfyui/stable-diffusion-xl":{"description":"Modelo SDXL de generaci\xf3n de im\xe1genes a partir de texto, compatible con generaci\xf3n de im\xe1genes en alta resoluci\xf3n 1024x1024, ofrece mejor calidad de imagen y mayor nivel de detalle"},"command":{"description":"Un modelo de conversaci\xf3n que sigue instrucciones, ofreciendo alta calidad y fiabilidad en tareas ling\xfc\xedsticas, adem\xe1s de tener una longitud de contexto m\xe1s larga que nuestros modelos de generaci\xf3n b\xe1sicos."},"command-a-03-2025":{"description":"Command A es nuestro modelo m\xe1s potente hasta la fecha, destacando en el uso de herramientas, agentes, generaci\xf3n aumentada por recuperaci\xf3n (RAG) y aplicaciones multiling\xfces. Command A tiene una longitud de contexto de 256K, puede ejecutarse con solo dos GPU y ha mejorado su rendimiento en un 150% en comparaci\xf3n con Command R+ 08-2024."},"command-light":{"description":"Una versi\xf3n m\xe1s peque\xf1a y r\xe1pida de Command, casi igual de potente, pero m\xe1s r\xe1pida."},"command-light-nightly":{"description":"Para acortar el intervalo entre lanzamientos de versiones principales, hemos lanzado versiones nocturnas del modelo Command. Para la serie command-light, esta versi\xf3n se llama command-light-nightly. Tenga en cuenta que command-light-nightly es la versi\xf3n m\xe1s reciente, experimental y (posiblemente) inestable. Las versiones nocturnas se actualizan regularmente sin previo aviso, por lo que no se recomienda su uso en entornos de producci\xf3n."},"command-nightly":{"description":"Para acortar el intervalo entre lanzamientos de versiones principales, hemos lanzado versiones nocturnas del modelo Command. Para la serie Command, esta versi\xf3n se llama command-cightly. Tenga en cuenta que command-nightly es la versi\xf3n m\xe1s reciente, experimental y (posiblemente) inestable. Las versiones nocturnas se actualizan regularmente sin previo aviso, por lo que no se recomienda su uso en entornos de producci\xf3n."},"command-r":{"description":"Command R es un LLM optimizado para tareas de di\xe1logo y contexto largo, especialmente adecuado para interacciones din\xe1micas y gesti\xf3n del conocimiento."},"command-r-03-2024":{"description":"Command R es un modelo de conversaci\xf3n que sigue instrucciones, ofreciendo una mayor calidad y fiabilidad en tareas ling\xfc\xedsticas, adem\xe1s de tener una longitud de contexto m\xe1s larga que los modelos anteriores. Se puede utilizar en flujos de trabajo complejos, como generaci\xf3n de c\xf3digo, generaci\xf3n aumentada por recuperaci\xf3n (RAG), uso de herramientas y agentes."},"command-r-08-2024":{"description":"command-r-08-2024 es una versi\xf3n actualizada del modelo Command R, lanzada en agosto de 2024."},"command-r-plus":{"description":"Command R+ es un modelo de lenguaje de gran tama\xf1o de alto rendimiento, dise\xf1ado para escenarios empresariales reales y aplicaciones complejas."},"command-r-plus-04-2024":{"description":"Command R+ es un modelo de conversaci\xf3n que sigue instrucciones, ofreciendo una mayor calidad y fiabilidad en tareas ling\xfc\xedsticas, adem\xe1s de tener una longitud de contexto m\xe1s larga que los modelos anteriores. Es ideal para flujos de trabajo complejos de RAG y uso de herramientas en m\xfaltiples pasos."},"command-r-plus-08-2024":{"description":"Command R+ es un modelo de conversaci\xf3n que sigue instrucciones, mostrando una mayor calidad y fiabilidad en tareas ling\xfc\xedsticas, con una longitud de contexto m\xe1s larga en comparaci\xf3n con modelos anteriores. Es m\xe1s adecuado para flujos de trabajo RAG complejos y el uso de herramientas en m\xfaltiples pasos."},"command-r7b-12-2024":{"description":"command-r7b-12-2024 es una versi\xf3n peque\xf1a y eficiente, lanzada en diciembre de 2024. Destaca en tareas que requieren razonamiento complejo y procesamiento en m\xfaltiples pasos, como RAG, uso de herramientas y agentes."},"computer-use-preview":{"description":"El modelo computer-use-preview est\xe1 dise\xf1ado exclusivamente para \\"herramientas de uso inform\xe1tico\\", entrenado para comprender y ejecutar tareas relacionadas con computadoras."},"dall-e-2":{"description":"El segundo modelo DALL\xb7E, que admite generaci\xf3n de im\xe1genes m\xe1s realistas y precisas, con una resoluci\xf3n cuatro veces mayor que la de la primera generaci\xf3n."},"dall-e-3":{"description":"El modelo DALL\xb7E m\xe1s reciente, lanzado en noviembre de 2023. Admite generaci\xf3n de im\xe1genes m\xe1s realistas y precisas, con una mayor capacidad de detalle."},"databricks/dbrx-instruct":{"description":"DBRX Instruct ofrece capacidades de procesamiento de instrucciones de alta fiabilidad, soportando aplicaciones en m\xfaltiples industrias."},"deepseek-ai/DeepSeek-OCR":{"description":"DeepSeek-OCR es un modelo de lenguaje visual desarrollado por DeepSeek AI, enfocado en el reconocimiento \xf3ptico de caracteres (OCR) y la \\"compresi\xf3n \xf3ptica contextual\\". Este modelo explora los l\xedmites de la compresi\xf3n de informaci\xf3n contextual a partir de im\xe1genes, permitiendo procesar documentos de manera eficiente y convertirlos en formatos de texto estructurado como Markdown. Es capaz de reconocer con precisi\xf3n el contenido textual en im\xe1genes, siendo especialmente \xfatil para digitalizaci\xf3n de documentos, extracci\xf3n de texto y procesamiento estructurado."},"deepseek-ai/DeepSeek-R1":{"description":"DeepSeek-R1 es un modelo de inferencia impulsado por aprendizaje reforzado (RL) que aborda los problemas de repetitividad y legibilidad en el modelo. Antes de RL, DeepSeek-R1 introdujo datos de arranque en fr\xedo, optimizando a\xfan m\xe1s el rendimiento de la inferencia. Su desempe\xf1o en tareas matem\xe1ticas, de c\xf3digo e inferencia es comparable al de OpenAI-o1, y ha mejorado su efectividad general a trav\xe9s de m\xe9todos de entrenamiento cuidadosamente dise\xf1ados."},"deepseek-ai/DeepSeek-R1-0528":{"description":"DeepSeek R1 mejora significativamente la profundidad de razonamiento e inferencia mediante el uso de recursos computacionales aumentados y la introducci\xf3n de mecanismos de optimizaci\xf3n algor\xedtmica en el postentrenamiento. Este modelo destaca en diversas evaluaciones de referencia, incluyendo matem\xe1ticas, programaci\xf3n y l\xf3gica general. Su rendimiento global se acerca a modelos l\xedderes como O3 y Gemini 2.5 Pro."},"deepseek-ai/DeepSeek-R1-0528-Qwen3-8B":{"description":"DeepSeek-R1-0528-Qwen3-8B es un modelo obtenido mediante destilaci\xf3n de cadenas de pensamiento del modelo DeepSeek-R1-0528 al Qwen3 8B Base. Este modelo alcanza el estado del arte (SOTA) entre modelos de c\xf3digo abierto, superando a Qwen3 8B en un 10% en la prueba AIME 2024 y alcanzando el nivel de rendimiento de Qwen3-235B-thinking. Sobresale en razonamiento matem\xe1tico, programaci\xf3n y l\xf3gica general, compartiendo arquitectura con Qwen3-8B pero utilizando la configuraci\xf3n de tokenizador de DeepSeek-R1-0528."},"deepseek-ai/DeepSeek-R1-Distill-Llama-70B":{"description":"El modelo de destilaci\xf3n DeepSeek-R1 optimiza el rendimiento de inferencia mediante aprendizaje por refuerzo y datos de arranque en fr\xedo, actualizando el est\xe1ndar de m\xfaltiples tareas en modelos de c\xf3digo abierto."},"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B":{"description":"El modelo de destilaci\xf3n DeepSeek-R1 optimiza el rendimiento de inferencia mediante aprendizaje por refuerzo y datos de arranque en fr\xedo, actualizando el est\xe1ndar de m\xfaltiples tareas en modelos de c\xf3digo abierto."},"deepseek-ai/DeepSeek-R1-Distill-Qwen-14B":{"description":"El modelo de destilaci\xf3n DeepSeek-R1 optimiza el rendimiento de inferencia mediante aprendizaje por refuerzo y datos de arranque en fr\xedo, actualizando el est\xe1ndar de m\xfaltiples tareas en modelos de c\xf3digo abierto."},"deepseek-ai/DeepSeek-R1-Distill-Qwen-32B":{"description":"DeepSeek-R1-Distill-Qwen-32B es un modelo obtenido mediante destilaci\xf3n de conocimiento basado en Qwen2.5-32B. Este modelo se ajust\xf3 utilizando 800,000 muestras seleccionadas generadas por DeepSeek-R1, mostrando un rendimiento excepcional en m\xfaltiples campos como matem\xe1ticas, programaci\xf3n e inferencia. Ha obtenido excelentes resultados en varias pruebas de referencia, alcanzando una precisi\xf3n del 94.3% en MATH-500, demostrando una fuerte capacidad de razonamiento matem\xe1tico."},"deepseek-ai/DeepSeek-R1-Distill-Qwen-7B":{"description":"DeepSeek-R1-Distill-Qwen-7B es un modelo obtenido mediante destilaci\xf3n de conocimiento basado en Qwen2.5-Math-7B. Este modelo se ajust\xf3 utilizando 800,000 muestras seleccionadas generadas por DeepSeek-R1, mostrando un rendimiento excepcional en m\xfaltiples campos como matem\xe1ticas, programaci\xf3n e inferencia. Ha obtenido excelentes resultados en varias pruebas de referencia, alcanzando una precisi\xf3n del 92.8% en MATH-500, una tasa de aprobaci\xf3n del 55.5% en AIME 2024, y una puntuaci\xf3n de 1189 en CodeForces, demostrando una fuerte capacidad matem\xe1tica y de programaci\xf3n como modelo de 7B."},"deepseek-ai/DeepSeek-V2.5":{"description":"DeepSeek V2.5 combina las excelentes caracter\xedsticas de versiones anteriores, mejorando la capacidad general y de codificaci\xf3n."},"deepseek-ai/DeepSeek-V3":{"description":"DeepSeek-V3 es un modelo de lenguaje de expertos mixtos (MoE) con 6710 millones de par\xe1metros, que utiliza atenci\xf3n latente de m\xfaltiples cabezas (MLA) y la arquitectura DeepSeekMoE, combinando una estrategia de balanceo de carga sin p\xe9rdidas auxiliares para optimizar la eficiencia de inferencia y entrenamiento. Al ser preentrenado en 14.8 billones de tokens de alta calidad y realizar ajustes supervisados y aprendizaje reforzado, DeepSeek-V3 supera en rendimiento a otros modelos de c\xf3digo abierto, acerc\xe1ndose a los modelos cerrados l\xedderes."},"deepseek-ai/DeepSeek-V3.1":{"description":"El modelo DeepSeek V3.1 adopta una arquitectura de inferencia h\xedbrida, compatible tanto con el modo de razonamiento como con el modo no razonante."},"deepseek-ai/DeepSeek-V3.1-Terminus":{"description":"DeepSeek-V3.1-Terminus es una versi\xf3n actualizada del modelo V3.1 lanzado por DeepSeek, posicionada como un modelo de lenguaje grande con agentes h\xedbridos. Esta actualizaci\xf3n mantiene las capacidades originales del modelo, enfoc\xe1ndose en corregir problemas reportados por los usuarios y mejorar la estabilidad. Mejora significativamente la coherencia del lenguaje, reduciendo la mezcla de chino e ingl\xe9s y la aparici\xf3n de caracteres an\xf3malos. El modelo integra el “Modo de pensamiento” y el “Modo sin pensamiento”, permitiendo a los usuarios cambiar flexiblemente mediante plantillas de chat para adaptarse a diferentes tareas. Como optimizaci\xf3n importante, V3.1-Terminus mejora el rendimiento del agente de c\xf3digo y del agente de b\xfasqueda, haci\xe9ndolos m\xe1s confiables en la invocaci\xf3n de herramientas y en la ejecuci\xf3n de tareas complejas de m\xfaltiples pasos."},"deepseek-ai/DeepSeek-V3.2-Exp":{"description":"DeepSeek-V3.2-Exp es una versi\xf3n experimental lanzada por DeepSeek como un paso intermedio hacia una arquitectura de pr\xf3xima generaci\xf3n. Basado en V3.1-Terminus, introduce el mecanismo de Atenci\xf3n Dispersa de DeepSeek (DeepSeek Sparse Attention, DSA) para mejorar la eficiencia en el entrenamiento e inferencia con contextos largos. Ha sido especialmente optimizado para la invocaci\xf3n de herramientas, la comprensi\xf3n de documentos extensos y el razonamiento en m\xfaltiples pasos. V3.2-Exp act\xfaa como un puente entre la investigaci\xf3n y la producci\xf3n, ideal para usuarios que buscan explorar una mayor eficiencia de razonamiento en escenarios con presupuestos de contexto elevados."},"deepseek-ai/deepseek-llm-67b-chat":{"description":"DeepSeek 67B es un modelo avanzado entrenado para di\xe1logos de alta complejidad."},"deepseek-ai/deepseek-r1":{"description":"LLM eficiente de \xfaltima generaci\xf3n, experto en razonamiento, matem\xe1ticas y programaci\xf3n."},"deepseek-ai/deepseek-v3.1":{"description":"DeepSeek V3.1: modelo de inferencia de pr\xf3xima generaci\xf3n que mejora las capacidades de razonamiento complejo y pensamiento en cadena, ideal para tareas que requieren an\xe1lisis profundo."},"deepseek-ai/deepseek-v3.1-terminus":{"description":"DeepSeek V3.1: un modelo de inferencia de nueva generaci\xf3n que mejora la capacidad de razonamiento complejo y pensamiento en cadena, ideal para tareas que requieren un an\xe1lisis profundo."},"deepseek-ai/deepseek-vl2":{"description":"DeepSeek-VL2 es un modelo de lenguaje visual de expertos mixtos (MoE) desarrollado sobre DeepSeekMoE-27B, que utiliza una arquitectura MoE de activaci\xf3n dispersa, logrando un rendimiento excepcional al activar solo 4.5B de par\xe1metros. Este modelo destaca en m\xfaltiples tareas como preguntas visuales, reconocimiento \xf3ptico de caracteres, comprensi\xf3n de documentos/tablas/gr\xe1ficos y localizaci\xf3n visual."},"deepseek-chat":{"description":"Un nuevo modelo de c\xf3digo abierto que fusiona capacidades generales y de codificaci\xf3n, que no solo conserva la capacidad de di\xe1logo general del modelo Chat original y la potente capacidad de procesamiento de c\xf3digo del modelo Coder, sino que tambi\xe9n se alinea mejor con las preferencias humanas. Adem\xe1s, DeepSeek-V2.5 ha logrado mejoras significativas en tareas de escritura, seguimiento de instrucciones y m\xe1s."},"deepseek-coder-33B-instruct":{"description":"DeepSeek Coder 33B es un modelo de lenguaje de c\xf3digo, entrenado con 20 billones de datos, de los cuales el 87% son c\xf3digo y el 13% son lenguajes en chino e ingl\xe9s. El modelo introduce un tama\xf1o de ventana de 16K y tareas de llenado de espacios, proporcionando funciones de autocompletado de c\xf3digo a nivel de proyecto y llenado de fragmentos."},"deepseek-coder-v2":{"description":"DeepSeek Coder V2 es un modelo de c\xf3digo de expertos h\xedbrido de c\xf3digo abierto, que destaca en tareas de codificaci\xf3n, comparable a GPT4-Turbo."},"deepseek-coder-v2:236b":{"description":"DeepSeek Coder V2 es un modelo de c\xf3digo de expertos h\xedbrido de c\xf3digo abierto, que destaca en tareas de codificaci\xf3n, comparable a GPT4-Turbo."},"deepseek-r1":{"description":"DeepSeek-R1 es un modelo de inferencia impulsado por aprendizaje reforzado (RL) que aborda los problemas de repetitividad y legibilidad en el modelo. Antes de RL, DeepSeek-R1 introdujo datos de arranque en fr\xedo, optimizando a\xfan m\xe1s el rendimiento de la inferencia. Su desempe\xf1o en tareas matem\xe1ticas, de c\xf3digo e inferencia es comparable al de OpenAI-o1, y ha mejorado su efectividad general a trav\xe9s de m\xe9todos de entrenamiento cuidadosamente dise\xf1ados."},"deepseek-r1-0528":{"description":"Modelo completo de 685 mil millones de par\xe1metros, lanzado el 28 de mayo de 2025. DeepSeek-R1 utiliza t\xe9cnicas de aprendizaje reforzado a gran escala en la fase de postentrenamiento, mejorando significativamente la capacidad de razonamiento del modelo con muy pocos datos etiquetados. Presenta alto rendimiento y gran capacidad en tareas de matem\xe1ticas, c\xf3digo y razonamiento en lenguaje natural."},"deepseek-r1-250528":{"description":"DeepSeek R1 250528, versi\xf3n completa del modelo de inferencia DeepSeek-R1, ideal para tareas complejas de matem\xe1ticas y l\xf3gica."},"deepseek-r1-70b-fast-online":{"description":"DeepSeek R1 70B versi\xf3n r\xe1pida, que soporta b\xfasqueda en l\xednea en tiempo real, ofreciendo una velocidad de respuesta m\xe1s r\xe1pida mientras mantiene el rendimiento del modelo."},"deepseek-r1-70b-online":{"description":"DeepSeek R1 70B versi\xf3n est\xe1ndar, que soporta b\xfasqueda en l\xednea en tiempo real, adecuada para tareas de conversaci\xf3n y procesamiento de textos que requieren informaci\xf3n actualizada."},"deepseek-r1-distill-llama":{"description":"deepseek-r1-distill-llama es un modelo basado en Llama destilado a partir de DeepSeek-R1."},"deepseek-r1-distill-llama-70b":{"description":"DeepSeek R1 Distill Llama 70B, modelo destilado que combina la capacidad de inferencia R1 con el ecosistema Llama."},"deepseek-r1-distill-llama-8b":{"description":"DeepSeek-R1-Distill-Llama-8B es un modelo de lenguaje grande destilado basado en Llama-3.1-8B, utilizando las salidas de DeepSeek R1."},"deepseek-r1-distill-qianfan-70b":{"description":"DeepSeek R1 Distill Qianfan 70B, modelo destilado R1 basado en Qianfan-70B, con excelente relaci\xf3n calidad-precio."},"deepseek-r1-distill-qianfan-8b":{"description":"DeepSeek R1 Distill Qianfan 8B, modelo destilado R1 basado en Qianfan-8B, ideal para aplicaciones medianas y peque\xf1as."},"deepseek-r1-distill-qianfan-llama-70b":{"description":"DeepSeek R1 Distill Qianfan Llama 70B, modelo destilado R1 basado en Llama-70B."},"deepseek-r1-distill-qwen":{"description":"deepseek-r1-distill-qwen es un modelo basado en Qwen destilado a partir de DeepSeek-R1."},"deepseek-r1-distill-qwen-1.5b":{"description":"DeepSeek R1 Distill Qwen 1.5B, modelo R1 ultraligero, adecuado para entornos con recursos extremadamente limitados."},"deepseek-r1-distill-qwen-14b":{"description":"DeepSeek R1 Distill Qwen 14B, modelo R1 de tama\xf1o medio, ideal para despliegue en m\xfaltiples escenarios."},"deepseek-r1-distill-qwen-32b":{"description":"DeepSeek R1 Distill Qwen 32B, modelo destilado R1 basado en Qwen-32B, equilibrando rendimiento y coste."},"deepseek-r1-distill-qwen-7b":{"description":"DeepSeek R1 Distill Qwen 7B, modelo R1 ligero, adecuado para entornos perimetrales y empresariales privados."},"deepseek-r1-fast-online":{"description":"DeepSeek R1 versi\xf3n r\xe1pida completa, que soporta b\xfasqueda en l\xednea en tiempo real, combinando la potente capacidad de 671B de par\xe1metros con una velocidad de respuesta m\xe1s r\xe1pida."},"deepseek-r1-online":{"description":"DeepSeek R1 versi\xf3n completa, con 671B de par\xe1metros, que soporta b\xfasqueda en l\xednea en tiempo real, con una capacidad de comprensi\xf3n y generaci\xf3n m\xe1s potente."},"deepseek-reasoner":{"description":"Modo de pensamiento de DeepSeek V3.2. Antes de proporcionar la respuesta final, el modelo genera una cadena de razonamiento para mejorar la precisi\xf3n de la respuesta."},"deepseek-v2":{"description":"DeepSeek V2 es un modelo de lenguaje Mixture-of-Experts eficiente, adecuado para necesidades de procesamiento econ\xf3mico."},"deepseek-v2:236b":{"description":"DeepSeek V2 236B es el modelo de c\xf3digo de dise\xf1o de DeepSeek, que ofrece una potente capacidad de generaci\xf3n de c\xf3digo."},"deepseek-v3":{"description":"DeepSeek-V3 es un modelo MoE desarrollado por Hangzhou DeepSeek Artificial Intelligence Technology Research Co., Ltd., que ha destacado en m\xfaltiples evaluaciones, ocupando el primer lugar en la lista de modelos de c\xf3digo abierto. En comparaci\xf3n con el modelo V2.5, la velocidad de generaci\xf3n se ha incrementado tres veces, brindando a los usuarios una experiencia de uso m\xe1s r\xe1pida y fluida."},"deepseek-v3-0324":{"description":"DeepSeek-V3-0324 es un modelo MoE de 671B par\xe1metros, destac\xe1ndose en habilidades de programaci\xf3n y t\xe9cnicas, comprensi\xf3n del contexto y procesamiento de textos largos."},"deepseek-v3.1":{"description":"DeepSeek-V3.1 es un nuevo modelo h\xedbrido de razonamiento lanzado por DeepSeek, que soporta dos modos de razonamiento: con pensamiento y sin pensamiento, con una eficiencia de pensamiento superior a DeepSeek-R1-0528. Tras una optimizaci\xf3n post-entrenamiento, el uso de herramientas Agent y el rendimiento en tareas inteligentes han mejorado significativamente. Soporta una ventana de contexto de 128k y una longitud m\xe1xima de salida de 64k tokens."},"deepseek-v3.1-terminus":{"description":"DeepSeek-V3.1-Terminus es una versi\xf3n optimizada del modelo de lenguaje a gran escala lanzado por DeepSeek, especialmente dise\xf1ado para dispositivos terminales."},"deepseek-v3.1-think-250821":{"description":"DeepSeek V3.1 Think 250821, modelo de pensamiento profundo correspondiente a la versi\xf3n Terminus, ideal para escenarios de inferencia de alto rendimiento."},"deepseek-v3.1:671b":{"description":"DeepSeek V3.1: modelo de inferencia de pr\xf3xima generaci\xf3n que mejora las capacidades de razonamiento complejo y pensamiento en cadena, ideal para tareas que requieren an\xe1lisis profundo."},"deepseek-v3.2-exp":{"description":"deepseek-v3.2-exp introduce el mecanismo de atenci\xf3n dispersa, con el objetivo de mejorar la eficiencia en el entrenamiento y la inferencia al procesar textos largos, con un precio inferior al de deepseek-v3.1."},"deepseek-v3.2-think":{"description":"DeepSeek V3.2 Think, versi\xf3n completa del modelo de pensamiento profundo, con capacidades mejoradas de razonamiento de cadenas largas."},"deepseek-vl2":{"description":"DeepSeek VL2, modelo multimodal que admite comprensi\xf3n de im\xe1genes y texto, as\xed como preguntas visuales de alta precisi\xf3n."},"deepseek-vl2-small":{"description":"DeepSeek VL2 Small, versi\xf3n multimodal ligera, adecuada para entornos con recursos limitados y escenarios de alta concurrencia."},"deepseek/deepseek-chat-v3-0324":{"description":"DeepSeek V3 es un modelo experto de mezcla de 685B par\xe1metros, la \xfaltima iteraci\xf3n de la serie de modelos de chat insignia del equipo de DeepSeek.\\n\\nHereda el modelo [DeepSeek V3](/deepseek/deepseek-chat-v3) y se desempe\xf1a excepcionalmente en diversas tareas."},"deepseek/deepseek-chat-v3-0324:free":{"description":"DeepSeek V3 es un modelo experto de mezcla de 685B par\xe1metros, la \xfaltima iteraci\xf3n de la serie de modelos de chat insignia del equipo de DeepSeek.\\n\\nHereda el modelo [DeepSeek V3](/deepseek/deepseek-chat-v3) y se desempe\xf1a excepcionalmente en diversas tareas."},"deepseek/deepseek-chat-v3.1":{"description":"DeepSeek-V3.1 es un modelo h\xedbrido de razonamiento grande que soporta contexto largo de 128K y cambio eficiente de modos, logrando un rendimiento y velocidad sobresalientes en llamadas a herramientas, generaci\xf3n de c\xf3digo y tareas complejas de razonamiento."},"deepseek/deepseek-r1":{"description":"El modelo DeepSeek R1 ha recibido una actualizaci\xf3n menor, actualmente en la versi\xf3n DeepSeek-R1-0528. En la \xfaltima actualizaci\xf3n, DeepSeek R1 mejora significativamente la profundidad y capacidad de razonamiento al aprovechar recursos computacionales aumentados y mecanismos de optimizaci\xf3n algor\xedtmica post-entrenamiento. El modelo destaca en evaluaciones de referencia en matem\xe1ticas, programaci\xf3n y l\xf3gica general, acerc\xe1ndose al rendimiento de modelos l\xedderes como O3 y Gemini 2.5 Pro."},"deepseek/deepseek-r1-0528":{"description":"DeepSeek-R1 mejora enormemente la capacidad de razonamiento del modelo con muy pocos datos etiquetados. Antes de generar la respuesta final, el modelo produce una cadena de pensamiento para aumentar la precisi\xf3n de la respuesta."},"deepseek/deepseek-r1-0528:free":{"description":"DeepSeek-R1 mejora enormemente la capacidad de razonamiento del modelo con muy pocos datos etiquetados. Antes de generar la respuesta final, el modelo produce una cadena de pensamiento para aumentar la precisi\xf3n de la respuesta."},"deepseek/deepseek-r1-distill-llama-70b":{"description":"DeepSeek R1 Distill Llama 70B es un modelo de lenguaje de gran escala basado en Llama3.3 70B. Este modelo ha sido ajustado finamente utilizando las salidas de DeepSeek R1, logrando un rendimiento competitivo comparable al de los modelos m\xe1s avanzados del mercado."},"deepseek/deepseek-r1-distill-llama-8b":{"description":"DeepSeek R1 Distill Llama 8B es un modelo de lenguaje grande destilado basado en Llama-3.1-8B-Instruct, entrenado utilizando la salida de DeepSeek R1."},"deepseek/deepseek-r1-distill-qwen-14b":{"description":"DeepSeek R1 Distill Qwen 14B es un modelo de lenguaje grande destilado basado en Qwen 2.5 14B, entrenado utilizando la salida de DeepSeek R1. Este modelo ha superado a o1-mini de OpenAI en m\xfaltiples pruebas de referencia, logrando resultados de vanguardia en modelos densos. A continuaci\xf3n se presentan algunos resultados de las pruebas de referencia:\\nAIME 2024 pass@1: 69.7\\nMATH-500 pass@1: 93.9\\nCalificaci\xf3n de CodeForces: 1481\\nEste modelo, ajustado a partir de la salida de DeepSeek R1, muestra un rendimiento competitivo comparable al de modelos de vanguardia de mayor escala."},"deepseek/deepseek-r1-distill-qwen-32b":{"description":"DeepSeek R1 Distill Qwen 32B es un modelo de lenguaje grande destilado basado en Qwen 2.5 32B, entrenado utilizando la salida de DeepSeek R1. Este modelo ha superado a o1-mini de OpenAI en m\xfaltiples pruebas de referencia, logrando resultados de vanguardia en modelos densos. A continuaci\xf3n se presentan algunos resultados de las pruebas de referencia:\\nAIME 2024 pass@1: 72.6\\nMATH-500 pass@1: 94.3\\nCalificaci\xf3n de CodeForces: 1691\\nEste modelo, ajustado a partir de la salida de DeepSeek R1, muestra un rendimiento competitivo comparable al de modelos de vanguardia de mayor escala."},"deepseek/deepseek-r1/community":{"description":"DeepSeek R1 es el \xfaltimo modelo de c\xf3digo abierto lanzado por el equipo de DeepSeek, que cuenta con un rendimiento de inferencia excepcional, especialmente en tareas de matem\xe1ticas, programaci\xf3n y razonamiento, alcanzando niveles comparables al modelo o1 de OpenAI."},"deepseek/deepseek-r1:free":{"description":"DeepSeek-R1 mejora significativamente la capacidad de razonamiento del modelo con muy pocos datos etiquetados. Antes de proporcionar la respuesta final, el modelo genera una cadena de pensamiento para mejorar la precisi\xf3n de la respuesta final."},"deepseek/deepseek-v3":{"description":"Modelo de lenguaje grande universal r\xe1pido con capacidades de razonamiento mejoradas."},"deepseek/deepseek-v3.1-base":{"description":"DeepSeek V3.1 Base es una versi\xf3n mejorada del modelo DeepSeek V3."},"deepseek/deepseek-v3/community":{"description":"DeepSeek-V3 ha logrado un avance significativo en la velocidad de inferencia en comparaci\xf3n con modelos anteriores. Se clasifica como el n\xfamero uno entre los modelos de c\xf3digo abierto y puede competir con los modelos cerrados m\xe1s avanzados del mundo. DeepSeek-V3 utiliza la arquitectura de atenci\xf3n multi-cabeza (MLA) y DeepSeekMoE, que han sido completamente validadas en DeepSeek-V2. Adem\xe1s, DeepSeek-V3 ha introducido una estrategia auxiliar sin p\xe9rdidas para el balanceo de carga y ha establecido objetivos de entrenamiento de predicci\xf3n de m\xfaltiples etiquetas para lograr un rendimiento m\xe1s robusto."},"deepseek_r1":{"description":"DeepSeek-R1 es un modelo de inferencia impulsado por aprendizaje por refuerzo (RL), que resuelve problemas de repetitividad y legibilidad en el modelo. Antes de RL, DeepSeek-R1 introdujo datos de arranque en fr\xedo, optimizando a\xfan m\xe1s el rendimiento de inferencia. Su rendimiento en tareas de matem\xe1ticas, c\xf3digo y razonamiento es comparable al de OpenAI-o1, y mediante un m\xe9todo de entrenamiento cuidadosamente dise\xf1ado, se ha mejorado el efecto general."},"deepseek_r1_distill_llama_70b":{"description":"DeepSeek-R1-Distill-Llama-70B es un modelo obtenido a partir de Llama-3.3-70B-Instruct mediante entrenamiento de destilaci\xf3n. Este modelo es parte de la serie DeepSeek-R1, mostrando un rendimiento sobresaliente en matem\xe1ticas, programaci\xf3n y razonamiento mediante el ajuste con muestras generadas por DeepSeek-R1."},"deepseek_r1_distill_qwen_14b":{"description":"DeepSeek-R1-Distill-Qwen-14B es un modelo obtenido a partir de Qwen2.5-14B mediante destilaci\xf3n de conocimiento. Este modelo se ajust\xf3 utilizando 800,000 muestras seleccionadas generadas por DeepSeek-R1, mostrando una excelente capacidad de inferencia."},"deepseek_r1_distill_qwen_32b":{"description":"DeepSeek-R1-Distill-Qwen-32B es un modelo obtenido a partir de Qwen2.5-32B mediante destilaci\xf3n de conocimiento. Este modelo se ajust\xf3 utilizando 800,000 muestras seleccionadas generadas por DeepSeek-R1, mostrando un rendimiento excepcional en m\xfaltiples campos como matem\xe1ticas, programaci\xf3n y razonamiento."},"doubao-1.5-lite-32k":{"description":"Doubao-1.5-lite es un modelo ligero de nueva generaci\xf3n, con una velocidad de respuesta extrema, alcanzando niveles de rendimiento y latencia de clase mundial."},"doubao-1.5-pro-256k":{"description":"Doubao-1.5-pro-256k es una versi\xf3n mejorada de Doubao-1.5-Pro, con un aumento del 10% en el rendimiento general. Soporta razonamiento con una ventana de contexto de 256k y una longitud de salida de hasta 12k tokens. Mayor rendimiento, ventana m\xe1s grande y una excelente relaci\xf3n calidad-precio, adecuado para una amplia gama de escenarios de aplicaci\xf3n."},"doubao-1.5-pro-32k":{"description":"Doubao-1.5-pro es un modelo de nueva generaci\xf3n, con un rendimiento completamente mejorado, destacando en conocimientos, c\xf3digo, razonamiento, entre otros."},"doubao-1.5-thinking-pro":{"description":"El modelo de pensamiento profundo Doubao-1.5, completamente nuevo, destaca en campos especializados como matem\xe1ticas, programaci\xf3n y razonamiento cient\xedfico, as\xed como en tareas generales como la escritura creativa, alcanzando o acerc\xe1ndose al nivel de \xe9lite de la industria en m\xfaltiples est\xe1ndares de referencia, como AIME 2024, Codeforces y GPQA. Soporta una ventana de contexto de 128k y una salida de 16k."},"doubao-1.5-thinking-pro-m":{"description":"Doubao-1.5 es un nuevo modelo de pensamiento profundo (la versi\xf3n m incluye capacidades nativas de inferencia multimodal profunda), que destaca en matem\xe1ticas, programaci\xf3n, razonamiento cient\xedfico y tareas generales como escritura creativa. Alcanza o se acerca al nivel de \xe9lite en benchmarks reconocidos como AIME 2024, Codeforces y GPQA. Soporta ventana de contexto de 128k y salida de 16k."},"doubao-1.5-thinking-vision-pro":{"description":"Nuevo modelo de pensamiento profundo visual con capacidades avanzadas de comprensi\xf3n e inferencia multimodal general, logrando resultados SOTA en 37 de 59 benchmarks p\xfablicos."},"doubao-1.5-ui-tars":{"description":"Doubao-1.5-UI-TARS es un modelo agente nativo orientado a la interacci\xf3n con interfaces gr\xe1ficas (GUI). Mediante capacidades humanas de percepci\xf3n, razonamiento y acci\xf3n, interact\xfaa de forma fluida con la GUI."},"doubao-1.5-vision-lite":{"description":"Doubao-1.5-vision-lite es un modelo multimodal de gran escala actualizado, que soporta el reconocimiento de im\xe1genes de cualquier resoluci\xf3n y proporciones extremas, mejorando la capacidad de razonamiento visual, reconocimiento de documentos, comprensi\xf3n de informaci\xf3n detallada y seguimiento de instrucciones. Soporta una ventana de contexto de 128k, con una longitud de salida que admite hasta 16k tokens."},"doubao-1.5-vision-pro":{"description":"Doubao-1.5-vision-pro es un modelo multimodal avanzado que soporta reconocimiento de im\xe1genes con cualquier resoluci\xf3n y proporciones extremas, mejorando el razonamiento visual, reconocimiento de documentos, comprensi\xf3n de detalles y seguimiento de instrucciones."},"doubao-1.5-vision-pro-32k":{"description":"Doubao-1.5-vision-pro es un modelo multimodal avanzado que soporta reconocimiento de im\xe1genes con cualquier resoluci\xf3n y proporciones extremas, mejorando el razonamiento visual, reconocimiento de documentos, comprensi\xf3n de detalles y seguimiento de instrucciones."},"doubao-lite-128k":{"description":"Ofrece una velocidad de respuesta excepcional y una mejor relaci\xf3n calidad-precio, proporcionando opciones m\xe1s flexibles para diferentes escenarios de los clientes. Soporta inferencia y ajuste fino con una ventana de contexto de 128k."},"doubao-lite-32k":{"description":"Ofrece una velocidad de respuesta excepcional y una mejor relaci\xf3n calidad-precio, proporcionando opciones m\xe1s flexibles para diferentes escenarios de los clientes. Soporta inferencia y ajuste fino con una ventana de contexto de 32k."},"doubao-lite-4k":{"description":"Ofrece una velocidad de respuesta excepcional y una mejor relaci\xf3n calidad-precio, proporcionando opciones m\xe1s flexibles para diferentes escenarios de los clientes. Soporta inferencia y ajuste fino con una ventana de contexto de 4k."},"doubao-pro-256k":{"description":"El modelo principal con mejor rendimiento, adecuado para tareas complejas, con excelentes resultados en preguntas de referencia, res\xfamenes, creaci\xf3n, clasificaci\xf3n de texto, juegos de rol y otros escenarios. Soporta inferencia y ajuste fino con una ventana de contexto de 256k."},"doubao-pro-32k":{"description":"El modelo principal con mejor rendimiento, adecuado para tareas complejas, con excelentes resultados en preguntas de referencia, res\xfamenes, creaci\xf3n, clasificaci\xf3n de texto, juegos de rol y otros escenarios. Soporta inferencia y ajuste fino con una ventana de contexto de 32k."},"doubao-seed-1.6":{"description":"Doubao-Seed-1.6 es un nuevo modelo multimodal de pensamiento profundo que soporta tres modos de pensamiento: autom\xe1tico, reflexivo y no reflexivo. En modo no reflexivo, el rendimiento del modelo mejora significativamente en comparaci\xf3n con Doubao-1.5-pro/250115. Soporta una ventana de contexto de 256k y una longitud m\xe1xima de salida de 16k tokens."},"doubao-seed-1.6-flash":{"description":"Doubao-Seed-1.6-flash es un modelo multimodal de pensamiento profundo con velocidad de inferencia extrema, TPOT de solo 10 ms; soporta comprensi\xf3n tanto textual como visual, con capacidad de comprensi\xf3n textual superior a la generaci\xf3n lite anterior y comprensi\xf3n visual comparable a los modelos pro de la competencia. Soporta una ventana de contexto de 256k y una longitud m\xe1xima de salida de 16k tokens."},"doubao-seed-1.6-lite":{"description":"Doubao-Seed-1.6-lite es un nuevo modelo multimodal de pensamiento profundo que permite ajustar el nivel de razonamiento (reasoning effort) en cuatro modos: M\xednimo, Bajo, Medio y Alto. Ofrece una excelente relaci\xf3n calidad-precio y es la mejor opci\xf3n para tareas comunes, con una ventana de contexto de hasta 256k."},"doubao-seed-1.6-thinking":{"description":"El modelo Doubao-Seed-1.6-thinking tiene una capacidad de pensamiento significativamente mejorada. En comparaci\xf3n con Doubao-1.5-thinking-pro, mejora a\xfan m\xe1s en habilidades b\xe1sicas como programaci\xf3n, matem\xe1ticas y razonamiento l\xf3gico, y soporta comprensi\xf3n visual. Soporta una ventana de contexto de 256k y una longitud m\xe1xima de salida de 16k tokens."},"doubao-seed-1.6-vision":{"description":"Doubao-Seed-1.6-vision es un modelo de pensamiento profundo visual que demuestra una capacidad multimodal general m\xe1s fuerte en escenarios como educaci\xf3n, revisi\xf3n de im\xe1genes, inspecci\xf3n y seguridad, y b\xfasqueda y respuesta con IA. Soporta una ventana de contexto de 256k y una longitud m\xe1xima de salida de 64k tokens."},"doubao-seededit-3-0-i2i-250628":{"description":"El modelo de generaci\xf3n de im\xe1genes Doubao fue desarrollado por el equipo Seed de ByteDance, soporta entrada de texto e imagen, ofreciendo una experiencia de generaci\xf3n de im\xe1genes altamente controlable y de alta calidad. Permite editar im\xe1genes mediante instrucciones de texto, generando im\xe1genes con lados entre 512 y 1536 p\xedxeles."},"doubao-seedream-3-0-t2i-250415":{"description":"El modelo de generaci\xf3n de im\xe1genes Seedream 3.0, desarrollado por el equipo Seed de ByteDance, soporta entrada de texto e imagen, ofreciendo una experiencia de generaci\xf3n de im\xe1genes altamente controlable y de alta calidad. Genera im\xe1genes basadas en indicaciones de texto."},"doubao-seedream-4-0-250828":{"description":"El modelo de generaci\xf3n de im\xe1genes Seedream 4.0, desarrollado por el equipo Seed de ByteDance, soporta entrada de texto e imagen, ofreciendo una experiencia de generaci\xf3n de im\xe1genes altamente controlable y de alta calidad. Genera im\xe1genes basadas en indicaciones de texto."},"doubao-vision-lite-32k":{"description":"El modelo Doubao-vision es un modelo multimodal desarrollado por Doubao, con potentes capacidades de comprensi\xf3n e inferencia de im\xe1genes, as\xed como una precisa comprensi\xf3n de instrucciones. El modelo muestra un rendimiento destacado en extracci\xf3n de informaci\xf3n texto-imagen y tareas de inferencia basadas en im\xe1genes, aplicable a tareas de preguntas visuales m\xe1s complejas y amplias."},"doubao-vision-pro-32k":{"description":"El modelo Doubao-vision es un modelo multimodal desarrollado por Doubao, con potentes capacidades de comprensi\xf3n e inferencia de im\xe1genes, as\xed como una precisa comprensi\xf3n de instrucciones. El modelo muestra un rendimiento destacado en extracci\xf3n de informaci\xf3n texto-imagen y tareas de inferencia basadas en im\xe1genes, aplicable a tareas de preguntas visuales m\xe1s complejas y amplias."},"emohaa":{"description":"Emohaa es un modelo psicol\xf3gico con capacidades de consulta profesional, ayudando a los usuarios a comprender problemas emocionales."},"ernie-4.5-0.3b":{"description":"ERNIE 4.5 0.3B, modelo ligero de c\xf3digo abierto, ideal para despliegues locales y personalizados."},"ernie-4.5-21b-a3b":{"description":"ERNIE 4.5 21B A3B, modelo de gran tama\xf1o de c\xf3digo abierto, con mejor rendimiento en tareas de comprensi\xf3n y generaci\xf3n."},"ernie-4.5-300b-a47b":{"description":"ERNIE 4.5 300B A47B es un modelo de expertos mixto a gran escala desarrollado por Wenxin de Baidu, con capacidades de razonamiento excepcionales."},"ernie-4.5-8k-preview":{"description":"ERNIE 4.5 8K Preview, modelo de vista previa con contexto de 8K, dise\xf1ado para probar y experimentar las capacidades de ERNIE 4.5."},"ernie-4.5-turbo-128k":{"description":"ERNIE 4.5 Turbo 128K, modelo general de alto rendimiento, compatible con b\xfasqueda mejorada y uso de herramientas, ideal para preguntas y respuestas, c\xf3digo, agentes inteligentes y m\xe1s."},"ernie-4.5-turbo-128k-preview":{"description":"ERNIE 4.5 Turbo 128K Preview, versi\xf3n de vista previa con capacidades equivalentes a la versi\xf3n oficial, ideal para pruebas y ajustes."},"ernie-4.5-turbo-32k":{"description":"ERNIE 4.5 Turbo 32K, versi\xf3n de contexto medio-largo, adecuada para preguntas y respuestas, recuperaci\xf3n de bases de conocimiento y di\xe1logos multivuelta."},"ernie-4.5-turbo-latest":{"description":"ERNIE 4.5 Turbo \xdaltima versi\xf3n, optimizada en rendimiento general, ideal como modelo principal en entornos de producci\xf3n."},"ernie-4.5-turbo-vl":{"description":"ERNIE 4.5 Turbo VL, modelo multimodal maduro, ideal para tareas de comprensi\xf3n e identificaci\xf3n de im\xe1genes y texto en producci\xf3n."},"ernie-4.5-turbo-vl-32k":{"description":"ERNIE 4.5 Turbo VL 32K, versi\xf3n multimodal de texto largo, adecuada para comprensi\xf3n conjunta de documentos extensos e im\xe1genes."},"ernie-4.5-turbo-vl-32k-preview":{"description":"ERNIE 4.5 Turbo VL 32K Preview, versi\xf3n de vista previa multimodal 32K, \xfatil para evaluar capacidades visuales de contexto largo."},"ernie-4.5-turbo-vl-latest":{"description":"ERNIE 4.5 Turbo VL \xdaltima versi\xf3n, versi\xf3n m\xe1s reciente multimodal, con mejor rendimiento en comprensi\xf3n e inferencia de im\xe1genes y texto."},"ernie-4.5-turbo-vl-preview":{"description":"ERNIE 4.5 Turbo VL Preview, modelo multimodal de vista previa, compatible con comprensi\xf3n y generaci\xf3n de im\xe1genes y texto, ideal para preguntas visuales y experiencias de comprensi\xf3n de contenido."},"ernie-4.5-vl-28b-a3b":{"description":"ERNIE 4.5 VL 28B A3B, modelo multimodal de c\xf3digo abierto, compatible con tareas de comprensi\xf3n e inferencia de im\xe1genes y texto."},"ernie-5.0-thinking-preview":{"description":"ERNIE 5.0 Thinking Preview, modelo insignia nativo totalmente multimodal, compatible con modelado unificado de texto, imagen, audio y video, con capacidades integrales mejoradas, ideal para preguntas complejas, creaci\xf3n y agentes inteligentes."},"ernie-char-8k":{"description":"ERNIE Character 8K, modelo de di\xe1logo con personalidad, ideal para construcci\xf3n de personajes IP y conversaciones de acompa\xf1amiento a largo plazo."},"ernie-char-fiction-8k":{"description":"ERNIE Character Fiction 8K, modelo de personalidad orientado a la creaci\xf3n de novelas y tramas, ideal para generaci\xf3n de historias largas."},"ernie-char-fiction-8k-preview":{"description":"ERNIE Character Fiction 8K Preview, versi\xf3n de vista previa del modelo de creaci\xf3n de personajes y tramas, para pruebas y experiencia funcional."},"ernie-irag-edit":{"description":"ERNIE iRAG Edit, modelo de edici\xf3n de im\xe1genes que admite borrado, repintado y generaci\xf3n de variantes."},"ernie-lite-8k":{"description":"ERNIE Lite 8K, modelo general ligero, ideal para preguntas y respuestas diarias y generaci\xf3n de contenido con sensibilidad al coste."},"ernie-lite-pro-128k":{"description":"ERNIE Lite Pro 128K, modelo ligero de alto rendimiento, ideal para escenarios sensibles a la latencia y al coste."},"ernie-novel-8k":{"description":"ERNIE Novel 8K, modelo para creaci\xf3n de novelas largas y tramas IP, experto en narrativas multirrol y multil\xednea."},"ernie-speed-128k":{"description":"ERNIE Speed 128K, modelo grande sin coste de entrada/salida, ideal para comprensi\xf3n de textos largos y pruebas a gran escala."},"ernie-speed-8k":{"description":"ERNIE Speed 8K, modelo gratuito y r\xe1pido, ideal para conversaciones diarias y tareas ligeras de texto."},"ernie-speed-pro-128k":{"description":"ERNIE Speed Pro 128K, modelo de alta concurrencia y excelente relaci\xf3n calidad-precio, ideal para servicios en l\xednea a gran escala y aplicaciones empresariales."},"ernie-tiny-8k":{"description":"ERNIE Tiny 8K, modelo ultraligero, ideal para preguntas simples, clasificaci\xf3n y escenarios de inferencia de bajo coste."},"ernie-x1-turbo-32k":{"description":"ERNIE X1 Turbo 32K, modelo de pensamiento r\xe1pido con contexto largo de 32K, ideal para razonamiento complejo y di\xe1logos multivuelta."},"ernie-x1.1-preview":{"description":"ERNIE X1.1 Preview, versi\xf3n de vista previa del modelo de pensamiento ERNIE X1.1, ideal para validaci\xf3n y pruebas de capacidades."},"fal-ai/bytedance/seedream/v4":{"description":"El modelo de generaci\xf3n de im\xe1genes Seedream 4.0, desarrollado por el equipo Seed de ByteDance, soporta entrada de texto e imagen, ofreciendo una experiencia de generaci\xf3n de im\xe1genes altamente controlable y de alta calidad. Genera im\xe1genes basadas en indicaciones de texto."},"fal-ai/flux-kontext/dev":{"description":"Modelo FLUX.1 enfocado en tareas de edici\xf3n de im\xe1genes, soporta entrada de texto e imagen."},"fal-ai/flux-pro/kontext":{"description":"FLUX.1 Kontext [pro] puede procesar texto e im\xe1genes de referencia como entrada, logrando ediciones locales dirigidas y transformaciones complejas de escenas completas sin interrupciones."},"fal-ai/flux/krea":{"description":"Flux Krea [dev] es un modelo generador de im\xe1genes con preferencia est\xe9tica, orientado a crear im\xe1genes m\xe1s realistas y naturales."},"fal-ai/flux/schnell":{"description":"FLUX.1 [schnell] es un modelo generador de im\xe1genes con 12 mil millones de par\xe1metros, enfocado en la generaci\xf3n r\xe1pida de im\xe1genes de alta calidad."},"fal-ai/hunyuan-image/v3":{"description":"Un potente modelo nativo de generaci\xf3n de im\xe1genes multimodales"},"fal-ai/imagen4/preview":{"description":"Modelo de generaci\xf3n de im\xe1genes de alta calidad proporcionado por Google."},"fal-ai/nano-banana":{"description":"Nano Banana es el modelo multimodal nativo m\xe1s reciente, r\xe1pido y eficiente de Google, que permite generar y editar im\xe1genes mediante conversaci\xf3n."},"fal-ai/qwen-image":{"description":"Potente modelo de im\xe1genes sin procesar del equipo Qwen, con impresionante capacidad para generar texto en chino y diversos estilos visuales de im\xe1genes."},"fal-ai/qwen-image-edit":{"description":"Modelo profesional de edici\xf3n de im\xe1genes lanzado por el equipo Qwen, que soporta edici\xf3n sem\xe1ntica y de apariencia, capaz de editar texto en chino e ingl\xe9s con precisi\xf3n, realizar transformaciones de estilo, rotaci\xf3n de objetos y otras ediciones de alta calidad."},"flux-1-schnell":{"description":"Modelo de generaci\xf3n de im\xe1genes a partir de texto con 12 mil millones de par\xe1metros desarrollado por Black Forest Labs, que utiliza tecnolog\xeda de destilaci\xf3n de difusi\xf3n adversarial latente, capaz de generar im\xe1genes de alta calidad en 1 a 4 pasos. Su rendimiento es comparable a alternativas propietarias y se publica bajo licencia Apache-2.0, apto para uso personal, investigaci\xf3n y comercial."},"flux-dev":{"description":"FLUX.1 [dev] es un modelo refinado y de pesos abiertos para aplicaciones no comerciales. Mantiene una calidad de imagen y capacidad de seguimiento de instrucciones similar a la versi\xf3n profesional de FLUX, pero con mayor eficiencia operativa. En comparaci\xf3n con modelos est\xe1ndar de tama\xf1o similar, es m\xe1s eficiente en el uso de recursos."},"flux-kontext-max":{"description":"Generaci\xf3n y edici\xf3n de im\xe1genes contextuales de vanguardia — combinando texto e im\xe1genes para obtener resultados precisos y coherentes."},"flux-kontext-pro":{"description":"Generaci\xf3n y edici\xf3n de im\xe1genes contextuales de vanguardia: combina texto e im\xe1genes para obtener resultados precisos y coherentes."},"flux-merged":{"description":"El modelo FLUX.1-merged combina las caracter\xedsticas profundas exploradas durante la fase de desarrollo de “DEV” con las ventajas de ejecuci\xf3n r\xe1pida representadas por “Schnell”. Esta combinaci\xf3n no solo ampl\xeda los l\xedmites de rendimiento del modelo, sino que tambi\xe9n ampl\xeda su rango de aplicaciones."},"flux-pro":{"description":"Modelo comercial de generaci\xf3n de im\xe1genes por IA de primer nivel — calidad de imagen incomparable y gran diversidad de resultados."},"flux-pro-1.1":{"description":"Modelo profesional mejorado de generaci\xf3n de im\xe1genes con IA — ofrece una calidad de imagen excepcional y una capacidad precisa para seguir las indicaciones."},"flux-pro-1.1-ultra":{"description":"Generaci\xf3n de im\xe1genes por IA de ultra alta resoluci\xf3n — compatible con salida de 4 megap\xedxeles; genera im\xe1genes en alta definici\xf3n en menos de 10 segundos."},"flux-schnell":{"description":"FLUX.1 [schnell], como el modelo de pocos pasos m\xe1s avanzado de c\xf3digo abierto actualmente, supera no solo a competidores similares sino tambi\xe9n a potentes modelos no refinados como Midjourney v6.0 y DALL\xb7E 3 (HD). Este modelo ha sido ajustado espec\xedficamente para conservar toda la diversidad de salida de la etapa de preentrenamiento. En comparaci\xf3n con los modelos m\xe1s avanzados del mercado, FLUX.1 [schnell] mejora significativamente la calidad visual, el cumplimiento de instrucciones, la variaci\xf3n de tama\xf1o/proporci\xf3n, el manejo de fuentes y la diversidad de salida, ofreciendo a los usuarios una experiencia de generaci\xf3n de im\xe1genes creativas m\xe1s rica y variada."},"flux.1-schnell":{"description":"FLUX.1-schnell, modelo de generaci\xf3n de im\xe1genes de alto rendimiento, ideal para crear r\xe1pidamente im\xe1genes de m\xfaltiples estilos."},"gemini-1.0-pro-001":{"description":"Gemini 1.0 Pro 001 (Ajuste) ofrece un rendimiento estable y ajustable, siendo una opci\xf3n ideal para soluciones de tareas complejas."},"gemini-1.0-pro-002":{"description":"Gemini 1.0 Pro 002 (Ajuste) proporciona un excelente soporte multimodal, centrado en la resoluci\xf3n efectiva de tareas complejas."},"gemini-1.0-pro-latest":{"description":"Gemini 1.0 Pro es el modelo de IA de alto rendimiento de Google, dise\xf1ado para la escalabilidad en una amplia gama de tareas."},"gemini-1.5-flash-001":{"description":"Gemini 1.5 Flash 001 es un modelo multimodal eficiente, que admite la escalabilidad para aplicaciones amplias."},"gemini-1.5-flash-002":{"description":"Gemini 1.5 Flash 002 es un modelo multimodal eficiente, que admite una amplia gama de aplicaciones."},"gemini-1.5-flash-8b":{"description":"Gemini 1.5 Flash 8B es un modelo multimodal eficiente que admite una amplia gama de aplicaciones."},"gemini-1.5-flash-8b-exp-0924":{"description":"Gemini 1.5 Flash 8B 0924 es el \xfaltimo modelo experimental, con mejoras significativas en el rendimiento tanto en casos de uso de texto como multimodal."},"gemini-1.5-flash-8b-latest":{"description":"Gemini 1.5 Flash 8B es un modelo multimodal eficiente que admite una amplia gama de aplicaciones escalables."},"gemini-1.5-flash-exp-0827":{"description":"Gemini 1.5 Flash 0827 ofrece capacidades de procesamiento multimodal optimizadas, adecuadas para diversas tareas complejas."},"gemini-1.5-flash-latest":{"description":"Gemini 1.5 Flash es el \xfaltimo modelo de IA multimodal de Google, con capacidades de procesamiento r\xe1pido, que admite entradas de texto, imagen y video, adecuado para la escalabilidad eficiente en diversas tareas."},"gemini-1.5-pro-001":{"description":"Gemini 1.5 Pro 001 es una soluci\xf3n de IA multimodal escalable, que admite una amplia gama de tareas complejas."},"gemini-1.5-pro-002":{"description":"Gemini 1.5 Pro 002 es el \xfaltimo modelo listo para producci\xf3n, que ofrece una calidad de salida superior, especialmente en tareas matem\xe1ticas, contextos largos y tareas visuales."},"gemini-1.5-pro-exp-0801":{"description":"Gemini 1.5 Pro 0801 ofrece excelentes capacidades de procesamiento multimodal, brindando mayor flexibilidad para el desarrollo de aplicaciones."},"gemini-1.5-pro-exp-0827":{"description":"Gemini 1.5 Pro 0827 combina las \xfaltimas tecnolog\xedas optimizadas para brindar capacidades de procesamiento de datos multimodales m\xe1s eficientes."},"gemini-1.5-pro-latest":{"description":"Gemini 1.5 Pro admite hasta 2 millones de tokens, siendo una opci\xf3n ideal para modelos multimodales de tama\xf1o medio, adecuados para un soporte multifac\xe9tico en tareas complejas."},"gemini-2.0-flash":{"description":"Gemini 2.0 Flash ofrece funciones y mejoras de pr\xf3xima generaci\xf3n, incluyendo velocidad excepcional, uso de herramientas nativas, generaci\xf3n multimodal y una ventana de contexto de 1M tokens."},"gemini-2.0-flash-001":{"description":"Gemini 2.0 Flash ofrece funciones y mejoras de pr\xf3xima generaci\xf3n, incluyendo velocidad excepcional, uso de herramientas nativas, generaci\xf3n multimodal y una ventana de contexto de 1M tokens."},"gemini-2.0-flash-exp":{"description":"Variante del modelo Gemini 2.0 Flash, optimizada para objetivos como la rentabilidad y la baja latencia."},"gemini-2.0-flash-exp-image-generation":{"description":"Modelo experimental Gemini 2.0 Flash, que admite la generaci\xf3n de im\xe1genes"},"gemini-2.0-flash-lite":{"description":"Variante del modelo Gemini 2.0 Flash, optimizada para objetivos como la rentabilidad y la baja latencia."},"gemini-2.0-flash-lite-001":{"description":"Variante del modelo Gemini 2.0 Flash, optimizada para objetivos como la rentabilidad y la baja latencia."},"gemini-2.5-flash":{"description":"Gemini 2.5 Flash es el modelo de mejor relaci\xf3n calidad-precio de Google, que ofrece funcionalidades completas."},"gemini-2.5-flash-image":{"description":"Nano Banana es el modelo multimodal nativo m\xe1s reciente, r\xe1pido y eficiente de Google, que permite generar y editar im\xe1genes mediante di\xe1logo."},"gemini-2.5-flash-image-preview":{"description":"Nano Banana es el modelo multimodal nativo m\xe1s reciente, r\xe1pido y eficiente de Google, que permite generar y editar im\xe1genes mediante di\xe1logo."},"gemini-2.5-flash-image-preview:image":{"description":"Nano Banana es el modelo multimodal nativo m\xe1s reciente, r\xe1pido y eficiente de Google, que permite generar y editar im\xe1genes mediante di\xe1logo."},"gemini-2.5-flash-image:image":{"description":"Nano Banana es el modelo multimodal nativo m\xe1s reciente, r\xe1pido y eficiente de Google, que permite generar y editar im\xe1genes mediante di\xe1logo."},"gemini-2.5-flash-lite":{"description":"Gemini 2.5 Flash-Lite es el modelo m\xe1s peque\xf1o y rentable de Google, dise\xf1ado para un uso a gran escala."},"gemini-2.5-flash-lite-preview-06-17":{"description":"Gemini 2.5 Flash-Lite Preview es el modelo m\xe1s peque\xf1o y con mejor relaci\xf3n calidad-precio de Google, dise\xf1ado para un uso a gran escala."},"gemini-2.5-flash-lite-preview-09-2025":{"description":"Versi\xf3n preliminar (25 de septiembre de 2025) de Gemini 2.5 Flash-Lite"},"gemini-2.5-flash-preview-04-17":{"description":"Gemini 2.5 Flash Preview es el modelo m\xe1s rentable de Google, que ofrece una funcionalidad completa."},"gemini-2.5-flash-preview-09-2025":{"description":"Versi\xf3n preliminar (25 de septiembre de 2025) de Gemini 2.5 Flash"},"gemini-2.5-pro":{"description":"Gemini 2.5 Pro es el modelo de pensamiento m\xe1s avanzado de Google, capaz de razonar sobre problemas complejos en c\xf3digo, matem\xe1ticas y \xe1reas STEM, as\xed como de analizar grandes conjuntos de datos, bases de c\xf3digo y documentos utilizando contextos largos."},"gemini-2.5-pro-preview-03-25":{"description":"Gemini 2.5 Pro Preview es el modelo de pensamiento m\xe1s avanzado de Google, capaz de razonar sobre problemas complejos en c\xf3digo, matem\xe1ticas y campos STEM, as\xed como de analizar grandes conjuntos de datos, bibliotecas de c\xf3digo y documentos utilizando un contexto largo."},"gemini-2.5-pro-preview-05-06":{"description":"Gemini 2.5 Pro Preview es el modelo de pensamiento m\xe1s avanzado de Google, capaz de razonar sobre problemas complejos en c\xf3digo, matem\xe1ticas y campos STEM, as\xed como de analizar grandes conjuntos de datos, bibliotecas de c\xf3digo y documentos utilizando un an\xe1lisis de contexto prolongado."},"gemini-2.5-pro-preview-06-05":{"description":"Gemini 2.5 Pro Preview es el modelo de pensamiento m\xe1s avanzado de Google, capaz de razonar sobre problemas complejos en c\xf3digo, matem\xe1ticas y \xe1reas STEM, as\xed como analizar grandes conjuntos de datos, bases de c\xf3digo y documentos utilizando contextos extensos."},"gemini-3-pro-preview":{"description":"Gemini 3 Pro es el modelo m\xe1s inteligente de Google, con razonamiento de \xfaltima generaci\xf3n, comprensi\xf3n multimodal y potentes capacidades de agente y codificaci\xf3n contextual."},"gemini-flash-latest":{"description":"\xdaltima versi\xf3n de Gemini Flash"},"gemini-flash-lite-latest":{"description":"\xdaltima versi\xf3n de Gemini Flash-Lite"},"gemini-pro-latest":{"description":"\xdaltima versi\xf3n de Gemini Pro"},"gemma-7b-it":{"description":"Gemma 7B es adecuado para el procesamiento de tareas de peque\xf1a y mediana escala, combinando rentabilidad."},"gemma2":{"description":"Gemma 2 es un modelo eficiente lanzado por Google, que abarca una variedad de escenarios de aplicaci\xf3n desde aplicaciones peque\xf1as hasta procesamiento de datos complejos."},"gemma2-9b-it":{"description":"Gemma 2 9B es un modelo optimizado para la integraci\xf3n de tareas y herramientas espec\xedficas."},"gemma2:27b":{"description":"Gemma 2 es un modelo eficiente lanzado por Google, que abarca una variedad de escenarios de aplicaci\xf3n desde aplicaciones peque\xf1as hasta procesamiento de datos complejos."},"gemma2:2b":{"description":"Gemma 2 es un modelo eficiente lanzado por Google, que abarca una variedad de escenarios de aplicaci\xf3n desde aplicaciones peque\xf1as hasta procesamiento de datos complejos."},"generalv3":{"description":"Spark Pro es un modelo de lenguaje grande de alto rendimiento optimizado para campos profesionales, enfocado en matem\xe1ticas, programaci\xf3n, medicina, educaci\xf3n y m\xe1s, y soporta b\xfasqueda en l\xednea y plugins integrados como clima y fecha. Su modelo optimizado muestra un rendimiento excepcional y eficiente en preguntas y respuestas complejas, comprensi\xf3n del lenguaje y creaci\xf3n de textos de alto nivel, siendo la opci\xf3n ideal para escenarios de aplicaci\xf3n profesional."},"generalv3.5":{"description":"Spark3.5 Max es la versi\xf3n m\xe1s completa, soportando b\xfasqueda en l\xednea y numerosos plugins integrados. Su capacidad central completamente optimizada, as\xed como la configuraci\xf3n de roles del sistema y la funci\xf3n de llamada a funciones, hacen que su rendimiento en diversos escenarios de aplicaci\xf3n complejos sea excepcional y sobresaliente."},"glm-4":{"description":"GLM-4 es la versi\xf3n anterior lanzada en enero de 2024, actualmente ha sido reemplazada por el m\xe1s potente GLM-4-0520."},"glm-4-0520":{"description":"GLM-4-0520 es la \xfaltima versi\xf3n del modelo, dise\xf1ada para tareas altamente complejas y diversas, con un rendimiento excepcional."},"glm-4-32b-0414":{"description":"GLM-4 32B 0414, versi\xf3n del modelo general de la serie GLM, compatible con generaci\xf3n y comprensi\xf3n de texto multitarea."},"glm-4-9b-chat":{"description":"GLM-4-9B-Chat ofrece un alto rendimiento en sem\xe1ntica, matem\xe1ticas, razonamiento, programaci\xf3n y conocimiento. Tambi\xe9n admite navegaci\xf3n web, ejecuci\xf3n de c\xf3digo, uso de herramientas personalizadas e inferencia de textos largos. Compatible con 26 idiomas, incluidos japon\xe9s, coreano y alem\xe1n."},"glm-4-air":{"description":"GLM-4-Air es una versi\xf3n de alto costo-beneficio, con un rendimiento cercano al GLM-4, ofreciendo velocidad y precios asequibles."},"glm-4-air-250414":{"description":"GLM-4-Air es una versi\xf3n de buena relaci\xf3n calidad-precio, con un rendimiento cercano al de GLM-4, ofreciendo velocidad r\xe1pida y un precio asequible."},"glm-4-airx":{"description":"GLM-4-AirX ofrece una versi\xf3n eficiente de GLM-4-Air, con velocidades de inferencia de hasta 2.6 veces."},"glm-4-alltools":{"description":"GLM-4-AllTools es un modelo de agente multifuncional, optimizado para soportar planificaci\xf3n de instrucciones complejas y llamadas a herramientas, como navegaci\xf3n web, interpretaci\xf3n de c\xf3digo y generaci\xf3n de texto, adecuado para la ejecuci\xf3n de m\xfaltiples tareas."},"glm-4-flash":{"description":"GLM-4-Flash es la opci\xf3n ideal para tareas simples, con la velocidad m\xe1s r\xe1pida y el precio m\xe1s bajo."},"glm-4-flash-250414":{"description":"GLM-4-Flash es la opci\xf3n ideal para tareas simples, siendo la m\xe1s r\xe1pida y gratuita."},"glm-4-flashx":{"description":"GLM-4-FlashX es una versi\xf3n mejorada de Flash, con una velocidad de inferencia ultrarr\xe1pida."},"glm-4-long":{"description":"GLM-4-Long admite entradas de texto extremadamente largas, adecuado para tareas de memoria y procesamiento de documentos a gran escala."},"glm-4-plus":{"description":"GLM-4-Plus, como buque insignia de alta inteligencia, tiene una poderosa capacidad para manejar textos largos y tareas complejas, con un rendimiento mejorado en general."},"glm-4.1v-thinking-flash":{"description":"La serie GLM-4.1V-Thinking es el modelo visual m\xe1s potente conocido en la categor\xeda de VLMs de 10 mil millones de par\xe1metros, integrando tareas de lenguaje visual de \xfaltima generaci\xf3n (SOTA) en su nivel, incluyendo comprensi\xf3n de video, preguntas sobre im\xe1genes, resoluci\xf3n de problemas acad\xe9micos, reconocimiento OCR, interpretaci\xf3n de documentos y gr\xe1ficos, agentes GUI, codificaci\xf3n web frontend, grounding, entre otros. En muchas tareas, supera incluso a modelos con 8 veces m\xe1s par\xe1metros como Qwen2.5-VL-72B. Gracias a t\xe9cnicas avanzadas de aprendizaje reforzado, el modelo domina el razonamiento mediante cadenas de pensamiento para mejorar la precisi\xf3n y riqueza de las respuestas, superando significativamente a los modelos tradicionales sin pensamiento en t\xe9rminos de resultados y explicabilidad."},"glm-4.1v-thinking-flashx":{"description":"La serie GLM-4.1V-Thinking es el modelo visual m\xe1s potente conocido en la categor\xeda de VLMs de 10 mil millones de par\xe1metros, integrando tareas de lenguaje visual de \xfaltima generaci\xf3n (SOTA) en su nivel, incluyendo comprensi\xf3n de video, preguntas sobre im\xe1genes, resoluci\xf3n de problemas acad\xe9micos, reconocimiento OCR, interpretaci\xf3n de documentos y gr\xe1ficos, agentes GUI, codificaci\xf3n web frontend, grounding, entre otros. En muchas tareas, supera incluso a modelos con 8 veces m\xe1s par\xe1metros como Qwen2.5-VL-72B. Gracias a t\xe9cnicas avanzadas de aprendizaje reforzado, el modelo domina el razonamiento mediante cadenas de pensamiento para mejorar la precisi\xf3n y riqueza de las respuestas, superando significativamente a los modelos tradicionales sin pensamiento en t\xe9rminos de resultados y explicabilidad."},"glm-4.5":{"description":"Modelo insignia de Zhipu, que soporta el cambio de modo de pensamiento, con una capacidad integral que alcanza el nivel SOTA de los modelos de c\xf3digo abierto, y una longitud de contexto de hasta 128K."},"glm-4.5-air":{"description":"Versi\xf3n ligera de GLM-4.5 que equilibra rendimiento y costo, con capacidad flexible para cambiar entre modelos de pensamiento h\xedbrido."},"glm-4.5-airx":{"description":"Versi\xf3n ultra r\xe1pida de GLM-4.5-Air, con respuesta m\xe1s r\xe1pida, dise\xf1ada para demandas de gran escala y alta velocidad."},"glm-4.5-flash":{"description":"Versi\xf3n gratuita de GLM-4.5, con un desempe\xf1o destacado en tareas de inferencia, codificaci\xf3n y agentes inteligentes."},"glm-4.5-x":{"description":"Versi\xf3n ultra r\xe1pida de GLM-4.5, que combina un rendimiento potente con una velocidad de generaci\xf3n de hasta 100 tokens por segundo."},"glm-4.5v":{"description":"La nueva generaci\xf3n del modelo de razonamiento visual de Zhipu, basada en la arquitectura MOE, cuenta con 106B de par\xe1metros totales y 12B de par\xe1metros de activaci\xf3n; alcanza el estado del arte (SOTA) entre los modelos multimodales de c\xf3digo abierto de la misma categor\xeda a nivel mundial en diversas pruebas de referencia, y cubre tareas comunes como comprensi\xf3n de im\xe1genes, v\xeddeo, documentos y tareas de interfaz gr\xe1fica de usuario (GUI)."},"glm-4.6":{"description":"El \xfaltimo modelo insignia de Zhipu, GLM-4.6 (355B), supera ampliamente a la generaci\xf3n anterior en codificaci\xf3n avanzada, procesamiento de textos largos, inferencia y capacidades de agentes inteligentes, especialmente en habilidades de programaci\xf3n alineadas con Claude Sonnet 4, convirti\xe9ndose en el modelo de codificaci\xf3n l\xedder en China."},"glm-4v":{"description":"GLM-4V proporciona una poderosa capacidad de comprensi\xf3n e inferencia de im\xe1genes, soportando diversas tareas visuales."},"glm-4v-flash":{"description":"GLM-4V-Flash se centra en la comprensi\xf3n eficiente de una \xfanica imagen, adecuada para escenarios de an\xe1lisis de im\xe1genes r\xe1pidos, como an\xe1lisis de im\xe1genes en tiempo real o procesamiento por lotes de im\xe1genes."},"glm-4v-plus":{"description":"GLM-4V-Plus tiene la capacidad de entender contenido de video y m\xfaltiples im\xe1genes, adecuado para tareas multimodales."},"glm-4v-plus-0111":{"description":"GLM-4V-Plus tiene la capacidad de comprender contenido de video y m\xfaltiples im\xe1genes, adecuado para tareas multimodales."},"glm-z1-air":{"description":"Modelo de inferencia: posee una poderosa capacidad de inferencia, adecuado para tareas que requieren razonamiento profundo."},"glm-z1-airx":{"description":"Inferencia ultrarr\xe1pida: con una velocidad de inferencia extremadamente r\xe1pida y un potente efecto de razonamiento."},"glm-z1-flash":{"description":"La serie GLM-Z1 posee una fuerte capacidad de razonamiento complejo, destacando en l\xf3gica, matem\xe1ticas y programaci\xf3n."},"glm-z1-flashx":{"description":"Alta velocidad y bajo costo: versi\xf3n mejorada Flash, con velocidad de inferencia ultrarr\xe1pida y mejor garant\xeda de concurrencia."},"glm-zero-preview":{"description":"GLM-Zero-Preview posee una poderosa capacidad de razonamiento complejo, destac\xe1ndose en \xe1reas como razonamiento l\xf3gico, matem\xe1ticas y programaci\xf3n."},"google/gemini-2.0-flash":{"description":"Gemini 2.0 Flash ofrece funcionalidades de pr\xf3xima generaci\xf3n y mejoras, incluyendo velocidad sobresaliente, uso integrado de herramientas, generaci\xf3n multimodal y una ventana de contexto de 1 mill\xf3n de tokens."},"google/gemini-2.0-flash-001":{"description":"Gemini 2.0 Flash ofrece funciones y mejoras de pr\xf3xima generaci\xf3n, incluyendo velocidad excepcional, uso de herramientas nativas, generaci\xf3n multimodal y una ventana de contexto de 1M tokens."},"google/gemini-2.0-flash-exp:free":{"description":"Gemini 2.0 Flash Experimental es el \xfaltimo modelo de IA multimodal experimental de Google, con una mejora de calidad en comparaci\xf3n con versiones anteriores, especialmente en conocimiento del mundo, c\xf3digo y contexto largo."},"google/gemini-2.0-flash-lite":{"description":"Gemini 2.0 Flash Lite ofrece funcionalidades de pr\xf3xima generaci\xf3n y mejoras, incluyendo velocidad sobresaliente, uso integrado de herramientas, generaci\xf3n multimodal y una ventana de contexto de 1 mill\xf3n de tokens."},"google/gemini-2.5-flash":{"description":"Gemini 2.5 Flash es un modelo de pensamiento que ofrece capacidades integrales sobresalientes. Est\xe1 dise\xf1ado para equilibrar precio y rendimiento, soportando multimodalidad y una ventana de contexto de 1 mill\xf3n de tokens."},"google/gemini-2.5-flash-image-preview":{"description":"Modelo experimental Gemini 2.5 Flash, compatible con generaci\xf3n de im\xe1genes."},"google/gemini-2.5-flash-lite":{"description":"Gemini 2.5 Flash-Lite es un modelo equilibrado y de baja latencia, con presupuesto de pensamiento configurable y conectividad de herramientas (por ejemplo, b\xfasqueda de Google y ejecuci\xf3n de c\xf3digo). Soporta entradas multimodales y ofrece una ventana de contexto de 1 mill\xf3n de tokens."},"google/gemini-2.5-flash-preview":{"description":"Gemini 2.5 Flash es el modelo principal m\xe1s avanzado de Google, dise\xf1ado para razonamiento avanzado, codificaci\xf3n, matem\xe1ticas y tareas cient\xedficas. Incluye la capacidad de \'pensar\' incorporada, lo que le permite proporcionar respuestas con mayor precisi\xf3n y un manejo m\xe1s detallado del contexto.\\n\\nNota: Este modelo tiene dos variantes: con pensamiento y sin pensamiento. La fijaci\xf3n de precios de salida var\xeda significativamente seg\xfan si la capacidad de pensamiento est\xe1 activada. Si elige la variante est\xe1ndar (sin el sufijo \':thinking\'), el modelo evitar\xe1 expl\xedcitamente generar tokens de pensamiento.\\n\\nPara aprovechar la capacidad de pensamiento y recibir tokens de pensamiento, debe elegir la variante \':thinking\', lo que resultar\xe1 en un precio de salida de pensamiento m\xe1s alto.\\n\\nAdem\xe1s, Gemini 2.5 Flash se puede configurar a trav\xe9s del par\xe1metro \'n\xfamero m\xe1ximo de tokens de razonamiento\', como se describe en la documentaci\xf3n (https://openrouter.ai/docs/use-cases/reasoning-tokens#max-tokens-for-reasoning)."},"google/gemini-2.5-flash-preview:thinking":{"description":"Gemini 2.5 Flash es el modelo principal m\xe1s avanzado de Google, dise\xf1ado para razonamiento avanzado, codificaci\xf3n, matem\xe1ticas y tareas cient\xedficas. Incluye la capacidad de \'pensar\' incorporada, lo que le permite proporcionar respuestas con mayor precisi\xf3n y un manejo m\xe1s detallado del contexto.\\n\\nNota: Este modelo tiene dos variantes: con pensamiento y sin pensamiento. La fijaci\xf3n de precios de salida var\xeda significativamente seg\xfan si la capacidad de pensamiento est\xe1 activada. Si elige la variante est\xe1ndar (sin el sufijo \':thinking\'), el modelo evitar\xe1 expl\xedcitamente generar tokens de pensamiento.\\n\\nPara aprovechar la capacidad de pensamiento y recibir tokens de pensamiento, debe elegir la variante \':thinking\', lo que resultar\xe1 en un precio de salida de pensamiento m\xe1s alto.\\n\\nAdem\xe1s, Gemini 2.5 Flash se puede configurar a trav\xe9s del par\xe1metro \'n\xfamero m\xe1ximo de tokens de razonamiento\', como se describe en la documentaci\xf3n (https://openrouter.ai/docs/use-cases/reasoning-tokens#max-tokens-for-reasoning)."},"google/gemini-2.5-pro":{"description":"Gemini 2.5 Pro es nuestro modelo Gemini de inferencia m\xe1s avanzado, capaz de resolver problemas complejos. Cuenta con una ventana de contexto de 2 millones de tokens y soporta entradas multimodales, incluyendo texto, im\xe1genes, audio, video y documentos PDF."},"google/gemini-2.5-pro-preview":{"description":"Gemini 2.5 Pro Preview es el modelo de pensamiento m\xe1s avanzado de Google, capaz de razonar sobre problemas complejos en c\xf3digo, matem\xe1ticas y \xe1reas STEM, as\xed como de analizar grandes conjuntos de datos, bases de c\xf3digo y documentos utilizando contextos extensos."},"google/gemini-embedding-001":{"description":"Modelo de incrustaciones de \xfaltima generaci\xf3n con rendimiento sobresaliente en tareas en ingl\xe9s, multiling\xfces y de c\xf3digo."},"google/gemini-flash-1.5":{"description":"Gemini 1.5 Flash ofrece capacidades de procesamiento multimodal optimizadas, adecuadas para una variedad de escenarios de tareas complejas."},"google/gemini-pro-1.5":{"description":"Gemini 1.5 Pro combina las \xfaltimas tecnolog\xedas de optimizaci\xf3n, proporcionando una capacidad de procesamiento de datos multimodal m\xe1s eficiente."},"google/gemma-2-27b":{"description":"Gemma 2 es un modelo eficiente lanzado por Google, que abarca una variedad de escenarios de aplicaci\xf3n desde aplicaciones peque\xf1as hasta procesamiento de datos complejos."},"google/gemma-2-27b-it":{"description":"Gemma 2 contin\xfaa con el concepto de dise\xf1o ligero y eficiente."},"google/gemma-2-2b-it":{"description":"Modelo de ajuste de instrucciones ligero de Google."},"google/gemma-2-9b":{"description":"Gemma 2 es un modelo eficiente lanzado por Google, que abarca una variedad de escenarios de aplicaci\xf3n desde aplicaciones peque\xf1as hasta procesamiento de datos complejos."},"google/gemma-2-9b-it":{"description":"Gemma 2 es una serie de modelos de texto de c\xf3digo abierto y ligeros de Google."},"google/gemma-2-9b-it:free":{"description":"Gemma 2 es una serie de modelos de texto de c\xf3digo abierto y livianos de Google."},"google/gemma-2b-it":{"description":"Gemma Instruct (2B) ofrece capacidades b\xe1sicas de procesamiento de instrucciones, adecuado para aplicaciones ligeras."},"google/gemma-3-12b-it":{"description":"Gemma 3 12B es un modelo de lenguaje de c\xf3digo abierto de Google que establece nuevos est\xe1ndares en eficiencia y rendimiento."},"google/gemma-3-27b-it":{"description":"Gemma 3 27B es un modelo de lenguaje de c\xf3digo abierto de Google, que establece nuevos est\xe1ndares en eficiencia y rendimiento."},"google/text-embedding-005":{"description":"Modelo de incrustaciones de texto enfocado en ingl\xe9s, optimizado para tareas de c\xf3digo y lenguaje ingl\xe9s."},"google/text-multilingual-embedding-002":{"description":"Modelo de incrustaciones de texto multiling\xfce optimizado para tareas transling\xfc\xedsticas, compatible con m\xfaltiples idiomas."},"gpt-3.5-turbo":{"description":"GPT 3.5 Turbo, adecuado para diversas tareas de generaci\xf3n y comprensi\xf3n de texto, actualmente apunta a gpt-3.5-turbo-0125."},"gpt-3.5-turbo-0125":{"description":"GPT 3.5 Turbo, adecuado para diversas tareas de generaci\xf3n y comprensi\xf3n de texto, actualmente apunta a gpt-3.5-turbo-0125."},"gpt-3.5-turbo-1106":{"description":"GPT 3.5 Turbo, adecuado para diversas tareas de generaci\xf3n y comprensi\xf3n de texto, actualmente apunta a gpt-3.5-turbo-0125."},"gpt-3.5-turbo-instruct":{"description":"GPT 3.5 Turbo, adecuado para diversas tareas de generaci\xf3n y comprensi\xf3n de texto, actualmente apunta a gpt-3.5-turbo-0125."},"gpt-35-turbo":{"description":"GPT 3.5 Turbo, un modelo eficiente proporcionado por OpenAI, es adecuado para tareas de conversaci\xf3n y generaci\xf3n de texto, con soporte para llamadas a funciones en paralelo."},"gpt-35-turbo-16k":{"description":"GPT 3.5 Turbo 16k, un modelo de generaci\xf3n de texto de alta capacidad, adecuado para tareas complejas."},"gpt-4":{"description":"GPT-4 ofrece una ventana de contexto m\xe1s grande, capaz de manejar entradas de texto m\xe1s largas, adecuado para escenarios que requieren integraci\xf3n de informaci\xf3n amplia y an\xe1lisis de datos."},"gpt-4-0125-preview":{"description":"El \xfaltimo modelo GPT-4 Turbo cuenta con funciones visuales. Ahora, las solicitudes visuales pueden utilizar el modo JSON y llamadas a funciones. GPT-4 Turbo es una versi\xf3n mejorada que ofrece soporte rentable para tareas multimodales. Encuentra un equilibrio entre precisi\xf3n y eficiencia, adecuado para aplicaciones que requieren interacci\xf3n en tiempo real."},"gpt-4-0613":{"description":"GPT-4 ofrece una ventana de contexto m\xe1s grande, capaz de manejar entradas de texto m\xe1s largas, adecuado para escenarios que requieren integraci\xf3n de informaci\xf3n amplia y an\xe1lisis de datos."},"gpt-4-1106-preview":{"description":"El \xfaltimo modelo GPT-4 Turbo cuenta con funciones visuales. Ahora, las solicitudes visuales pueden utilizar el modo JSON y llamadas a funciones. GPT-4 Turbo es una versi\xf3n mejorada que ofrece soporte rentable para tareas multimodales. Encuentra un equilibrio entre precisi\xf3n y eficiencia, adecuado para aplicaciones que requieren interacci\xf3n en tiempo real."},"gpt-4-32k":{"description":"GPT-4 ofrece una ventana de contexto m\xe1s grande, capaz de manejar entradas de texto m\xe1s largas, adecuado para escenarios que requieren integraci\xf3n de informaci\xf3n amplia y an\xe1lisis de datos."},"gpt-4-32k-0613":{"description":"GPT-4 ofrece una ventana de contexto m\xe1s grande, capaz de manejar entradas de texto m\xe1s largas, adecuado para escenarios que requieren integraci\xf3n de informaci\xf3n amplia y an\xe1lisis de datos."},"gpt-4-turbo":{"description":"El \xfaltimo modelo GPT-4 Turbo cuenta con funciones visuales. Ahora, las solicitudes visuales pueden utilizar el modo JSON y llamadas a funciones. GPT-4 Turbo es una versi\xf3n mejorada que ofrece soporte rentable para tareas multimodales. Encuentra un equilibrio entre precisi\xf3n y eficiencia, adecuado para aplicaciones que requieren interacci\xf3n en tiempo real."},"gpt-4-turbo-2024-04-09":{"description":"El \xfaltimo modelo GPT-4 Turbo cuenta con funciones visuales. Ahora, las solicitudes visuales pueden utilizar el modo JSON y llamadas a funciones. GPT-4 Turbo es una versi\xf3n mejorada que ofrece soporte rentable para tareas multimodales. Encuentra un equilibrio entre precisi\xf3n y eficiencia, adecuado para aplicaciones que requieren interacci\xf3n en tiempo real."},"gpt-4-turbo-preview":{"description":"El \xfaltimo modelo GPT-4 Turbo cuenta con funciones visuales. Ahora, las solicitudes visuales pueden utilizar el modo JSON y llamadas a funciones. GPT-4 Turbo es una versi\xf3n mejorada que ofrece soporte rentable para tareas multimodales. Encuentra un equilibrio entre precisi\xf3n y eficiencia, adecuado para aplicaciones que requieren interacci\xf3n en tiempo real."},"gpt-4-vision-preview":{"description":"El \xfaltimo modelo GPT-4 Turbo cuenta con funciones visuales. Ahora, las solicitudes visuales pueden utilizar el modo JSON y llamadas a funciones. GPT-4 Turbo es una versi\xf3n mejorada que ofrece soporte rentable para tareas multimodales. Encuentra un equilibrio entre precisi\xf3n y eficiencia, adecuado para aplicaciones que requieren interacci\xf3n en tiempo real."},"gpt-4.1":{"description":"GPT-4.1 es nuestro modelo insignia para tareas complejas. Es ideal para resolver problemas en m\xfaltiples dominios."},"gpt-4.1-mini":{"description":"GPT-4.1 mini ofrece un equilibrio entre inteligencia, velocidad y costo, lo que lo convierte en un modelo atractivo para muchos casos de uso."},"gpt-4.1-nano":{"description":"GPT-4.1 mini ofrece un equilibrio entre inteligencia, velocidad y costo, lo que lo convierte en un modelo atractivo para muchos casos de uso."},"gpt-4.5-preview":{"description":"GPT-4.5-preview es el modelo de prop\xf3sito general m\xe1s reciente, con un profundo conocimiento del mundo y una mejor comprensi\xf3n de las intenciones de los usuarios; destaca en tareas creativas y en la planificaci\xf3n de agentes. El conocimiento de este modelo est\xe1 actualizado hasta octubre de 2023."},"gpt-4o":{"description":"ChatGPT-4o es un modelo din\xe1mico que se actualiza en tiempo real para mantener la versi\xf3n m\xe1s actual. Combina una poderosa comprensi\xf3n y generaci\xf3n de lenguaje, adecuado para aplicaciones a gran escala, incluyendo servicio al cliente, educaci\xf3n y soporte t\xe9cnico."},"gpt-4o-2024-05-13":{"description":"ChatGPT-4o es un modelo din\xe1mico que se actualiza en tiempo real para mantener la versi\xf3n m\xe1s actual. Combina una poderosa comprensi\xf3n y generaci\xf3n de lenguaje, adecuado para aplicaciones a gran escala, incluyendo servicio al cliente, educaci\xf3n y soporte t\xe9cnico."},"gpt-4o-2024-08-06":{"description":"ChatGPT-4o es un modelo din\xe1mico que se actualiza en tiempo real para mantener la versi\xf3n m\xe1s actual. Combina una poderosa comprensi\xf3n y generaci\xf3n de lenguaje, adecuado para aplicaciones a gran escala, incluyendo servicio al cliente, educaci\xf3n y soporte t\xe9cnico."},"gpt-4o-2024-11-20":{"description":"ChatGPT-4o es un modelo din\xe1mico que se actualiza en tiempo real para mantener la versi\xf3n m\xe1s reciente. Combina una poderosa comprensi\xf3n del lenguaje con habilidades de generaci\xf3n, adecuada para escenarios de aplicaci\xf3n a gran escala, incluidos servicio al cliente, educaci\xf3n y soporte t\xe9cnico."},"gpt-4o-audio-preview":{"description":"Modelo GPT-4o Audio Preview, compatible con entrada y salida de audio."},"gpt-4o-mini":{"description":"GPT-4o mini es el \xfaltimo modelo lanzado por OpenAI despu\xe9s de GPT-4 Omni, que admite entradas de texto e imagen y genera texto como salida. Como su modelo m\xe1s avanzado de menor tama\xf1o, es mucho m\xe1s econ\xf3mico que otros modelos de vanguardia recientes y es m\xe1s de un 60% m\xe1s barato que GPT-3.5 Turbo. Mantiene una inteligencia de vanguardia mientras ofrece una relaci\xf3n calidad-precio significativa. GPT-4o mini obtuvo un puntaje del 82% en la prueba MMLU y actualmente se clasifica por encima de GPT-4 en preferencias de chat."},"gpt-4o-mini-audio-preview":{"description":"Modelo GPT-4o mini Audio, que soporta entrada y salida de audio."},"gpt-4o-mini-realtime-preview":{"description":"Versi\xf3n en tiempo real de GPT-4o-mini, que admite entrada y salida de audio y texto en tiempo real."},"gpt-4o-mini-search-preview":{"description":"GPT-4o mini versi\xf3n preliminar de b\xfasqueda es un modelo entrenado espec\xedficamente para comprender y ejecutar consultas de b\xfasqueda web, utilizando la API de Chat Completions. Adem\xe1s de los costos por tokens, las consultas de b\xfasqueda web incurren en cargos por cada llamada a la herramienta."},"gpt-4o-mini-transcribe":{"description":"GPT-4o Mini Transcribe es un modelo de conversi\xf3n de voz a texto que utiliza GPT-4o para transcribir audio. En comparaci\xf3n con el modelo Whisper original, mejora la tasa de error de palabras y aumenta la precisi\xf3n y el reconocimiento del idioma. \xdaselo para obtener transcripciones m\xe1s precisas."},"gpt-4o-mini-tts":{"description":"GPT-4o mini TTS es un modelo de texto a voz basado en GPT-4o mini, que ofrece generaci\xf3n de voz de alta calidad a un costo m\xe1s bajo."},"gpt-4o-realtime-preview":{"description":"Versi\xf3n en tiempo real de GPT-4o, que admite entrada y salida de audio y texto en tiempo real."},"gpt-4o-realtime-preview-2024-10-01":{"description":"Versi\xf3n en tiempo real de GPT-4o, que admite entrada y salida de audio y texto en tiempo real."},"gpt-4o-realtime-preview-2025-06-03":{"description":"Versi\xf3n en tiempo real de GPT-4o, que soporta entrada y salida de audio y texto en tiempo real."},"gpt-4o-search-preview":{"description":"GPT-4o versi\xf3n preliminar de b\xfasqueda es un modelo entrenado espec\xedficamente para comprender y ejecutar consultas de b\xfasqueda web, utilizando la API de Chat Completions. Adem\xe1s de los costos por tokens, las consultas de b\xfasqueda web incurren en cargos por cada llamada a la herramienta."},"gpt-4o-transcribe":{"description":"GPT-4o Transcribe es un modelo de conversi\xf3n de voz a texto que utiliza GPT-4o para transcribir audio. En comparaci\xf3n con el modelo Whisper original, mejora la tasa de error de palabras y aumenta la precisi\xf3n y el reconocimiento del idioma. \xdaselo para obtener transcripciones m\xe1s precisas."},"gpt-5":{"description":"El mejor modelo para tareas de codificaci\xf3n y agentes multidisciplinarios. GPT-5 logra avances en precisi\xf3n, velocidad, razonamiento, reconocimiento contextual, pensamiento estructurado y resoluci\xf3n de problemas."},"gpt-5-chat":{"description":"GPT-5 Chat es una versi\xf3n preliminar optimizada para escenarios conversacionales. Admite entrada de texto e imagen, y solo genera salida de texto. Ideal para chatbots y aplicaciones de IA conversacional."},"gpt-5-chat-latest":{"description":"Modelo GPT-5 utilizado en ChatGPT. Combina una potente comprensi\xf3n y generaci\xf3n del lenguaje, ideal para aplicaciones de interacci\xf3n conversacional."},"gpt-5-codex":{"description":"GPT-5 Codex es una versi\xf3n optimizada de GPT-5 para tareas de codificaci\xf3n de agentes en entornos Codex o similares."},"gpt-5-mini":{"description":"Versi\xf3n m\xe1s r\xe1pida y econ\xf3mica de GPT-5, adecuada para tareas bien definidas. Ofrece respuestas m\xe1s r\xe1pidas manteniendo una salida de alta calidad."},"gpt-5-nano":{"description":"Versi\xf3n m\xe1s r\xe1pida y econ\xf3mica de GPT-5. Perfecta para escenarios que requieren respuestas r\xe1pidas y son sensibles al costo."},"gpt-5-pro":{"description":"GPT-5 pro utiliza m\xe1s capacidad de c\xf3mputo para pensar de forma m\xe1s profunda y ofrecer respuestas de mayor calidad de manera constante."},"gpt-5.1":{"description":"GPT-5.1: modelo insignia optimizado para tareas de codificaci\xf3n y agentes, con soporte para intensidad de razonamiento configurable y contextos m\xe1s largos."},"gpt-5.1-chat-latest":{"description":"GPT-5.1 Chat: variante de GPT-5.1 para ChatGPT, ideal para escenarios conversacionales."},"gpt-5.1-codex":{"description":"GPT-5.1 Codex: versi\xf3n de GPT-5.1 optimizada para tareas de codificaci\xf3n agentica, disponible en la API de Respuestas para flujos de trabajo de c\xf3digo/agente m\xe1s complejos."},"gpt-5.1-codex-mini":{"description":"GPT-5.1 Codex mini: variante de Codex m\xe1s compacta y econ\xf3mica, optimizada para tareas de codificaci\xf3n agentica."},"gpt-audio":{"description":"GPT Audio es un modelo de chat general para entrada y salida de audio, compatible con el uso de audio I/O en la API de Chat Completions."},"gpt-image-1":{"description":"Modelo nativo multimodal de generaci\xf3n de im\xe1genes de ChatGPT."},"gpt-image-1-mini":{"description":"Una versi\xf3n m\xe1s econ\xf3mica de GPT Image 1, con soporte nativo para entrada de texto e imagen y generaci\xf3n de salida en formato de imagen."},"gpt-oss-120b":{"description":"Este modelo requiere solicitud para su uso. GPT-OSS-120B es un modelo de lenguaje de c\xf3digo abierto a gran escala desarrollado por OpenAI, con potentes capacidades de generaci\xf3n de texto."},"gpt-oss-20b":{"description":"Este modelo requiere solicitud para su uso. GPT-OSS-20B es un modelo de lenguaje de c\xf3digo abierto de tama\xf1o medio desarrollado por OpenAI, con capacidades eficientes de generaci\xf3n de texto."},"gpt-oss:120b":{"description":"GPT-OSS 120B es un modelo de lenguaje abierto de gran escala lanzado por OpenAI, que emplea la tecnolog\xeda de cuantificaci\xf3n MXFP4, siendo un modelo insignia. Requiere m\xfaltiples GPU o estaciones de trabajo de alto rendimiento para su ejecuci\xf3n, y ofrece un rendimiento sobresaliente en razonamiento complejo, generaci\xf3n de c\xf3digo y procesamiento multiling\xfce, soportando llamadas avanzadas a funciones e integraci\xf3n de herramientas."},"gpt-oss:20b":{"description":"GPT-OSS 20B es un modelo de lenguaje grande de c\xf3digo abierto lanzado por OpenAI, que utiliza la tecnolog\xeda de cuantificaci\xf3n MXFP4, adecuado para ejecutarse en GPUs de consumo de alta gama o Macs con Apple Silicon. Este modelo destaca en generaci\xf3n de di\xe1logos, escritura de c\xf3digo y tareas de razonamiento, soportando llamadas a funciones y uso de herramientas."},"gpt-realtime":{"description":"Modelo universal en tiempo real que soporta entrada y salida de texto y audio, adem\xe1s de entrada de im\xe1genes."},"grok-2-image-1212":{"description":"Nuestro \xfaltimo modelo de generaci\xf3n de im\xe1genes puede crear im\xe1genes v\xedvidas y realistas a partir de indicaciones textuales. Destaca en generaci\xf3n de im\xe1genes para marketing, redes sociales y entretenimiento."},"grok-2-vision-1212":{"description":"Este modelo ha mejorado en precisi\xf3n, cumplimiento de instrucciones y capacidades multiling\xfces."},"grok-3":{"description":"Modelo insignia, experto en extracci\xf3n de datos, programaci\xf3n y resumen de texto para aplicaciones empresariales, con profundo conocimiento en finanzas, medicina, derecho y ciencias."},"grok-3-mini":{"description":"Modelo ligero que piensa antes de responder. R\xe1pido e inteligente, adecuado para tareas l\xf3gicas que no requieren conocimientos profundos de dominio y capaz de proporcionar la trayectoria original del pensamiento."},"grok-4":{"description":"Nuestro modelo insignia m\xe1s reciente y potente, que destaca en procesamiento de lenguaje natural, c\xe1lculo matem\xe1tico y razonamiento — un competidor vers\xe1til y perfecto."},"grok-4-0709":{"description":"Grok 4 de xAI, con potentes capacidades de razonamiento."},"grok-4-1-fast-non-reasoning":{"description":"Modelo multimodal de vanguardia, optimizado espec\xedficamente para llamadas de herramientas de agente de alto rendimiento."},"grok-4-1-fast-reasoning":{"description":"Modelo multimodal de vanguardia, optimizado espec\xedficamente para llamadas de herramientas de agente de alto rendimiento."},"grok-4-fast-non-reasoning":{"description":"Nos complace anunciar Grok 4 Fast, nuestro \xfaltimo avance en modelos de inferencia con alta relaci\xf3n costo-beneficio."},"grok-4-fast-reasoning":{"description":"Nos complace anunciar Grok 4 Fast, nuestro \xfaltimo avance en modelos de inferencia con alta relaci\xf3n costo-beneficio."},"grok-code-fast-1":{"description":"Nos complace presentar grok-code-fast-1, un modelo de inferencia r\xe1pido y econ\xf3mico que destaca en la codificaci\xf3n de agentes."},"groq/compound":{"description":"Compound es un sistema de IA compuesto, respaldado por m\xfaltiples modelos disponibles p\xfablicamente ya soportados en GroqCloud, que puede usar herramientas de manera inteligente y selectiva para responder consultas de usuarios."},"groq/compound-mini":{"description":"Compound-mini es un sistema de IA compuesto, respaldado por modelos disponibles p\xfablicamente ya soportados en GroqCloud, que puede usar herramientas de manera inteligente y selectiva para responder consultas de usuarios."},"gryphe/mythomax-l2-13b":{"description":"MythoMax l2 13B es un modelo de lenguaje que combina creatividad e inteligencia, fusionando m\xfaltiples modelos de vanguardia."},"hunyuan-a13b":{"description":"El primer modelo de razonamiento h\xedbrido de Hunyuan, una versi\xf3n mejorada de hunyuan-standard-256K, con un total de 80 mil millones de par\xe1metros y 13 mil millones activados. Por defecto opera en modo de pensamiento lento, pero soporta cambio entre modos r\xe1pido y lento mediante par\xe1metros o instrucciones, a\xf1adiendo / no_think antes de la consulta para alternar. Su capacidad general mejora integralmente respecto a la generaci\xf3n anterior, con avances notables en matem\xe1ticas, ciencias, comprensi\xf3n de textos largos y habilidades de agente."},"hunyuan-code":{"description":"El \xfaltimo modelo de generaci\xf3n de c\xf3digo de Hunyuan, entrenado con 200B de datos de c\xf3digo de alta calidad, con medio a\xf1o de entrenamiento de datos SFT de alta calidad, aumentando la longitud de la ventana de contexto a 8K, destac\xe1ndose en m\xe9tricas autom\xe1ticas de generaci\xf3n de c\xf3digo en cinco lenguajes; en evaluaciones de calidad humana de tareas de c\xf3digo en diez aspectos en cinco lenguajes, su rendimiento se encuentra en la primera categor\xeda."},"hunyuan-functioncall":{"description":"El \xfaltimo modelo FunctionCall de Hunyuan con arquitectura MOE, entrenado con datos de FunctionCall de alta calidad, con una ventana de contexto de 32K, liderando en m\xfaltiples dimensiones de m\xe9tricas de evaluaci\xf3n."},"hunyuan-large":{"description":"El modelo Hunyuan-large tiene un total de aproximadamente 389B de par\xe1metros, con aproximadamente 52B de par\xe1metros activados, siendo el modelo MoE de c\xf3digo abierto con la mayor escala de par\xe1metros y el mejor rendimiento en la arquitectura Transformer en la industria actual."},"hunyuan-large-longcontext":{"description":"Especializado en tareas de texto largo como res\xfamenes de documentos y preguntas y respuestas de documentos, tambi\xe9n tiene la capacidad de manejar tareas generales de generaci\xf3n de texto. Destaca en el an\xe1lisis y generaci\xf3n de textos largos, pudiendo abordar eficazmente las necesidades de procesamiento de contenido largo y complejo."},"hunyuan-large-vision":{"description":"Este modelo es adecuado para escenarios de comprensi\xf3n de im\xe1genes y texto, basado en el modelo visual-ling\xfc\xedstico Hunyuan Large. Soporta entrada de m\xfaltiples im\xe1genes de cualquier resoluci\xf3n junto con texto, generando contenido textual, con un enfoque en tareas relacionadas con la comprensi\xf3n de im\xe1genes y texto, mostrando mejoras significativas en capacidades multiling\xfces."},"hunyuan-lite":{"description":"Actualizado a una estructura MOE, con una ventana de contexto de 256k, lidera en m\xfaltiples conjuntos de evaluaci\xf3n en NLP, c\xf3digo, matem\xe1ticas, industria y m\xe1s, superando a muchos modelos de c\xf3digo abierto."},"hunyuan-lite-vision":{"description":"El modelo multimodal m\xe1s reciente de 7B de Hunyuan, con una ventana de contexto de 32K, soporta di\xe1logos multimodales en chino e ingl\xe9s, reconocimiento de objetos en im\xe1genes, comprensi\xf3n de documentos y tablas, matem\xe1ticas multimodales, entre otros, superando a modelos competidores de 7B en m\xfaltiples dimensiones de evaluaci\xf3n."},"hunyuan-pro":{"description":"Modelo de texto largo MOE-32K con un tama\xf1o de par\xe1metros de billones. Alcanzando niveles de liderazgo absoluto en varios benchmarks, con capacidades complejas de instrucciones y razonamiento, habilidades matem\xe1ticas complejas, soporte para llamadas a funciones, optimizado para aplicaciones en traducci\xf3n multiling\xfce, finanzas, derecho y medicina."},"hunyuan-role":{"description":"El \xfaltimo modelo de rol de Hunyuan, un modelo de rol ajustado y entrenado oficialmente por Hunyuan, que se basa en el modelo Hunyuan y se entrena con un conjunto de datos de escenarios de rol, logrando un mejor rendimiento en escenarios de rol."},"hunyuan-standard":{"description":"Adopta una estrategia de enrutamiento mejorada, al tiempo que mitiga problemas de equilibrio de carga y convergencia de expertos. En el caso de textos largos, el \xedndice de precisi\xf3n alcanza el 99.9%. MOE-32K ofrece una mejor relaci\xf3n calidad-precio, equilibrando efectividad y costo, permitiendo el procesamiento de entradas de texto largo."},"hunyuan-standard-256K":{"description":"Adopta una estrategia de enrutamiento mejorada, al tiempo que mitiga problemas de equilibrio de carga y convergencia de expertos. En el caso de textos largos, el \xedndice de precisi\xf3n alcanza el 99.9%. MOE-256K rompe barreras en longitud y efectividad, ampliando enormemente la longitud de entrada permitida."},"hunyuan-standard-vision":{"description":"El modelo multimodal m\xe1s reciente de Hunyuan, que soporta respuestas en m\xfaltiples idiomas, con capacidades equilibradas en chino e ingl\xe9s."},"hunyuan-t1-20250321":{"description":"Construye de manera integral las capacidades de modelos en ciencias exactas y humanidades, con una fuerte capacidad para capturar informaci\xf3n de textos largos. Soporta la inferencia y respuesta a problemas cient\xedficos de diversas dificultades, incluyendo matem\xe1ticas, l\xf3gica, ciencias y c\xf3digo."},"hunyuan-t1-20250403":{"description":"Mejora la capacidad de generaci\xf3n de c\xf3digo a nivel de proyecto; mejora la calidad de la escritura generada en texto; mejora la comprensi\xf3n de temas en texto, el seguimiento de instrucciones tob en m\xfaltiples rondas y la comprensi\xf3n de palabras; optimiza problemas de salida con mezcla de caracteres tradicionales y simplificados, as\xed como mezcla de chino e ingl\xe9s."},"hunyuan-t1-20250529":{"description":"Optimiza la creaci\xf3n de textos, redacci\xf3n de ensayos, mejora habilidades en programaci\xf3n frontend, matem\xe1ticas y razonamiento l\xf3gico, y aumenta la capacidad de seguir instrucciones."},"hunyuan-t1-20250711":{"description":"Mejora significativa en habilidades avanzadas de matem\xe1ticas, l\xf3gica y codificaci\xf3n, optimizaci\xf3n de la estabilidad de salida del modelo y aumento de la capacidad para textos largos."},"hunyuan-t1-latest":{"description":"Mejora significativamente las capacidades del modelo principal de pensamiento lento en matem\xe1ticas avanzadas, razonamiento complejo, c\xf3digo dif\xedcil, cumplimiento de instrucciones y calidad en la creaci\xf3n de textos."},"hunyuan-t1-vision-20250619":{"description":"La \xfaltima versi\xf3n del modelo de pensamiento profundo multimodal t1-vision de Hunyuan, que soporta cadenas de pensamiento nativas multimodales, con mejoras integrales respecto a la versi\xf3n predeterminada anterior."},"hunyuan-t1-vision-20250916":{"description":"La \xfaltima versi\xf3n del modelo de pensamiento visual profundo Hunyuan t1-vision ofrece mejoras integrales respecto a su versi\xf3n anterior en tareas como preguntas y respuestas generales sobre im\xe1genes, localizaci\xf3n visual, OCR, interpretaci\xf3n de gr\xe1ficos, resoluci\xf3n de problemas a partir de fotos y creaci\xf3n visual. Tambi\xe9n se ha optimizado notablemente su rendimiento en ingl\xe9s y lenguas minoritarias."},"hunyuan-turbo":{"description":"Versi\xf3n preliminar de la nueva generaci\xf3n del modelo de lenguaje de Hunyuan, que utiliza una nueva estructura de modelo de expertos mixtos (MoE), con una eficiencia de inferencia m\xe1s r\xe1pida y un rendimiento m\xe1s fuerte en comparaci\xf3n con Hunyuan-Pro."},"hunyuan-turbo-20241223":{"description":"Optimizaci\xf3n de esta versi\xf3n: escalado de instrucciones de datos, mejora significativa de la capacidad de generalizaci\xf3n del modelo; mejora significativa de las capacidades de matem\xe1ticas, c\xf3digo y razonamiento l\xf3gico; optimizaci\xf3n de la comprensi\xf3n de texto y de palabras relacionadas; optimizaci\xf3n de la calidad de generaci\xf3n de contenido en la creaci\xf3n de texto."},"hunyuan-turbo-latest":{"description":"Optimizaci\xf3n de la experiencia general, incluyendo comprensi\xf3n de NLP, creaci\xf3n de texto, conversaci\xf3n casual, preguntas y respuestas de conocimiento, traducci\xf3n, entre otros; mejora de la humanizaci\xf3n, optimizaci\xf3n de la inteligencia emocional del modelo; mejora de la capacidad del modelo para aclarar proactivamente en caso de ambig\xfcedad en la intenci\xf3n; mejora de la capacidad de manejo de problemas de an\xe1lisis de palabras; mejora de la calidad y la interactividad de la creaci\xf3n; mejora de la experiencia en m\xfaltiples turnos."},"hunyuan-turbo-vision":{"description":"El nuevo modelo insignia de lenguaje visual de Hunyuan de nueva generaci\xf3n, que utiliza una nueva estructura de modelo de expertos mixtos (MoE), mejorando de manera integral las capacidades de reconocimiento b\xe1sico, creaci\xf3n de contenido, preguntas y respuestas de conocimiento, y an\xe1lisis y razonamiento en comparaci\xf3n con la generaci\xf3n anterior de modelos."},"hunyuan-turbos-20250313":{"description":"Unificaci\xf3n del estilo de pasos para resolver problemas matem\xe1ticos, fortaleciendo las preguntas y respuestas multil\xednea en matem\xe1ticas. Optimizaci\xf3n del estilo de respuesta en creaci\xf3n de texto, eliminando el tono artificial de IA y aumentando la elegancia literaria."},"hunyuan-turbos-20250416":{"description":"Actualizaci\xf3n de la base de preentrenamiento para fortalecer la comprensi\xf3n y el seguimiento de instrucciones; mejora en matem\xe1ticas, programaci\xf3n, l\xf3gica y ciencias durante la fase de alineaci\xf3n; mejora en calidad de escritura creativa, comprensi\xf3n de texto, precisi\xf3n en traducci\xf3n y preguntas de conocimiento en humanidades; refuerzo de capacidades de agentes en diversos campos, con especial \xe9nfasis en la comprensi\xf3n de di\xe1logos multil\xednea."},"hunyuan-turbos-20250604":{"description":"Actualizaci\xf3n de la base de preentrenamiento, mejora en la escritura y comprensi\xf3n lectora, aumento significativo en habilidades de programaci\xf3n y ciencias, y progreso continuo en el seguimiento de instrucciones complejas."},"hunyuan-turbos-20250926":{"description":"Mejora en la calidad de los datos base de preentrenamiento. Optimizaci\xf3n de la estrategia de entrenamiento en la fase postentrenamiento, con mejoras continuas en capacidades de agente, idiomas menores en ingl\xe9s, cumplimiento de instrucciones, c\xf3digo y ciencias."},"hunyuan-turbos-latest":{"description":"hunyuan-TurboS es la \xfaltima versi\xf3n del modelo insignia Hunyuan, con una mayor capacidad de pensamiento y una mejor experiencia."},"hunyuan-turbos-longtext-128k-20250325":{"description":"Especializado en tareas de texto largo como res\xfamenes de documentos y preguntas sobre documentos, tambi\xe9n tiene la capacidad de manejar tareas generales de generaci\xf3n de texto. Destaca en el an\xe1lisis y generaci\xf3n de textos largos, capaz de abordar eficazmente las necesidades complejas y detalladas de procesamiento de contenido extenso."},"hunyuan-turbos-role-plus":{"description":"Modelo de rol m\xe1s reciente de Hunyuan, afinado oficialmente por Hunyuan, entrenado adicionalmente con conjuntos de datos de escenarios de juego de roles, ofreciendo mejores resultados b\xe1sicos en dichos escenarios."},"hunyuan-turbos-vision":{"description":"Este modelo est\xe1 dise\xf1ado para escenarios de comprensi\xf3n de im\xe1genes y texto, basado en la \xfaltima generaci\xf3n de modelos insignia visual-ling\xfc\xedsticos turbos de Hunyuan. Se enfoca en tareas relacionadas con la comprensi\xf3n de im\xe1genes, incluyendo reconocimiento de entidades basado en im\xe1genes, preguntas de conocimiento, creaci\xf3n de textos y resoluci\xf3n de problemas mediante fotos, con mejoras integrales respecto a la generaci\xf3n anterior."},"hunyuan-turbos-vision-20250619":{"description":"La \xfaltima versi\xf3n del modelo insignia visual-ling\xfc\xedstico turbos-vision de Hunyuan, que mejora integralmente la comprensi\xf3n de im\xe1genes y texto, incluyendo reconocimiento de entidades basado en im\xe1genes, preguntas de conocimiento, creaci\xf3n de textos y resoluci\xf3n de problemas mediante fotos, respecto a la versi\xf3n predeterminada anterior."},"hunyuan-vision":{"description":"El \xfaltimo modelo multimodal de Hunyuan, que admite la entrada de im\xe1genes y texto para generar contenido textual."},"image-01":{"description":"Nuevo modelo de generaci\xf3n de im\xe1genes con detalles finos, soporta generaci\xf3n de im\xe1genes a partir de texto e imagen."},"image-01-live":{"description":"Modelo de generaci\xf3n de im\xe1genes con detalles finos, soporta generaci\xf3n a partir de texto y configuraci\xf3n de estilo art\xedstico."},"imagen-4.0-fast-generate-001":{"description":"Versi\xf3n Fast de la serie de modelos Imagen de texto a imagen de cuarta generaci\xf3n"},"imagen-4.0-generate-001":{"description":"Serie Imagen de cuarta generaci\xf3n para generar im\xe1genes a partir de texto."},"imagen-4.0-generate-preview-06-06":{"description":"Serie de modelos de generaci\xf3n de im\xe1genes de texto a imagen de cuarta generaci\xf3n de Imagen."},"imagen-4.0-ultra-generate-001":{"description":"Imagen, serie de modelos de texto a imagen de cuarta generaci\xf3n, versi\xf3n Ultra"},"imagen-4.0-ultra-generate-preview-06-06":{"description":"Versi\xf3n Ultra de la serie de modelos de generaci\xf3n de im\xe1genes de texto a imagen de cuarta generaci\xf3n de Imagen."},"inception/mercury-coder-small":{"description":"Mercury Coder Small es la opci\xf3n ideal para tareas de generaci\xf3n, depuraci\xf3n y refactorizaci\xf3n de c\xf3digo, con latencia m\xednima."},"inclusionAI/Ling-1T":{"description":"Ling-1T es el primer modelo insignia sin razonamiento de la serie \\"Ling 2.0\\", con un total de un bill\xf3n de par\xe1metros y aproximadamente 50 mil millones de par\xe1metros activos por token. Construido sobre la arquitectura Ling 2.0, Ling-1T est\xe1 dise\xf1ado para superar los l\xedmites del razonamiento eficiente y la cognici\xf3n escalable. Ling-1T-base ha sido entrenado con m\xe1s de 20 billones de tokens de alta calidad y con alta densidad de razonamiento."},"inclusionAI/Ling-flash-2.0":{"description":"Ling-flash-2.0 es el tercer modelo de la serie Ling 2.0 basado en la arquitectura MoE, lanzado por el equipo Bailing de Ant Group. Cuenta con 100 mil millones de par\xe1metros totales, pero solo activa 6.1 mil millones por token (4.8 mil millones sin incluir embeddings). Como un modelo de configuraci\xf3n ligera, Ling-flash-2.0 demuestra en m\xfaltiples evaluaciones oficiales un rendimiento comparable o superior a modelos densos de 40 mil millones y a modelos MoE de mayor escala. Este modelo busca explorar caminos eficientes bajo el consenso de que un modelo grande equivale a muchos par\xe1metros, mediante un dise\xf1o arquitect\xf3nico y estrategias de entrenamiento extremas."},"inclusionAI/Ling-mini-2.0":{"description":"Ling-mini-2.0 es un modelo de lenguaje grande de alto rendimiento y tama\xf1o reducido basado en arquitectura MoE. Cuenta con 16 mil millones de par\xe1metros totales, pero solo activa 1.4 mil millones por token (789 millones sin incluir embeddings), logrando una velocidad de generaci\xf3n muy alta. Gracias a un dise\xf1o MoE eficiente y a un entrenamiento masivo con datos de alta calidad, Ling-mini-2.0 ofrece un rendimiento de primer nivel en tareas downstream, comparable a modelos densos de menos de 10 mil millones y a modelos MoE de mayor escala."},"inclusionAI/Ring-1T":{"description":"Ring-1T es un modelo de pensamiento de c\xf3digo abierto a escala de un bill\xf3n de par\xe1metros, lanzado por el equipo Bailing. Basado en la arquitectura Ling 2.0 y el modelo base Ling-1T, cuenta con un total de un bill\xf3n de par\xe1metros y 50 mil millones de par\xe1metros activos, y admite una ventana de contexto de hasta 128K. El modelo ha sido optimizado mediante aprendizaje por refuerzo con recompensas verificables a gran escala."},"inclusionAI/Ring-flash-2.0":{"description":"Ring-flash-2.0 es un modelo de pensamiento de alto rendimiento profundamente optimizado basado en Ling-flash-2.0-base. Utiliza arquitectura MoE con 100 mil millones de par\xe1metros totales, pero solo activa 6.1 mil millones en cada inferencia. Gracias al algoritmo innovador icepop, resuelve la inestabilidad de los grandes modelos MoE en entrenamiento por refuerzo (RL), mejorando continuamente su capacidad de razonamiento complejo en entrenamientos prolongados. Ring-flash-2.0 ha logrado avances significativos en competencias matem\xe1ticas, generaci\xf3n de c\xf3digo y razonamiento l\xf3gico, superando modelos densos de hasta 40 mil millones de par\xe1metros y equipar\xe1ndose a modelos MoE de mayor escala y modelos de pensamiento de alto rendimiento cerrados. Aunque est\xe1 enfocado en razonamiento complejo, tambi\xe9n destaca en tareas creativas de escritura. Adem\xe1s, su dise\xf1o eficiente permite un rendimiento r\xe1pido y reduce significativamente los costos de despliegue en escenarios de alta concurrencia."},"internlm/internlm2_5-7b-chat":{"description":"InternLM2.5 ofrece soluciones de di\xe1logo inteligente en m\xfaltiples escenarios."},"internlm2.5-latest":{"description":"Nuestra \xfaltima serie de modelos, con un rendimiento de inferencia excepcional, que admite una longitud de contexto de 1M y una mayor capacidad de seguimiento de instrucciones y llamadas a herramientas."},"internlm3-latest":{"description":"Nuestra \xfaltima serie de modelos, con un rendimiento de inferencia excepcional, lidera el mercado de modelos de c\xf3digo abierto de tama\xf1o similar. Apunta por defecto a nuestra serie de modelos InternLM3 m\xe1s reciente."},"internvl2.5-38b-mpo":{"description":"InternVL2.5 38B MPO, modelo multimodal preentrenado, compatible con tareas complejas de inferencia de im\xe1genes y texto."},"internvl2.5-latest":{"description":"La versi\xf3n InternVL2.5 que seguimos manteniendo, que ofrece un rendimiento excelente y estable. Por defecto, apunta a nuestra serie de modelos InternVL2.5 m\xe1s reciente, actualmente apuntando a internvl2.5-78b."},"internvl3-14b":{"description":"InternVL3 14B, modelo multimodal de tama\xf1o medio, equilibrando rendimiento y coste."},"internvl3-1b":{"description":"InternVL3 1B, modelo multimodal ligero, ideal para despliegue en entornos con recursos limitados."},"internvl3-38b":{"description":"InternVL3 38B, modelo multimodal de c\xf3digo abierto a gran escala, ideal para tareas de comprensi\xf3n de im\xe1genes y texto de alta precisi\xf3n."},"internvl3-latest":{"description":"Nuestro modelo multimodal m\xe1s reciente, que posee una mayor capacidad de comprensi\xf3n de texto e imagen, as\xed como una comprensi\xf3n de im\xe1genes a largo plazo, con un rendimiento comparable a los mejores modelos cerrados. Por defecto, apunta a nuestra serie de modelos InternVL m\xe1s reciente, actualmente apuntando a internvl3-78b."},"irag-1.0":{"description":"ERNIE iRAG, modelo de generaci\xf3n mejorada por recuperaci\xf3n de im\xe1genes, compatible con b\xfasqueda por imagen, recuperaci\xf3n de im\xe1genes y texto, y generaci\xf3n de contenido."},"jamba-large":{"description":"Nuestro modelo m\xe1s potente y avanzado, dise\xf1ado para manejar tareas complejas a nivel empresarial, con un rendimiento excepcional."},"jamba-mini":{"description":"El modelo m\xe1s eficiente de su categor\xeda, que combina velocidad y calidad, con un tama\xf1o m\xe1s peque\xf1o."},"jina-deepsearch-v1":{"description":"La b\xfasqueda profunda combina la b\xfasqueda en la web, la lectura y el razonamiento para realizar investigaciones exhaustivas. Puedes considerarlo como un agente que acepta tus tareas de investigaci\xf3n: realiza una b\xfasqueda amplia y pasa por m\xfaltiples iteraciones antes de proporcionar una respuesta. Este proceso implica una investigaci\xf3n continua, razonamiento y resoluci\xf3n de problemas desde diferentes \xe1ngulos. Esto es fundamentalmente diferente de los grandes modelos est\xe1ndar que generan respuestas directamente a partir de datos preentrenados y de los sistemas RAG tradicionales que dependen de b\xfasquedas superficiales \xfanicas."},"kimi-k2":{"description":"Kimi-K2 es un modelo base con arquitectura MoE lanzado por Moonshot AI, con capacidades avanzadas de codificaci\xf3n y agentes, totalizando 1 bill\xf3n de par\xe1metros y 32 mil millones de par\xe1metros activados. En pruebas de referencia en categor\xedas principales como razonamiento general, programaci\xf3n, matem\xe1ticas y agentes, el rendimiento del modelo K2 supera a otros modelos de c\xf3digo abierto populares."},"kimi-k2-0711-preview":{"description":"kimi-k2 es un modelo base con arquitectura MoE que posee capacidades excepcionales en c\xf3digo y agentes, con un total de 1T par\xe1metros y 32B par\xe1metros activados. En pruebas de rendimiento en categor\xedas principales como razonamiento general, programaci\xf3n, matem\xe1ticas y agentes, el modelo K2 supera a otros modelos de c\xf3digo abierto populares."},"kimi-k2-0905-preview":{"description":"El modelo kimi-k2-0905-preview tiene una longitud de contexto de 256k, con una mayor capacidad de codificaci\xf3n agentiva, una est\xe9tica y funcionalidad mejoradas en el c\xf3digo frontend, y una mejor comprensi\xf3n del contexto."},"kimi-k2-instruct":{"description":"Kimi K2 Instruct, modelo de inferencia oficial de Kimi, compatible con contexto largo, c\xf3digo, preguntas y respuestas, entre otros escenarios."},"kimi-k2-turbo-preview":{"description":"kimi-k2 es un modelo base con arquitectura MoE que ofrece potentes capacidades para c\xf3digo y agentes, con 1T par\xe1metros totales y 32B par\xe1metros activados. En las pruebas de referencia en categor\xedas principales como razonamiento de conocimiento general, programaci\xf3n, matem\xe1ticas y agentes, el rendimiento del modelo K2 supera al de otros modelos de c\xf3digo abierto m\xe1s extendidos."},"kimi-k2:1t":{"description":"Kimi K2 es un modelo de lenguaje de expertos mixtos a gran escala (MoE) desarrollado por la IA del lado oscuro de la luna, con un total de un bill\xf3n de par\xe1metros y 32 mil millones de par\xe1metros activados por cada pasada hacia adelante. Est\xe1 optimizado para capacidades de agente, incluyendo el uso avanzado de herramientas, razonamiento y s\xedntesis de c\xf3digo."},"kimi-latest":{"description":"El producto asistente inteligente Kimi utiliza el \xfaltimo modelo grande de Kimi, que puede incluir caracter\xedsticas que a\xfan no est\xe1n estables. Soporta la comprensi\xf3n de im\xe1genes y seleccionar\xe1 autom\xe1ticamente el modelo de facturaci\xf3n de 8k/32k/128k seg\xfan la longitud del contexto de la solicitud."},"kimi-thinking-preview":{"description":"El modelo kimi-thinking-preview, proporcionado por la cara oculta de la luna, es un modelo multimodal de pensamiento con capacidades de razonamiento multimodal y general, especializado en razonamiento profundo para ayudar a resolver problemas m\xe1s complejos."},"learnlm-1.5-pro-experimental":{"description":"LearnLM es un modelo de lenguaje experimental y espec\xedfico para tareas, entrenado para cumplir con los principios de la ciencia del aprendizaje, capaz de seguir instrucciones sistem\xe1ticas en escenarios de ense\xf1anza y aprendizaje, actuando como un tutor experto, entre otros."},"learnlm-2.0-flash-experimental":{"description":"LearnLM es un modelo de lenguaje experimental y espec\xedfico para tareas, entrenado para cumplir con los principios de la ciencia del aprendizaje, capaz de seguir instrucciones sistem\xe1ticas en escenarios de ense\xf1anza y aprendizaje, actuando como un tutor experto, entre otros."},"lite":{"description":"Spark Lite es un modelo de lenguaje grande y ligero, con una latencia extremadamente baja y una capacidad de procesamiento eficiente, completamente gratuito y de c\xf3digo abierto, que admite funciones de b\xfasqueda en l\xednea en tiempo real. Su caracter\xedstica de respuesta r\xe1pida lo hace destacar en aplicaciones de inferencia y ajuste de modelos en dispositivos de baja potencia, brindando a los usuarios una excelente relaci\xf3n costo-beneficio y experiencia inteligente, especialmente en escenarios de preguntas y respuestas, generaci\xf3n de contenido y b\xfasqueda."},"llama-3.1-70b-versatile":{"description":"Llama 3.1 70B ofrece una capacidad de razonamiento AI m\xe1s potente, adecuada para aplicaciones complejas, soportando un procesamiento computacional extenso y garantizando eficiencia y precisi\xf3n."},"llama-3.1-8b-instant":{"description":"Llama 3.1 8B es un modelo de alto rendimiento que ofrece una r\xe1pida capacidad de generaci\xf3n de texto, ideal para aplicaciones que requieren eficiencia a gran escala y rentabilidad."},"llama-3.1-instruct":{"description":"El modelo Llama 3.1 ajustado para instrucciones est\xe1 optimizado para escenarios de conversaci\xf3n, superando a muchos modelos de chat de c\xf3digo abierto existentes en pruebas de referencia comunes de la industria."},"llama-3.2-11b-vision-instruct":{"description":"Capacidad excepcional de razonamiento visual en im\xe1genes de alta resoluci\xf3n, adecuada para aplicaciones de comprensi\xf3n visual."},"llama-3.2-11b-vision-preview":{"description":"Llama 3.2 est\xe1 dise\xf1ado para manejar tareas que combinan datos visuales y textuales. Destaca en tareas como la descripci\xf3n de im\xe1genes y preguntas visuales, cruzando la brecha entre la generaci\xf3n de lenguaje y el razonamiento visual."},"llama-3.2-90b-vision-instruct":{"description":"Capacidad avanzada de razonamiento de im\xe1genes para aplicaciones de agentes de comprensi\xf3n visual."},"llama-3.2-90b-vision-preview":{"description":"Llama 3.2 est\xe1 dise\xf1ado para manejar tareas que combinan datos visuales y textuales. Destaca en tareas como la descripci\xf3n de im\xe1genes y preguntas visuales, cruzando la brecha entre la generaci\xf3n de lenguaje y el razonamiento visual."},"llama-3.2-vision-instruct":{"description":"El modelo Llama 3.2-Vision con ajuste fino de instrucciones est\xe1 optimizado para reconocimiento visual, razonamiento sobre im\xe1genes, descripci\xf3n de im\xe1genes y respuesta a preguntas generales relacionadas con im\xe1genes."},"llama-3.3-70b":{"description":"Llama 3.3 70B: un modelo Llama de tama\xf1o medio-grande que equilibra capacidad de razonamiento y rendimiento."},"llama-3.3-70b-versatile":{"description":"El modelo de lenguaje multiling\xfce Meta Llama 3.3 (LLM) es un modelo generativo preentrenado y ajustado para instrucciones de 70B (entrada/salida de texto). El modelo de texto puro ajustado para instrucciones de Llama 3.3 est\xe1 optimizado para casos de uso de conversaci\xf3n multiling\xfce y supera a muchos modelos de chat de c\xf3digo abierto y cerrado en benchmarks industriales comunes."},"llama-3.3-instruct":{"description":"El modelo de instrucci\xf3n Llama 3.3, optimizado para escenarios de di\xe1logo, supera a muchos modelos de chat de c\xf3digo abierto existentes en pruebas de referencia comunes de la industria."},"llama-4-scout-17b-16e-instruct":{"description":"Llama 4 Scout: un modelo de alto rendimiento de la serie Llama, dise\xf1ado para escenarios que requieren alto rendimiento y baja latencia."},"llama3-70b-8192":{"description":"Meta Llama 3 70B proporciona una capacidad de procesamiento de complejidad inigualable, dise\xf1ado a medida para proyectos de alta demanda."},"llama3-8b-8192":{"description":"Meta Llama 3 8B ofrece un rendimiento de razonamiento de alta calidad, adecuado para diversas necesidades de aplicaci\xf3n."},"llama3-groq-70b-8192-tool-use-preview":{"description":"Llama 3 Groq 70B Tool Use ofrece una potente capacidad de invocaci\xf3n de herramientas, apoyando el procesamiento eficiente de tareas complejas."},"llama3-groq-8b-8192-tool-use-preview":{"description":"Llama 3 Groq 8B Tool Use es un modelo optimizado para el uso eficiente de herramientas, que admite c\xe1lculos paralelos r\xe1pidos."},"llama3.1":{"description":"Llama 3.1 es el modelo l\xedder lanzado por Meta, que admite hasta 405B de par\xe1metros, aplicable en di\xe1logos complejos, traducci\xf3n multiling\xfce y an\xe1lisis de datos."},"llama3.1-8b":{"description":"Llama 3.1 8B: una variante ligera y de baja latencia de Llama, adecuada para inferencia en l\xednea y escenarios interactivos de bajo consumo."},"llama3.1:405b":{"description":"Llama 3.1 es el modelo l\xedder lanzado por Meta, que admite hasta 405B de par\xe1metros, aplicable en di\xe1logos complejos, traducci\xf3n multiling\xfce y an\xe1lisis de datos."},"llama3.1:70b":{"description":"Llama 3.1 es el modelo l\xedder lanzado por Meta, que admite hasta 405B de par\xe1metros, aplicable en di\xe1logos complejos, traducci\xf3n multiling\xfce y an\xe1lisis de datos."},"llava":{"description":"LLaVA es un modelo multimodal que combina un codificador visual y Vicuna, utilizado para una poderosa comprensi\xf3n visual y ling\xfc\xedstica."},"llava-v1.5-7b-4096-preview":{"description":"LLaVA 1.5 7B proporciona capacidades de procesamiento visual integradas, generando salidas complejas a partir de entradas de informaci\xf3n visual."},"llava:13b":{"description":"LLaVA es un modelo multimodal que combina un codificador visual y Vicuna, utilizado para una poderosa comprensi\xf3n visual y ling\xfc\xedstica."},"llava:34b":{"description":"LLaVA es un modelo multimodal que combina un codificador visual y Vicuna, utilizado para una poderosa comprensi\xf3n visual y ling\xfc\xedstica."},"magistral-medium-latest":{"description":"Magistral Medium 1.2 es un modelo de inferencia de vanguardia con soporte visual, lanzado por Mistral AI en septiembre de 2025."},"magistral-small-2509":{"description":"Magistral Small 1.2 es un modelo de inferencia peque\xf1o y de c\xf3digo abierto con soporte visual, lanzado por Mistral AI en septiembre de 2025."},"mathstral":{"description":"MathΣtral est\xe1 dise\xf1ado para la investigaci\xf3n cient\xedfica y el razonamiento matem\xe1tico, proporcionando capacidades de c\xe1lculo efectivas y explicaci\xf3n de resultados."},"max-32k":{"description":"Spark Max 32K est\xe1 equipado con una capacidad de procesamiento de contexto grande, con una comprensi\xf3n contextual m\xe1s fuerte y habilidades de razonamiento l\xf3gico, soportando entradas de texto de 32K tokens, adecuado para la lectura de documentos largos, preguntas y respuestas de conocimiento privado y otros escenarios."},"megrez-3b-instruct":{"description":"Megrez 3B Instruct es un modelo eficiente de bajo n\xfamero de par\xe1metros desarrollado por Wuwen Xinqiong."},"meituan/longcat-flash-chat":{"description":"Modelo base no reflexivo de c\xf3digo abierto de Meituan, optimizado para interacciones conversacionales y tareas de agentes inteligentes, con un rendimiento destacado en llamadas a herramientas y escenarios complejos de m\xfaltiples turnos."},"meta-llama-3-70b-instruct":{"description":"Un poderoso modelo de 70 mil millones de par\xe1metros que sobresale en razonamiento, codificaci\xf3n y amplias aplicaciones de lenguaje."},"meta-llama-3-8b-instruct":{"description":"Un modelo vers\xe1til de 8 mil millones de par\xe1metros optimizado para tareas de di\xe1logo y generaci\xf3n de texto."},"meta-llama-3.1-405b-instruct":{"description":"Los modelos de texto solo ajustados por instrucciones Llama 3.1 est\xe1n optimizados para casos de uso de di\xe1logo multiling\xfce y superan muchos de los modelos de chat de c\xf3digo abierto y cerrados disponibles en los benchmarks de la industria."},"meta-llama-3.1-70b-instruct":{"description":"Los modelos de texto solo ajustados por instrucciones Llama 3.1 est\xe1n optimizados para casos de uso de di\xe1logo multiling\xfce y superan muchos de los modelos de chat de c\xf3digo abierto y cerrados disponibles en los benchmarks de la industria."},"meta-llama-3.1-8b-instruct":{"description":"Los modelos de texto solo ajustados por instrucciones Llama 3.1 est\xe1n optimizados para casos de uso de di\xe1logo multiling\xfce y superan muchos de los modelos de chat de c\xf3digo abierto y cerrados disponibles en los benchmarks de la industria."},"meta-llama/Llama-2-13b-chat-hf":{"description":"LLaMA-2 Chat (13B) ofrece una excelente capacidad de procesamiento de lenguaje y una experiencia de interacci\xf3n sobresaliente."},"meta-llama/Llama-2-70b-hf":{"description":"LLaMA-2 ofrece excelentes capacidades de procesamiento del lenguaje y una experiencia de interacci\xf3n excepcional."},"meta-llama/Llama-3-70b-chat-hf":{"description":"LLaMA-3 Chat (70B) es un modelo de chat potente, que soporta necesidades de conversaci\xf3n complejas."},"meta-llama/Llama-3-8b-chat-hf":{"description":"LLaMA-3 Chat (8B) ofrece soporte multiling\xfce, abarcando un amplio conocimiento en diversos campos."},"meta-llama/Llama-3.2-11B-Vision-Instruct-Turbo":{"description":"LLaMA 3.2 est\xe1 dise\xf1ado para manejar tareas que combinan datos visuales y textuales. Se destaca en tareas como descripci\xf3n de im\xe1genes y preguntas visuales, cruzando la brecha entre la generaci\xf3n de lenguaje y el razonamiento visual."},"meta-llama/Llama-3.2-3B-Instruct-Turbo":{"description":"LLaMA 3.2 est\xe1 dise\xf1ado para manejar tareas que combinan datos visuales y textuales. Se destaca en tareas como descripci\xf3n de im\xe1genes y preguntas visuales, cruzando la brecha entre la generaci\xf3n de lenguaje y el razonamiento visual."},"meta-llama/Llama-3.2-90B-Vision-Instruct-Turbo":{"description":"LLaMA 3.2 est\xe1 dise\xf1ado para manejar tareas que combinan datos visuales y textuales. Se destaca en tareas como descripci\xf3n de im\xe1genes y preguntas visuales, cruzando la brecha entre la generaci\xf3n de lenguaje y el razonamiento visual."},"meta-llama/Llama-3.3-70B-Instruct-Turbo":{"description":"El modelo de lenguaje grande multiling\xfce Meta Llama 3.3 (LLM) es un modelo generativo preentrenado y ajustado por instrucciones de 70B (entrada de texto/salida de texto). El modelo de texto puro ajustado por instrucciones de Llama 3.3 est\xe1 optimizado para casos de uso de di\xe1logo multiling\xfce y supera a muchos modelos de chat de c\xf3digo abierto y cerrados en benchmarks de la industria."},"meta-llama/Llama-Vision-Free":{"description":"LLaMA 3.2 est\xe1 dise\xf1ado para manejar tareas que combinan datos visuales y textuales. Se destaca en tareas como descripci\xf3n de im\xe1genes y preguntas visuales, cruzando la brecha entre la generaci\xf3n de lenguaje y el razonamiento visual."},"meta-llama/Meta-Llama-3-70B-Instruct-Lite":{"description":"Llama 3 70B Instruct Lite es ideal para entornos que requieren alto rendimiento y baja latencia."},"meta-llama/Meta-Llama-3-70B-Instruct-Turbo":{"description":"Llama 3 70B Instruct Turbo ofrece una capacidad excepcional de comprensi\xf3n y generaci\xf3n de lenguaje, ideal para las tareas de c\xe1lculo m\xe1s exigentes."},"meta-llama/Meta-Llama-3-8B-Instruct-Lite":{"description":"Llama 3 8B Instruct Lite es adecuado para entornos con recursos limitados, ofreciendo un excelente equilibrio de rendimiento."},"meta-llama/Meta-Llama-3-8B-Instruct-Turbo":{"description":"Llama 3 8B Instruct Turbo es un modelo de lenguaje de alto rendimiento, adecuado para una amplia gama de escenarios de aplicaci\xf3n."},"meta-llama/Meta-Llama-3.1-405B-Instruct":{"description":"LLaMA 3.1 405B es un potente modelo de preentrenamiento y ajuste de instrucciones."},"meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo":{"description":"El modelo Llama 3.1 Turbo de 405B proporciona un soporte de contexto de gran capacidad para el procesamiento de grandes datos, destac\xe1ndose en aplicaciones de inteligencia artificial a gran escala."},"meta-llama/Meta-Llama-3.1-70B":{"description":"Llama 3.1 es el modelo l\xedder lanzado por Meta, que soporta hasta 405B de par\xe1metros, aplicable en di\xe1logos complejos, traducci\xf3n multiling\xfce y an\xe1lisis de datos."},"meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo":{"description":"El modelo Llama 3.1 70B est\xe1 finamente ajustado para aplicaciones de alta carga, cuantificado a FP8 para ofrecer una capacidad de c\xe1lculo y precisi\xf3n m\xe1s eficientes, asegurando un rendimiento excepcional en escenarios complejos."},"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo":{"description":"El modelo Llama 3.1 8B utiliza cuantificaci\xf3n FP8, soportando hasta 131,072 tokens de contexto, destac\xe1ndose entre los modelos de c\xf3digo abierto, ideal para tareas complejas y superando muchos est\xe1ndares de la industria."},"meta-llama/llama-3-70b-instruct":{"description":"Llama 3 70B Instruct est\xe1 optimizado para escenarios de conversaci\xf3n de alta calidad, destac\xe1ndose en diversas evaluaciones humanas."},"meta-llama/llama-3-8b-instruct":{"description":"Llama 3 8B Instruct optimiza los escenarios de conversaci\xf3n de alta calidad, con un rendimiento superior a muchos modelos cerrados."},"meta-llama/llama-3.1-70b-instruct":{"description":"Llama 3.1 70B Instruct est\xe1 dise\xf1ado para conversaciones de alta calidad, destac\xe1ndose en evaluaciones humanas, especialmente en escenarios de alta interacci\xf3n."},"meta-llama/llama-3.1-8b-instruct":{"description":"Llama 3.1 8B Instruct es la \xfaltima versi\xf3n lanzada por Meta, optimizada para escenarios de conversaci\xf3n de alta calidad, superando a muchos modelos cerrados l\xedderes."},"meta-llama/llama-3.1-8b-instruct:free":{"description":"LLaMA 3.1 ofrece soporte multiling\xfce y es uno de los modelos generativos m\xe1s avanzados de la industria."},"meta-llama/llama-3.2-11b-vision-instruct":{"description":"LLaMA 3.2 est\xe1 dise\xf1ado para manejar tareas que combinan datos visuales y textuales. Destaca en tareas como la descripci\xf3n de im\xe1genes y preguntas visuales, superando la brecha entre la generaci\xf3n de lenguaje y el razonamiento visual."},"meta-llama/llama-3.2-3b-instruct":{"description":"meta-llama/llama-3.2-3b-instruct"},"meta-llama/llama-3.2-90b-vision-instruct":{"description":"LLaMA 3.2 est\xe1 dise\xf1ado para manejar tareas que combinan datos visuales y textuales. Destaca en tareas como la descripci\xf3n de im\xe1genes y preguntas visuales, superando la brecha entre la generaci\xf3n de lenguaje y el razonamiento visual."},"meta-llama/llama-3.3-70b-instruct":{"description":"Llama 3.3 es el modelo de lenguaje de c\xf3digo abierto multiling\xfce m\xe1s avanzado de la serie Llama, que ofrece un rendimiento comparable al modelo de 405B a un costo extremadamente bajo. Basado en la estructura Transformer, y mejorado en utilidad y seguridad a trav\xe9s de ajuste fino supervisado (SFT) y aprendizaje por refuerzo con retroalimentaci\xf3n humana (RLHF). Su versi\xf3n ajustada para instrucciones est\xe1 optimizada para di\xe1logos multiling\xfces, superando a muchos modelos de chat de c\xf3digo abierto y cerrado en m\xfaltiples benchmarks de la industria. La fecha l\xedmite de conocimiento es diciembre de 2023."},"meta-llama/llama-3.3-70b-instruct:free":{"description":"Llama 3.3 es el modelo de lenguaje de c\xf3digo abierto multiling\xfce m\xe1s avanzado de la serie Llama, que ofrece un rendimiento comparable al modelo de 405B a un costo extremadamente bajo. Basado en la estructura Transformer, y mejorado en utilidad y seguridad a trav\xe9s de ajuste fino supervisado (SFT) y aprendizaje por refuerzo con retroalimentaci\xf3n humana (RLHF). Su versi\xf3n ajustada para instrucciones est\xe1 optimizada para di\xe1logos multiling\xfces, superando a muchos modelos de chat de c\xf3digo abierto y cerrado en m\xfaltiples benchmarks de la industria. La fecha l\xedmite de conocimiento es diciembre de 2023."},"meta.llama3-1-405b-instruct-v1:0":{"description":"Meta Llama 3.1 405B Instruct es el modelo m\xe1s grande y potente de la serie Llama 3.1 Instruct, un modelo de generaci\xf3n de datos de di\xe1logo y razonamiento altamente avanzado, que tambi\xe9n puede servir como base para un preentrenamiento o ajuste fino especializado en dominios espec\xedficos. Los modelos de lenguaje de gran tama\xf1o (LLMs) multiling\xfces que ofrece Llama 3.1 son un conjunto de modelos generativos preentrenados y ajustados por instrucciones, que incluyen tama\xf1os de 8B, 70B y 405B (entrada/salida de texto). Los modelos de texto ajustados por instrucciones de Llama 3.1 (8B, 70B, 405B) est\xe1n optimizados para casos de uso de di\xe1logo multiling\xfce y superan a muchos modelos de chat de c\xf3digo abierto disponibles en pruebas de referencia de la industria. Llama 3.1 est\xe1 dise\xf1ado para usos comerciales y de investigaci\xf3n en m\xfaltiples idiomas. Los modelos de texto ajustados por instrucciones son adecuados para chats similares a asistentes, mientras que los modelos preentrenados pueden adaptarse a diversas tareas de generaci\xf3n de lenguaje natural. El modelo Llama 3.1 tambi\xe9n admite el uso de su salida para mejorar otros modelos, incluida la generaci\xf3n de datos sint\xe9ticos y el refinamiento. Llama 3.1 es un modelo de lenguaje autorregresivo que utiliza una arquitectura de transformador optimizada. Las versiones ajustadas utilizan ajuste fino supervisado (SFT) y aprendizaje por refuerzo con retroalimentaci\xf3n humana (RLHF) para alinearse con las preferencias humanas de ayuda y seguridad."},"meta.llama3-1-70b-instruct-v1:0":{"description":"La versi\xf3n actualizada de Meta Llama 3.1 70B Instruct incluye una longitud de contexto ampliada de 128K, multiling\xfcismo y capacidades de razonamiento mejoradas. Los modelos de lenguaje a gran escala (LLMs) de Llama 3.1 son un conjunto de modelos generativos preentrenados y ajustados por instrucciones, que incluyen tama\xf1os de 8B, 70B y 405B (entrada/salida de texto). Los modelos de texto ajustados por instrucciones de Llama 3.1 (8B, 70B, 405B) est\xe1n optimizados para casos de uso de di\xe1logo multiling\xfce y superan muchos modelos de chat de c\xf3digo abierto disponibles en pruebas de referencia de la industria comunes. Llama 3.1 est\xe1 dise\xf1ado para usos comerciales y de investigaci\xf3n en m\xfaltiples idiomas. Los modelos de texto ajustados por instrucciones son adecuados para chats similares a asistentes, mientras que los modelos preentrenados pueden adaptarse a diversas tareas de generaci\xf3n de lenguaje natural. El modelo Llama 3.1 tambi\xe9n admite el uso de su salida de modelo para mejorar otros modelos, incluyendo la generaci\xf3n de datos sint\xe9ticos y refinamiento. Llama 3.1 es un modelo de lenguaje autoregresivo utilizando una arquitectura de transformador optimizada. La versi\xf3n ajustada utiliza ajuste fino supervisado (SFT) y aprendizaje por refuerzo con retroalimentaci\xf3n humana (RLHF) para alinearse con las preferencias humanas de utilidad y seguridad."},"meta.llama3-1-8b-instruct-v1:0":{"description":"La versi\xf3n actualizada de Meta Llama 3.1 8B Instruct incluye una longitud de contexto ampliada de 128K, multiling\xfcismo y capacidades de razonamiento mejoradas. Los modelos de lenguaje a gran escala (LLMs) de Llama 3.1 son un conjunto de modelos generativos preentrenados y ajustados por instrucciones, que incluyen tama\xf1os de 8B, 70B y 405B (entrada/salida de texto). Los modelos de texto ajustados por instrucciones de Llama 3.1 (8B, 70B, 405B) est\xe1n optimizados para casos de uso de di\xe1logo multiling\xfce y superan muchos modelos de chat de c\xf3digo abierto disponibles en pruebas de referencia de la industria comunes. Llama 3.1 est\xe1 dise\xf1ado para usos comerciales y de investigaci\xf3n en m\xfaltiples idiomas. Los modelos de texto ajustados por instrucciones son adecuados para chats similares a asistentes, mientras que los modelos preentrenados pueden adaptarse a diversas tareas de generaci\xf3n de lenguaje natural. El modelo Llama 3.1 tambi\xe9n admite el uso de su salida de modelo para mejorar otros modelos, incluyendo la generaci\xf3n de datos sint\xe9ticos y refinamiento. Llama 3.1 es un modelo de lenguaje autoregresivo utilizando una arquitectura de transformador optimizada. La versi\xf3n ajustada utiliza ajuste fino supervisado (SFT) y aprendizaje por refuerzo con retroalimentaci\xf3n humana (RLHF) para alinearse con las preferencias humanas de utilidad y seguridad."},"meta.llama3-70b-instruct-v1:0":{"description":"Meta Llama 3 es un modelo de lenguaje de gran tama\xf1o (LLM) abierto dirigido a desarrolladores, investigadores y empresas, dise\xf1ado para ayudarles a construir, experimentar y escalar de manera responsable sus ideas de IA generativa. Como parte de un sistema base para la innovaci\xf3n de la comunidad global, es ideal para la creaci\xf3n de contenido, IA de di\xe1logo, comprensi\xf3n del lenguaje, I+D y aplicaciones empresariales."},"meta.llama3-8b-instruct-v1:0":{"description":"Meta Llama 3 es un modelo de lenguaje de gran tama\xf1o (LLM) abierto dirigido a desarrolladores, investigadores y empresas, dise\xf1ado para ayudarles a construir, experimentar y escalar de manera responsable sus ideas de IA generativa. Como parte de un sistema base para la innovaci\xf3n de la comunidad global, es ideal para dispositivos de borde con recursos y capacidades computacionales limitadas, as\xed como para tiempos de entrenamiento m\xe1s r\xe1pidos."},"meta/Llama-3.2-11B-Vision-Instruct":{"description":"Destaca en razonamiento de im\xe1genes de alta resoluci\xf3n, ideal para aplicaciones de comprensi\xf3n visual."},"meta/Llama-3.2-90B-Vision-Instruct":{"description":"Capacidades avanzadas de razonamiento de im\xe1genes para aplicaciones de agentes de comprensi\xf3n visual."},"meta/Llama-3.3-70B-Instruct":{"description":"Llama 3.3 es el modelo de lenguaje grande multiling\xfce de c\xf3digo abierto m\xe1s avanzado de la serie Llama, que ofrece un rendimiento comparable a modelos de 405 mil millones de par\xe1metros a un costo muy bajo. Basado en la arquitectura Transformer, mejorado mediante ajuste fino supervisado (SFT) y aprendizaje por refuerzo con retroalimentaci\xf3n humana (RLHF) para mejorar su utilidad y seguridad. Su versi\xf3n ajustada por instrucciones est\xe1 optimizada para di\xe1logos multiling\xfces y supera a muchos modelos de chat abiertos y cerrados en varios puntos de referencia industriales. Fecha de corte de conocimiento: diciembre de 2023."},"meta/Meta-Llama-3-70B-Instruct":{"description":"Un potente modelo de 70 mil millones de par\xe1metros, que destaca en razonamiento, codificaci\xf3n y aplicaciones ling\xfc\xedsticas amplias."},"meta/Meta-Llama-3-8B-Instruct":{"description":"Un modelo vers\xe1til de 8 mil millones de par\xe1metros, optimizado para tareas de di\xe1logo y generaci\xf3n de texto."},"meta/Meta-Llama-3.1-405B-Instruct":{"description":"Modelo de texto ajustado por instrucciones Llama 3.1, optimizado para casos de uso de di\xe1logo multiling\xfce, con un rendimiento destacado en muchos modelos de chat abiertos y cerrados disponibles y en puntos de referencia industriales comunes."},"meta/Meta-Llama-3.1-70B-Instruct":{"description":"Modelo de texto ajustado por instrucciones Llama 3.1, optimizado para casos de uso de di\xe1logo multiling\xfce, con un rendimiento destacado en muchos modelos de chat abiertos y cerrados disponibles y en puntos de referencia industriales comunes."},"meta/Meta-Llama-3.1-8B-Instruct":{"description":"Modelo de texto ajustado por instrucciones Llama 3.1, optimizado para casos de uso de di\xe1logo multiling\xfce, con un rendimiento destacado en muchos modelos de chat abiertos y cerrados disponibles y en puntos de referencia industriales comunes."},"meta/llama-3-70b":{"description":"Modelo de c\xf3digo abierto de 70 mil millones de par\xe1metros ajustado cuidadosamente por Meta para cumplimiento de instrucciones. Operado por Groq con su hardware personalizado de unidad de procesamiento de lenguaje (LPU) para ofrecer inferencia r\xe1pida y eficiente."},"meta/llama-3-8b":{"description":"Modelo de c\xf3digo abierto de 8 mil millones de par\xe1metros ajustado cuidadosamente por Meta para cumplimiento de instrucciones. Operado por Groq con su hardware personalizado de unidad de procesamiento de lenguaje (LPU) para ofrecer inferencia r\xe1pida y eficiente."},"meta/llama-3.1-405b-instruct":{"description":"LLM avanzado, que soporta generaci\xf3n de datos sint\xe9ticos, destilaci\xf3n de conocimiento y razonamiento, adecuado para chatbots, programaci\xf3n y tareas de dominio espec\xedfico."},"meta/llama-3.1-70b":{"description":"Versi\xf3n actualizada de Meta Llama 3 70B Instruct, que incluye una longitud de contexto extendida de 128K, soporte multiling\xfce y capacidades de razonamiento mejoradas."},"meta/llama-3.1-70b-instruct":{"description":"Potencia di\xe1logos complejos, con excelente comprensi\xf3n del contexto, capacidad de razonamiento y generaci\xf3n de texto."},"meta/llama-3.1-8b":{"description":"Llama 3.1 8B soporta una ventana de contexto de 128K, lo que lo hace ideal para interfaces de conversaci\xf3n en tiempo real y an\xe1lisis de datos, ofreciendo un ahorro de costos significativo en comparaci\xf3n con modelos m\xe1s grandes. Operado por Groq con su hardware personalizado de unidad de procesamiento de lenguaje (LPU) para ofrecer inferencia r\xe1pida y eficiente."},"meta/llama-3.1-8b-instruct":{"description":"Modelo de \xfaltima generaci\xf3n avanzado, con comprensi\xf3n del lenguaje, excelente capacidad de razonamiento y generaci\xf3n de texto."},"meta/llama-3.2-11b":{"description":"Modelo de generaci\xf3n de razonamiento visual ajustado por instrucciones (entrada de texto + imagen / salida de texto), optimizado para reconocimiento visual, razonamiento de im\xe1genes, generaci\xf3n de t\xedtulos y respuestas a preguntas generales sobre im\xe1genes."},"meta/llama-3.2-11b-vision-instruct":{"description":"Modelo de visi\xf3n-lenguaje de vanguardia, experto en razonamiento de alta calidad a partir de im\xe1genes."},"meta/llama-3.2-1b":{"description":"Modelo solo de texto, compatible con casos de uso en dispositivos, como recuperaci\xf3n de conocimiento local multiling\xfce, resumen y reescritura."},"meta/llama-3.2-1b-instruct":{"description":"Modelo de lenguaje peque\xf1o de \xfaltima generaci\xf3n, con comprensi\xf3n del lenguaje, excelente capacidad de razonamiento y generaci\xf3n de texto."},"meta/llama-3.2-3b":{"description":"Modelo solo de texto, ajustado cuidadosamente para soportar casos de uso en dispositivos, como recuperaci\xf3n de conocimiento local multiling\xfce, resumen y reescritura."},"meta/llama-3.2-3b-instruct":{"description":"Modelo de lenguaje peque\xf1o de \xfaltima generaci\xf3n, con comprensi\xf3n del lenguaje, excelente capacidad de razonamiento y generaci\xf3n de texto."},"meta/llama-3.2-90b":{"description":"Modelo de generaci\xf3n de razonamiento visual ajustado por instrucciones (entrada de texto + imagen / salida de texto), optimizado para reconocimiento visual, razonamiento de im\xe1genes, generaci\xf3n de t\xedtulos y respuestas a preguntas generales sobre im\xe1genes."},"meta/llama-3.2-90b-vision-instruct":{"description":"Modelo de visi\xf3n-lenguaje de vanguardia, experto en razonamiento de alta calidad a partir de im\xe1genes."},"meta/llama-3.3-70b":{"description":"Combinaci\xf3n perfecta de rendimiento y eficiencia. Este modelo soporta IA conversacional de alto rendimiento, dise\xf1ado para creaci\xf3n de contenido, aplicaciones empresariales e investigaci\xf3n, ofreciendo capacidades avanzadas de comprensi\xf3n del lenguaje, incluyendo resumen de texto, clasificaci\xf3n, an\xe1lisis de sentimientos y generaci\xf3n de c\xf3digo."},"meta/llama-3.3-70b-instruct":{"description":"Modelo LLM avanzado, experto en razonamiento, matem\xe1ticas, sentido com\xfan y llamadas a funciones."},"meta/llama-4-maverick":{"description":"La colecci\xf3n de modelos Llama 4 es una IA multimodal nativa que soporta experiencias de texto y multimodales. Estos modelos utilizan una arquitectura de expertos mixtos para ofrecer un rendimiento l\xedder en la industria en comprensi\xf3n de texto e im\xe1genes. Llama 4 Maverick, un modelo de 17 mil millones de par\xe1metros con 128 expertos. Proporcionado por DeepInfra."},"meta/llama-4-scout":{"description":"La colecci\xf3n de modelos Llama 4 es una IA multimodal nativa que soporta experiencias de texto y multimodales. Estos modelos utilizan una arquitectura de expertos mixtos para ofrecer un rendimiento l\xedder en la industria en comprensi\xf3n de texto e im\xe1genes. Llama 4 Scout, un modelo de 17 mil millones de par\xe1metros con 16 expertos. Proporcionado por DeepInfra."},"microsoft/Phi-3-medium-128k-instruct":{"description":"El mismo modelo Phi-3-medium, pero con un tama\xf1o de contexto mayor, adecuado para RAG o indicaciones breves."},"microsoft/Phi-3-medium-4k-instruct":{"description":"Un modelo de 14 mil millones de par\xe1metros, con mejor calidad que Phi-3-mini, enfocado en datos de alta calidad y razonamiento intensivo."},"microsoft/Phi-3-mini-128k-instruct":{"description":"El mismo modelo Phi-3-mini, pero con un tama\xf1o de contexto mayor, adecuado para RAG o indicaciones breves."},"microsoft/Phi-3-mini-4k-instruct":{"description":"El miembro m\xe1s peque\xf1o de la familia Phi-3, optimizado para calidad y baja latencia."},"microsoft/Phi-3-small-128k-instruct":{"description":"El mismo modelo Phi-3-small, pero con un tama\xf1o de contexto mayor, adecuado para RAG o indicaciones breves."},"microsoft/Phi-3-small-8k-instruct":{"description":"Un modelo de 7 mil millones de par\xe1metros, con mejor calidad que Phi-3-mini, enfocado en datos de alta calidad y razonamiento intensivo."},"microsoft/Phi-3.5-mini-instruct":{"description":"Versi\xf3n actualizada del modelo Phi-3-mini."},"microsoft/Phi-3.5-vision-instruct":{"description":"Versi\xf3n actualizada del modelo Phi-3-vision."},"microsoft/WizardLM-2-8x22B":{"description":"WizardLM 2 es un modelo de lenguaje proporcionado por Microsoft AI, que destaca en di\xe1logos complejos, multiling\xfcismo, razonamiento y asistentes inteligentes."},"microsoft/wizardlm-2-8x22b":{"description":"WizardLM-2 8x22B es el modelo Wizard m\xe1s avanzado de Microsoft AI, mostrando un rendimiento extremadamente competitivo."},"minicpm-v":{"description":"MiniCPM-V es la nueva generaci\xf3n de modelos multimodales lanzada por OpenBMB, que cuenta con una excelente capacidad de reconocimiento OCR y comprensi\xf3n multimodal, soportando una amplia gama de escenarios de aplicaci\xf3n."},"minimax-m2":{"description":"MiniMax M2 es un modelo de lenguaje grande y eficiente, dise\xf1ado para flujos de trabajo de codificaci\xf3n y agentes."},"minimax/minimax-m2":{"description":"Dise\xf1ado para una codificaci\xf3n eficiente y flujos de trabajo de agentes."},"minimaxai/minimax-m2":{"description":"MiniMax-M2 es un modelo de expertos mixtos (MoE) compacto, r\xe1pido y rentable, con un total de 230 mil millones de par\xe1metros y 10 mil millones de par\xe1metros activos. Est\xe1 dise\xf1ado para ofrecer un rendimiento de primer nivel en tareas de codificaci\xf3n y agentes, manteniendo una inteligencia general robusta. El modelo destaca en edici\xf3n de m\xfaltiples archivos, ciclos cerrados de codificaci\xf3n-ejecuci\xf3n-correcci\xf3n, verificaci\xf3n y correcci\xf3n de pruebas, as\xed como en complejas cadenas de herramientas de enlaces largos, lo que lo convierte en una opci\xf3n ideal para los flujos de trabajo de los desarrolladores."},"ministral-3b-latest":{"description":"Ministral 3B es el modelo de borde de primer nivel mundial de Mistral."},"ministral-8b-latest":{"description":"Ministral 8B es el modelo de borde con la mejor relaci\xf3n calidad-precio de Mistral."},"mistral":{"description":"Mistral es un modelo de 7B lanzado por Mistral AI, adecuado para necesidades de procesamiento de lenguaje variables."},"mistral-ai/Mistral-Large-2411":{"description":"El modelo insignia de Mistral, adecuado para tareas complejas que requieren capacidades de razonamiento a gran escala o alta especializaci\xf3n (generaci\xf3n de texto sint\xe9tico, generaci\xf3n de c\xf3digo, RAG o agentes)."},"mistral-ai/Mistral-Nemo":{"description":"Mistral Nemo es un modelo de lenguaje avanzado (LLM) que ofrece capacidades de razonamiento, conocimiento mundial y codificaci\xf3n l\xedderes en su categor\xeda de tama\xf1o."},"mistral-ai/mistral-small-2503":{"description":"Mistral Small est\xe1 disponible para cualquier tarea basada en lenguaje que requiera alta eficiencia y baja latencia."},"mistral-large":{"description":"Mixtral Large es el modelo insignia de Mistral, combinando capacidades de generaci\xf3n de c\xf3digo, matem\xe1ticas y razonamiento, soportando una ventana de contexto de 128k."},"mistral-large-instruct":{"description":"Mistral-Large-Instruct-2407 es un modelo avanzado de lenguaje denso (LLM) con 123 mil millones de par\xe1metros, que posee capacidades de razonamiento, conocimiento y codificaci\xf3n de \xfaltima generaci\xf3n."},"mistral-large-latest":{"description":"Mistral Large es el modelo insignia, especializado en tareas multiling\xfces, razonamiento complejo y generaci\xf3n de c\xf3digo, ideal para aplicaciones de alta gama."},"mistral-medium-latest":{"description":"Mistral Medium 3 ofrece un rendimiento de vanguardia a un costo 8 veces menor y simplifica fundamentalmente el despliegue empresarial."},"mistral-nemo":{"description":"Mistral Nemo, desarrollado en colaboraci\xf3n entre Mistral AI y NVIDIA, es un modelo de 12B de alto rendimiento."},"mistral-nemo-instruct":{"description":"Mistral-Nemo-Instruct-2407 es un modelo de lenguaje grande (LLM) que es una versi\xf3n ajustada por instrucciones de Mistral-Nemo-Base-2407."},"mistral-small":{"description":"Mistral Small se puede utilizar en cualquier tarea basada en lenguaje que requiera alta eficiencia y baja latencia."},"mistral-small-latest":{"description":"Mistral Small es una opci\xf3n rentable, r\xe1pida y confiable, adecuada para casos de uso como traducci\xf3n, resumen y an\xe1lisis de sentimientos."},"mistral/codestral":{"description":"Mistral Codestral 25.01 es un modelo de codificaci\xf3n de \xfaltima generaci\xf3n optimizado para casos de uso de baja latencia y alta frecuencia. Domina m\xe1s de 80 lenguajes de programaci\xf3n y sobresale en tareas como relleno intermedio (FIM), correcci\xf3n de c\xf3digo y generaci\xf3n de pruebas."},"mistral/codestral-embed":{"description":"Modelo de incrustaci\xf3n de c\xf3digo que puede integrarse en bases de datos y repositorios de c\xf3digo para apoyar asistentes de codificaci\xf3n."},"mistral/devstral-small":{"description":"Devstral es un modelo de lenguaje grande agente para tareas de ingenier\xeda de software, ideal para agentes de ingenier\xeda de software."},"mistral/magistral-medium":{"description":"Pensamiento complejo respaldado por comprensi\xf3n profunda, con razonamiento transparente que puede seguir y verificar. Este modelo mantiene un razonamiento de alta fidelidad en m\xfaltiples idiomas, incluso cuando cambia de idioma a mitad de tarea."},"mistral/magistral-small":{"description":"Pensamiento complejo respaldado por comprensi\xf3n profunda, con razonamiento transparente que puede seguir y verificar. Este modelo mantiene un razonamiento de alta fidelidad en m\xfaltiples idiomas, incluso cuando cambia de idioma a mitad de tarea."},"mistral/ministral-3b":{"description":"Un modelo compacto y eficiente para tareas en dispositivos como asistentes inteligentes y an\xe1lisis local, que ofrece un rendimiento de baja latencia."},"mistral/ministral-8b":{"description":"Un modelo m\xe1s potente con inferencia m\xe1s r\xe1pida y eficiente en memoria, ideal para flujos de trabajo complejos y aplicaciones exigentes en el borde."},"mistral/mistral-embed":{"description":"Modelo de incrustaci\xf3n de texto universal para b\xfasqueda sem\xe1ntica, similitud, agrupamiento y flujos de trabajo RAG."},"mistral/mistral-large":{"description":"Mistral Large es ideal para tareas complejas que requieren capacidades de inferencia grandes o altamente especializadas, como generaci\xf3n de texto sint\xe9tico, generaci\xf3n de c\xf3digo, RAG o agentes."},"mistral/mistral-small":{"description":"Mistral Small es ideal para tareas simples que pueden procesarse en lotes, como clasificaci\xf3n, soporte al cliente o generaci\xf3n de texto. Ofrece un rendimiento excelente a un precio asequible."},"mistral/mixtral-8x22b-instruct":{"description":"Modelo 8x22b Instruct. 8x22b es un modelo de expertos mixtos de c\xf3digo abierto operado por Mistral."},"mistral/pixtral-12b":{"description":"Un modelo de 12B con capacidades de comprensi\xf3n de im\xe1genes adem\xe1s de texto."},"mistral/pixtral-large":{"description":"Pixtral Large es el segundo modelo de nuestra familia multimodal, demostrando un nivel avanzado de comprensi\xf3n de im\xe1genes. En particular, el modelo puede entender documentos, gr\xe1ficos y im\xe1genes naturales, manteniendo la capacidad l\xedder en comprensi\xf3n de texto de Mistral Large 2."},"mistralai/Mistral-7B-Instruct-v0.1":{"description":"Mistral (7B) Instruct es conocido por su alto rendimiento, adecuado para diversas tareas de lenguaje."},"mistralai/Mistral-7B-Instruct-v0.2":{"description":"Mistral 7B es un modelo ajustado bajo demanda, proporcionando respuestas optimizadas para tareas."},"mistralai/Mistral-7B-Instruct-v0.3":{"description":"Mistral (7B) Instruct v0.3 ofrece una capacidad de c\xe1lculo eficiente y comprensi\xf3n del lenguaje natural, adecuado para una amplia gama de aplicaciones."},"mistralai/Mistral-7B-v0.1":{"description":"Mistral 7B es un modelo compacto pero de alto rendimiento, ideal para tareas simples como clasificaci\xf3n y generaci\xf3n de texto, con buenas capacidades de razonamiento."},"mistralai/Mixtral-8x22B-Instruct-v0.1":{"description":"Mixtral-8x22B Instruct (141B) es un modelo de lenguaje de gran tama\xf1o, que soporta demandas de procesamiento extremadamente altas."},"mistralai/Mixtral-8x7B-Instruct-v0.1":{"description":"Mixtral 8x7B es un modelo de expertos dispersos preentrenado, utilizado para tareas de texto de uso general."},"mistralai/Mixtral-8x7B-v0.1":{"description":"Mixtral 8x7B es un modelo de expertos dispersos que utiliza m\xfaltiples par\xe1metros para aumentar la velocidad de razonamiento, adecuado para tareas de generaci\xf3n de m\xfaltiples idiomas y c\xf3digos."},"mistralai/mistral-nemo":{"description":"Mistral Nemo es un modelo de 7.3B par\xe1metros con soporte multiling\xfce y programaci\xf3n de alto rendimiento."},"mixtral":{"description":"Mixtral es el modelo de expertos de Mistral AI, con pesos de c\xf3digo abierto, que ofrece soporte en generaci\xf3n de c\xf3digo y comprensi\xf3n del lenguaje."},"mixtral-8x7b-32768":{"description":"Mixtral 8x7B ofrece una capacidad de c\xe1lculo paralelo de alta tolerancia a fallos, adecuada para tareas complejas."},"mixtral:8x22b":{"description":"Mixtral es el modelo de expertos de Mistral AI, con pesos de c\xf3digo abierto, que ofrece soporte en generaci\xf3n de c\xf3digo y comprensi\xf3n del lenguaje."},"moonshot-v1-128k":{"description":"Moonshot V1 128K es un modelo con capacidad de procesamiento de contexto ultra largo, adecuado para generar textos extensos, satisfaciendo las demandas de tareas de generaci\xf3n complejas, capaz de manejar hasta 128,000 tokens, ideal para aplicaciones en investigaci\xf3n, acad\xe9micas y generaci\xf3n de documentos grandes."},"moonshot-v1-128k-vision-preview":{"description":"El modelo visual Kimi (incluyendo moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-preview, etc.) puede entender el contenido de las im\xe1genes, incluyendo texto en im\xe1genes, colores de im\xe1genes y formas de objetos."},"moonshot-v1-32k":{"description":"Moonshot V1 32K ofrece capacidad de procesamiento de contexto de longitud media, capaz de manejar 32,768 tokens, especialmente adecuado para generar diversos documentos largos y di\xe1logos complejos, aplicable en creaci\xf3n de contenido, generaci\xf3n de informes y sistemas de di\xe1logo."},"moonshot-v1-32k-vision-preview":{"description":"El modelo visual Kimi (incluyendo moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-preview, etc.) puede entender el contenido de las im\xe1genes, incluyendo texto en im\xe1genes, colores de im\xe1genes y formas de objetos."},"moonshot-v1-8k":{"description":"Moonshot V1 8K est\xe1 dise\xf1ado para tareas de generaci\xf3n de texto corto, con un rendimiento de procesamiento eficiente, capaz de manejar 8,192 tokens, ideal para di\xe1logos breves, toma de notas y generaci\xf3n r\xe1pida de contenido."},"moonshot-v1-8k-vision-preview":{"description":"El modelo visual Kimi (incluyendo moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-preview, etc.) puede entender el contenido de las im\xe1genes, incluyendo texto en im\xe1genes, colores de im\xe1genes y formas de objetos."},"moonshot-v1-auto":{"description":"Moonshot V1 Auto puede seleccionar el modelo adecuado seg\xfan la cantidad de tokens ocupados en el contexto actual."},"moonshotai/Kimi-Dev-72B":{"description":"Kimi-Dev-72B es un modelo de c\xf3digo abierto de gran escala, optimizado mediante aprendizaje reforzado a gran escala, capaz de generar parches robustos y listos para producci\xf3n. Este modelo alcanz\xf3 un nuevo r\xe9cord del 60.4 % en SWE-bench Verified, estableciendo un nuevo est\xe1ndar para modelos de c\xf3digo abierto en tareas automatizadas de ingenier\xeda de software como la correcci\xf3n de errores y la revisi\xf3n de c\xf3digo."},"moonshotai/Kimi-K2-Instruct-0905":{"description":"Kimi K2-Instruct-0905 es la versi\xf3n m\xe1s reciente y potente de Kimi K2. Es un modelo de lenguaje de expertos mixtos (MoE) de primer nivel, con un total de un bill\xf3n de par\xe1metros y 32 mil millones de par\xe1metros activados. Las principales caracter\xedsticas de este modelo incluyen: inteligencia mejorada para agentes de codificaci\xf3n, mostrando un rendimiento notable en pruebas de referencia p\xfablicas y en tareas reales de agentes de codificaci\xf3n; y una experiencia mejorada en la codificaci\xf3n frontend, con avances tanto en la est\xe9tica como en la funcionalidad de la programaci\xf3n frontend."},"moonshotai/kimi-k2":{"description":"Kimi K2 es un modelo de lenguaje de expertos mixtos (MoE) a gran escala desarrollado por Moonshot AI, con un total de un bill\xf3n de par\xe1metros y 32 mil millones de par\xe1metros activos por pasada. Est\xe1 optimizado para capacidades de agente, incluyendo uso avanzado de herramientas, razonamiento y s\xedntesis de c\xf3digo."},"moonshotai/kimi-k2-0905":{"description":"El modelo kimi-k2-0905-preview tiene una longitud de contexto de 256k, con una mayor capacidad de codificaci\xf3n agentiva, una est\xe9tica y funcionalidad mejoradas en el c\xf3digo frontend, y una mejor comprensi\xf3n del contexto."},"moonshotai/kimi-k2-instruct-0905":{"description":"El modelo kimi-k2-0905-preview tiene una longitud de contexto de 256k, con una mayor capacidad de codificaci\xf3n agentiva, una est\xe9tica y funcionalidad mejoradas en el c\xf3digo frontend, y una mejor comprensi\xf3n del contexto."},"morph/morph-v3-fast":{"description":"Morph ofrece un modelo de IA especializado que aplica r\xe1pidamente los cambios de c\xf3digo sugeridos por modelos de vanguardia como Claude o GPT-4o a sus archivos de c\xf3digo existentes, con una velocidad de m\xe1s de 4500 tokens por segundo. Act\xfaa como el \xfaltimo paso en el flujo de trabajo de codificaci\xf3n de IA. Soporta 16k tokens de entrada y 16k tokens de salida."},"morph/morph-v3-large":{"description":"Morph ofrece un modelo de IA especializado que aplica cambios de c\xf3digo sugeridos por modelos de vanguardia como Claude o GPT-4o a sus archivos de c\xf3digo existentes, con una velocidad de m\xe1s de 2500 tokens por segundo. Act\xfaa como el \xfaltimo paso en el flujo de trabajo de codificaci\xf3n de IA. Soporta 16k tokens de entrada y 16k tokens de salida."},"nousresearch/hermes-2-pro-llama-3-8b":{"description":"Hermes 2 Pro Llama 3 8B es una versi\xf3n mejorada de Nous Hermes 2, que incluye los conjuntos de datos m\xe1s recientes desarrollados internamente."},"nvidia/Llama-3.1-Nemotron-70B-Instruct-HF":{"description":"Llama 3.1 Nemotron 70B es un modelo de lenguaje a gran escala personalizado por NVIDIA, dise\xf1ado para mejorar la utilidad de las respuestas generadas por LLM a las consultas de los usuarios. Este modelo ha destacado en pruebas de referencia como Arena Hard, AlpacaEval 2 LC y GPT-4-Turbo MT-Bench, ocupando el primer lugar en los tres benchmarks de alineaci\xf3n autom\xe1tica hasta el 1 de octubre de 2024. El modelo se entrena utilizando RLHF (especialmente REINFORCE), Llama-3.1-Nemotron-70B-Reward y HelpSteer2-Preference sobre la base del modelo Llama-3.1-70B-Instruct."},"nvidia/llama-3.1-nemotron-51b-instruct":{"description":"Modelo de lenguaje \xfanico, que ofrece una precisi\xf3n y eficiencia inigualables."},"nvidia/llama-3.1-nemotron-70b-instruct":{"description":"Llama-3.1-Nemotron-70B-Instruct es un modelo de lenguaje grande personalizado por NVIDIA, dise\xf1ado para mejorar la utilidad de las respuestas generadas por LLM."},"o1":{"description":"Se centra en el razonamiento avanzado y la resoluci\xf3n de problemas complejos, incluidas tareas matem\xe1ticas y cient\xedficas. Es muy adecuado para aplicaciones que requieren una comprensi\xf3n profunda del contexto y flujos de trabajo de agentes."},"o1-mini":{"description":"o1-mini es un modelo de inferencia r\xe1pido y rentable dise\xf1ado para aplicaciones de programaci\xf3n, matem\xe1ticas y ciencias. Este modelo tiene un contexto de 128K y una fecha de corte de conocimiento en octubre de 2023."},"o1-preview":{"description":"Enfocado en el razonamiento avanzado y en la resoluci\xf3n de problemas complejos, incluidas tareas de matem\xe1ticas y de ciencias. Es ideal para aplicaciones que requieren una comprensi\xf3n profunda del contexto y flujos de trabajo aut\xf3nomos."},"o1-pro":{"description":"La serie o1 ha sido entrenada mediante aprendizaje reforzado para pensar antes de responder y ejecutar tareas de razonamiento complejas. El modelo o1-pro utiliza m\xe1s recursos computacionales para un pensamiento m\xe1s profundo, proporcionando respuestas de calidad superior de manera constante."},"o3":{"description":"o3 es un modelo vers\xe1til y potente, que destaca en m\xfaltiples campos. Establece un nuevo est\xe1ndar para tareas de matem\xe1ticas, ciencia, programaci\xf3n y razonamiento visual. Tambi\xe9n es h\xe1bil en redacci\xf3n t\xe9cnica y seguimiento de instrucciones. Los usuarios pueden utilizarlo para analizar texto, c\xf3digo e im\xe1genes, resolviendo problemas complejos de m\xfaltiples pasos."},"o3-2025-04-16":{"description":"o3 es el nuevo modelo de razonamiento de OpenAI, soporta entrada de texto e imagen y salida de texto, adecuado para tareas complejas que requieren conocimiento general amplio."},"o3-deep-research":{"description":"o3-deep-research es nuestro modelo de investigaci\xf3n profunda m\xe1s avanzado, dise\xf1ado espec\xedficamente para manejar tareas complejas de investigaci\xf3n en m\xfaltiples pasos. Puede buscar y sintetizar informaci\xf3n de Internet, as\xed como acceder y utilizar tus propios datos a trav\xe9s del conector MCP."},"o3-mini":{"description":"o3-mini es nuestro \xfaltimo modelo de inferencia de tama\xf1o peque\xf1o, que ofrece alta inteligencia con los mismos objetivos de costo y latencia que o1-mini."},"o3-pro":{"description":"El modelo o3-pro utiliza m\xe1s capacidad computacional para pensar m\xe1s profundamente y siempre ofrecer mejores respuestas, y solo est\xe1 disponible para uso bajo la API de Responses."},"o3-pro-2025-06-10":{"description":"o3 Pro es el nuevo modelo de razonamiento de OpenAI, soporta entrada de texto e imagen y salida de texto, adecuado para tareas complejas que requieren conocimiento general amplio."},"o4-mini":{"description":"o4-mini es nuestro \xfaltimo modelo de la serie o en formato peque\xf1o. Est\xe1 optimizado para una inferencia r\xe1pida y efectiva, mostrando una alta eficiencia y rendimiento en tareas de codificaci\xf3n y visuales."},"o4-mini-2025-04-16":{"description":"o4-mini es un modelo de razonamiento de OpenAI, soporta entrada de texto e imagen y salida de texto, adecuado para tareas complejas que requieren conocimiento general amplio. Este modelo tiene un contexto de 200K."},"o4-mini-deep-research":{"description":"o4-mini-deep-research es nuestro modelo de investigaci\xf3n profunda m\xe1s r\xe1pido y asequible, ideal para manejar tareas complejas de investigaci\xf3n en m\xfaltiples pasos. Puede buscar y sintetizar informaci\xf3n de Internet, as\xed como acceder y utilizar tus propios datos a trav\xe9s del conector MCP."},"open-codestral-mamba":{"description":"Codestral Mamba es un modelo de lenguaje Mamba 2 enfocado en la generaci\xf3n de c\xf3digo, que proporciona un fuerte apoyo para tareas avanzadas de codificaci\xf3n y razonamiento."},"open-mistral-7b":{"description":"Mistral 7B es un modelo compacto pero de alto rendimiento, especializado en el procesamiento por lotes y tareas simples, como clasificaci\xf3n y generaci\xf3n de texto, con buenas capacidades de razonamiento."},"open-mistral-nemo":{"description":"Mistral Nemo es un modelo de 12B desarrollado en colaboraci\xf3n con Nvidia, que ofrece un rendimiento de razonamiento y codificaci\xf3n excepcional, f\xe1cil de integrar y reemplazar."},"open-mixtral-8x22b":{"description":"Mixtral 8x22B es un modelo de expertos m\xe1s grande, enfocado en tareas complejas, que ofrece una excelente capacidad de razonamiento y un mayor rendimiento."},"open-mixtral-8x7b":{"description":"Mixtral 8x7B es un modelo de expertos dispersos que utiliza m\xfaltiples par\xe1metros para mejorar la velocidad de razonamiento, adecuado para el procesamiento de tareas de m\xfaltiples idiomas y generaci\xf3n de c\xf3digo."},"openai/gpt-3.5-turbo":{"description":"El modelo m\xe1s competente y rentable de la serie GPT-3.5 de OpenAI, optimizado para prop\xf3sitos de chat, pero que tambi\xe9n funciona bien en tareas tradicionales de completado."},"openai/gpt-3.5-turbo-instruct":{"description":"Capacidades similares a los modelos de la era GPT-3. Compatible con puntos finales de completado tradicionales en lugar de puntos finales de completado de chat."},"openai/gpt-4-turbo":{"description":"gpt-4-turbo de OpenAI posee un amplio conocimiento general y experiencia en dominios, permiti\xe9ndole seguir instrucciones complejas en lenguaje natural y resolver problemas dif\xedciles con precisi\xf3n. Su fecha de corte de conocimiento es abril de 2023 y tiene una ventana de contexto de 128,000 tokens."},"openai/gpt-4.1":{"description":"GPT 4.1 es el modelo insignia de OpenAI, adecuado para tareas complejas. Es excelente para resolver problemas interdisciplinarios."},"openai/gpt-4.1-mini":{"description":"GPT 4.1 mini equilibra inteligencia, velocidad y costo, convirti\xe9ndolo en un modelo atractivo para muchos casos de uso."},"openai/gpt-4.1-nano":{"description":"GPT-4.1 nano es el modelo GPT 4.1 m\xe1s r\xe1pido y rentable."},"openai/gpt-4o":{"description":"GPT-4o de OpenAI tiene un amplio conocimiento general y experiencia en dominios, capaz de seguir instrucciones complejas en lenguaje natural y resolver problemas dif\xedciles con precisi\xf3n. Ofrece un rendimiento equivalente a GPT-4 Turbo con una API m\xe1s r\xe1pida y econ\xf3mica."},"openai/gpt-4o-mini":{"description":"GPT-4o mini de OpenAI es su modelo peque\xf1o m\xe1s avanzado y rentable. Es multimodal (acepta entradas de texto o imagen y produce texto) y es m\xe1s inteligente que gpt-3.5-turbo, manteniendo la misma velocidad."},"openai/gpt-5":{"description":"GPT-5 es el modelo de lenguaje insignia de OpenAI, sobresaliendo en razonamiento complejo, amplio conocimiento del mundo real, tareas intensivas en c\xf3digo y tareas de agente de m\xfaltiples pasos."},"openai/gpt-5-mini":{"description":"GPT-5 mini es un modelo optimizado en costos que sobresale en tareas de razonamiento y chat. Ofrece el mejor equilibrio entre velocidad, costo y capacidad."},"openai/gpt-5-nano":{"description":"GPT-5 nano es un modelo de alto rendimiento que sobresale en tareas simples de instrucciones o clasificaci\xf3n."},"openai/gpt-oss-120b":{"description":"Modelo de lenguaje grande universal extremadamente competente con capacidades de razonamiento potentes y controlables."},"openai/gpt-oss-20b":{"description":"Modelo de lenguaje compacto con pesos de c\xf3digo abierto, optimizado para baja latencia y entornos con recursos limitados, incluyendo despliegues locales y en el borde."},"openai/o1":{"description":"o1 de OpenAI es un modelo de inferencia insignia dise\xf1ado para problemas complejos que requieren pensamiento profundo. Proporciona capacidades de razonamiento potentes y mayor precisi\xf3n para tareas complejas de m\xfaltiples pasos."},"openai/o1-mini":{"description":"o1-mini es un modelo de inferencia r\xe1pido y rentable dise\xf1ado para aplicaciones de programaci\xf3n, matem\xe1ticas y ciencias. Este modelo tiene un contexto de 128K y una fecha de corte de conocimiento en octubre de 2023."},"openai/o1-preview":{"description":"o1 es el nuevo modelo de inferencia de OpenAI, adecuado para tareas complejas que requieren un amplio conocimiento general. Este modelo tiene un contexto de 128K y una fecha de corte de conocimiento en octubre de 2023."},"openai/o3":{"description":"o3 de OpenAI es el modelo de inferencia m\xe1s potente, estableciendo nuevos est\xe1ndares en codificaci\xf3n, matem\xe1ticas, ciencias y percepci\xf3n visual. Sobresale en consultas complejas que requieren an\xe1lisis multifac\xe9tico, con ventajas especiales en an\xe1lisis de im\xe1genes, gr\xe1ficos y diagramas."},"openai/o3-mini":{"description":"o3-mini es el modelo de inferencia peque\xf1o m\xe1s reciente de OpenAI, que ofrece alta inteligencia con los mismos objetivos de costo y latencia que o1-mini."},"openai/o3-mini-high":{"description":"o3-mini de alto nivel de razonamiento proporciona alta inteligencia con los mismos objetivos de costo y latencia que o1-mini."},"openai/o4-mini":{"description":"o4-mini de OpenAI ofrece inferencia r\xe1pida y rentable, con un rendimiento sobresaliente para su tama\xf1o, especialmente en matem\xe1ticas (destacando en la prueba de referencia AIME), codificaci\xf3n y tareas visuales."},"openai/o4-mini-high":{"description":"Versi\xf3n de alto nivel de inferencia de o4-mini, optimizada para una inferencia r\xe1pida y efectiva, mostrando una alta eficiencia y rendimiento en tareas de codificaci\xf3n y visuales."},"openai/text-embedding-3-large":{"description":"El modelo de incrustaciones m\xe1s competente de OpenAI, adecuado para tareas en ingl\xe9s y otros idiomas."},"openai/text-embedding-3-small":{"description":"Versi\xf3n mejorada y de mayor rendimiento del modelo de incrustaciones ada de OpenAI."},"openai/text-embedding-ada-002":{"description":"Modelo tradicional de incrustaciones de texto de OpenAI."},"openrouter/auto":{"description":"Seg\xfan la longitud del contexto, el tema y la complejidad, tu solicitud se enviar\xe1 a Llama 3 70B Instruct, Claude 3.5 Sonnet (autoajuste) o GPT-4o."},"perplexity/sonar":{"description":"Producto ligero de Perplexity con capacidad de b\xfasqueda fundamentada, m\xe1s r\xe1pido y econ\xf3mico que Sonar Pro."},"perplexity/sonar-pro":{"description":"Producto insignia de Perplexity con capacidad de b\xfasqueda fundamentada, que soporta consultas avanzadas y operaciones de seguimiento."},"perplexity/sonar-reasoning":{"description":"Modelo enfocado en razonamiento que produce cadenas de pensamiento (CoT) en las respuestas, ofreciendo explicaciones detalladas con b\xfasqueda fundamentada."},"perplexity/sonar-reasoning-pro":{"description":"Modelo avanzado enfocado en razonamiento que produce cadenas de pensamiento (CoT) en las respuestas, ofreciendo explicaciones integrales con capacidades de b\xfasqueda mejoradas y m\xfaltiples consultas de b\xfasqueda por solicitud."},"phi3":{"description":"Phi-3 es un modelo abierto ligero lanzado por Microsoft, adecuado para una integraci\xf3n eficiente y razonamiento de conocimiento a gran escala."},"phi3:14b":{"description":"Phi-3 es un modelo abierto ligero lanzado por Microsoft, adecuado para una integraci\xf3n eficiente y razonamiento de conocimiento a gran escala."},"pixtral-12b-2409":{"description":"El modelo Pixtral muestra una fuerte capacidad en tareas como comprensi\xf3n de gr\xe1ficos e im\xe1genes, preguntas y respuestas de documentos, razonamiento multimodal y seguimiento de instrucciones, capaz de ingerir im\xe1genes en resoluci\xf3n y proporci\xf3n natural, y manejar una cantidad arbitraria de im\xe1genes en una ventana de contexto larga de hasta 128K tokens."},"pixtral-large-latest":{"description":"Pixtral Large es un modelo multimodal de c\xf3digo abierto con 124 mil millones de par\xe1metros, construido sobre Mistral Large 2. Este es nuestro segundo modelo en la familia multimodal, que muestra un nivel de comprensi\xf3n de im\xe1genes de vanguardia."},"pro-128k":{"description":"Spark Pro 128K est\xe1 equipado con una capacidad de procesamiento de contexto extragrande, capaz de manejar hasta 128K de informaci\xf3n contextual, especialmente adecuado para el an\xe1lisis completo y el manejo de relaciones l\xf3gicas a largo plazo en contenido extenso, proporcionando una l\xf3gica fluida y coherente y un soporte diverso de citas en comunicaciones de texto complejas."},"pro-deepseek-r1":{"description":"Modelo exclusivo para servicios empresariales, incluye servicio concurrente."},"pro-deepseek-v3":{"description":"Modelo exclusivo para servicios empresariales, incluye servicio concurrente."},"qianfan-70b":{"description":"Qianfan 70B, un modelo chino de gran tama\xf1o, ideal para la generaci\xf3n de contenido de alta calidad y tareas de razonamiento complejo."},"qianfan-8b":{"description":"Qianfan 8B, un modelo general de tama\xf1o medio, adecuado para generaci\xf3n de texto y preguntas y respuestas con equilibrio entre coste y rendimiento."},"qianfan-agent-intent-32k":{"description":"Qianfan Agent Intent 32K, modelo orientado al reconocimiento de intenciones y orquestaci\xf3n de agentes, compatible con contextos largos."},"qianfan-agent-lite-8k":{"description":"Qianfan Agent Lite 8K, modelo ligero de agente, ideal para di\xe1logos multivuelta de bajo coste y orquestaci\xf3n empresarial."},"qianfan-agent-speed-32k":{"description":"Qianfan Agent Speed 32K, modelo de agente de alto rendimiento, adecuado para aplicaciones de agentes a gran escala y multitarea."},"qianfan-agent-speed-8k":{"description":"Qianfan Agent Speed 8K, modelo de agente de alta concurrencia, dise\xf1ado para di\xe1logos cortos y respuestas r\xe1pidas."},"qianfan-check-vl":{"description":"Qianfan Check VL, modelo de revisi\xf3n y detecci\xf3n de contenido multimodal, compatible con tareas de cumplimiento e identificaci\xf3n de im\xe1genes y texto."},"qianfan-composition":{"description":"Qianfan Composition, modelo de creaci\xf3n multimodal, compatible con comprensi\xf3n y generaci\xf3n combinada de texto e imagen."},"qianfan-engcard-vl":{"description":"Qianfan EngCard VL, modelo de reconocimiento multimodal enfocado en escenarios en ingl\xe9s."},"qianfan-lightning-128b-a19b":{"description":"Qianfan Lightning 128B A19B, modelo general de alto rendimiento en chino, ideal para preguntas complejas y tareas de razonamiento a gran escala."},"qianfan-llama-vl-8b":{"description":"Qianfan Llama VL 8B, modelo multimodal basado en Llama, orientado a tareas generales de comprensi\xf3n de texto e imagen."},"qianfan-multipicocr":{"description":"Qianfan MultiPicOCR, modelo OCR para m\xfaltiples im\xe1genes, compatible con detecci\xf3n y reconocimiento de texto en varias im\xe1genes."},"qianfan-qi-vl":{"description":"Qianfan QI VL, modelo de preguntas y respuestas multimodal, dise\xf1ado para recuperaci\xf3n precisa y respuestas en escenarios complejos de texto e imagen."},"qianfan-singlepicocr":{"description":"Qianfan SinglePicOCR, modelo OCR para una sola imagen, compatible con reconocimiento de caracteres de alta precisi\xf3n."},"qianfan-vl-70b":{"description":"Qianfan VL 70B, modelo de lenguaje visual de gran tama\xf1o, ideal para escenarios complejos de comprensi\xf3n de texto e imagen."},"qianfan-vl-8b":{"description":"Qianfan VL 8B, modelo de lenguaje visual ligero, adecuado para preguntas y respuestas cotidianas sobre im\xe1genes y an\xe1lisis."},"qvq-72b-preview":{"description":"El modelo QVQ es un modelo de investigaci\xf3n experimental desarrollado por el equipo de Qwen, enfocado en mejorar la capacidad de razonamiento visual, especialmente en el \xe1mbito del razonamiento matem\xe1tico."},"qvq-max":{"description":"Modelo de razonamiento visual QVQ de Tongyi Qianwen, que soporta entrada visual y salida de cadena de pensamiento, mostrando capacidades superiores en matem\xe1ticas, programaci\xf3n, an\xe1lisis visual, creaci\xf3n y tareas generales."},"qvq-plus":{"description":"Modelo de razonamiento visual. Soporta entrada visual y salida en cadena de pensamiento. Versi\xf3n plus lanzada tras el modelo qvq-max, con mayor velocidad de razonamiento y un equilibrio mejorado entre eficacia y coste en comparaci\xf3n con qvq-max."},"qwen-3-32b":{"description":"Qwen 3 32B: el modelo de la serie Qwen ofrece un excelente rendimiento en tareas multiling\xfces y de codificaci\xf3n, ideal para aplicaciones de producci\xf3n a escala media."},"qwen-3-coder-480b":{"description":"Qwen 3 Coder 480B: un modelo de contexto largo dise\xf1ado para generaci\xf3n de c\xf3digo y tareas complejas de programaci\xf3n."},"qwen-coder-plus":{"description":"Modelo de c\xf3digo Tongyi Qianwen."},"qwen-coder-turbo":{"description":"Modelo de c\xf3digo Tongyi Qianwen."},"qwen-coder-turbo-latest":{"description":"El modelo de c\xf3digo Tongyi Qwen."},"qwen-flash":{"description":"La serie Tongyi Qianwen ofrece modelos de la mayor rapidez y de coste extremadamente bajo, adecuados para tareas sencillas."},"qwen-image":{"description":"Qwen-Image es un modelo de generaci\xf3n de im\xe1genes de uso general que admite diversos estilos art\xedsticos y destaca por su capacidad para renderizar textos complejos, especialmente textos en chino e ingl\xe9s. El modelo soporta maquetaci\xf3n en varias l\xedneas, generaci\xf3n de texto a nivel de p\xe1rrafo y representaci\xf3n de detalles finos, lo que permite crear dise\xf1os complejos que combinan texto e imagen."},"qwen-image-edit":{"description":"Qwen Image Edit es un modelo de generaci\xf3n de im\xe1genes que permite la edici\xf3n y modificaci\xf3n de im\xe1genes bas\xe1ndose en una imagen de entrada y un texto indicativo, capaz de realizar ajustes precisos y transformaciones creativas en la imagen original seg\xfan las necesidades del usuario."},"qwen-long":{"description":"Qwen es un modelo de lenguaje a gran escala que admite contextos de texto largos y funciones de conversaci\xf3n basadas en documentos largos y m\xfaltiples."},"qwen-math-plus":{"description":"Modelo matem\xe1tico Tongyi Qianwen especializado en resoluci\xf3n de problemas matem\xe1ticos."},"qwen-math-plus-latest":{"description":"El modelo de matem\xe1ticas Tongyi Qwen est\xe1 dise\xf1ado espec\xedficamente para resolver problemas matem\xe1ticos."},"qwen-math-turbo":{"description":"Modelo matem\xe1tico Tongyi Qianwen especializado en resoluci\xf3n de problemas matem\xe1ticos."},"qwen-math-turbo-latest":{"description":"El modelo de matem\xe1ticas Tongyi Qwen est\xe1 dise\xf1ado espec\xedficamente para resolver problemas matem\xe1ticos."},"qwen-max":{"description":"El modelo de lenguaje a gran escala Qwen Max, de billones de par\xe1metros, admite entradas en diferentes idiomas como chino e ingl\xe9s, y actualmente es el modelo API detr\xe1s de la versi\xf3n del producto Qwen 2.5."},"qwen-omni-turbo":{"description":"La serie Qwen-Omni soporta entrada de m\xfaltiples modalidades, incluyendo video, audio, im\xe1genes y texto, y produce salida en audio y texto."},"qwen-plus":{"description":"La versi\xf3n mejorada del modelo de lenguaje a gran escala Qwen admite entradas en diferentes idiomas como chino e ingl\xe9s."},"qwen-turbo":{"description":"通义千问 Turbo dejar\xe1 de recibir actualizaciones; se recomienda sustituirlo por 通义千问 Flash. 通义千问 es un modelo de lenguaje a gran escala que admite entradas en chino, ingl\xe9s y otros idiomas."},"qwen-vl-chat-v1":{"description":"Qwen VL admite formas de interacci\xf3n flexibles, incluyendo m\xfaltiples im\xe1genes, preguntas y respuestas en m\xfaltiples rondas, y capacidades creativas."},"qwen-vl-max":{"description":"Modelo visual-ling\xfc\xedstico a gran escala Tongyi Qianwen de m\xe1xima capacidad. En comparaci\xf3n con la versi\xf3n mejorada, incrementa a\xfan m\xe1s la capacidad de razonamiento visual y el seguimiento de instrucciones, ofreciendo un nivel superior de percepci\xf3n y cognici\xf3n visual."},"qwen-vl-max-latest":{"description":"Modelo de lenguaje visual a ultra gran escala Tongyi Qianwen. En comparaci\xf3n con la versi\xf3n mejorada, mejora a\xfan m\xe1s la capacidad de razonamiento visual y de seguimiento de instrucciones, ofreciendo un nivel m\xe1s alto de percepci\xf3n y cognici\xf3n visual."},"qwen-vl-ocr":{"description":"Tongyi Qianwen OCR es un modelo especializado en extracci\xf3n de texto, enfocado en documentos, tablas, ex\xe1menes y escritura manuscrita. Puede reconocer m\xfaltiples idiomas, incluyendo chino, ingl\xe9s, franc\xe9s, japon\xe9s, coreano, alem\xe1n, ruso, italiano, vietnamita y \xe1rabe."},"qwen-vl-plus":{"description":"Versi\xf3n mejorada del modelo visual-ling\xfc\xedstico a gran escala Tongyi Qianwen. Mejora considerablemente la capacidad de reconocimiento de detalles y texto, soportando im\xe1genes con resoluci\xf3n superior a un mill\xf3n de p\xedxeles y proporciones de aspecto arbitrarias."},"qwen-vl-plus-latest":{"description":"Versi\xf3n mejorada del modelo de lenguaje visual a gran escala Tongyi Qianwen. Mejora significativamente la capacidad de reconocimiento de detalles y de texto, soportando im\xe1genes con resoluci\xf3n de m\xe1s de un mill\xf3n de p\xedxeles y proporciones de ancho y alto arbitrarias."},"qwen-vl-v1":{"description":"Iniciado con el modelo de lenguaje Qwen-7B, se a\xf1ade un modelo de imagen, un modelo preentrenado con una resoluci\xf3n de entrada de imagen de 448."},"qwen/qwen-2-7b-instruct":{"description":"Qwen2 es una nueva serie de modelos de lenguaje grande Qwen. Qwen2 7B es un modelo basado en transformador que destaca en comprensi\xf3n del lenguaje, capacidades multiling\xfces, programaci\xf3n, matem\xe1ticas y razonamiento."},"qwen/qwen-2-7b-instruct:free":{"description":"Qwen2 es una nueva serie de modelos de lenguaje de gran tama\xf1o, con una mayor capacidad de comprensi\xf3n y generaci\xf3n."},"qwen/qwen-2-vl-72b-instruct":{"description":"Qwen2-VL es la \xfaltima iteraci\xf3n del modelo Qwen-VL, alcanzando un rendimiento de vanguardia en pruebas de comprensi\xf3n visual, incluyendo MathVista, DocVQA, RealWorldQA y MTVQA. Qwen2-VL puede entender videos de m\xe1s de 20 minutos, permitiendo preguntas y respuestas, di\xe1logos y creaci\xf3n de contenido de alta calidad basados en video. Tambi\xe9n posee capacidades complejas de razonamiento y toma de decisiones, pudiendo integrarse con dispositivos m\xf3viles, robots, etc., para realizar operaciones autom\xe1ticas basadas en el entorno visual y las instrucciones de texto. Adem\xe1s del ingl\xe9s y el chino, Qwen2-VL ahora tambi\xe9n admite la comprensi\xf3n de texto en diferentes idiomas dentro de im\xe1genes, incluyendo la mayor\xeda de los idiomas europeos, japon\xe9s, coreano, \xe1rabe y vietnamita."},"qwen/qwen-2.5-72b-instruct":{"description":"Qwen2.5-72B-Instruct es una de las \xfaltimas series de modelos de lenguaje grande lanzadas por Alibaba Cloud. Este modelo de 72B presenta capacidades significativamente mejoradas en \xe1reas como codificaci\xf3n y matem\xe1ticas. Tambi\xe9n ofrece soporte multiling\xfce, abarcando m\xe1s de 29 idiomas, incluidos chino e ingl\xe9s. El modelo ha mejorado notablemente en el seguimiento de instrucciones, la comprensi\xf3n de datos estructurados y la generaci\xf3n de salidas estructuradas (especialmente JSON)."},"qwen/qwen2.5-32b-instruct":{"description":"Qwen2.5-32B-Instruct es una de las \xfaltimas series de modelos de lenguaje grande lanzadas por Alibaba Cloud. Este modelo de 32B presenta capacidades significativamente mejoradas en \xe1reas como codificaci\xf3n y matem\xe1ticas. Tambi\xe9n ofrece soporte multiling\xfce, abarcando m\xe1s de 29 idiomas, incluidos chino e ingl\xe9s. El modelo ha mejorado notablemente en el seguimiento de instrucciones, la comprensi\xf3n de datos estructurados y la generaci\xf3n de salidas estructuradas (especialmente JSON)."},"qwen/qwen2.5-7b-instruct":{"description":"LLM orientado a chino e ingl\xe9s, enfocado en \xe1reas como lenguaje, programaci\xf3n, matem\xe1ticas y razonamiento."},"qwen/qwen2.5-coder-32b-instruct":{"description":"LLM avanzado, que soporta generaci\xf3n de c\xf3digo, razonamiento y correcci\xf3n, abarcando lenguajes de programaci\xf3n populares."},"qwen/qwen2.5-coder-7b-instruct":{"description":"Poderoso modelo de c\xf3digo de tama\xf1o mediano, que soporta longitudes de contexto de 32K, experto en programaci\xf3n multiling\xfce."},"qwen/qwen3-14b":{"description":"Qwen3-14B es un modelo de lenguaje causal denso de 14.8 mil millones de par\xe1metros en la serie Qwen3, dise\xf1ado para razonamiento complejo y di\xe1logos eficientes. Soporta un cambio sin problemas entre un modo de \'pensamiento\' para tareas de matem\xe1ticas, programaci\xf3n y razonamiento l\xf3gico, y un modo \'no reflexivo\' para di\xe1logos generales. Este modelo ha sido ajustado para seguir instrucciones, utilizar herramientas de agentes, escribir creativamente y realizar tareas multiling\xfces en m\xe1s de 100 idiomas y dialectos. Maneja de forma nativa un contexto de 32K tokens y se puede expandir a 131K tokens utilizando extensiones basadas en YaRN."},"qwen/qwen3-14b:free":{"description":"Qwen3-14B es un modelo de lenguaje causal denso de 14.8 mil millones de par\xe1metros en la serie Qwen3, dise\xf1ado para razonamiento complejo y di\xe1logos eficientes. Soporta un cambio sin problemas entre un modo de \'pensamiento\' para tareas de matem\xe1ticas, programaci\xf3n y razonamiento l\xf3gico, y un modo \'no reflexivo\' para di\xe1logos generales. Este modelo ha sido ajustado para seguir instrucciones, utilizar herramientas de agentes, escribir creativamente y realizar tareas multiling\xfces en m\xe1s de 100 idiomas y dialectos. Maneja de forma nativa un contexto de 32K tokens y se puede expandir a 131K tokens utilizando extensiones basadas en YaRN."},"qwen/qwen3-235b-a22b":{"description":"Qwen3-235B-A22B es un modelo de mezcla de expertos (MoE) de 235B par\xe1metros desarrollado por Qwen, que activa 22B par\xe1metros en cada pasada hacia adelante. Soporta un cambio sin problemas entre un modo de \'pensamiento\' para razonamiento complejo, matem\xe1ticas y tareas de c\xf3digo, y un modo \'no reflexivo\' para eficiencia en di\xe1logos generales. Este modelo demuestra una fuerte capacidad de razonamiento, soporte multiling\xfce (m\xe1s de 100 idiomas y dialectos), y habilidades avanzadas de seguimiento de instrucciones y llamadas a herramientas de agentes. Maneja de forma nativa una ventana de contexto de 32K tokens y se puede expandir a 131K tokens utilizando extensiones basadas en YaRN."},"qwen/qwen3-235b-a22b:free":{"description":"Qwen3-235B-A22B es un modelo de mezcla de expertos (MoE) de 235B par\xe1metros desarrollado por Qwen, que activa 22B par\xe1metros en cada pasada hacia adelante. Soporta un cambio sin problemas entre un modo de \'pensamiento\' para razonamiento complejo, matem\xe1ticas y tareas de c\xf3digo, y un modo \'no reflexivo\' para eficiencia en di\xe1logos generales. Este modelo demuestra una fuerte capacidad de razonamiento, soporte multiling\xfce (m\xe1s de 100 idiomas y dialectos), y habilidades avanzadas de seguimiento de instrucciones y llamadas a herramientas de agentes. Maneja de forma nativa una ventana de contexto de 32K tokens y se puede expandir a 131K tokens utilizando extensiones basadas en YaRN."},"qwen/qwen3-30b-a3b":{"description":"Qwen3 es la \xfaltima generaci\xf3n de la serie de modelos de lenguaje Qwen, con una arquitectura de mezcla densa y de expertos (MoE), que destaca en razonamiento, soporte multiling\xfce y tareas avanzadas de agentes. Su capacidad \xfanica para cambiar sin problemas entre un modo de pensamiento para razonamiento complejo y un modo no reflexivo para di\xe1logos eficientes garantiza un rendimiento vers\xe1til y de alta calidad.\\n\\nQwen3 supera significativamente a modelos anteriores como QwQ y Qwen2.5, ofreciendo capacidades excepcionales en matem\xe1ticas, codificaci\xf3n, razonamiento de sentido com\xfan, escritura creativa y di\xe1logos interactivos. La variante Qwen3-30B-A3B contiene 30.5 mil millones de par\xe1metros (3.3 mil millones de par\xe1metros activados), 48 capas, 128 expertos (activando 8 por tarea) y admite un contexto de hasta 131K tokens (usando YaRN), estableciendo un nuevo est\xe1ndar para modelos de c\xf3digo abierto."},"qwen/qwen3-30b-a3b:free":{"description":"Qwen3 es la \xfaltima generaci\xf3n de la serie de modelos de lenguaje Qwen, con una arquitectura de mezcla densa y de expertos (MoE), que destaca en razonamiento, soporte multiling\xfce y tareas avanzadas de agentes. Su capacidad \xfanica para cambiar sin problemas entre un modo de pensamiento para razonamiento complejo y un modo no reflexivo para di\xe1logos eficientes garantiza un rendimiento vers\xe1til y de alta calidad.\\n\\nQwen3 supera significativamente a modelos anteriores como QwQ y Qwen2.5, ofreciendo capacidades excepcionales en matem\xe1ticas, codificaci\xf3n, razonamiento de sentido com\xfan, escritura creativa y di\xe1logos interactivos. La variante Qwen3-30B-A3B contiene 30.5 mil millones de par\xe1metros (3.3 mil millones de par\xe1metros activados), 48 capas, 128 expertos (activando 8 por tarea) y admite un contexto de hasta 131K tokens (usando YaRN), estableciendo un nuevo est\xe1ndar para modelos de c\xf3digo abierto."},"qwen/qwen3-32b":{"description":"Qwen3-32B es un modelo de lenguaje causal denso de 32.8 mil millones de par\xe1metros en la serie Qwen3, optimizado para razonamiento complejo y di\xe1logos eficientes. Soporta un cambio sin problemas entre un modo de \'pensamiento\' para tareas de matem\xe1ticas, codificaci\xf3n y razonamiento l\xf3gico, y un modo \'no reflexivo\' para di\xe1logos m\xe1s r\xe1pidos y generales. Este modelo muestra un rendimiento robusto en seguir instrucciones, utilizar herramientas de agentes, escribir creativamente y realizar tareas multiling\xfces en m\xe1s de 100 idiomas y dialectos. Maneja de forma nativa un contexto de 32K tokens y se puede expandir a 131K tokens utilizando extensiones basadas en YaRN."},"qwen/qwen3-32b:free":{"description":"Qwen3-32B es un modelo de lenguaje causal denso de 32.8 mil millones de par\xe1metros en la serie Qwen3, optimizado para razonamiento complejo y di\xe1logos eficientes. Soporta un cambio sin problemas entre un modo de \'pensamiento\' para tareas de matem\xe1ticas, codificaci\xf3n y razonamiento l\xf3gico, y un modo \'no reflexivo\' para di\xe1logos m\xe1s r\xe1pidos y generales. Este modelo muestra un rendimiento robusto en seguir instrucciones, utilizar herramientas de agentes, escribir creativamente y realizar tareas multiling\xfces en m\xe1s de 100 idiomas y dialectos. Maneja de forma nativa un contexto de 32K tokens y se puede expandir a 131K tokens utilizando extensiones basadas en YaRN."},"qwen/qwen3-8b:free":{"description":"Qwen3-8B es un modelo de lenguaje causal denso de 8.2 mil millones de par\xe1metros en la serie Qwen3, dise\xf1ado para tareas intensivas en razonamiento y di\xe1logos eficientes. Soporta un cambio sin problemas entre un modo de \'pensamiento\' para matem\xe1ticas, codificaci\xf3n y razonamiento l\xf3gico, y un modo \'no reflexivo\' para di\xe1logos generales. Este modelo ha sido ajustado para seguir instrucciones, integrar agentes, escribir creativamente y utilizar m\xe1s de 100 idiomas y dialectos. Soporta de forma nativa una ventana de contexto de 32K tokens y se puede expandir a 131K tokens a trav\xe9s de YaRN."},"qwen2":{"description":"Qwen2 es el nuevo modelo de lenguaje a gran escala de Alibaba, que ofrece un rendimiento excepcional para satisfacer diversas necesidades de aplicaci\xf3n."},"qwen2.5":{"description":"Qwen2.5 es la nueva generaci\xf3n de modelos de lenguaje a gran escala de Alibaba, que ofrece un rendimiento excepcional para satisfacer diversas necesidades de aplicaci\xf3n."},"qwen2.5-14b-instruct":{"description":"El modelo de 14B de Tongyi Qwen 2.5, de c\xf3digo abierto."},"qwen2.5-14b-instruct-1m":{"description":"El modelo de 72B de Qwen2.5 es de c\xf3digo abierto."},"qwen2.5-32b-instruct":{"description":"El modelo de 32B de Tongyi Qwen 2.5, de c\xf3digo abierto."},"qwen2.5-72b-instruct":{"description":"El modelo de 72B de Tongyi Qwen 2.5, de c\xf3digo abierto."},"qwen2.5-7b-instruct":{"description":"Qwen2.5 7B Instruct, modelo de instrucciones de c\xf3digo abierto maduro, adecuado para di\xe1logos y generaci\xf3n en m\xfaltiples escenarios."},"qwen2.5-coder-1.5b-instruct":{"description":"La versi\xf3n de c\xf3digo abierto del modelo Qwen para codificaci\xf3n."},"qwen2.5-coder-14b-instruct":{"description":"Versi\xf3n de c\xf3digo de c\xf3digo abierto del modelo Tongyi Qianwen."},"qwen2.5-coder-32b-instruct":{"description":"Versi\xf3n de c\xf3digo abierto del modelo de c\xf3digo Qwen de Tongyi."},"qwen2.5-coder-7b-instruct":{"description":"La versi\xf3n de c\xf3digo abierto del modelo de c\xf3digo Tongyi Qwen."},"qwen2.5-coder-instruct":{"description":"Qwen2.5-Coder es el modelo de lenguaje de gran tama\xf1o m\xe1s reciente de la serie Qwen especializado en c\xf3digo (anteriormente conocido como CodeQwen)."},"qwen2.5-instruct":{"description":"Qwen2.5 es la \xfaltima serie de modelos de lenguaje extenso Qwen. Para Qwen2.5, hemos lanzado varios modelos de lenguaje base y modelos de lenguaje ajustados por instrucciones, con par\xe1metros que van desde 500 millones hasta 7.2 mil millones."},"qwen2.5-math-1.5b-instruct":{"description":"El modelo Qwen-Math tiene habilidades poderosas para resolver problemas matem\xe1ticos."},"qwen2.5-math-72b-instruct":{"description":"El modelo Qwen-Math tiene una poderosa capacidad para resolver problemas matem\xe1ticos."},"qwen2.5-math-7b-instruct":{"description":"El modelo Qwen-Math tiene una poderosa capacidad para resolver problemas matem\xe1ticos."},"qwen2.5-omni-7b":{"description":"La serie de modelos Qwen-Omni admite la entrada de datos de m\xfaltiples modalidades, incluyendo video, audio, im\xe1genes y texto, y produce audio y texto como salida."},"qwen2.5-vl-32b-instruct":{"description":"Qwen2.5 VL 32B Instruct, modelo multimodal de c\xf3digo abierto, ideal para despliegue privado y aplicaciones en diversos escenarios."},"qwen2.5-vl-72b-instruct":{"description":"Mejora general en seguimiento de instrucciones, matem\xe1ticas, resoluci\xf3n de problemas y c\xf3digo, con capacidades de reconocimiento de objetos mejoradas, soporta formatos diversos para localizar elementos visuales con precisi\xf3n, y puede entender archivos de video largos (hasta 10 minutos) y localizar eventos en segundos, comprendiendo la secuencia y velocidad del tiempo, soportando el control de agentes en OS o m\xf3viles, con fuerte capacidad de extracci\xf3n de informaci\xf3n clave y salida en formato Json. Esta versi\xf3n es la de 72B, la m\xe1s potente de la serie."},"qwen2.5-vl-7b-instruct":{"description":"Qwen2.5 VL 7B Instruct, modelo multimodal ligero, que equilibra coste de implementaci\xf3n y capacidad de reconocimiento."},"qwen2.5-vl-instruct":{"description":"Qwen2.5-VL es la \xfaltima versi\xf3n del modelo de lenguaje visual de la familia de modelos Qwen."},"qwen2.5:0.5b":{"description":"Qwen2.5 es la nueva generaci\xf3n de modelos de lenguaje a gran escala de Alibaba, que ofrece un rendimiento excepcional para satisfacer diversas necesidades de aplicaci\xf3n."},"qwen2.5:1.5b":{"description":"Qwen2.5 es la nueva generaci\xf3n de modelos de lenguaje a gran escala de Alibaba, que ofrece un rendimiento excepcional para satisfacer diversas necesidades de aplicaci\xf3n."},"qwen2.5:72b":{"description":"Qwen2.5 es la nueva generaci\xf3n de modelos de lenguaje a gran escala de Alibaba, que ofrece un rendimiento excepcional para satisfacer diversas necesidades de aplicaci\xf3n."},"qwen2:0.5b":{"description":"Qwen2 es el nuevo modelo de lenguaje a gran escala de Alibaba, que ofrece un rendimiento excepcional para satisfacer diversas necesidades de aplicaci\xf3n."},"qwen2:1.5b":{"description":"Qwen2 es el nuevo modelo de lenguaje a gran escala de Alibaba, que ofrece un rendimiento excepcional para satisfacer diversas necesidades de aplicaci\xf3n."},"qwen2:72b":{"description":"Qwen2 es el nuevo modelo de lenguaje a gran escala de Alibaba, que ofrece un rendimiento excepcional para satisfacer diversas necesidades de aplicaci\xf3n."},"qwen3":{"description":"Qwen3 es la nueva generaci\xf3n de modelo de lenguaje a gran escala de Alibaba, que ofrece un rendimiento excepcional para satisfacer diversas necesidades de aplicaci\xf3n."},"qwen3-0.6b":{"description":"Qwen3 0.6B, modelo de nivel inicial, adecuado para razonamiento simple y entornos con recursos extremadamente limitados."},"qwen3-1.7b":{"description":"Qwen3 1.7B, modelo ultraligero, f\xe1cil de implementar en dispositivos perif\xe9ricos y terminales."},"qwen3-14b":{"description":"Qwen3 14B, modelo de tama\xf1o medio, ideal para generaci\xf3n de texto y preguntas multiling\xfces."},"qwen3-235b-a22b":{"description":"Qwen3 235B A22B, modelo general de gran tama\xf1o, orientado a tareas complejas diversas."},"qwen3-235b-a22b-instruct-2507":{"description":"Qwen3 235B A22B Instruct 2507, modelo insignia de instrucciones, ideal para generaci\xf3n y razonamiento en m\xfaltiples tareas."},"qwen3-235b-a22b-thinking-2507":{"description":"Qwen3 235B A22B Thinking 2507, modelo de pensamiento a gran escala, dise\xf1ado para razonamiento de alta dificultad."},"qwen3-30b-a3b":{"description":"Qwen3 30B A3B, modelo general de tama\xf1o medio a grande, equilibrado entre coste y rendimiento."},"qwen3-30b-a3b-instruct-2507":{"description":"Qwen3 30B A3B Instruct 2507, modelo de instrucciones de tama\xf1o medio a grande, ideal para generaci\xf3n y preguntas de alta calidad."},"qwen3-30b-a3b-thinking-2507":{"description":"Qwen3 30B A3B Thinking 2507, modelo de pensamiento de tama\xf1o medio a grande, que equilibra precisi\xf3n y coste."},"qwen3-32b":{"description":"Qwen3 32B, adecuado para tareas generales que requieren mayor capacidad de comprensi\xf3n."},"qwen3-4b":{"description":"Qwen3 4B, ideal para aplicaciones peque\xf1as y medianas y escenarios de inferencia local."},"qwen3-8b":{"description":"Qwen3 8B, modelo ligero, implementaci\xf3n flexible, adecuado para servicios de alta concurrencia."},"qwen3-coder-30b-a3b-instruct":{"description":"Versi\xf3n de c\xf3digo abierto del modelo de codificaci\xf3n Tongyi Qianwen. El nuevo qwen3-coder-30b-a3b-instruct, basado en Qwen3, es un modelo de generaci\xf3n de c\xf3digo con potentes capacidades como Agente de Programaci\xf3n, especializado en llamadas a herramientas e interacci\xf3n con entornos, capaz de programar de forma aut\xf3noma con habilidades de codificaci\xf3n sobresalientes y capacidades generales."},"qwen3-coder-480b-a35b-instruct":{"description":"Qwen3 Coder 480B A35B Instruct, modelo insignia para programaci\xf3n, compatible con m\xfaltiples lenguajes y comprensi\xf3n de c\xf3digo complejo."},"qwen3-coder-flash":{"description":"Modelo de c\xf3digo Tongyi Qianwen. La \xfaltima serie de modelos Qwen3-Coder est\xe1 basada en Qwen3 para generaci\xf3n de c\xf3digo, con una potente capacidad de agente de codificaci\xf3n, experta en llamadas a herramientas e interacci\xf3n con el entorno, capaz de programaci\xf3n aut\xf3noma, combinando una excelente habilidad en c\xf3digo con capacidades generales."},"qwen3-coder-plus":{"description":"Modelo de c\xf3digo Tongyi Qianwen. La \xfaltima serie de modelos Qwen3-Coder est\xe1 basada en Qwen3 para generaci\xf3n de c\xf3digo, con una potente capacidad de agente de codificaci\xf3n, experta en llamadas a herramientas e interacci\xf3n con el entorno, capaz de programaci\xf3n aut\xf3noma, combinando una excelente habilidad en c\xf3digo con capacidades generales."},"qwen3-coder:480b":{"description":"Modelo de contexto largo de alto rendimiento de Alibaba, optimizado para tareas de agentes y codificaci\xf3n."},"qwen3-max":{"description":"La serie Max de Tongyi Qianwen 3 representa una mejora significativa en la capacidad general respecto a la serie 2.5, con habilidades mejoradas en comprensi\xf3n de texto en chino e ingl\xe9s, seguimiento de instrucciones complejas, tareas abiertas subjetivas, multiling\xfcismo y llamadas a herramientas; adem\xe1s, reduce las alucinaciones de conocimiento del modelo. La \xfaltima versi\xf3n qwen3-max ha sido especialmente mejorada en programaci\xf3n de agentes y llamadas a herramientas respecto a la versi\xf3n previa qwen3-max-preview. El modelo oficial lanzado alcanza un nivel SOTA en su campo, adapt\xe1ndose a demandas m\xe1s complejas de agentes."},"qwen3-max-preview":{"description":"El modelo m\xe1s avanzado de la serie Tongyi Qianwen, ideal para tareas complejas y de m\xfaltiples pasos. La versi\xf3n preliminar ya admite razonamiento."},"qwen3-next-80b-a3b-instruct":{"description":"Modelo de c\xf3digo abierto de nueva generaci\xf3n basado en Qwen3 en modo no reflexivo, que ofrece una mejor comprensi\xf3n del texto en chino, mayor capacidad de razonamiento l\xf3gico y un mejor desempe\xf1o en tareas de generaci\xf3n de texto en comparaci\xf3n con la versi\xf3n anterior (Tongyi Qianwen 3-235B-A22B-Instruct-2507)."},"qwen3-next-80b-a3b-thinking":{"description":"Qwen3 Next 80B A3B Thinking, versi\xf3n insignia de razonamiento orientada a tareas complejas."},"qwen3-omni-flash":{"description":"El modelo Qwen-Omni puede recibir entradas combinadas de texto, im\xe1genes, audio y video, y generar respuestas en forma de texto o voz. Ofrece m\xfaltiples voces humanizadas, admite salida de voz en varios idiomas y dialectos, y puede aplicarse en escenarios como creaci\xf3n de texto, reconocimiento visual y asistentes de voz."},"qwen3-vl-235b-a22b-instruct":{"description":"Qwen3 VL 235B A22B Instruct, modelo multimodal insignia, orientado a escenarios exigentes de comprensi\xf3n y creaci\xf3n."},"qwen3-vl-235b-a22b-thinking":{"description":"Qwen3 VL 235B A22B Thinking, versi\xf3n de pensamiento insignia, dise\xf1ada para tareas complejas de razonamiento y planificaci\xf3n multimodal."},"qwen3-vl-30b-a3b-instruct":{"description":"Qwen3 VL 30B A3B Instruct, modelo multimodal de gran tama\xf1o, que equilibra precisi\xf3n y rendimiento de razonamiento."},"qwen3-vl-30b-a3b-thinking":{"description":"Qwen3 VL 30B A3B Thinking, versi\xf3n de pensamiento para tareas multimodales complejas."},"qwen3-vl-32b-instruct":{"description":"Qwen3 VL 32B Instruct, modelo multimodal ajustado por instrucciones, ideal para preguntas y creaci\xf3n de alta calidad con texto e imagen."},"qwen3-vl-32b-thinking":{"description":"Qwen3 VL 32B Thinking, versi\xf3n de pensamiento multimodal, reforzada para razonamiento complejo y an\xe1lisis de cadenas largas."},"qwen3-vl-8b-instruct":{"description":"Qwen3 VL 8B Instruct, modelo multimodal ligero, adecuado para preguntas visuales cotidianas e integraci\xf3n en aplicaciones."},"qwen3-vl-8b-thinking":{"description":"Qwen3 VL 8B Thinking, modelo de cadena de pensamiento multimodal, ideal para razonamiento detallado sobre informaci\xf3n visual."},"qwen3-vl-flash":{"description":"Qwen3 VL Flash: versi\xf3n ligera de inferencia r\xe1pida, ideal para escenarios sensibles a la latencia o con solicitudes en gran volumen."},"qwen3-vl-plus":{"description":"Tongyi Qianwen VL es un modelo generativo de texto con capacidad de comprensi\xf3n visual (im\xe1genes). No solo puede realizar OCR (reconocimiento de texto en im\xe1genes), sino tambi\xe9n resumir y razonar, por ejemplo, extrayendo atributos de fotos de productos o resolviendo problemas a partir de im\xe1genes de ejercicios."},"qwq":{"description":"QwQ es un modelo de investigaci\xf3n experimental que se centra en mejorar la capacidad de razonamiento de la IA."},"qwq-32b":{"description":"El modelo de inferencia QwQ, entrenado con el modelo Qwen2.5-32B, ha mejorado significativamente su capacidad de inferencia a trav\xe9s del aprendizaje por refuerzo. Los indicadores clave del modelo, como el c\xf3digo matem\xe1tico y otros indicadores centrales (AIME 24/25, LiveCodeBench), as\xed como algunos indicadores generales (IFEval, LiveBench, etc.), han alcanzado el nivel del modelo DeepSeek-R1 en su versi\xf3n completa, superando notablemente a DeepSeek-R1-Distill-Qwen-32B, que tambi\xe9n se basa en Qwen2.5-32B."},"qwq-32b-preview":{"description":"El modelo QwQ es un modelo de investigaci\xf3n experimental desarrollado por el equipo de Qwen, enfocado en mejorar la capacidad de razonamiento de la IA."},"qwq-plus":{"description":"Modelo de razonamiento QwQ basado en el modelo Qwen2.5, que mejora significativamente la capacidad de razonamiento mediante aprendizaje reforzado. Los indicadores clave en matem\xe1ticas y c\xf3digo (AIME 24/25, LiveCodeBench) y algunos indicadores generales (IFEval, LiveBench, etc.) alcanzan el nivel completo de DeepSeek-R1."},"qwq_32b":{"description":"Modelo de inferencia de tama\xf1o mediano de la serie Qwen. En comparaci\xf3n con los modelos tradicionales de ajuste por instrucciones, QwQ, que posee capacidades de pensamiento y razonamiento, puede mejorar significativamente el rendimiento en tareas de resoluci\xf3n de problemas, especialmente en tareas dif\xedciles."},"r1-1776":{"description":"R1-1776 es una versi\xf3n del modelo DeepSeek R1, que ha sido entrenada posteriormente para proporcionar informaci\xf3n factual sin censura y sin sesgos."},"solar-mini":{"description":"Solar Mini es un LLM compacto que supera a GPT-3.5, con potentes capacidades multiling\xfces, soportando ingl\xe9s y coreano, ofreciendo soluciones eficientes y compactas."},"solar-mini-ja":{"description":"Solar Mini (Ja) ampl\xeda las capacidades de Solar Mini, enfoc\xe1ndose en japon\xe9s, mientras mantiene un rendimiento eficiente y excelente en el uso de ingl\xe9s y coreano."},"solar-pro":{"description":"Solar Pro es un LLM de alta inteligencia lanzado por Upstage, enfocado en la capacidad de seguimiento de instrucciones en un solo GPU, con una puntuaci\xf3n IFEval superior a 80. Actualmente soporta ingl\xe9s, y se planea lanzar la versi\xf3n oficial en noviembre de 2024, ampliando el soporte de idiomas y la longitud del contexto."},"sonar":{"description":"Producto de b\xfasqueda ligero basado en contexto de b\xfasqueda, m\xe1s r\xe1pido y econ\xf3mico que Sonar Pro."},"sonar-deep-research":{"description":"Deep Research realiza una investigaci\xf3n exhaustiva a nivel de expertos y la compila en informes accesibles y pr\xe1cticos."},"sonar-pro":{"description":"Producto de b\xfasqueda avanzada que soporta contexto de b\xfasqueda, consultas avanzadas y seguimiento."},"sonar-reasoning":{"description":"Nuevo producto API respaldado por el modelo de razonamiento de DeepSeek."},"sonar-reasoning-pro":{"description":"Un nuevo producto API respaldado por el modelo de razonamiento DeepSeek."},"stable-diffusion-3-medium":{"description":"El \xfaltimo gran modelo de generaci\xf3n de im\xe1genes a partir de texto lanzado por Stability AI. Esta versi\xf3n mejora significativamente la calidad de imagen, comprensi\xf3n textual y diversidad de estilos, heredando las ventajas de generaciones anteriores. Puede interpretar con mayor precisi\xf3n indicaciones complejas en lenguaje natural y generar im\xe1genes m\xe1s precisas y variadas."},"stable-diffusion-3.5-large":{"description":"stable-diffusion-3.5-large es un modelo generativo multimodal de difusi\xf3n transformadora (MMDiT) con 800 millones de par\xe1metros, que ofrece calidad de imagen sobresaliente y alta correspondencia con las indicaciones. Soporta generaci\xf3n de im\xe1genes de alta resoluci\xf3n de hasta 1 mill\xf3n de p\xedxeles y funciona eficientemente en hardware de consumo com\xfan."},"stable-diffusion-3.5-large-turbo":{"description":"stable-diffusion-3.5-large-turbo es un modelo basado en stable-diffusion-3.5-large que utiliza tecnolog\xeda de destilaci\xf3n de difusi\xf3n adversarial (ADD) para lograr mayor velocidad."},"stable-diffusion-v1.5":{"description":"stable-diffusion-v1.5 se inicializa con pesos del punto de control stable-diffusion-v1.2 y se ajusta finamente durante 595k pasos a resoluci\xf3n 512x512 sobre \\"laion-aesthetics v2 5+\\", reduciendo en un 10% la condicionamiento textual para mejorar el muestreo guiado sin clasificador."},"stable-diffusion-xl":{"description":"stable-diffusion-xl presenta mejoras significativas respecto a la versi\xf3n v1.5 y ofrece resultados comparables al modelo SOTA de c\xf3digo abierto midjourney. Las mejoras incluyen un backbone unet tres veces mayor, un m\xf3dulo de refinamiento para mejorar la calidad de las im\xe1genes generadas y t\xe9cnicas de entrenamiento m\xe1s eficientes."},"stable-diffusion-xl-base-1.0":{"description":"Modelo generativo de im\xe1genes a partir de texto desarrollado y liberado por Stability AI, con capacidades creativas l\xedderes en la industria. Posee excelente comprensi\xf3n de instrucciones y soporta definiciones de contenido mediante prompts inversos para generaci\xf3n precisa."},"step-1-128k":{"description":"Equilibrio entre rendimiento y costo, adecuado para escenarios generales."},"step-1-256k":{"description":"Capacidad de procesamiento de contexto de longitud ultra larga, especialmente adecuada para an\xe1lisis de documentos largos."},"step-1-32k":{"description":"Soporta di\xe1logos de longitud media, adecuado para diversas aplicaciones."},"step-1-8k":{"description":"Modelo peque\xf1o, adecuado para tareas ligeras."},"step-1-flash":{"description":"Modelo de alta velocidad, adecuado para di\xe1logos en tiempo real."},"step-1.5v-mini":{"description":"Este modelo tiene una potente capacidad de comprensi\xf3n de video."},"step-1o-turbo-vision":{"description":"Este modelo tiene una poderosa capacidad de comprensi\xf3n de im\xe1genes, superando a 1o en matem\xe1ticas y programaci\xf3n. El modelo es m\xe1s peque\xf1o que 1o y tiene una velocidad de salida m\xe1s r\xe1pida."},"step-1o-vision-32k":{"description":"Este modelo posee una poderosa capacidad de comprensi\xf3n de im\xe1genes. En comparaci\xf3n con la serie de modelos step-1v, ofrece un rendimiento visual superior."},"step-1v-32k":{"description":"Soporta entradas visuales, mejorando la experiencia de interacci\xf3n multimodal."},"step-1v-8k":{"description":"Modelo visual peque\xf1o, adecuado para tareas b\xe1sicas de texto e imagen."},"step-1x-edit":{"description":"Modelo especializado en tareas de edici\xf3n de im\xe1genes, capaz de modificar y mejorar im\xe1genes seg\xfan descripciones textuales e im\xe1genes de ejemplo proporcionadas por el usuario. Entiende la intenci\xf3n del usuario y genera resultados de edici\xf3n de imagen que cumplen con los requisitos."},"step-1x-medium":{"description":"Modelo con fuerte capacidad de generaci\xf3n de im\xe1genes, que soporta entrada mediante descripciones textuales. Posee soporte nativo para chino, comprendiendo y procesando mejor descripciones en este idioma, capturando con mayor precisi\xf3n la sem\xe1ntica para convertirla en caracter\xedsticas visuales y lograr generaci\xf3n de im\xe1genes m\xe1s precisa. Puede generar im\xe1genes de alta resoluci\xf3n y calidad, con cierta capacidad de transferencia de estilo."},"step-2-16k":{"description":"Soporta interacciones de contexto a gran escala, adecuado para escenarios de di\xe1logo complejos."},"step-2-16k-exp":{"description":"Versi\xf3n experimental del modelo step-2, que incluye las caracter\xedsticas m\xe1s recientes y se actualiza continuamente. No se recomienda su uso en entornos de producci\xf3n formales."},"step-2-mini":{"description":"Un modelo de gran velocidad basado en la nueva arquitectura de atenci\xf3n autogestionada MFA, que logra efectos similares a los de step1 a un costo muy bajo, manteniendo al mismo tiempo un mayor rendimiento y tiempos de respuesta m\xe1s r\xe1pidos. Capaz de manejar tareas generales, con habilidades destacadas en programaci\xf3n."},"step-2x-large":{"description":"Nueva generaci\xf3n del modelo Step Star para generaci\xf3n de im\xe1genes, enfocado en tareas de generaci\xf3n basadas en texto, capaz de crear im\xe1genes de alta calidad seg\xfan descripciones proporcionadas por el usuario. El nuevo modelo produce im\xe1genes con texturas m\xe1s realistas y mejor capacidad para generar texto en chino e ingl\xe9s."},"step-3":{"description":"Este modelo cuenta con una destacada capacidad de percepci\xf3n visual y de razonamiento complejo. Es capaz de realizar con precisi\xf3n la comprensi\xf3n de conocimientos complejos entre distintos \xe1mbitos, el an\xe1lisis cruzado de informaci\xf3n matem\xe1tica y visual, as\xed como una amplia variedad de problemas de an\xe1lisis visual en la vida cotidiana."},"step-r1-v-mini":{"description":"Este modelo es un gran modelo de inferencia con una poderosa capacidad de comprensi\xf3n de im\xe1genes, capaz de procesar informaci\xf3n de im\xe1genes y texto, generando contenido textual tras un profundo razonamiento. Este modelo destaca en el campo del razonamiento visual, adem\xe1s de poseer capacidades de razonamiento matem\xe1tico, de c\xf3digo y textual de primer nivel. La longitud del contexto es de 100k."},"step3":{"description":"Step3 es un modelo multimodal desarrollado por StepStar, con potentes capacidades de comprensi\xf3n visual."},"stepfun-ai/step3":{"description":"Step3 es un modelo de inferencia multimodal de vanguardia publicado por 阶跃星辰 (StepFun), construido sobre una arquitectura Mixture-of-Experts (MoE) con 321B de par\xe1metros totales y 38B de par\xe1metros de activaci\xf3n. El modelo presenta un dise\xf1o de extremo a extremo orientado a minimizar el coste de decodificaci\xf3n, al tiempo que ofrece un rendimiento de primer nivel en razonamiento visual-ling\xfc\xedstico. Gracias al dise\xf1o sin\xe9rgico entre la atenci\xf3n por descomposici\xf3n de m\xfaltiples matrices (MFA) y el desacoplamiento atenci\xf3n‑FFN (AFD), Step3 mantiene una eficiencia sobresaliente tanto en aceleradores de gama alta como de gama baja. En la fase de preentrenamiento, Step3 proces\xf3 m\xe1s de 20T de tokens de texto y 4T de tokens mixtos imagen-texto, abarcando m\xe1s de una decena de idiomas. El modelo ha alcanzado niveles l\xedderes entre los modelos de c\xf3digo abierto en m\xfaltiples benchmarks, incluidos matem\xe1ticas, c\xf3digo y tareas multimodales."},"taichu_llm":{"description":"El modelo de lenguaje Taichu de Zīdōng tiene una poderosa capacidad de comprensi\xf3n del lenguaje, as\xed como habilidades en creaci\xf3n de textos, preguntas y respuestas, programaci\xf3n de c\xf3digo, c\xe1lculos matem\xe1ticos, razonamiento l\xf3gico, an\xe1lisis de sentimientos y res\xfamenes de texto. Combina de manera innovadora el preentrenamiento con grandes datos y un conocimiento rico de m\xfaltiples fuentes, perfeccionando continuamente la tecnolog\xeda algor\xedtmica y absorbiendo nuevos conocimientos en vocabulario, estructura, gram\xe1tica y sem\xe1ntica de grandes vol\xfamenes de datos textuales, logrando una evoluci\xf3n constante del modelo. Proporciona a los usuarios informaci\xf3n y servicios m\xe1s convenientes, as\xed como una experiencia m\xe1s inteligente."},"taichu_o1":{"description":"taichu_o1 es un nuevo modelo de inferencia de gran escala, que logra un razonamiento similar al humano a trav\xe9s de interacciones multimodales y aprendizaje por refuerzo, apoyando la deducci\xf3n de decisiones complejas, mostrando rutas de pensamiento modeladas mientras mantiene una alta precisi\xf3n en la salida, adecuado para an\xe1lisis de estrategias y razonamiento profundo."},"taichu_vl":{"description":"Integra capacidades de comprensi\xf3n de im\xe1genes, transferencia de conocimiento y atribuci\xf3n l\xf3gica, destac\xe1ndose en el campo de preguntas y respuestas basadas en texto e imagen."},"tencent/Hunyuan-A13B-Instruct":{"description":"Hunyuan-A13B-Instruct cuenta con 80 mil millones de par\xe1metros, activando solo 13 mil millones para igualar modelos m\xe1s grandes, soporta razonamiento h\xedbrido de \\"pensamiento r\xe1pido/pensamiento lento\\"; comprensi\xf3n estable de textos largos; validado por BFCL-v3 y τ-Bench, con capacidades avanzadas de agente; combina GQA y m\xfaltiples formatos de cuantificaci\xf3n para lograr inferencias eficientes."},"tencent/Hunyuan-MT-7B":{"description":"El modelo de traducci\xf3n Hunyuan (Hunyuan Translation Model) est\xe1 compuesto por el modelo de traducci\xf3n Hunyuan-MT-7B y el modelo integrado Hunyuan-MT-Chimera. Hunyuan-MT-7B es un modelo de traducci\xf3n ligero con 7 mil millones de par\xe1metros, dise\xf1ado para traducir texto fuente a un idioma objetivo. Admite traducci\xf3n entre 33 idiomas y 5 lenguas minoritarias chinas. En la competencia internacional de traducci\xf3n autom\xe1tica WMT25, Hunyuan-MT-7B obtuvo el primer lugar en 30 de las 31 categor\xedas ling\xfc\xedsticas en las que particip\xf3, demostrando su sobresaliente capacidad de traducci\xf3n. Para escenarios de traducci\xf3n, Tencent Hunyuan ha propuesto un paradigma de entrenamiento completo que abarca desde el preentrenamiento hasta el ajuste supervisado, seguido de refuerzo para traducci\xf3n e integraci\xf3n, logrando un rendimiento l\xedder en la industria entre modelos de tama\xf1o similar. El modelo es eficiente en c\xf3mputo, f\xe1cil de implementar y adecuado para m\xfaltiples aplicaciones."},"text-embedding-3-large":{"description":"El modelo de vectorizaci\xf3n m\xe1s potente, adecuado para tareas en ingl\xe9s y no ingl\xe9s."},"text-embedding-3-small":{"description":"Un modelo de Embedding de nueva generaci\xf3n, eficiente y econ\xf3mico, adecuado para la recuperaci\xf3n de conocimiento, aplicaciones RAG y m\xe1s."},"thudm/glm-4-32b":{"description":"GLM-4-32B-0414 es un modelo de lenguaje de pesos abiertos de 32B biling\xfce (chino-ingl\xe9s), optimizado para generaci\xf3n de c\xf3digo, llamadas a funciones y tareas de estilo agente. Ha sido preentrenado en 15T de datos de alta calidad y re-razonamiento, y se ha perfeccionado a\xfan m\xe1s utilizando alineaci\xf3n de preferencias humanas, muestreo de rechazo y aprendizaje por refuerzo. Este modelo destaca en razonamiento complejo, generaci\xf3n de artefactos y tareas de salida estructurada, alcanzando un rendimiento comparable al de GPT-4o y DeepSeek-V3-0324 en m\xfaltiples pruebas de referencia."},"thudm/glm-4-32b:free":{"description":"GLM-4-32B-0414 es un modelo de lenguaje de pesos abiertos de 32B biling\xfce (chino-ingl\xe9s), optimizado para generaci\xf3n de c\xf3digo, llamadas a funciones y tareas de estilo agente. Ha sido preentrenado en 15T de datos de alta calidad y re-razonamiento, y se ha perfeccionado a\xfan m\xe1s utilizando alineaci\xf3n de preferencias humanas, muestreo de rechazo y aprendizaje por refuerzo. Este modelo destaca en razonamiento complejo, generaci\xf3n de artefactos y tareas de salida estructurada, alcanzando un rendimiento comparable al de GPT-4o y DeepSeek-V3-0324 en m\xfaltiples pruebas de referencia."},"thudm/glm-4-9b-chat":{"description":"Versi\xf3n de c\xf3digo abierto de la \xfaltima generaci\xf3n del modelo preentrenado GLM-4 lanzado por Zhizhu AI."},"thudm/glm-z1-32b":{"description":"GLM-Z1-32B-0414 es una variante de razonamiento mejorada de GLM-4-32B, construida para resolver problemas de matem\xe1ticas profundas, l\xf3gica y orientados al c\xf3digo. Aplica aprendizaje por refuerzo extendido (espec\xedfico para tareas y basado en preferencias emparejadas generales) para mejorar el rendimiento en tareas complejas de m\xfaltiples pasos. En comparaci\xf3n con el modelo base GLM-4-32B, Z1 mejora significativamente las capacidades de razonamiento estructurado y en dominios formalizados.\\n\\nEste modelo admite la ejecuci\xf3n forzada de pasos de \'pensamiento\' a trav\xe9s de ingenier\xeda de indicaciones y proporciona una coherencia mejorada para salidas de formato largo. Est\xe1 optimizado para flujos de trabajo de agentes y admite contextos largos (a trav\xe9s de YaRN), llamadas a herramientas JSON y configuraciones de muestreo de alta precisi\xf3n para razonamiento estable. Es ideal para casos de uso que requieren razonamiento reflexivo, de m\xfaltiples pasos o deducci\xf3n formal."},"thudm/glm-z1-rumination-32b":{"description":"THUDM: GLM Z1 Rumination 32B es un modelo de razonamiento profundo de 32B par\xe1metros en la serie GLM-4-Z1, optimizado para tareas complejas y abiertas que requieren un pensamiento prolongado. Se basa en glm-4-32b-0414, a\xf1adiendo una fase adicional de aprendizaje por refuerzo y estrategias de alineaci\xf3n multietapa, introduciendo una capacidad de \'reflexi\xf3n\' dise\xf1ada para simular el procesamiento cognitivo extendido. Esto incluye razonamiento iterativo, an\xe1lisis de m\xfaltiples saltos y flujos de trabajo mejorados por herramientas, como b\xfasqueda, recuperaci\xf3n y s\xedntesis consciente de citas.\\n\\nEste modelo destaca en escritura de investigaci\xf3n, an\xe1lisis comparativo y preguntas complejas. Soporta llamadas a funciones para primitivos de b\xfasqueda y navegaci\xf3n (`search`, `click`, `open`, `finish`), lo que permite su uso en tuber\xedas de agentes. El comportamiento reflexivo est\xe1 moldeado por un control c\xedclico de m\xfaltiples rondas con mecanismos de recompensa basados en reglas y decisiones retrasadas, y se basa en marcos de investigaci\xf3n profunda como el stack de alineaci\xf3n interno de OpenAI. Esta variante es adecuada para escenarios que requieren profundidad en lugar de velocidad."},"tngtech/deepseek-r1t-chimera:free":{"description":"DeepSeek-R1T-Chimera se crea combinando DeepSeek-R1 y DeepSeek-V3 (0324), fusionando la capacidad de razonamiento de R1 con las mejoras de eficiencia de tokens de V3. Se basa en la arquitectura DeepSeek-MoE Transformer y est\xe1 optimizado para tareas generales de generaci\xf3n de texto.\\n\\nEste modelo combina los pesos preentrenados de los dos modelos fuente para equilibrar el rendimiento en razonamiento, eficiencia y tareas de seguimiento de instrucciones. Se publica bajo la licencia MIT, destinado a fines de investigaci\xf3n y comerciales."},"togethercomputer/StripedHyena-Nous-7B":{"description":"StripedHyena Nous (7B) proporciona una capacidad de c\xe1lculo mejorada a trav\xe9s de estrategias y arquitecturas de modelos eficientes."},"tts-1":{"description":"El modelo m\xe1s reciente de texto a voz, optimizado para velocidad en escenarios en tiempo real."},"tts-1-hd":{"description":"El modelo m\xe1s reciente de texto a voz, optimizado para calidad."},"upstage/SOLAR-10.7B-Instruct-v1.0":{"description":"Upstage SOLAR Instruct v1 (11B) es adecuado para tareas de instrucciones detalladas, ofreciendo una excelente capacidad de procesamiento de lenguaje."},"us.anthropic.claude-3-5-sonnet-20241022-v2:0":{"description":"Claude 3.5 Sonnet eleva el est\xe1ndar de la industria, superando a modelos competidores y a Claude 3 Opus, destac\xe1ndose en evaluaciones amplias, mientras mantiene la velocidad y costo de nuestros modelos de nivel medio."},"us.anthropic.claude-3-7-sonnet-20250219-v1:0":{"description":"Claude 3.7 sonnet es el modelo de pr\xf3xima generaci\xf3n m\xe1s r\xe1pido de Anthropic. En comparaci\xf3n con Claude 3 Haiku, Claude 3.7 Sonnet ha mejorado en todas las habilidades y ha superado al modelo m\xe1s grande de la generaci\xf3n anterior, Claude 3 Opus, en muchas pruebas de referencia de inteligencia."},"us.anthropic.claude-haiku-4-5-20251001-v1:0":{"description":"Claude Haiku 4.5 es el modelo Haiku m\xe1s r\xe1pido e inteligente de Anthropic, con una velocidad rel\xe1mpago y una capacidad de razonamiento ampliada."},"us.anthropic.claude-sonnet-4-5-20250929-v1:0":{"description":"Claude Sonnet 4.5 es el modelo m\xe1s inteligente desarrollado por Anthropic hasta la fecha."},"v0-1.0-md":{"description":"El modelo v0-1.0-md es una versi\xf3n antigua que ofrece servicios a trav\xe9s de la API v0"},"v0-1.5-lg":{"description":"El modelo v0-1.5-lg es adecuado para tareas avanzadas de pensamiento o razonamiento"},"v0-1.5-md":{"description":"El modelo v0-1.5-md es adecuado para tareas cotidianas y generaci\xf3n de interfaces de usuario (UI)"},"vercel/v0-1.0-md":{"description":"Acceso al modelo detr\xe1s de v0 para generar, reparar y optimizar aplicaciones web modernas, con razonamiento espec\xedfico para frameworks y conocimiento actualizado."},"vercel/v0-1.5-md":{"description":"Acceso al modelo detr\xe1s de v0 para generar, reparar y optimizar aplicaciones web modernas, con razonamiento espec\xedfico para frameworks y conocimiento actualizado."},"wan2.2-t2i-flash":{"description":"Versi\xf3n ultra r\xe1pida Wanxiang 2.2, el modelo m\xe1s reciente. Mejora integral en creatividad, estabilidad y realismo, con velocidad de generaci\xf3n r\xe1pida y alta relaci\xf3n calidad-precio."},"wan2.2-t2i-plus":{"description":"Versi\xf3n profesional Wanxiang 2.2, el modelo m\xe1s reciente. Mejora integral en creatividad, estabilidad y realismo, con generaci\xf3n de detalles ricos."},"wanx-v1":{"description":"Modelo base de generaci\xf3n de im\xe1genes a partir de texto, correspondiente al modelo general 1.0 del sitio oficial Tongyi Wanxiang."},"wanx2.0-t2i-turbo":{"description":"Especializado en retratos con textura, velocidad media y bajo costo. Corresponde al modelo ultra r\xe1pido 2.0 del sitio oficial Tongyi Wanxiang."},"wanx2.1-t2i-plus":{"description":"Versi\xf3n completamente mejorada. Genera im\xe1genes con detalles m\xe1s ricos, velocidad ligeramente m\xe1s lenta. Corresponde al modelo profesional 2.1 del sitio oficial Tongyi Wanxiang."},"wanx2.1-t2i-turbo":{"description":"Versi\xf3n completamente mejorada. Generaci\xf3n r\xe1pida, resultados completos y alta relaci\xf3n calidad-precio. Corresponde al modelo ultra r\xe1pido 2.1 del sitio oficial Tongyi Wanxiang."},"whisper-1":{"description":"Modelo universal de reconocimiento de voz que soporta reconocimiento de voz multiling\xfce, traducci\xf3n de voz y detecci\xf3n de idioma."},"wizardlm2":{"description":"WizardLM 2 es un modelo de lenguaje proporcionado por Microsoft AI, que destaca en di\xe1logos complejos, multiling\xfces, razonamiento y asistentes inteligentes."},"wizardlm2:8x22b":{"description":"WizardLM 2 es un modelo de lenguaje proporcionado por Microsoft AI, que destaca en di\xe1logos complejos, multiling\xfces, razonamiento y asistentes inteligentes."},"x-ai/grok-4-fast":{"description":"Nos complace presentar Grok 4 Fast, nuestro \xfaltimo avance en modelos de inferencia rentables."},"x-ai/grok-code-fast-1":{"description":"Nos complace lanzar grok-code-fast-1, un modelo de inferencia r\xe1pido y rentable con un rendimiento sobresaliente en codificaci\xf3n para agentes."},"x1":{"description":"El modelo Spark X1 se actualizar\xe1 a\xfan m\xe1s, logrando resultados en tareas generales como razonamiento, generaci\xf3n de texto y comprensi\xf3n del lenguaje que se comparan con OpenAI o1 y DeepSeek R1, adem\xe1s de liderar en tareas matem\xe1ticas en el pa\xeds."},"xai/grok-2":{"description":"Grok 2 es un modelo de lenguaje de vanguardia con capacidades de razonamiento avanzadas. Sobresale en chat, codificaci\xf3n y razonamiento, superando a Claude 3.5 Sonnet y GPT-4-Turbo en la clasificaci\xf3n LMSYS."},"xai/grok-2-vision":{"description":"El modelo visual Grok 2 sobresale en tareas basadas en visi\xf3n, ofreciendo un rendimiento de vanguardia en razonamiento matem\xe1tico visual (MathVista) y preguntas y respuestas basadas en documentos (DocVQA). Puede procesar diversos tipos de informaci\xf3n visual, incluyendo documentos, gr\xe1ficos, diagramas, capturas de pantalla y fotograf\xedas."},"xai/grok-3":{"description":"Modelo insignia de xAI que sobresale en casos de uso empresariales como extracci\xf3n de datos, codificaci\xf3n y resumen de texto. Posee un profundo conocimiento en finanzas, salud, derecho y ciencias."},"xai/grok-3-fast":{"description":"Modelo insignia de xAI que sobresale en casos de uso empresariales como extracci\xf3n de datos, codificaci\xf3n y resumen de texto. La variante r\xe1pida del modelo opera en infraestructura m\xe1s veloz, ofreciendo tiempos de respuesta mucho m\xe1s r\xe1pidos que el est\xe1ndar, a un costo mayor por token de salida."},"xai/grok-3-mini":{"description":"Modelo ligero de xAI que piensa antes de responder. Ideal para tareas simples o basadas en l\xf3gica que no requieren profundo conocimiento especializado. La trayectoria de pensamiento original es accesible."},"xai/grok-3-mini-fast":{"description":"Modelo ligero de xAI que piensa antes de responder. Ideal para tareas simples o basadas en l\xf3gica que no requieren profundo conocimiento especializado. La trayectoria de pensamiento original es accesible. La variante r\xe1pida del modelo opera en infraestructura m\xe1s veloz, ofreciendo tiempos de respuesta mucho m\xe1s r\xe1pidos que el est\xe1ndar, a un costo mayor por token de salida."},"xai/grok-4":{"description":"El modelo insignia m\xe1s reciente y avanzado de xAI, que ofrece un rendimiento inigualable en lenguaje natural, matem\xe1ticas y razonamiento, siendo un competidor perfecto y vers\xe1til."},"yi-large":{"description":"Modelo de mil millones de par\xe1metros completamente nuevo, que ofrece capacidades excepcionales de preguntas y respuestas y generaci\xf3n de texto."},"yi-large-fc":{"description":"Basado en el modelo yi-large, soporta y refuerza la capacidad de llamadas a herramientas, adecuado para diversos escenarios de negocio que requieren la construcci\xf3n de agentes o flujos de trabajo."},"yi-large-preview":{"description":"Versi\xf3n inicial, se recomienda usar yi-large (nueva versi\xf3n)."},"yi-large-rag":{"description":"Servicio de alto nivel basado en el modelo yi-large, combinando t\xe9cnicas de recuperaci\xf3n y generaci\xf3n para proporcionar respuestas precisas y servicios de b\xfasqueda de informaci\xf3n en tiempo real."},"yi-large-turbo":{"description":"Excelente relaci\xf3n calidad-precio y rendimiento excepcional. Ajuste de alta precisi\xf3n basado en el rendimiento, velocidad de razonamiento y costo."},"yi-lightning":{"description":"\xdaltimo modelo de alto rendimiento que garantiza una salida de alta calidad y mejora significativamente la velocidad de razonamiento."},"yi-lightning-lite":{"description":"Versi\xf3n ligera, se recomienda usar yi-lightning."},"yi-medium":{"description":"Modelo de tama\xf1o mediano, ajustado y equilibrado, con una buena relaci\xf3n calidad-precio. Optimizaci\xf3n profunda de la capacidad de seguimiento de instrucciones."},"yi-medium-200k":{"description":"Ventana de contexto de 200K, que ofrece una profunda comprensi\xf3n y generaci\xf3n de texto de largo formato."},"yi-spark":{"description":"Peque\xf1o y \xe1gil, modelo ligero y r\xe1pido. Ofrece capacidades mejoradas de c\xe1lculo matem\xe1tico y escritura de c\xf3digo."},"yi-vision":{"description":"Modelo para tareas visuales complejas, que ofrece un alto rendimiento en comprensi\xf3n y an\xe1lisis de im\xe1genes."},"yi-vision-v2":{"description":"Modelo para tareas visuales complejas, que ofrece capacidades de comprensi\xf3n y an\xe1lisis de alto rendimiento basadas en m\xfaltiples im\xe1genes."},"z-ai/glm-4.6":{"description":"El nuevo modelo insignia de Zhipu, GLM-4.6, supera ampliamente a su predecesor en codificaci\xf3n avanzada, procesamiento de textos largos, razonamiento y capacidades de agentes inteligentes."},"zai-org/GLM-4.5":{"description":"GLM-4.5 es un modelo base dise\xf1ado para aplicaciones de agentes inteligentes, utilizando arquitectura Mixture-of-Experts (MoE). Est\xe1 profundamente optimizado para llamadas a herramientas, navegaci\xf3n web, ingenier\xeda de software y programaci\xf3n frontend, soportando integraci\xf3n fluida con agentes de c\xf3digo como Claude Code y Roo Code. GLM-4.5 emplea un modo de inferencia h\xedbrido que se adapta a escenarios de razonamiento complejo y uso cotidiano."},"zai-org/GLM-4.5-Air":{"description":"GLM-4.5-Air es un modelo base dise\xf1ado para aplicaciones de agentes inteligentes, utilizando arquitectura Mixture-of-Experts (MoE). Est\xe1 profundamente optimizado para llamadas a herramientas, navegaci\xf3n web, ingenier\xeda de software y programaci\xf3n frontend, soportando integraci\xf3n fluida con agentes de c\xf3digo como Claude Code y Roo Code. GLM-4.5 emplea un modo de inferencia h\xedbrido que se adapta a escenarios de razonamiento complejo y uso cotidiano."},"zai-org/GLM-4.5V":{"description":"GLM-4.5V es la \xfaltima generaci\xf3n de modelo de lenguaje visual (VLM) publicada por Zhipu AI. Este modelo se basa en el modelo de texto insignia GLM-4.5-Air, que cuenta con 106.000 millones de par\xe1metros totales y 12.000 millones de par\xe1metros de activaci\xf3n, y emplea una arquitectura de expertos mixtos (MoE) para lograr un rendimiento excelente con un coste de inferencia reducido. T\xe9cnicamente, GLM-4.5V contin\xfaa la l\xednea de GLM-4.1V-Thinking e introduce innovaciones como el codificado rotacional de posiciones en 3D (3D-RoPE), que mejora de forma notable la percepci\xf3n y el razonamiento sobre las relaciones en el espacio tridimensional. Gracias a optimizaciones en preentrenamiento, ajuste supervisado y aprendizaje por refuerzo, este modelo es capaz de procesar diversos tipos de contenido visual, como im\xe1genes, v\xeddeo y documentos largos, y ha alcanzado niveles punteros entre los modelos open source de su categor\xeda en 41 benchmarks multimodales p\xfablicos. Adem\xe1s, el modelo incorpora un interruptor de \'modo de pensamiento\' que permite a los usuarios alternar entre respuestas r\xe1pidas y razonamiento profundo para equilibrar eficiencia y rendimiento."},"zai-org/GLM-4.6":{"description":"En comparaci\xf3n con GLM-4.5, GLM-4.6 presenta varias mejoras clave. Su ventana de contexto se ampli\xf3 de 128K a 200K tokens, permitiendo al modelo manejar tareas de agente m\xe1s complejas. El modelo obtuvo puntuaciones m\xe1s altas en pruebas de referencia de c\xf3digo y mostr\xf3 un rendimiento superior en aplicaciones como Claude Code, Cline, Roo Code y Kilo Code, incluyendo mejoras en la generaci\xf3n de interfaces front-end visualmente refinadas. GLM-4.6 exhibe un rendimiento de inferencia notablemente mejorado y soporta el uso de herramientas durante la inferencia, lo que aporta una capacidad integral m\xe1s fuerte. Destaca en el uso de herramientas y agentes basados en b\xfasqueda, y se integra de manera m\xe1s efectiva en marcos de agentes. En escritura, el modelo se ajusta mejor a las preferencias humanas en estilo y legibilidad, y se comporta de forma m\xe1s natural en escenarios de juego de roles."},"zai/glm-4.5":{"description":"La serie de modelos GLM-4.5 est\xe1 dise\xf1ada espec\xedficamente como modelos base para agentes inteligentes. El modelo insignia GLM-4.5 integra 355 mil millones de par\xe1metros totales (32 mil millones activos), unificando razonamiento, codificaci\xf3n y capacidades de agente para abordar demandas complejas de aplicaciones. Como sistema de razonamiento h\xedbrido, ofrece modos de operaci\xf3n dual."},"zai/glm-4.5-air":{"description":"GLM-4.5 y GLM-4.5-Air son nuestros modelos insignia m\xe1s recientes, dise\xf1ados espec\xedficamente como modelos base para aplicaciones de agentes. Ambos utilizan una arquitectura de expertos mixtos (MoE). GLM-4.5 tiene un total de 355 mil millones de par\xe1metros con 32 mil millones activos por pasada, mientras que GLM-4.5-Air presenta un dise\xf1o m\xe1s simplificado con 106 mil millones de par\xe1metros totales y 12 mil millones activos."},"zai/glm-4.5v":{"description":"GLM-4.5V est\xe1 construido sobre el modelo base GLM-4.5-Air, heredando la tecnolog\xeda verificada de GLM-4.1V-Thinking y logrando una escalabilidad eficiente mediante una potente arquitectura MoE de 106 mil millones de par\xe1metros."}}')}}]);