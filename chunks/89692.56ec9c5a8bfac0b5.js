"use strict";(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[89692],{89692:n=>{n.exports=JSON.parse('{"01-ai/yi-1.5-34b-chat":{"description":"Zero One Vạn Vật, m\xf4 h\xecnh tinh chỉnh m\xe3 nguồn mở mới nhất với 34 tỷ tham số, hỗ trợ nhiều t\xecnh huống đối thoại, dữ liệu đ\xe0o tạo chất lượng cao, ph\xf9 hợp với sở th\xedch của con người."},"01-ai/yi-1.5-9b-chat":{"description":"Zero One Vạn Vật, m\xf4 h\xecnh tinh chỉnh m\xe3 nguồn mở mới nhất với 9 tỷ tham số, hỗ trợ nhiều t\xecnh huống đối thoại, dữ liệu đ\xe0o tạo chất lượng cao, ph\xf9 hợp với sở th\xedch của con người."},"360/deepseek-r1":{"description":"【Phi\xean bản triển khai 360】DeepSeek-R1 đ\xe3 sử dụng c\xf4ng nghệ học tăng cường quy m\xf4 lớn trong giai đoạn huấn luyện sau, n\xe2ng cao khả năng suy luận của m\xf4 h\xecnh một c\xe1ch đ\xe1ng kể với rất \xedt dữ liệu được g\xe1n nh\xe3n. Hiệu suất trong c\xe1c nhiệm vụ to\xe1n học, m\xe3, suy luận ng\xf4n ngữ tự nhi\xean tương đương với phi\xean bản ch\xednh thức OpenAI o1."},"360gpt-pro":{"description":"360GPT Pro l\xe0 th\xe0nh vi\xean quan trọng trong d\xf2ng m\xf4 h\xecnh AI của 360, đ\xe1p ứng nhu cầu đa dạng của c\xe1c ứng dụng ng\xf4n ngữ tự nhi\xean với khả năng xử l\xfd văn bản hiệu quả, hỗ trợ hiểu văn bản d\xe0i v\xe0 đối thoại nhiều v\xf2ng."},"360gpt-pro-trans":{"description":"M\xf4 h\xecnh chuy\xean dụng cho dịch thuật, được tối ưu h\xf3a bằng c\xe1ch tinh chỉnh s\xe2u, mang lại hiệu quả dịch thuật h\xe0ng đầu."},"360gpt-turbo":{"description":"360GPT Turbo cung cấp khả năng t\xednh to\xe1n v\xe0 đối thoại mạnh mẽ, c\xf3 khả năng hiểu ngữ nghĩa v\xe0 hiệu suất tạo ra xuất sắc, l\xe0 giải ph\xe1p trợ l\xfd th\xf4ng minh l\xfd tưởng cho doanh nghiệp v\xe0 nh\xe0 ph\xe1t triển."},"360gpt-turbo-responsibility-8k":{"description":"360GPT Turbo Responsibility 8K nhấn mạnh an to\xe0n ngữ nghĩa v\xe0 định hướng tr\xe1ch nhiệm, được thiết kế đặc biệt cho c\xe1c t\xecnh huống ứng dụng c\xf3 y\xeau cầu cao về an to\xe0n nội dung, đảm bảo độ ch\xednh x\xe1c v\xe0 độ ổn định trong trải nghiệm người d\xf9ng."},"360gpt2-o1":{"description":"360gpt2-o1 sử dụng t\xecm kiếm c\xe2y để x\xe2y dựng chuỗi tư duy, v\xe0 đưa v\xe0o cơ chế phản hồi, sử dụng học tăng cường để đ\xe0o tạo, m\xf4 h\xecnh c\xf3 khả năng tự phản hồi v\xe0 sửa lỗi."},"360gpt2-pro":{"description":"360GPT2 Pro l\xe0 m\xf4 h\xecnh xử l\xfd ng\xf4n ngữ tự nhi\xean cao cấp do c\xf4ng ty 360 ph\xe1t h\xe0nh, c\xf3 khả năng tạo v\xe0 hiểu văn bản xuất sắc, đặc biệt trong lĩnh vực tạo ra v\xe0 s\xe1ng tạo, c\xf3 thể xử l\xfd c\xe1c nhiệm vụ chuyển đổi ng\xf4n ngữ phức tạp v\xe0 diễn xuất vai tr\xf2."},"360zhinao2-o1":{"description":"360zhinao2-o1 sử dụng t\xecm kiếm c\xe2y để x\xe2y dựng chuỗi tư duy, v\xe0 giới thiệu cơ chế phản hồi, sử dụng học tăng cường để đ\xe0o tạo, m\xf4 h\xecnh c\xf3 khả năng tự phản hồi v\xe0 sửa lỗi."},"4.0Ultra":{"description":"Spark4.0 Ultra l\xe0 phi\xean bản mạnh mẽ nhất trong d\xf2ng m\xf4 h\xecnh lớn Xinghuo, n\xe2ng cao khả năng hiểu v\xe0 t\xf3m tắt nội dung văn bản trong khi n\xe2ng cấp li\xean kết t\xecm kiếm trực tuyến. Đ\xe2y l\xe0 giải ph\xe1p to\xe0n diện nhằm n\xe2ng cao năng suất văn ph\xf2ng v\xe0 đ\xe1p ứng ch\xednh x\xe1c nhu cầu, l\xe0 sản phẩm th\xf4ng minh dẫn đầu ng\xe0nh."},"AnimeSharp":{"description":"AnimeSharp (c\xf2n gọi l\xe0 “4x‑AnimeSharp”) l\xe0 m\xf4 h\xecnh si\xeau ph\xe2n giải m\xe3 nguồn mở do Kim2091 ph\xe1t triển dựa tr\xean kiến tr\xfac ESRGAN, tập trung v\xe0o ph\xf3ng to v\xe0 l\xe0m sắc n\xe9t h\xecnh ảnh phong c\xe1ch anime. N\xf3 được đổi t\xean từ “4x-TextSharpV1” v\xe0o th\xe1ng 2 năm 2022, ban đầu cũng ph\xf9 hợp với h\xecnh ảnh văn bản nhưng đ\xe3 được tối ưu đ\xe1ng kể cho nội dung anime."},"Baichuan2-Turbo":{"description":"Sử dụng c\xf4ng nghệ tăng cường t\xecm kiếm để kết nối to\xe0n diện giữa m\xf4 h\xecnh lớn v\xe0 kiến thức lĩnh vực, kiến thức to\xe0n cầu. Hỗ trợ tải l\xean nhiều loại t\xe0i liệu như PDF, Word v\xe0 nhập URL, th\xf4ng tin được thu thập kịp thời v\xe0 to\xe0n diện, kết quả đầu ra ch\xednh x\xe1c v\xe0 chuy\xean nghiệp."},"Baichuan3-Turbo":{"description":"Tối ưu h\xf3a cho c\xe1c t\xecnh huống doanh nghiệp thường xuy\xean, hiệu quả được cải thiện đ\xe1ng kể, chi ph\xed hiệu quả cao. So với m\xf4 h\xecnh Baichuan2, s\xe1ng tạo nội dung tăng 20%, trả lời c\xe2u hỏi kiến thức tăng 17%, khả năng đ\xf3ng vai tăng 40%. Hiệu quả tổng thể tốt hơn GPT3.5."},"Baichuan3-Turbo-128k":{"description":"C\xf3 cửa sổ ngữ cảnh si\xeau d\xe0i 128K, tối ưu h\xf3a cho c\xe1c t\xecnh huống doanh nghiệp thường xuy\xean, hiệu quả được cải thiện đ\xe1ng kể, chi ph\xed hiệu quả cao. So với m\xf4 h\xecnh Baichuan2, s\xe1ng tạo nội dung tăng 20%, trả lời c\xe2u hỏi kiến thức tăng 17%, khả năng đ\xf3ng vai tăng 40%. Hiệu quả tổng thể tốt hơn GPT3.5."},"Baichuan4":{"description":"M\xf4 h\xecnh c\xf3 khả năng h\xe0ng đầu trong nước, vượt trội hơn c\xe1c m\xf4 h\xecnh ch\xednh thống nước ngo\xe0i trong c\xe1c nhiệm vụ tiếng Trung như b\xe1ch khoa to\xe0n thư, văn bản d\xe0i, s\xe1ng tạo nội dung. Cũng c\xf3 khả năng đa phương tiện h\xe0ng đầu trong ng\xe0nh, thể hiện xuất sắc trong nhiều ti\xeau chuẩn đ\xe1nh gi\xe1 uy t\xedn."},"Baichuan4-Air":{"description":"M\xf4 h\xecnh c\xf3 khả năng h\xe0ng đầu trong nước, vượt trội hơn c\xe1c m\xf4 h\xecnh ch\xednh thống nước ngo\xe0i trong c\xe1c nhiệm vụ tiếng Trung như b\xe1ch khoa to\xe0n thư, văn bản d\xe0i v\xe0 s\xe1ng tạo nội dung. Cũng c\xf3 khả năng đa phương tiện h\xe0ng đầu trong ng\xe0nh, thể hiện xuất sắc trong nhiều ti\xeau chuẩn đ\xe1nh gi\xe1 uy t\xedn."},"Baichuan4-Turbo":{"description":"M\xf4 h\xecnh c\xf3 khả năng h\xe0ng đầu trong nước, vượt trội hơn c\xe1c m\xf4 h\xecnh ch\xednh thống nước ngo\xe0i trong c\xe1c nhiệm vụ tiếng Trung như b\xe1ch khoa to\xe0n thư, văn bản d\xe0i v\xe0 s\xe1ng tạo nội dung. Cũng c\xf3 khả năng đa phương tiện h\xe0ng đầu trong ng\xe0nh, thể hiện xuất sắc trong nhiều ti\xeau chuẩn đ\xe1nh gi\xe1 uy t\xedn."},"ByteDance-Seed/Seed-OSS-36B-Instruct":{"description":"Seed-OSS l\xe0 một loạt c\xe1c m\xf4 h\xecnh ng\xf4n ngữ lớn m\xe3 nguồn mở do nh\xf3m Seed của ByteDance ph\xe1t triển, được thiết kế đặc biệt cho khả năng xử l\xfd ngữ cảnh d\xe0i mạnh mẽ, suy luận, t\xe1c nh\xe2n (agent) v\xe0 năng lực tổng qu\xe1t. Trong loạt n\xe0y, Seed-OSS-36B-Instruct l\xe0 một m\xf4 h\xecnh tinh chỉnh chỉ thị với 36 tỷ tham số, hỗ trợ ngữ cảnh si\xeau d\xe0i nguy\xean bản, cho ph\xe9p xử l\xfd một lượng lớn t\xe0i liệu hoặc kho m\xe3 phức tạp trong một lần. M\xf4 h\xecnh được tối ưu đặc biệt cho c\xe1c t\xe1c vụ suy luận, tạo m\xe3 v\xe0 t\xe1c nh\xe2n (như sử dụng c\xf4ng cụ), đồng thời duy tr\xec năng lực tổng qu\xe1t c\xe2n bằng v\xe0 xuất sắc. Một điểm nổi bật của m\xf4 h\xecnh n\xe0y l\xe0 t\xednh năng “Ng\xe2n s\xe1ch suy nghĩ” (Thinking Budget), cho ph\xe9p người d\xf9ng điều chỉnh linh hoạt độ d\xe0i suy luận theo nhu cầu, từ đ\xf3 n\xe2ng cao hiệu quả suy luận trong ứng dụng thực tế."},"DeepSeek-R1":{"description":"M\xf4 h\xecnh LLM hiệu quả ti\xean tiến nhất, xuất sắc trong suy luận, to\xe1n học v\xe0 lập tr\xecnh."},"DeepSeek-R1-Distill-Llama-70B":{"description":"DeepSeek R1 - m\xf4 h\xecnh lớn hơn v\xe0 th\xf4ng minh hơn trong bộ c\xf4ng cụ DeepSeek - đ\xe3 được chưng cất v\xe0o kiến tr\xfac Llama 70B. Dựa tr\xean c\xe1c b\xe0i kiểm tra v\xe0 đ\xe1nh gi\xe1 của con người, m\xf4 h\xecnh n\xe0y th\xf4ng minh hơn so với Llama 70B gốc, đặc biệt thể hiện xuất sắc trong c\xe1c nhiệm vụ y\xeau cầu độ ch\xednh x\xe1c về to\xe1n học v\xe0 sự thật."},"DeepSeek-R1-Distill-Qwen-1.5B":{"description":"M\xf4 h\xecnh chưng cất DeepSeek-R1 dựa tr\xean Qwen2.5-Math-1.5B, tối ưu h\xf3a hiệu suất suy luận th\xf4ng qua học tăng cường v\xe0 dữ liệu khởi động lạnh, m\xf4 h\xecnh m\xe3 nguồn mở l\xe0m mới ti\xeau chuẩn đa nhiệm."},"DeepSeek-R1-Distill-Qwen-14B":{"description":"M\xf4 h\xecnh chưng cất DeepSeek-R1 dựa tr\xean Qwen2.5-14B, tối ưu h\xf3a hiệu suất suy luận th\xf4ng qua học tăng cường v\xe0 dữ liệu khởi động lạnh, m\xf4 h\xecnh m\xe3 nguồn mở l\xe0m mới ti\xeau chuẩn đa nhiệm."},"DeepSeek-R1-Distill-Qwen-32B":{"description":"D\xf2ng DeepSeek-R1 tối ưu h\xf3a hiệu suất suy luận th\xf4ng qua học tăng cường v\xe0 dữ liệu khởi động lạnh, m\xf4 h\xecnh m\xe3 nguồn mở l\xe0m mới ti\xeau chuẩn đa nhiệm, vượt qua mức OpenAI-o1-mini."},"DeepSeek-R1-Distill-Qwen-7B":{"description":"M\xf4 h\xecnh chưng cất DeepSeek-R1 dựa tr\xean Qwen2.5-Math-7B, tối ưu h\xf3a hiệu suất suy luận th\xf4ng qua học tăng cường v\xe0 dữ liệu khởi động lạnh, m\xf4 h\xecnh m\xe3 nguồn mở l\xe0m mới ti\xeau chuẩn đa nhiệm."},"DeepSeek-V3":{"description":"DeepSeek-V3 l\xe0 một m\xf4 h\xecnh MoE do c\xf4ng ty DeepSeek tự ph\xe1t triển. Nhiều kết quả đ\xe1nh gi\xe1 của DeepSeek-V3 đ\xe3 vượt qua c\xe1c m\xf4 h\xecnh m\xe3 nguồn mở kh\xe1c như Qwen2.5-72B v\xe0 Llama-3.1-405B, v\xe0 về hiệu suất kh\xf4ng thua k\xe9m c\xe1c m\xf4 h\xecnh đ\xf3ng nguồn h\xe0ng đầu thế giới như GPT-4o v\xe0 Claude-3.5-Sonnet."},"DeepSeek-V3-1":{"description":"DeepSeek V3.1: M\xf4 h\xecnh suy luận thế hệ tiếp theo, n\xe2ng cao khả năng suy luận phức tạp v\xe0 tư duy chuỗi, ph\xf9 hợp cho c\xe1c nhiệm vụ cần ph\xe2n t\xedch s\xe2u."},"DeepSeek-V3-Fast":{"description":"Nh\xe0 cung cấp m\xf4 h\xecnh: nền tảng sophnet. DeepSeek V3 Fast l\xe0 phi\xean bản tốc độ cao TPS của DeepSeek V3 0324, kh\xf4ng lượng tử h\xf3a, c\xf3 khả năng m\xe3 h\xf3a v\xe0 to\xe1n học mạnh mẽ hơn, phản hồi nhanh hơn!"},"DeepSeek-V3.1":{"description":"DeepSeek-V3.1 - chế độ kh\xf4ng suy nghĩ; DeepSeek-V3.1 l\xe0 m\xf4 h\xecnh suy luận lai mới của DeepSeek, hỗ trợ hai chế độ suy luận l\xe0 suy nghĩ v\xe0 kh\xf4ng suy nghĩ, hiệu quả suy nghĩ cao hơn so với DeepSeek-R1-0528. Qua tối ưu hậu huấn luyện, hiệu suất sử dụng c\xf4ng cụ Agent v\xe0 c\xe1c t\xe1c vụ t\xe1c nh\xe2n được cải thiện đ\xe1ng kể."},"DeepSeek-V3.1-Fast":{"description":"DeepSeek V3.1 Fast l\xe0 phi\xean bản tốc độ cao TPS của DeepSeek V3.1. Chế độ suy nghĩ lai: th\xf4ng qua thay đổi mẫu tr\xf2 chuyện, một m\xf4 h\xecnh c\xf3 thể đồng thời hỗ trợ cả chế độ suy nghĩ v\xe0 kh\xf4ng suy nghĩ. Gọi c\xf4ng cụ th\xf4ng minh hơn: nhờ tối ưu hậu huấn luyện, m\xf4 h\xecnh thể hiện r\xf5 rệt sự cải thiện trong việc sử dụng c\xf4ng cụ v\xe0 c\xe1c t\xe1c vụ đại l\xfd."},"DeepSeek-V3.1-Think":{"description":"DeepSeek-V3.1 - chế độ suy nghĩ; DeepSeek-V3.1 l\xe0 m\xf4 h\xecnh suy luận lai mới của DeepSeek, hỗ trợ hai chế độ suy luận l\xe0 suy nghĩ v\xe0 kh\xf4ng suy nghĩ, hiệu quả suy nghĩ cao hơn so với DeepSeek-R1-0528. Qua tối ưu hậu huấn luyện, hiệu suất sử dụng c\xf4ng cụ Agent v\xe0 c\xe1c t\xe1c vụ t\xe1c nh\xe2n được cải thiện đ\xe1ng kể."},"DeepSeek-V3.2-Exp":{"description":"DeepSeek V3.2 l\xe0 m\xf4 h\xecnh lớn chung mới nhất của DeepSeek, hỗ trợ kiến tr\xfac suy luận hỗn hợp v\xe0 c\xf3 khả năng Agent mạnh mẽ hơn."},"DeepSeek-V3.2-Exp-Think":{"description":"Chế độ suy nghĩ của DeepSeek V3.2. Trước khi đưa ra c\xe2u trả lời cuối c\xf9ng, m\xf4 h\xecnh sẽ xuất ra một chuỗi suy nghĩ nhằm n\xe2ng cao độ ch\xednh x\xe1c của c\xe2u trả lời."},"Doubao-lite-128k":{"description":"Doubao-lite sở hữu tốc độ phản hồi tối ưu, hiệu quả chi ph\xed tốt hơn, cung cấp lựa chọn linh hoạt hơn cho c\xe1c kịch bản kh\xe1c nhau của kh\xe1ch h\xe0ng. Hỗ trợ suy luận v\xe0 tinh chỉnh với cửa sổ ngữ cảnh 128k."},"Doubao-lite-32k":{"description":"Doubao-lite sở hữu tốc độ phản hồi tối ưu, hiệu quả chi ph\xed tốt hơn, cung cấp lựa chọn linh hoạt hơn cho c\xe1c kịch bản kh\xe1c nhau của kh\xe1ch h\xe0ng. Hỗ trợ suy luận v\xe0 tinh chỉnh với cửa sổ ngữ cảnh 32k."},"Doubao-lite-4k":{"description":"Doubao-lite sở hữu tốc độ phản hồi tối ưu, hiệu quả chi ph\xed tốt hơn, cung cấp lựa chọn linh hoạt hơn cho c\xe1c kịch bản kh\xe1c nhau của kh\xe1ch h\xe0ng. Hỗ trợ suy luận v\xe0 tinh chỉnh với cửa sổ ngữ cảnh 4k."},"Doubao-pro-128k":{"description":"M\xf4 h\xecnh chủ lực với hiệu quả tốt nhất, ph\xf9 hợp xử l\xfd c\xe1c nhiệm vụ phức tạp, c\xf3 hiệu quả xuất sắc trong c\xe1c kịch bản như hỏi đ\xe1p tham khảo, t\xf3m tắt, s\xe1ng tạo, ph\xe2n loại văn bản, nhập vai. Hỗ trợ suy luận v\xe0 tinh chỉnh với cửa sổ ngữ cảnh 128k."},"Doubao-pro-32k":{"description":"M\xf4 h\xecnh chủ lực với hiệu quả tốt nhất, ph\xf9 hợp xử l\xfd c\xe1c nhiệm vụ phức tạp, c\xf3 hiệu quả xuất sắc trong c\xe1c kịch bản như hỏi đ\xe1p tham khảo, t\xf3m tắt, s\xe1ng tạo, ph\xe2n loại văn bản, nhập vai. Hỗ trợ suy luận v\xe0 tinh chỉnh với cửa sổ ngữ cảnh 32k."},"Doubao-pro-4k":{"description":"M\xf4 h\xecnh chủ lực với hiệu quả tốt nhất, ph\xf9 hợp xử l\xfd c\xe1c nhiệm vụ phức tạp, c\xf3 hiệu quả xuất sắc trong c\xe1c kịch bản như hỏi đ\xe1p tham khảo, t\xf3m tắt, s\xe1ng tạo, ph\xe2n loại văn bản, nhập vai. Hỗ trợ suy luận v\xe0 tinh chỉnh với cửa sổ ngữ cảnh 4k."},"DreamO":{"description":"DreamO l\xe0 m\xf4 h\xecnh tạo h\xecnh ảnh t\xf9y chỉnh m\xe3 nguồn mở do ByteDance v\xe0 Đại học Bắc Kinh hợp t\xe1c ph\xe1t triển, nhằm hỗ trợ tạo h\xecnh ảnh đa nhiệm th\xf4ng qua kiến tr\xfac thống nhất. N\xf3 sử dụng phương ph\xe1p m\xf4 h\xecnh h\xf3a kết hợp hiệu quả, c\xf3 thể tạo ra h\xecnh ảnh nhất qu\xe1n v\xe0 t\xf9y chỉnh cao dựa tr\xean c\xe1c điều kiện như danh t\xednh, chủ thể, phong c\xe1ch, nền do người d\xf9ng chỉ định."},"ERNIE-3.5-128K":{"description":"M\xf4 h\xecnh ng\xf4n ngữ quy m\xf4 lớn h\xe0ng đầu do Baidu tự ph\xe1t triển, bao phủ một lượng lớn t\xe0i liệu tiếng Trung v\xe0 tiếng Anh, c\xf3 khả năng tổng qu\xe1t mạnh mẽ, c\xf3 thể đ\xe1p ứng hầu hết c\xe1c y\xeau cầu về đối thoại, hỏi đ\xe1p, s\xe1ng tạo nội dung v\xe0 c\xe1c t\xecnh huống ứng dụng plugin; hỗ trợ tự động kết nối với plugin t\xecm kiếm của Baidu, đảm bảo th\xf4ng tin hỏi đ\xe1p lu\xf4n được cập nhật kịp thời."},"ERNIE-3.5-8K":{"description":"M\xf4 h\xecnh ng\xf4n ngữ quy m\xf4 lớn h\xe0ng đầu do Baidu tự ph\xe1t triển, bao phủ một lượng lớn t\xe0i liệu tiếng Trung v\xe0 tiếng Anh, c\xf3 khả năng tổng qu\xe1t mạnh mẽ, c\xf3 thể đ\xe1p ứng hầu hết c\xe1c y\xeau cầu về đối thoại, hỏi đ\xe1p, s\xe1ng tạo nội dung v\xe0 c\xe1c t\xecnh huống ứng dụng plugin; hỗ trợ tự động kết nối với plugin t\xecm kiếm của Baidu, đảm bảo th\xf4ng tin hỏi đ\xe1p lu\xf4n được cập nhật kịp thời."},"ERNIE-3.5-8K-Preview":{"description":"M\xf4 h\xecnh ng\xf4n ngữ quy m\xf4 lớn h\xe0ng đầu do Baidu tự ph\xe1t triển, bao phủ một lượng lớn t\xe0i liệu tiếng Trung v\xe0 tiếng Anh, c\xf3 khả năng tổng qu\xe1t mạnh mẽ, c\xf3 thể đ\xe1p ứng hầu hết c\xe1c y\xeau cầu về đối thoại, hỏi đ\xe1p, s\xe1ng tạo nội dung v\xe0 c\xe1c t\xecnh huống ứng dụng plugin; hỗ trợ tự động kết nối với plugin t\xecm kiếm của Baidu, đảm bảo th\xf4ng tin hỏi đ\xe1p lu\xf4n được cập nhật kịp thời."},"ERNIE-4.0-8K-Latest":{"description":"M\xf4 h\xecnh ng\xf4n ngữ quy m\xf4 si\xeau lớn h\xe0ng đầu do Baidu tự ph\xe1t triển, so với ERNIE 3.5 đ\xe3 n\xe2ng cấp to\xe0n diện khả năng của m\xf4 h\xecnh, ph\xf9 hợp rộng r\xe3i với c\xe1c nhiệm vụ phức tạp trong nhiều lĩnh vực; hỗ trợ tự động kết nối với plugin t\xecm kiếm Baidu, đảm bảo th\xf4ng tin hỏi đ\xe1p lu\xf4n cập nhật."},"ERNIE-4.0-8K-Preview":{"description":"M\xf4 h\xecnh ng\xf4n ngữ quy m\xf4 si\xeau lớn h\xe0ng đầu do Baidu tự ph\xe1t triển, so với ERNIE 3.5 đ\xe3 n\xe2ng cấp to\xe0n diện khả năng của m\xf4 h\xecnh, ph\xf9 hợp rộng r\xe3i với c\xe1c nhiệm vụ phức tạp trong nhiều lĩnh vực; hỗ trợ tự động kết nối với plugin t\xecm kiếm Baidu, đảm bảo th\xf4ng tin hỏi đ\xe1p lu\xf4n cập nhật."},"ERNIE-4.0-Turbo-8K-Latest":{"description":"M\xf4 h\xecnh ng\xf4n ngữ quy m\xf4 si\xeau lớn tự ph\xe1t triển của Baidu, c\xf3 hiệu suất tổng thể xuất sắc, ph\xf9 hợp rộng r\xe3i cho c\xe1c t\xecnh huống t\xe1c vụ phức tạp trong nhiều lĩnh vực; hỗ trợ tự động kết nối với plugin t\xecm kiếm của Baidu, đảm bảo t\xednh kịp thời của th\xf4ng tin c\xe2u hỏi đ\xe1p. So với ERNIE 4.0, n\xf3 c\xf3 hiệu suất tốt hơn."},"ERNIE-4.0-Turbo-8K-Preview":{"description":"M\xf4 h\xecnh ng\xf4n ngữ quy m\xf4 si\xeau lớn h\xe0ng đầu do Baidu tự ph\xe1t triển, c\xf3 hiệu suất tổng thể xuất sắc, ph\xf9 hợp rộng r\xe3i với c\xe1c nhiệm vụ phức tạp trong nhiều lĩnh vực; hỗ trợ tự động kết nối với plugin t\xecm kiếm Baidu, đảm bảo th\xf4ng tin hỏi đ\xe1p lu\xf4n cập nhật. So với ERNIE 4.0, hiệu suất tốt hơn."},"ERNIE-Character-8K":{"description":"M\xf4 h\xecnh ng\xf4n ngữ quy m\xf4 lớn cho c\xe1c t\xecnh huống chuy\xean biệt do Baidu tự ph\xe1t triển, ph\xf9 hợp cho c\xe1c ứng dụng như NPC trong game, đối thoại dịch vụ kh\xe1ch h\xe0ng, v\xe0 vai tr\xf2 trong đối thoại, phong c\xe1ch nh\xe2n vật r\xf5 r\xe0ng v\xe0 nhất qu\xe1n hơn, khả năng tu\xe2n thủ chỉ dẫn mạnh mẽ, hiệu suất suy diễn tốt hơn."},"ERNIE-Lite-Pro-128K":{"description":"M\xf4 h\xecnh ng\xf4n ngữ quy m\xf4 lớn nhẹ do Baidu tự ph\xe1t triển, kết hợp hiệu suất m\xf4 h\xecnh xuất sắc với khả năng suy diễn, hiệu quả tốt hơn ERNIE Lite, ph\xf9 hợp cho việc suy diễn tr\xean thẻ tăng tốc AI c\xf3 c\xf4ng suất thấp."},"ERNIE-Speed-128K":{"description":"M\xf4 h\xecnh ng\xf4n ngữ quy m\xf4 lớn hiệu suất cao do Baidu ph\xe1t h\xe0nh v\xe0o năm 2024, c\xf3 khả năng tổng qu\xe1t xuất sắc, ph\xf9 hợp l\xe0m m\xf4 h\xecnh nền để tinh chỉnh, xử l\xfd tốt hơn c\xe1c vấn đề trong c\xe1c t\xecnh huống cụ thể, đồng thời c\xf3 khả năng suy diễn tuyệt vời."},"ERNIE-Speed-Pro-128K":{"description":"M\xf4 h\xecnh ng\xf4n ngữ quy m\xf4 lớn hiệu suất cao do Baidu ph\xe1t h\xe0nh v\xe0o năm 2024, c\xf3 khả năng tổng qu\xe1t xuất sắc, hiệu quả tốt hơn ERNIE Speed, ph\xf9 hợp l\xe0m m\xf4 h\xecnh nền để tinh chỉnh, xử l\xfd tốt hơn c\xe1c vấn đề trong c\xe1c t\xecnh huống cụ thể, đồng thời c\xf3 khả năng suy diễn tuyệt vời."},"FLUX-1.1-pro":{"description":"FLUX.1.1 Pro"},"FLUX.1-Kontext-dev":{"description":"FLUX.1-Kontext-dev l\xe0 m\xf4 h\xecnh tạo v\xe0 chỉnh sửa h\xecnh ảnh đa phương thức dựa tr\xean kiến tr\xfac Rectified Flow Transformer do Black Forest Labs ph\xe1t triển, với quy m\xf4 12 tỷ tham số, tập trung v\xe0o việc tạo, t\xe1i cấu tr\xfac, n\xe2ng cao hoặc chỉnh sửa h\xecnh ảnh dựa tr\xean điều kiện ngữ cảnh cho trước. M\xf4 h\xecnh kết hợp ưu điểm tạo c\xf3 kiểm so\xe1t của m\xf4 h\xecnh khuếch t\xe1n v\xe0 khả năng m\xf4 h\xecnh h\xf3a ngữ cảnh của Transformer, hỗ trợ xuất h\xecnh ảnh chất lượng cao, ứng dụng rộng r\xe3i trong sửa chữa h\xecnh ảnh, ho\xe0n thiện h\xecnh ảnh, t\xe1i cấu tr\xfac cảnh quan trực quan."},"FLUX.1-Kontext-pro":{"description":"FLUX.1 Kontext [pro]"},"FLUX.1-dev":{"description":"FLUX.1-dev l\xe0 m\xf4 h\xecnh ng\xf4n ngữ đa phương thức m\xe3 nguồn mở do Black Forest Labs ph\xe1t triển, tối ưu cho c\xe1c t\xe1c vụ kết hợp h\xecnh ảnh v\xe0 văn bản. N\xf3 t\xedch hợp khả năng hiểu v\xe0 tạo h\xecnh ảnh c\xf9ng văn bản, x\xe2y dựng tr\xean nền tảng c\xe1c m\xf4 h\xecnh ng\xf4n ngữ lớn ti\xean tiến như Mistral-7B, th\xf4ng qua bộ m\xe3 h\xf3a thị gi\xe1c thiết kế tinh vi v\xe0 điều chỉnh chỉ dẫn đa giai đoạn, đạt được khả năng xử l\xfd phối hợp h\xecnh ảnh-văn bản v\xe0 suy luận t\xe1c vụ phức tạp."},"Gryphe/MythoMax-L2-13b":{"description":"MythoMax-L2 (13B) l\xe0 một m\xf4 h\xecnh s\xe1ng tạo, ph\xf9 hợp cho nhiều lĩnh vực ứng dụng v\xe0 nhiệm vụ phức tạp."},"HelloMeme":{"description":"HelloMeme l\xe0 c\xf4ng cụ AI c\xf3 thể tự động tạo meme, ảnh động hoặc video ngắn dựa tr\xean h\xecnh ảnh hoặc h\xe0nh động bạn cung cấp. Bạn kh\xf4ng cần c\xf3 kỹ năng vẽ hay lập tr\xecnh, chỉ cần chuẩn bị h\xecnh ảnh tham khảo, n\xf3 sẽ gi\xfap bạn tạo ra nội dung đẹp mắt, th\xfa vị v\xe0 đồng nhất về phong c\xe1ch."},"HiDream-I1-Full":{"description":"HiDream-E1-Full l\xe0 m\xf4 h\xecnh chỉnh sửa h\xecnh ảnh đa phương thức m\xe3 nguồn mở do HiDream.ai ph\xe1t triển, dựa tr\xean kiến tr\xfac Diffusion Transformer ti\xean tiến v\xe0 kết hợp khả năng hiểu ng\xf4n ngữ mạnh mẽ (t\xedch hợp LLaMA 3.1-8B-Instruct). M\xf4 h\xecnh hỗ trợ tạo h\xecnh ảnh, chuyển đổi phong c\xe1ch, chỉnh sửa cục bộ v\xe0 vẽ lại nội dung qua chỉ dẫn ng\xf4n ngữ tự nhi\xean, c\xf3 khả năng hiểu v\xe0 thực thi tốt giữa h\xecnh ảnh v\xe0 văn bản."},"HunyuanDiT-v1.2-Diffusers-Distilled":{"description":"hunyuandit-v1.2-distilled l\xe0 m\xf4 h\xecnh tạo h\xecnh ảnh từ văn bản nhẹ, được tối ưu qua kỹ thuật chưng cất, c\xf3 khả năng tạo h\xecnh ảnh chất lượng cao nhanh ch\xf3ng, đặc biệt ph\xf9 hợp với m\xf4i trường t\xe0i nguy\xean thấp v\xe0 c\xe1c t\xe1c vụ tạo h\xecnh ảnh thời gian thực."},"InstantCharacter":{"description":"InstantCharacter l\xe0 m\xf4 h\xecnh tạo nh\xe2n vật c\xe1 nh\xe2n h\xf3a kh\xf4ng cần tinh chỉnh do đội AI Tencent ph\xe1t h\xe0nh năm 2025, nhằm đạt được tạo nh\xe2n vật nhất qu\xe1n, độ trung thực cao v\xe0 đa cảnh. M\xf4 h\xecnh hỗ trợ x\xe2y dựng nh\xe2n vật chỉ dựa tr\xean một h\xecnh ảnh tham khảo v\xe0 c\xf3 thể linh hoạt chuyển nh\xe2n vật đ\xf3 sang nhiều phong c\xe1ch, h\xe0nh động v\xe0 nền kh\xe1c nhau."},"InternVL2-8B":{"description":"InternVL2-8B l\xe0 một m\xf4 h\xecnh ng\xf4n ngữ h\xecnh ảnh mạnh mẽ, hỗ trợ xử l\xfd đa phương tiện giữa h\xecnh ảnh v\xe0 văn bản, c\xf3 khả năng nhận diện ch\xednh x\xe1c nội dung h\xecnh ảnh v\xe0 tạo ra m\xf4 tả hoặc c\xe2u trả lời li\xean quan."},"InternVL2.5-26B":{"description":"InternVL2.5-26B l\xe0 một m\xf4 h\xecnh ng\xf4n ngữ h\xecnh ảnh mạnh mẽ, hỗ trợ xử l\xfd đa phương tiện giữa h\xecnh ảnh v\xe0 văn bản, c\xf3 khả năng nhận diện ch\xednh x\xe1c nội dung h\xecnh ảnh v\xe0 tạo ra m\xf4 tả hoặc c\xe2u trả lời li\xean quan."},"Kolors":{"description":"Kolors l\xe0 m\xf4 h\xecnh tạo h\xecnh ảnh từ văn bản do nh\xf3m Kolors của Kuaishou ph\xe1t triển. Được huấn luyện tr\xean h\xe0ng tỷ tham số, nổi bật về chất lượng h\xecnh ảnh, hiểu ngữ nghĩa tiếng Trung v\xe0 khả năng hiển thị văn bản."},"Kwai-Kolors/Kolors":{"description":"Kolors l\xe0 m\xf4 h\xecnh tạo h\xecnh ảnh từ văn bản quy m\xf4 lớn dựa tr\xean khuếch t\xe1n tiềm ẩn do nh\xf3m Kolors của Kuaishou ph\xe1t triển. M\xf4 h\xecnh được huấn luyện tr\xean h\xe0ng tỷ cặp văn bản-h\xecnh ảnh, thể hiện ưu thế r\xf5 rệt về chất lượng h\xecnh ảnh, độ ch\xednh x\xe1c ngữ nghĩa phức tạp v\xe0 khả năng hiển thị k\xfd tự tiếng Trung v\xe0 tiếng Anh. N\xf3 hỗ trợ đầu v\xe0o tiếng Trung v\xe0 tiếng Anh, đồng thời thể hiện xuất sắc trong việc hiểu v\xe0 tạo nội dung đặc th\xf9 tiếng Trung."},"Kwaipilot/KAT-Dev":{"description":"KAT-Dev (32B) l\xe0 một m\xf4 h\xecnh m\xe3 nguồn mở với 32 tỷ tham số, được thiết kế đặc biệt cho c\xe1c t\xe1c vụ kỹ thuật phần mềm. Trong b\xe0i kiểm tra chuẩn SWE-Bench Verified, m\xf4 h\xecnh đạt tỷ lệ giải quyết 62,4%, xếp hạng thứ năm trong số c\xe1c m\xf4 h\xecnh m\xe3 nguồn mở c\xf3 quy m\xf4 kh\xe1c nhau. M\xf4 h\xecnh n\xe0y được tối ưu h\xf3a qua nhiều giai đoạn, bao gồm huấn luyện trung gian, tinh chỉnh c\xf3 gi\xe1m s\xe1t (SFT) v\xe0 học tăng cường (RL), nhằm cung cấp hỗ trợ mạnh mẽ cho c\xe1c nhiệm vụ lập tr\xecnh phức tạp như ho\xe0n th\xe0nh m\xe3, sửa lỗi, đ\xe1nh gi\xe1 m\xe3 v\xe0 nhiều hơn nữa."},"Llama-3.2-11B-Vision-Instruct":{"description":"Khả năng suy luận h\xecnh ảnh xuất sắc tr\xean h\xecnh ảnh độ ph\xe2n giải cao, ph\xf9 hợp cho c\xe1c ứng dụng hiểu biết thị gi\xe1c."},"Llama-3.2-90B-Vision-Instruct\\t":{"description":"Khả năng suy luận h\xecnh ảnh cao cấp cho c\xe1c ứng dụng đại l\xfd hiểu biết thị gi\xe1c."},"Meta-Llama-3-3-70B-Instruct":{"description":"Llama 3.3 70B: M\xf4 h\xecnh Transformer đa năng, th\xedch hợp cho c\xe1c nhiệm vụ đối thoại v\xe0 tạo nội dung."},"Meta-Llama-3.1-405B-Instruct":{"description":"M\xf4 h\xecnh văn bản được tinh chỉnh theo chỉ dẫn Llama 3.1, được tối ưu h\xf3a cho c\xe1c trường hợp sử dụng đối thoại đa ng\xf4n ngữ, thể hiện xuất sắc trong nhiều m\xf4 h\xecnh tr\xf2 chuyện m\xe3 nguồn mở v\xe0 đ\xf3ng c\xf3 sẵn tr\xean nhiều ti\xeau chuẩn ng\xe0nh."},"Meta-Llama-3.1-70B-Instruct":{"description":"M\xf4 h\xecnh văn bản được tinh chỉnh theo chỉ dẫn Llama 3.1, được tối ưu h\xf3a cho c\xe1c trường hợp sử dụng đối thoại đa ng\xf4n ngữ, thể hiện xuất sắc trong nhiều m\xf4 h\xecnh tr\xf2 chuyện m\xe3 nguồn mở v\xe0 đ\xf3ng c\xf3 sẵn tr\xean nhiều ti\xeau chuẩn ng\xe0nh."},"Meta-Llama-3.1-8B-Instruct":{"description":"M\xf4 h\xecnh văn bản được tinh chỉnh theo chỉ dẫn Llama 3.1, được tối ưu h\xf3a cho c\xe1c trường hợp sử dụng đối thoại đa ng\xf4n ngữ, thể hiện xuất sắc trong nhiều m\xf4 h\xecnh tr\xf2 chuyện m\xe3 nguồn mở v\xe0 đ\xf3ng c\xf3 sẵn tr\xean nhiều ti\xeau chuẩn ng\xe0nh."},"Meta-Llama-3.2-1B-Instruct":{"description":"M\xf4 h\xecnh ng\xf4n ngữ nhỏ ti\xean tiến nhất, c\xf3 khả năng hiểu ng\xf4n ngữ, khả năng suy luận xuất sắc v\xe0 khả năng sinh văn bản."},"Meta-Llama-3.2-3B-Instruct":{"description":"M\xf4 h\xecnh ng\xf4n ngữ nhỏ ti\xean tiến nhất, c\xf3 khả năng hiểu ng\xf4n ngữ, khả năng suy luận xuất sắc v\xe0 khả năng sinh văn bản."},"Meta-Llama-3.3-70B-Instruct":{"description":"Llama 3.3 l\xe0 m\xf4 h\xecnh ng\xf4n ngữ lớn m\xe3 nguồn mở đa ng\xf4n ngữ ti\xean tiến nhất trong d\xf2ng Llama, mang đến trải nghiệm hiệu suất tương đương m\xf4 h\xecnh 405B với chi ph\xed cực thấp. Dựa tr\xean cấu tr\xfac Transformer, v\xe0 được cải thiện t\xednh hữu \xedch v\xe0 an to\xe0n th\xf4ng qua tinh chỉnh gi\xe1m s\xe1t (SFT) v\xe0 học tăng cường từ phản hồi của con người (RLHF). Phi\xean bản tinh chỉnh theo chỉ dẫn của n\xf3 được tối ưu h\xf3a cho c\xe1c cuộc đối thoại đa ng\xf4n ngữ, thể hiện tốt hơn nhiều m\xf4 h\xecnh tr\xf2 chuyện m\xe3 nguồn mở v\xe0 đ\xf3ng trong nhiều ti\xeau chuẩn ng\xe0nh. Ng\xe0y cắt đứt kiến thức l\xe0 th\xe1ng 12 năm 2023."},"Meta-Llama-4-Maverick-17B-128E-Instruct-FP8":{"description":"Llama 4 Maverick: M\xf4 h\xecnh quy m\xf4 lớn dựa tr\xean Mixture-of-Experts, cung cấp chiến lược k\xedch hoạt chuy\xean gia hiệu quả để đạt hiệu suất xuất sắc trong suy luận."},"MiniMax-M1":{"description":"M\xf4 h\xecnh suy luận tự ph\xe1t triển ho\xe0n to\xe0n mới. Dẫn đầu to\xe0n cầu: 80K chuỗi tư duy x 1M đầu v\xe0o, hiệu quả s\xe1nh ngang với c\xe1c m\xf4 h\xecnh h\xe0ng đầu quốc tế"},"MiniMax-M2":{"description":"Được thiết kế đặc biệt cho lập tr\xecnh hiệu quả v\xe0 quy tr\xecnh l\xe0m việc của Agent"},"MiniMax-Text-01":{"description":"Trong d\xf2ng m\xf4 h\xecnh MiniMax-01, ch\xfang t\xf4i đ\xe3 thực hiện những đổi mới t\xe1o bạo: lần đầu ti\xean hiện thực h\xf3a quy m\xf4 lớn cơ chế ch\xfa \xfd tuyến t\xednh, kiến tr\xfac Transformer truyền thống kh\xf4ng c\xf2n l\xe0 lựa chọn duy nhất. M\xf4 h\xecnh n\xe0y c\xf3 số lượng tham số l\xean tới 4560 tỷ, trong đ\xf3 k\xedch hoạt một lần l\xe0 45,9 tỷ. Hiệu suất tổng hợp của m\xf4 h\xecnh tương đương với c\xe1c m\xf4 h\xecnh h\xe0ng đầu quốc tế, đồng thời c\xf3 khả năng xử l\xfd hiệu quả ngữ cảnh d\xe0i nhất to\xe0n cầu l\xean tới 4 triệu token, gấp 32 lần GPT-4o v\xe0 20 lần Claude-3.5-Sonnet."},"MiniMaxAI/MiniMax-M1-80k":{"description":"MiniMax-M1 l\xe0 m\xf4 h\xecnh suy luận ch\xfa \xfd hỗn hợp quy m\xf4 lớn với trọng số m\xe3 nguồn mở, sở hữu 456 tỷ 600 triệu tham số, mỗi Token c\xf3 thể k\xedch hoạt khoảng 45,9 tỷ tham số. M\xf4 h\xecnh hỗ trợ ngữ cảnh si\xeau d\xe0i l\xean đến 1 triệu Token một c\xe1ch nguy\xean bản, v\xe0 th\xf4ng qua cơ chế ch\xfa \xfd chớp nho\xe1ng, trong c\xe1c t\xe1c vụ sinh 100.000 Token tiết kiệm 75% lượng ph\xe9p t\xednh dấu chấm động so với DeepSeek R1. Đồng thời, MiniMax-M1 \xe1p dụng kiến tr\xfac MoE (chuy\xean gia hỗn hợp), kết hợp thuật to\xe1n CISPO v\xe0 thiết kế ch\xfa \xfd hỗn hợp trong huấn luyện tăng cường hiệu quả, đạt hiệu suất h\xe0ng đầu trong ng\xe0nh khi suy luận đầu v\xe0o d\xe0i v\xe0 c\xe1c kịch bản kỹ thuật phần mềm thực tế."},"MiniMaxAI/MiniMax-M2":{"description":"MiniMax-M2 t\xe1i định nghĩa hiệu suất cho c\xe1c t\xe1c nh\xe2n AI. Đ\xe2y l\xe0 một m\xf4 h\xecnh MoE nhỏ gọn, nhanh ch\xf3ng v\xe0 tiết kiệm chi ph\xed, với tổng số 230 tỷ tham số v\xe0 10 tỷ tham số k\xedch hoạt, được thiết kế để đạt hiệu năng h\xe0ng đầu trong c\xe1c t\xe1c vụ m\xe3 h\xf3a v\xe0 t\xe1c nh\xe2n, đồng thời duy tr\xec tr\xed tuệ nh\xe2n tạo tổng qu\xe1t mạnh mẽ. Chỉ với 10 tỷ tham số k\xedch hoạt, MiniMax-M2 c\xf3 thể mang lại hiệu suất tương đương với c\xe1c m\xf4 h\xecnh quy m\xf4 lớn, khiến n\xf3 trở th\xe0nh lựa chọn l\xfd tưởng cho c\xe1c ứng dụng hiệu suất cao."},"Moonshot-Kimi-K2-Instruct":{"description":"Tổng tham số 1T, tham số k\xedch hoạt 32B. Trong c\xe1c m\xf4 h\xecnh kh\xf4ng suy nghĩ, đạt tr\xecnh độ h\xe0ng đầu về kiến thức ti\xean tiến, to\xe1n học v\xe0 lập tr\xecnh, đặc biệt ph\xf9 hợp với c\xe1c t\xe1c vụ đại l\xfd chung. Được tối ưu kỹ lưỡng cho t\xe1c vụ đại l\xfd, kh\xf4ng chỉ trả lời c\xe2u hỏi m\xe0 c\xf2n c\xf3 thể thực hiện h\xe0nh động. Ph\xf9 hợp nhất cho tr\xf2 chuyện ứng biến, trải nghiệm đại l\xfd chung, l\xe0 m\xf4 h\xecnh phản xạ kh\xf4ng cần suy nghĩ l\xe2u."},"NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO":{"description":"Nous Hermes 2 - Mixtral 8x7B-DPO (46.7B) l\xe0 m\xf4 h\xecnh chỉ dẫn ch\xednh x\xe1c cao, ph\xf9 hợp cho t\xednh to\xe1n phức tạp."},"OmniConsistency":{"description":"OmniConsistency n\xe2ng cao t\xednh nhất qu\xe1n phong c\xe1ch v\xe0 khả năng tổng qu\xe1t h\xf3a trong c\xe1c t\xe1c vụ h\xecnh ảnh sang h\xecnh ảnh (Image-to-Image) bằng c\xe1ch giới thiệu c\xe1c Diffusion Transformers (DiTs) quy m\xf4 lớn v\xe0 dữ liệu phong c\xe1ch gh\xe9p đ\xf4i, tr\xe1nh suy giảm phong c\xe1ch."},"Phi-3-medium-128k-instruct":{"description":"M\xf4 h\xecnh Phi-3-medium giống nhau, nhưng với k\xedch thước ngữ cảnh lớn hơn cho RAG hoặc gợi \xfd \xedt."},"Phi-3-medium-4k-instruct":{"description":"M\xf4 h\xecnh 14B tham số, chứng minh chất lượng tốt hơn Phi-3-mini, tập trung v\xe0o dữ liệu d\xe0y đặc l\xfd luận chất lượng cao."},"Phi-3-mini-128k-instruct":{"description":"M\xf4 h\xecnh Phi-3-mini giống nhau, nhưng với k\xedch thước ngữ cảnh lớn hơn cho RAG hoặc gợi \xfd \xedt."},"Phi-3-mini-4k-instruct":{"description":"Th\xe0nh vi\xean nhỏ nhất của gia đ\xecnh Phi-3. Tối ưu h\xf3a cho cả chất lượng v\xe0 độ trễ thấp."},"Phi-3-small-128k-instruct":{"description":"M\xf4 h\xecnh Phi-3-small giống nhau, nhưng với k\xedch thước ngữ cảnh lớn hơn cho RAG hoặc gợi \xfd \xedt."},"Phi-3-small-8k-instruct":{"description":"M\xf4 h\xecnh 7B tham số, chứng minh chất lượng tốt hơn Phi-3-mini, tập trung v\xe0o dữ liệu d\xe0y đặc l\xfd luận chất lượng cao."},"Phi-3.5-mini-instruct":{"description":"Phi-3-mini l\xe0 phi\xean bản cập nhật của m\xf4 h\xecnh."},"Phi-3.5-vision-instrust":{"description":"Phi-3-vision l\xe0 phi\xean bản cập nhật của m\xf4 h\xecnh."},"Pro/Qwen/Qwen2-7B-Instruct":{"description":"Qwen2-7B-Instruct l\xe0 m\xf4 h\xecnh ng\xf4n ngữ lớn được tinh chỉnh theo chỉ dẫn trong loạt Qwen2, với quy m\xf4 tham số l\xe0 7B. M\xf4 h\xecnh n\xe0y dựa tr\xean kiến tr\xfac Transformer, sử dụng h\xe0m k\xedch hoạt SwiGLU, độ lệch QKV trong ch\xfa \xfd v\xe0 ch\xfa \xfd theo nh\xf3m. N\xf3 c\xf3 khả năng xử l\xfd đầu v\xe0o quy m\xf4 lớn. M\xf4 h\xecnh thể hiện xuất sắc trong nhiều b\xe0i kiểm tra chuẩn về hiểu ng\xf4n ngữ, sinh ng\xf4n ngữ, khả năng đa ng\xf4n ngữ, m\xe3 h\xf3a, to\xe1n học v\xe0 suy luận, vượt qua hầu hết c\xe1c m\xf4 h\xecnh m\xe3 nguồn mở v\xe0 thể hiện sức cạnh tranh tương đương với c\xe1c m\xf4 h\xecnh độc quyền trong một số nhiệm vụ. Qwen2-7B-Instruct đ\xe3 thể hiện sự cải thiện đ\xe1ng kể về hiệu suất trong nhiều b\xe0i kiểm tra so với Qwen1.5-7B-Chat."},"Pro/Qwen/Qwen2.5-7B-Instruct":{"description":"Qwen2.5-7B-Instruct l\xe0 một trong những m\xf4 h\xecnh ng\xf4n ngữ lớn mới nhất do Alibaba Cloud ph\xe1t h\xe0nh. M\xf4 h\xecnh 7B n\xe0y c\xf3 khả năng cải thiện đ\xe1ng kể trong c\xe1c lĩnh vực m\xe3 h\xf3a v\xe0 to\xe1n học. M\xf4 h\xecnh cũng cung cấp hỗ trợ đa ng\xf4n ngữ, bao gồm hơn 29 ng\xf4n ngữ, bao gồm tiếng Trung, tiếng Anh, v.v. M\xf4 h\xecnh đ\xe3 c\xf3 sự cải thiện đ\xe1ng kể trong việc tu\xe2n theo chỉ dẫn, hiểu dữ liệu c\xf3 cấu tr\xfac v\xe0 tạo ra đầu ra c\xf3 cấu tr\xfac (đặc biệt l\xe0 JSON)."},"Pro/Qwen/Qwen2.5-Coder-7B-Instruct":{"description":"Qwen2.5-Coder-7B-Instruct l\xe0 phi\xean bản mới nhất trong loạt m\xf4 h\xecnh ng\xf4n ngữ lớn chuy\xean biệt cho m\xe3 do Alibaba Cloud ph\xe1t h\xe0nh. M\xf4 h\xecnh n\xe0y được cải thiện đ\xe1ng kể khả năng tạo m\xe3, suy luận v\xe0 sửa chữa th\xf4ng qua việc đ\xe0o tạo tr\xean 5.5 triệu tỷ tokens, kh\xf4ng chỉ n\xe2ng cao khả năng lập tr\xecnh m\xe0 c\xf2n duy tr\xec lợi thế về khả năng to\xe1n học v\xe0 tổng qu\xe1t. M\xf4 h\xecnh cung cấp nền tảng to\xe0n diện hơn cho c\xe1c ứng dụng thực tế như t\xe1c nh\xe2n m\xe3."},"Pro/Qwen/Qwen2.5-VL-7B-Instruct":{"description":"Qwen2.5-VL l\xe0 th\xe0nh vi\xean mới của series Qwen, sở hữu khả năng hiểu thị gi\xe1c mạnh mẽ, c\xf3 thể ph\xe2n t\xedch văn bản, biểu đồ v\xe0 bố cục trong h\xecnh ảnh, cũng như hiểu video d\xe0i v\xe0 bắt c\xe1c sự kiện, c\xf3 thể suy luận, thao t\xe1c c\xf4ng cụ, hỗ trợ định vị vật thể đa định dạng v\xe0 tạo ra đầu ra c\xf3 cấu tr\xfac, tối ưu h\xf3a việc huấn luyện độ ph\xe2n giải v\xe0 tốc độ khung h\xecnh động cho việc hiểu video, đồng thời cải thiện hiệu suất của bộ m\xe3 h\xf3a thị gi\xe1c."},"Pro/THUDM/GLM-4.1V-9B-Thinking":{"description":"GLM-4.1V-9B-Thinking l\xe0 một m\xf4 h\xecnh ng\xf4n ngữ thị gi\xe1c (VLM) m\xe3 nguồn mở được ph\xe1t h\xe0nh chung bởi Zhipu AI v\xe0 Ph\xf2ng th\xed nghiệm KEG của Đại học Thanh Hoa, được thiết kế đặc biệt để xử l\xfd c\xe1c nhiệm vụ nhận thức đa phương thức phức tạp. M\xf4 h\xecnh n\xe0y dựa tr\xean m\xf4 h\xecnh cơ sở GLM-4-9B-0414, th\xf4ng qua việc giới thiệu cơ chế suy luận “Chuỗi tư duy” (Chain-of-Thought) v\xe0 \xe1p dụng chiến lược học tăng cường, đ\xe3 n\xe2ng cao đ\xe1ng kể khả năng suy luận đa phương thức v\xe0 t\xednh ổn định của n\xf3."},"Pro/THUDM/glm-4-9b-chat":{"description":"GLM-4-9B-Chat l\xe0 phi\xean bản m\xe3 nguồn mở trong loạt m\xf4 h\xecnh tiền huấn luyện GLM-4 do Zhizhu AI ph\xe1t h\xe0nh. M\xf4 h\xecnh n\xe0y thể hiện xuất sắc trong nhiều lĩnh vực như ngữ nghĩa, to\xe1n học, suy luận, m\xe3 v\xe0 kiến thức. Ngo\xe0i việc hỗ trợ đối thoại nhiều v\xf2ng, GLM-4-9B-Chat c\xf2n c\xf3 c\xe1c t\xednh năng n\xe2ng cao như duyệt web, thực thi m\xe3, gọi c\xf4ng cụ t\xf9y chỉnh (Function Call) v\xe0 suy luận văn bản d\xe0i. M\xf4 h\xecnh hỗ trợ 26 ng\xf4n ngữ, bao gồm tiếng Trung, tiếng Anh, tiếng Nhật, tiếng H\xe0n v\xe0 tiếng Đức. Trong nhiều b\xe0i kiểm tra chuẩn, GLM-4-9B-Chat đ\xe3 thể hiện hiệu suất xuất sắc, như AlignBench-v2, MT-Bench, MMLU v\xe0 C-Eval. M\xf4 h\xecnh hỗ trợ độ d\xe0i ngữ cảnh tối đa 128K, ph\xf9 hợp cho nghi\xean cứu học thuật v\xe0 ứng dụng thương mại."},"Pro/deepseek-ai/DeepSeek-R1":{"description":"DeepSeek-R1 l\xe0 một m\xf4 h\xecnh suy diễn được điều khiển bởi học tăng cường (RL), giải quyết c\xe1c vấn đề về t\xednh lặp lại v\xe0 khả năng đọc trong m\xf4 h\xecnh. Trước khi \xe1p dụng RL, DeepSeek-R1 đ\xe3 giới thiệu dữ liệu khởi động lạnh, tối ưu h\xf3a th\xeam hiệu suất suy diễn. N\xf3 thể hiện hiệu suất tương đương với OpenAI-o1 trong c\xe1c nhiệm vụ to\xe1n học, m\xe3 v\xe0 suy diễn, v\xe0 th\xf4ng qua phương ph\xe1p đ\xe0o tạo được thiết kế cẩn thận, n\xe2ng cao hiệu quả tổng thể."},"Pro/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B":{"description":"DeepSeek-R1-Distill-Qwen-7B l\xe0 m\xf4 h\xecnh được tạo ra từ Qwen2.5-Math-7B th\xf4ng qua qu\xe1 tr\xecnh chưng cất kiến thức. M\xf4 h\xecnh n\xe0y được tinh chỉnh bằng 800.000 mẫu được chọn lọc từ DeepSeek-R1, thể hiện khả năng suy luận xuất sắc. N\xf3 đ\xe3 đạt được hiệu suất tốt trong nhiều b\xe0i kiểm tra chuẩn, trong đ\xf3 c\xf3 độ ch\xednh x\xe1c 92,8% tr\xean MATH-500, tỷ lệ vượt qua 55,5% tr\xean AIME 2024, v\xe0 điểm số 1189 tr\xean CodeForces, thể hiện khả năng to\xe1n học v\xe0 lập tr\xecnh mạnh mẽ cho một m\xf4 h\xecnh c\xf3 quy m\xf4 7B."},"Pro/deepseek-ai/DeepSeek-V3":{"description":"DeepSeek-V3 l\xe0 một m\xf4 h\xecnh ng\xf4n ngữ hỗn hợp chuy\xean gia (MoE) với 6710 tỷ tham số, sử dụng ch\xfa \xfd tiềm ẩn đa đầu (MLA) v\xe0 kiến tr\xfac DeepSeekMoE, kết hợp chiến lược c\xe2n bằng tải kh\xf4ng c\xf3 tổn thất phụ trợ, tối ưu h\xf3a hiệu suất suy diễn v\xe0 đ\xe0o tạo. Th\xf4ng qua việc được tiền huấn luyện tr\xean 14.8 triệu tỷ token chất lượng cao, v\xe0 thực hiện tinh chỉnh gi\xe1m s\xe1t v\xe0 học tăng cường, DeepSeek-V3 vượt trội hơn c\xe1c m\xf4 h\xecnh m\xe3 nguồn mở kh\xe1c, gần với c\xe1c m\xf4 h\xecnh đ\xf3ng k\xedn h\xe0ng đầu."},"Pro/deepseek-ai/DeepSeek-V3.1-Terminus":{"description":"DeepSeek-V3.1-Terminus l\xe0 phi\xean bản cập nhật của m\xf4 h\xecnh V3.1 do DeepSeek ph\xe1t h\xe0nh, được định vị l\xe0 m\xf4 h\xecnh ng\xf4n ngữ lớn với tr\xed tuệ hỗn hợp. Bản cập nhật n\xe0y tập trung sửa c\xe1c vấn đề phản hồi từ người d\xf9ng v\xe0 n\xe2ng cao độ ổn định trong khi vẫn giữ nguy\xean khả năng của m\xf4 h\xecnh. N\xf3 cải thiện đ\xe1ng kể t\xednh nhất qu\xe1n ng\xf4n ngữ, giảm thiểu việc sử dụng lẫn lộn tiếng Trung v\xe0 tiếng Anh cũng như c\xe1c k\xfd tự bất thường. M\xf4 h\xecnh t\xedch hợp \\"Chế độ suy nghĩ\\" (Thinking Mode) v\xe0 \\"Chế độ kh\xf4ng suy nghĩ\\" (Non-thinking Mode), người d\xf9ng c\xf3 thể linh hoạt chuyển đổi qua c\xe1c mẫu tr\xf2 chuyện để ph\xf9 hợp với c\xe1c nhiệm vụ kh\xe1c nhau. Một tối ưu quan trọng l\xe0 V3.1-Terminus tăng cường hiệu suất của Agent m\xe3 (Code Agent) v\xe0 Agent t\xecm kiếm (Search Agent), gi\xfap ch\xfang đ\xe1ng tin cậy hơn trong việc gọi c\xf4ng cụ v\xe0 thực hiện c\xe1c nhiệm vụ phức tạp nhiều bước."},"Pro/deepseek-ai/DeepSeek-V3.2-Exp":{"description":"DeepSeek-V3.2-Exp l\xe0 phi\xean bản thử nghiệm V3.2 do DeepSeek ph\xe1t h\xe0nh, đ\xf3ng vai tr\xf2 l\xe0 bước chuyển tiếp trong h\xe0nh tr\xecnh hướng tới kiến tr\xfac thế hệ tiếp theo. Dựa tr\xean nền tảng của V3.1-Terminus, phi\xean bản n\xe0y t\xedch hợp cơ chế Ch\xfa \xfd Thưa (DeepSeek Sparse Attention - DSA) nhằm n\xe2ng cao hiệu quả huấn luyện v\xe0 suy luận trong ngữ cảnh d\xe0i. N\xf3 được tối ưu h\xf3a đặc biệt cho việc gọi c\xf4ng cụ, hiểu t\xe0i liệu d\xe0i v\xe0 suy luận nhiều bước. V3.2-Exp l\xe0 cầu nối giữa nghi\xean cứu v\xe0 ứng dụng thực tế, ph\xf9 hợp với người d\xf9ng mong muốn kh\xe1m ph\xe1 hiệu suất suy luận cao hơn trong c\xe1c t\xecnh huống c\xf3 ng\xe2n s\xe1ch ngữ cảnh lớn."},"Pro/moonshotai/Kimi-K2-Instruct-0905":{"description":"Kimi K2-Instruct-0905 l\xe0 phi\xean bản mới nhất v\xe0 mạnh mẽ nhất của Kimi K2. Đ\xe2y l\xe0 một m\xf4 h\xecnh ng\xf4n ngữ chuy\xean gia hỗn hợp (MoE) h\xe0ng đầu với tổng số tham số l\xean đến 1 ngh\xecn tỷ v\xe0 32 tỷ tham số k\xedch hoạt. C\xe1c đặc điểm ch\xednh của m\xf4 h\xecnh bao gồm: tăng cường tr\xed tuệ m\xe3 h\xf3a t\xe1c nh\xe2n, thể hiện sự cải thiện đ\xe1ng kể trong c\xe1c b\xe0i kiểm tra chuẩn c\xf4ng khai v\xe0 c\xe1c nhiệm vụ m\xe3 h\xf3a t\xe1c nh\xe2n trong thế giới thực; cải tiến trải nghiệm m\xe3 h\xf3a giao diện người d\xf9ng, n\xe2ng cao cả về t\xednh thẩm mỹ v\xe0 t\xednh thực tiễn trong lập tr\xecnh giao diện."},"QwQ-32B-Preview":{"description":"QwQ-32B-Preview l\xe0 một m\xf4 h\xecnh xử l\xfd ng\xf4n ngữ tự nhi\xean độc đ\xe1o, c\xf3 khả năng xử l\xfd hiệu quả c\xe1c nhiệm vụ tạo đối thoại phức tạp v\xe0 hiểu ngữ cảnh."},"Qwen/QVQ-72B-Preview":{"description":"QVQ-72B-Preview l\xe0 một m\xf4 h\xecnh nghi\xean cứu do đội ngũ Qwen ph\xe1t triển, tập trung v\xe0o khả năng suy diễn h\xecnh ảnh, c\xf3 lợi thế độc đ\xe1o trong việc hiểu c\xe1c cảnh phức tạp v\xe0 giải quyết c\xe1c vấn đề to\xe1n học li\xean quan đến h\xecnh ảnh."},"Qwen/QwQ-32B":{"description":"QwQ l\xe0 m\xf4 h\xecnh suy diễn của d\xf2ng Qwen. So với c\xe1c m\xf4 h\xecnh tinh chỉnh theo chỉ dẫn truyền thống, QwQ c\xf3 khả năng tư duy v\xe0 suy diễn, c\xf3 thể đạt được hiệu suất được cải thiện đ\xe1ng kể trong c\xe1c nhiệm vụ hạ nguồn, đặc biệt l\xe0 trong việc giải quyết c\xe1c vấn đề kh\xf3 khăn. QwQ-32B l\xe0 m\xf4 h\xecnh suy diễn trung b\xecnh, c\xf3 thể đạt được hiệu suất cạnh tranh khi so s\xe1nh với c\xe1c m\xf4 h\xecnh suy diễn ti\xean tiến nhất (như DeepSeek-R1, o1-mini). M\xf4 h\xecnh n\xe0y sử dụng c\xe1c c\xf4ng nghệ như RoPE, SwiGLU, RMSNorm v\xe0 Attention QKV bias, c\xf3 cấu tr\xfac mạng 64 lớp v\xe0 40 đầu ch\xfa \xfd Q (trong kiến tr\xfac GQA, KV l\xe0 8)."},"Qwen/QwQ-32B-Preview":{"description":"QwQ-32B-Preview l\xe0 m\xf4 h\xecnh nghi\xean cứu thử nghiệm mới nhất của Qwen, tập trung v\xe0o việc n\xe2ng cao khả năng suy luận của AI. Th\xf4ng qua việc kh\xe1m ph\xe1 c\xe1c cơ chế phức tạp như trộn ng\xf4n ngữ v\xe0 suy luận đệ quy, những lợi thế ch\xednh bao gồm khả năng ph\xe2n t\xedch suy luận mạnh mẽ, khả năng to\xe1n học v\xe0 lập tr\xecnh. Tuy nhi\xean, cũng c\xf3 những vấn đề về chuyển đổi ng\xf4n ngữ, v\xf2ng lặp suy luận, c\xe1c vấn đề an to\xe0n v\xe0 sự kh\xe1c biệt về c\xe1c khả năng kh\xe1c."},"Qwen/Qwen-Image":{"description":"Qwen-Image l\xe0 m\xf4 h\xecnh nền tạo ảnh do đội ngũ Tongyi Qianwen của Alibaba ph\xe1t triển, với 20 tỷ tham số. M\xf4 h\xecnh n\xe0y đạt được những tiến bộ đ\xe1ng kể trong việc hiển thị văn bản phức tạp v\xe0 chỉnh sửa h\xecnh ảnh ch\xednh x\xe1c, đặc biệt xuất sắc trong việc tạo ra h\xecnh ảnh chứa văn bản tiếng Trung v\xe0 tiếng Anh với độ trung thực cao. Qwen-Image kh\xf4ng chỉ xử l\xfd tốt bố cục nhiều d\xf2ng v\xe0 văn bản cấp đoạn, m\xe0 c\xf2n duy tr\xec sự nhất qu\xe1n trong bố cục v\xe0 h\xe0i h\xf2a về ngữ cảnh khi tạo ảnh. B\xean cạnh khả năng hiển thị văn bản vượt trội, m\xf4 h\xecnh c\xf2n hỗ trợ nhiều phong c\xe1ch nghệ thuật, từ ảnh hiện thực đến thẩm mỹ anime, linh hoạt đ\xe1p ứng c\xe1c nhu cầu s\xe1ng tạo kh\xe1c nhau. Đồng thời, n\xf3 cũng sở hữu khả năng chỉnh sửa v\xe0 hiểu h\xecnh ảnh mạnh mẽ, hỗ trợ c\xe1c thao t\xe1c n\xe2ng cao như chuyển đổi phong c\xe1ch, th\xeam hoặc x\xf3a đối tượng, tăng cường chi tiết, chỉnh sửa văn bản v\xe0 điều khiển tư thế cơ thể người, hướng tới việc trở th\xe0nh một m\xf4 h\xecnh nền th\xf4ng minh to\xe0n diện cho s\xe1ng tạo v\xe0 xử l\xfd h\xecnh ảnh t\xedch hợp ng\xf4n ngữ, bố cục v\xe0 thị gi\xe1c."},"Qwen/Qwen-Image-Edit-2509":{"description":"Qwen-Image-Edit-2509 l\xe0 phi\xean bản chỉnh sửa h\xecnh ảnh mới nhất của Qwen-Image, được ph\xe1t h\xe0nh bởi đội ngũ Tongyi Qianwen của Alibaba. M\xf4 h\xecnh n\xe0y được huấn luyện chuy\xean s\xe2u dựa tr\xean Qwen-Image với 20 tỷ tham số, mở rộng th\xe0nh c\xf4ng khả năng hiển thị văn bản độc đ\xe1o sang lĩnh vực chỉnh sửa h\xecnh ảnh, cho ph\xe9p chỉnh sửa ch\xednh x\xe1c văn bản trong ảnh. Ngo\xe0i ra, Qwen-Image-Edit \xe1p dụng kiến tr\xfac s\xe1ng tạo, đưa h\xecnh ảnh đầu v\xe0o đồng thời v\xe0o Qwen2.5-VL (để kiểm so\xe1t ngữ nghĩa thị gi\xe1c) v\xe0 VAE Encoder (để kiểm so\xe1t diện mạo thị gi\xe1c), từ đ\xf3 đạt được khả năng chỉnh sửa k\xe9p về ngữ nghĩa v\xe0 diện mạo. Điều n\xe0y c\xf3 nghĩa l\xe0 m\xf4 h\xecnh kh\xf4ng chỉ hỗ trợ chỉnh sửa cục bộ như th\xeam, x\xf3a hoặc thay đổi c\xe1c yếu tố, m\xe0 c\xf2n hỗ trợ chỉnh sửa ngữ nghĩa thị gi\xe1c n\xe2ng cao như s\xe1ng tạo IP, chuyển đổi phong c\xe1ch m\xe0 vẫn giữ được t\xednh nhất qu\xe1n về ngữ nghĩa. M\xf4 h\xecnh đ\xe3 thể hiện hiệu suất h\xe0ng đầu (SOTA) tr\xean nhiều bộ đ\xe1nh gi\xe1 c\xf4ng khai, trở th\xe0nh một m\xf4 h\xecnh nền chỉnh sửa h\xecnh ảnh mạnh mẽ."},"Qwen/Qwen2-72B-Instruct":{"description":"Qwen2 l\xe0 m\xf4 h\xecnh ng\xf4n ngữ tổng qu\xe1t ti\xean tiến, hỗ trợ nhiều loại chỉ dẫn."},"Qwen/Qwen2-7B-Instruct":{"description":"Qwen2-72B-Instruct l\xe0 m\xf4 h\xecnh ng\xf4n ngữ lớn được tinh chỉnh theo chỉ dẫn trong loạt Qwen2, với quy m\xf4 tham số l\xe0 72B. M\xf4 h\xecnh n\xe0y dựa tr\xean kiến tr\xfac Transformer, sử dụng h\xe0m k\xedch hoạt SwiGLU, độ lệch QKV trong ch\xfa \xfd v\xe0 ch\xfa \xfd theo nh\xf3m. N\xf3 c\xf3 khả năng xử l\xfd đầu v\xe0o quy m\xf4 lớn. M\xf4 h\xecnh thể hiện xuất sắc trong nhiều b\xe0i kiểm tra chuẩn về hiểu ng\xf4n ngữ, sinh ng\xf4n ngữ, khả năng đa ng\xf4n ngữ, m\xe3 h\xf3a, to\xe1n học v\xe0 suy luận, vượt qua hầu hết c\xe1c m\xf4 h\xecnh m\xe3 nguồn mở v\xe0 thể hiện sức cạnh tranh tương đương với c\xe1c m\xf4 h\xecnh độc quyền trong một số nhiệm vụ."},"Qwen/Qwen2-VL-72B-Instruct":{"description":"Qwen2-VL l\xe0 phi\xean bản mới nhất của m\xf4 h\xecnh Qwen-VL, đạt được hiệu suất h\xe0ng đầu trong c\xe1c thử nghiệm chuẩn hiểu biết h\xecnh ảnh."},"Qwen/Qwen2.5-14B-Instruct":{"description":"Qwen2.5 l\xe0 một loạt m\xf4 h\xecnh ng\xf4n ngữ lớn ho\xe0n to\xe0n mới, nhằm tối ưu h\xf3a việc xử l\xfd c\xe1c nhiệm vụ theo hướng dẫn."},"Qwen/Qwen2.5-32B-Instruct":{"description":"Qwen2.5 l\xe0 một loạt m\xf4 h\xecnh ng\xf4n ngữ lớn ho\xe0n to\xe0n mới, nhằm tối ưu h\xf3a việc xử l\xfd c\xe1c nhiệm vụ theo hướng dẫn."},"Qwen/Qwen2.5-72B-Instruct":{"description":"M\xf4 h\xecnh ng\xf4n ngữ lớn được ph\xe1t triển bởi đội ngũ Qianwen của Alibaba Cloud"},"Qwen/Qwen2.5-72B-Instruct-128K":{"description":"Qwen2.5 l\xe0 một loạt m\xf4 h\xecnh ng\xf4n ngữ lớn ho\xe0n to\xe0n mới, sở hữu khả năng hiểu v\xe0 tạo ra mạnh mẽ hơn."},"Qwen/Qwen2.5-72B-Instruct-Turbo":{"description":"Qwen2.5 l\xe0 một loạt m\xf4 h\xecnh ng\xf4n ngữ lớn ho\xe0n to\xe0n mới, được thiết kế để tối ưu h\xf3a việc xử l\xfd c\xe1c t\xe1c vụ chỉ dẫn."},"Qwen/Qwen2.5-7B-Instruct":{"description":"Qwen2.5 l\xe0 một loạt m\xf4 h\xecnh ng\xf4n ngữ lớn ho\xe0n to\xe0n mới, nhằm tối ưu h\xf3a việc xử l\xfd c\xe1c nhiệm vụ theo hướng dẫn."},"Qwen/Qwen2.5-7B-Instruct-Turbo":{"description":"Qwen2.5 l\xe0 một loạt m\xf4 h\xecnh ng\xf4n ngữ lớn ho\xe0n to\xe0n mới, được thiết kế để tối ưu h\xf3a việc xử l\xfd c\xe1c t\xe1c vụ chỉ dẫn."},"Qwen/Qwen2.5-Coder-32B-Instruct":{"description":"Qwen2.5-Coder tập trung v\xe0o việc viết m\xe3."},"Qwen/Qwen2.5-Coder-7B-Instruct":{"description":"Qwen2.5-Coder-7B-Instruct l\xe0 phi\xean bản mới nhất trong loạt m\xf4 h\xecnh ng\xf4n ngữ lớn chuy\xean biệt cho m\xe3 do Alibaba Cloud ph\xe1t h\xe0nh. M\xf4 h\xecnh n\xe0y được cải thiện đ\xe1ng kể khả năng tạo m\xe3, suy luận v\xe0 sửa chữa th\xf4ng qua việc đ\xe0o tạo tr\xean 5.5 triệu tỷ tokens, kh\xf4ng chỉ n\xe2ng cao khả năng lập tr\xecnh m\xe0 c\xf2n duy tr\xec lợi thế về khả năng to\xe1n học v\xe0 tổng qu\xe1t. M\xf4 h\xecnh cung cấp nền tảng to\xe0n diện hơn cho c\xe1c ứng dụng thực tế như t\xe1c nh\xe2n m\xe3."},"Qwen/Qwen2.5-VL-32B-Instruct":{"description":"Qwen2.5-VL-32B-Instruct l\xe0 m\xf4 h\xecnh đa phương thức do đội ngũ Qwen2.5-VL ph\xe1t triển, l\xe0 một phần của loạt Qwen2.5-VL. M\xf4 h\xecnh n\xe0y kh\xf4ng chỉ giỏi nhận diện c\xe1c vật thể th\xf4ng thường, m\xe0 c\xf2n c\xf3 thể ph\xe2n t\xedch văn bản, biểu đồ, biểu tượng, h\xecnh vẽ v\xe0 bố cục trong h\xecnh ảnh. N\xf3 c\xf3 thể hoạt động như một đại l\xfd thị gi\xe1c, c\xf3 khả năng suy luận v\xe0 điều khiển c\xf4ng cụ một c\xe1ch động, bao gồm cả việc sử dụng m\xe1y t\xednh v\xe0 điện thoại. Ngo\xe0i ra, m\xf4 h\xecnh n\xe0y c\xf3 thể x\xe1c định ch\xednh x\xe1c vị tr\xed của c\xe1c đối tượng trong h\xecnh ảnh v\xe0 tạo ra đầu ra c\xf3 cấu tr\xfac cho h\xf3a đơn, bảng biểu, v.v. So với m\xf4 h\xecnh tiền nhiệm Qwen2-VL, phi\xean bản n\xe0y đ\xe3 được cải thiện đ\xe1ng kể về khả năng giải to\xe1n v\xe0 giải quyết vấn đề th\xf4ng qua học tăng cường, v\xe0 phong c\xe1ch phản hồi cũng ph\xf9 hợp hơn với sở th\xedch của con người."},"Qwen/Qwen2.5-VL-72B-Instruct":{"description":"Qwen2.5-VL l\xe0 m\xf4 h\xecnh ng\xf4n ngữ thị gi\xe1c trong loạt Qwen2.5. M\xf4 h\xecnh n\xe0y c\xf3 những cải tiến đ\xe1ng kể: c\xf3 khả năng hiểu thị gi\xe1c mạnh hơn, c\xf3 thể nhận diện c\xe1c vật thể th\xf4ng thường, ph\xe2n t\xedch văn bản, biểu đồ v\xe0 bố cục; hoạt động như một đại l\xfd thị gi\xe1c c\xf3 thể suy luận v\xe0 hướng dẫn sử dụng c\xf4ng cụ một c\xe1ch động; hỗ trợ hiểu c\xe1c video d\xe0i hơn 1 giờ v\xe0 bắt c\xe1c sự kiện quan trọng; c\xf3 thể định vị ch\xednh x\xe1c c\xe1c vật thể trong h\xecnh ảnh th\xf4ng qua việc tạo khung giới hạn hoặc điểm; hỗ trợ tạo ra đầu ra c\xf3 cấu tr\xfac, đặc biệt ph\xf9 hợp với dữ liệu qu\xe9t như h\xf3a đơn, bảng biểu."},"Qwen/Qwen3-14B":{"description":"Qwen3 l\xe0 một m\xf4 h\xecnh lớn thế hệ mới của Tongyi Qianwen với khả năng n\xe2ng cao đ\xe1ng kể, đạt được tr\xecnh độ h\xe0ng đầu trong nhiều khả năng cốt l\xf5i như suy luận, tổng qu\xe1t, đại l\xfd v\xe0 đa ng\xf4n ngữ, đồng thời hỗ trợ chuyển đổi chế độ suy nghĩ."},"Qwen/Qwen3-235B-A22B":{"description":"Qwen3 l\xe0 một m\xf4 h\xecnh lớn thế hệ mới của Tongyi Qianwen với khả năng n\xe2ng cao đ\xe1ng kể, đạt được tr\xecnh độ h\xe0ng đầu trong nhiều khả năng cốt l\xf5i như suy luận, tổng qu\xe1t, đại l\xfd v\xe0 đa ng\xf4n ngữ, đồng thời hỗ trợ chuyển đổi chế độ suy nghĩ."},"Qwen/Qwen3-235B-A22B-Instruct-2507":{"description":"Qwen3-235B-A22B-Instruct-2507 l\xe0 m\xf4 h\xecnh ng\xf4n ngữ lớn chuy\xean gia hỗn hợp (MoE) h\xe0ng đầu trong d\xf2ng Qwen3 do đội ngũ Aliyun Tongyi Qianwen ph\xe1t triển. M\xf4 h\xecnh c\xf3 tổng 235 tỷ tham số, mỗi lần suy luận k\xedch hoạt 22 tỷ tham số. Đ\xe2y l\xe0 phi\xean bản cập nhật của Qwen3-235B-A22B kh\xf4ng ở chế độ suy nghĩ, tập trung cải thiện đ\xe1ng kể khả năng tu\xe2n thủ chỉ dẫn, suy luận logic, hiểu văn bản, to\xe1n học, khoa học, lập tr\xecnh v\xe0 sử dụng c\xf4ng cụ. Ngo\xe0i ra, m\xf4 h\xecnh tăng cường bao phủ kiến thức đa ng\xf4n ngữ v\xe0 điều chỉnh tốt hơn sở th\xedch người d\xf9ng trong c\xe1c t\xe1c vụ chủ quan v\xe0 mở, tạo ra văn bản hữu \xedch v\xe0 chất lượng cao hơn."},"Qwen/Qwen3-235B-A22B-Thinking-2507":{"description":"Qwen3-235B-A22B-Thinking-2507 l\xe0 th\xe0nh vi\xean trong d\xf2ng m\xf4 h\xecnh ng\xf4n ngữ lớn Qwen3 do đội ngũ Alibaba Tongyi Qianwen ph\xe1t triển, tập trung v\xe0o c\xe1c t\xe1c vụ suy luận phức tạp v\xe0 kh\xf3 khăn. M\xf4 h\xecnh dựa tr\xean kiến tr\xfac chuy\xean gia hỗn hợp (MoE), tổng tham số 235 tỷ, mỗi token k\xedch hoạt khoảng 22 tỷ tham số, gi\xfap tăng hiệu quả t\xednh to\xe1n trong khi duy tr\xec hiệu suất mạnh mẽ. L\xe0 m\xf4 h\xecnh “suy nghĩ” chuy\xean biệt, n\xf3 cải thiện đ\xe1ng kể khả năng suy luận logic, to\xe1n học, khoa học, lập tr\xecnh v\xe0 c\xe1c b\xe0i kiểm tra học thuật, đạt tr\xecnh độ h\xe0ng đầu trong c\xe1c m\xf4 h\xecnh suy nghĩ m\xe3 nguồn mở. M\xf4 h\xecnh cũng tăng cường khả năng chung như tu\xe2n thủ chỉ dẫn, sử dụng c\xf4ng cụ v\xe0 tạo văn bản, hỗ trợ ngữ cảnh d\xe0i 256K token, rất ph\xf9 hợp cho c\xe1c kịch bản cần suy luận s\xe2u v\xe0 xử l\xfd t\xe0i liệu d\xe0i."},"Qwen/Qwen3-30B-A3B":{"description":"Qwen3 l\xe0 một m\xf4 h\xecnh lớn thế hệ mới của Tongyi Qianwen với khả năng n\xe2ng cao đ\xe1ng kể, đạt được tr\xecnh độ h\xe0ng đầu trong nhiều khả năng cốt l\xf5i như suy luận, tổng qu\xe1t, đại l\xfd v\xe0 đa ng\xf4n ngữ, đồng thời hỗ trợ chuyển đổi chế độ suy nghĩ."},"Qwen/Qwen3-30B-A3B-Instruct-2507":{"description":"Qwen3-30B-A3B-Instruct-2507 l\xe0 phi\xean bản cập nhật của Qwen3-30B-A3B ở chế độ kh\xf4ng suy nghĩ. Đ\xe2y l\xe0 một m\xf4 h\xecnh chuy\xean gia hỗn hợp (MoE) với tổng cộng 30,5 tỷ tham số v\xe0 3,3 tỷ tham số k\xedch hoạt. M\xf4 h\xecnh n\xe0y đ\xe3 được cải tiến quan trọng ở nhiều kh\xeda cạnh, bao gồm n\xe2ng cao đ\xe1ng kể khả năng tu\xe2n thủ chỉ dẫn, suy luận logic, hiểu văn bản, to\xe1n học, khoa học, lập tr\xecnh v\xe0 sử dụng c\xf4ng cụ. Đồng thời, n\xf3 đạt được tiến bộ thực chất trong việc bao phủ kiến thức đa ng\xf4n ngữ v\xe0 c\xf3 khả năng điều chỉnh tốt hơn với sở th\xedch của người d\xf9ng trong c\xe1c nhiệm vụ chủ quan v\xe0 mở, từ đ\xf3 tạo ra c\xe1c phản hồi hữu \xedch hơn v\xe0 văn bản chất lượng cao hơn. Ngo\xe0i ra, khả năng hiểu văn bản d\xe0i của m\xf4 h\xecnh cũng được n\xe2ng l\xean đến 256K. M\xf4 h\xecnh n\xe0y chỉ hỗ trợ chế độ kh\xf4ng suy nghĩ v\xe0 kh\xf4ng tạo ra thẻ `<think></think>` trong đầu ra."},"Qwen/Qwen3-30B-A3B-Thinking-2507":{"description":"Qwen3-30B-A3B-Thinking-2507 l\xe0 m\xf4 h\xecnh \\"suy nghĩ\\" mới nhất trong d\xf2ng Qwen3, được ph\xe1t h\xe0nh bởi nh\xf3m Tongyi Qianwen của Alibaba. L\xe0 một m\xf4 h\xecnh chuy\xean gia hỗn hợp (MoE) với tổng cộng 305亿 (30,5 tỷ) tham số v\xe0 33亿 (3,3 tỷ) tham số k\xedch hoạt, m\xf4 h\xecnh tập trung v\xe0o n\xe2ng cao khả năng xử l\xfd c\xe1c nhiệm vụ phức tạp. M\xf4 h\xecnh n\xe0y thể hiện hiệu năng cải thiện r\xf5 rệt tr\xean c\xe1c chuẩn đ\xe1nh gi\xe1 học thuật về suy luận logic, to\xe1n học, khoa học, lập tr\xecnh v\xe0 những b\xe0i to\xe1n đ\xf2i hỏi chuy\xean m\xf4n của con người. Đồng thời, c\xe1c năng lực chung như tu\xe2n thủ hướng dẫn, sử dụng c\xf4ng cụ, sinh văn bản v\xe0 căn chỉnh theo sở th\xedch con người cũng được tăng cường đ\xe1ng kể. M\xf4 h\xecnh hỗ trợ nguy\xean sinh khả năng hiểu ngữ cảnh d\xe0i 256K v\xe0 c\xf3 thể mở rộng l\xean tới 1 triệu token. Phi\xean bản n\xe0y được thiết kế d\xe0nh cho \\"chế độ suy nghĩ\\", nhằm giải quyết c\xe1c nhiệm vụ c\xf3 độ phức tạp cao th\xf4ng qua qu\xe1 tr\xecnh suy luận từng bước chi tiết, đồng thời năng lực t\xe1c nh\xe2n (Agent) của n\xf3 cũng thể hiện xuất sắc."},"Qwen/Qwen3-32B":{"description":"Qwen3 l\xe0 một m\xf4 h\xecnh lớn thế hệ mới của Tongyi Qianwen với khả năng n\xe2ng cao đ\xe1ng kể, đạt được tr\xecnh độ h\xe0ng đầu trong nhiều khả năng cốt l\xf5i như suy luận, tổng qu\xe1t, đại l\xfd v\xe0 đa ng\xf4n ngữ, đồng thời hỗ trợ chuyển đổi chế độ suy nghĩ."},"Qwen/Qwen3-8B":{"description":"Qwen3 l\xe0 một m\xf4 h\xecnh lớn thế hệ mới của Tongyi Qianwen với khả năng n\xe2ng cao đ\xe1ng kể, đạt được tr\xecnh độ h\xe0ng đầu trong nhiều khả năng cốt l\xf5i như suy luận, tổng qu\xe1t, đại l\xfd v\xe0 đa ng\xf4n ngữ, đồng thời hỗ trợ chuyển đổi chế độ suy nghĩ."},"Qwen/Qwen3-Coder-30B-A3B-Instruct":{"description":"Qwen3-Coder-30B-A3B-Instruct l\xe0 một m\xf4 h\xecnh m\xe3 trong d\xf2ng Qwen3 được ph\xe1t triển bởi đội ngũ Tongyi Qianwen của Alibaba. L\xe0 một m\xf4 h\xecnh được tinh giản v\xe0 tối ưu h\xf3a, n\xf3 tập trung n\xe2ng cao khả năng xử l\xfd m\xe3 nguồn trong khi vẫn duy tr\xec hiệu năng v\xe0 hiệu suất cao. M\xf4 h\xecnh n\xe0y thể hiện ưu thế hiệu năng nổi bật so với c\xe1c m\xf4 h\xecnh m\xe3 nguồn mở trong c\xe1c t\xe1c vụ phức tạp như lập tr\xecnh t\xe1c nh\xe2n (Agentic Coding), tự động h\xf3a thao t\xe1c tr\xecnh duyệt v\xe0 gọi c\xf4ng cụ. N\xf3 hỗ trợ ngữ cảnh d\xe0i 256K token một c\xe1ch nguy\xean bản v\xe0 c\xf3 thể mở rộng tới 1M token, gi\xfap hiểu v\xe0 xử l\xfd ở mức độ to\xe0n bộ kho m\xe3 tốt hơn. Ngo\xe0i ra, m\xf4 h\xecnh c\xf2n cung cấp hỗ trợ lập tr\xecnh t\xe1c nh\xe2n mạnh mẽ cho c\xe1c nền tảng như Qwen Code, CLINE v\xe0 được thiết kế với định dạng gọi h\xe0m chuy\xean biệt."},"Qwen/Qwen3-Coder-480B-A35B-Instruct":{"description":"Qwen3-Coder-480B-A35B-Instruct l\xe0 m\xf4 h\xecnh m\xe3 do Alibaba ph\xe1t h\xe0nh, được đ\xe1nh gi\xe1 l\xe0 c\xf3 khả năng t\xe1c nh\xe2n (agentic) mạnh mẽ nhất t\xednh đến nay. Đ\xe2y l\xe0 một m\xf4 h\xecnh chuy\xean gia hỗn hợp (Mixture of Experts, MoE) với tổng cộng 480 tỷ tham số v\xe0 35 tỷ tham số k\xedch hoạt, c\xe2n bằng giữa hiệu suất v\xe0 hiệu quả. M\xf4 h\xecnh n\xe0y hỗ trợ ngữ cảnh gốc d\xe0i 256K (khoảng 260 ngh\xecn) token v\xe0 c\xf3 thể được mở rộng tới 1 triệu token th\xf4ng qua c\xe1c phương ph\xe1p ngoại suy như YaRN, gi\xfap n\xf3 xử l\xfd c\xe1c kho m\xe3 quy m\xf4 lớn v\xe0 c\xe1c nhiệm vụ lập tr\xecnh phức tạp. Qwen3-Coder được thiết kế cho quy tr\xecnh l\xe0m việc lập tr\xecnh theo m\xf4 h\xecnh t\xe1c nh\xe2n, kh\xf4ng chỉ sinh m\xe3 m\xe0 c\xf2n c\xf3 khả năng tương t\xe1c tự chủ với c\xe1c c\xf4ng cụ v\xe0 m\xf4i trường ph\xe1t triển để giải quyết những vấn đề lập tr\xecnh phức tạp. Trong nhiều bộ đ\xe1nh gi\xe1 chuẩn về m\xe3 nguồn v\xe0 nhiệm vụ t\xe1c nh\xe2n, m\xf4 h\xecnh n\xe0y đạt thứ hạng dẫn đầu trong c\xe1c m\xf4 h\xecnh m\xe3 nguồn mở, với hiệu năng c\xf3 thể s\xe1nh ngang c\xe1c m\xf4 h\xecnh h\xe0ng đầu như Claude Sonnet 4."},"Qwen/Qwen3-Next-80B-A3B-Instruct":{"description":"Qwen3-Next-80B-A3B-Instruct l\xe0 m\xf4 h\xecnh nền tảng thế hệ tiếp theo do đội ngũ Alibaba Tongyi Qianwen ph\xe1t h\xe0nh. N\xf3 dựa tr\xean kiến tr\xfac Qwen3-Next ho\xe0n to\xe0n mới, nhằm đạt được hiệu quả tối ưu trong huấn luyện v\xe0 suy luận. M\xf4 h\xecnh n\xe0y \xe1p dụng cơ chế ch\xfa \xfd hỗn hợp s\xe1ng tạo (Gated DeltaNet v\xe0 Gated Attention), cấu tr\xfac chuy\xean gia hỗn hợp c\xf3 độ thưa cao (MoE) c\xf9ng nhiều tối ưu h\xf3a về độ ổn định trong huấn luyện. L\xe0 một m\xf4 h\xecnh thưa với tổng số 80 tỷ tham số, n\xf3 chỉ k\xedch hoạt khoảng 3 tỷ tham số trong qu\xe1 tr\xecnh suy luận, gi\xfap giảm đ\xe1ng kể chi ph\xed t\xednh to\xe1n v\xe0 khi xử l\xfd c\xe1c t\xe1c vụ ngữ cảnh d\xe0i tr\xean 32K token, th\xf4ng lượng suy luận cao hơn m\xf4 h\xecnh Qwen3-32B hơn 10 lần. M\xf4 h\xecnh n\xe0y l\xe0 phi\xean bản tinh chỉnh theo chỉ dẫn, thiết kế cho c\xe1c t\xe1c vụ chung v\xe0 kh\xf4ng hỗ trợ chế độ Chuỗi suy nghĩ (Thinking). Về hiệu năng, n\xf3 tương đương với m\xf4 h\xecnh chủ lực Qwen3-235B của Tongyi Qianwen trong một số b\xe0i kiểm tra chuẩn, đặc biệt thể hiện ưu thế r\xf5 rệt trong c\xe1c t\xe1c vụ ngữ cảnh si\xeau d\xe0i."},"Qwen/Qwen3-Next-80B-A3B-Thinking":{"description":"Qwen3-Next-80B-A3B-Thinking l\xe0 m\xf4 h\xecnh nền tảng thế hệ tiếp theo do đội ngũ Alibaba Tongyi Qianwen ph\xe1t h\xe0nh, được thiết kế chuy\xean biệt cho c\xe1c t\xe1c vụ suy luận phức tạp. N\xf3 dựa tr\xean kiến tr\xfac s\xe1ng tạo Qwen3-Next, kết hợp cơ chế ch\xfa \xfd hỗn hợp (Gated DeltaNet v\xe0 Gated Attention) v\xe0 cấu tr\xfac chuy\xean gia hỗn hợp c\xf3 độ thưa cao (MoE), nhằm đạt hiệu quả tối ưu trong huấn luyện v\xe0 suy luận. L\xe0 m\xf4 h\xecnh thưa với tổng số 80 tỷ tham số, n\xf3 chỉ k\xedch hoạt khoảng 3 tỷ tham số trong qu\xe1 tr\xecnh suy luận, giảm đ\xe1ng kể chi ph\xed t\xednh to\xe1n, v\xe0 khi xử l\xfd c\xe1c t\xe1c vụ ngữ cảnh d\xe0i tr\xean 32K token, th\xf4ng lượng cao hơn m\xf4 h\xecnh Qwen3-32B hơn 10 lần. Phi\xean bản “Thinking” n\xe0y được tối ưu để thực hiện c\xe1c t\xe1c vụ đa bước kh\xf3 như chứng minh to\xe1n học, tổng hợp m\xe3, ph\xe2n t\xedch logic v\xe0 lập kế hoạch, v\xe0 mặc định xuất ra qu\xe1 tr\xecnh suy luận dưới dạng chuỗi suy nghĩ c\xf3 cấu tr\xfac. Về hiệu năng, n\xf3 kh\xf4ng chỉ vượt trội so với c\xe1c m\xf4 h\xecnh c\xf3 chi ph\xed cao hơn như Qwen3-32B-Thinking m\xe0 c\xf2n vượt qua Gemini-2.5-Flash-Thinking trong nhiều b\xe0i kiểm tra chuẩn."},"Qwen/Qwen3-Omni-30B-A3B-Captioner":{"description":"Qwen3-Omni-30B-A3B-Captioner l\xe0 một m\xf4 h\xecnh ng\xf4n ngữ thị gi\xe1c (VLM) thuộc d\xf2ng Qwen3 do nh\xf3m Tongyi Qianwen của Alibaba ph\xe1t triển. M\xf4 h\xecnh n\xe0y chuy\xean d\xf9ng để tạo ra c\xe1c m\xf4 tả h\xecnh ảnh chất lượng cao, chi tiết v\xe0 ch\xednh x\xe1c. Dựa tr\xean kiến tr\xfac chuy\xean gia hỗn hợp (MoE) với tổng cộng 30 tỷ tham số, n\xf3 c\xf3 khả năng hiểu s\xe2u nội dung h\xecnh ảnh v\xe0 chuyển đổi th\xe0nh m\xf4 tả ng\xf4n ngữ tự nhi\xean mượt m\xe0. M\xf4 h\xecnh thể hiện xuất sắc trong việc nắm bắt chi tiết h\xecnh ảnh, hiểu cảnh vật, nhận diện đối tượng v\xe0 suy luận mối quan hệ, đặc biệt ph\xf9 hợp với c\xe1c ứng dụng y\xeau cầu hiểu v\xe0 m\xf4 tả h\xecnh ảnh ch\xednh x\xe1c."},"Qwen/Qwen3-Omni-30B-A3B-Instruct":{"description":"Qwen3-Omni-30B-A3B-Instruct l\xe0 một th\xe0nh vi\xean trong d\xf2ng Qwen3 mới nhất do nh\xf3m Tongyi Qianwen của Alibaba ph\xe1t triển. Đ\xe2y l\xe0 m\xf4 h\xecnh chuy\xean gia hỗn hợp (MoE) với tổng cộng 30 tỷ tham số v\xe0 3 tỷ tham số k\xedch hoạt, gi\xfap duy tr\xec hiệu suất mạnh mẽ trong khi giảm chi ph\xed suy luận. M\xf4 h\xecnh được huấn luyện tr\xean dữ liệu chất lượng cao, đa nguồn v\xe0 đa ng\xf4n ngữ, sở hữu năng lực tổng qu\xe1t vượt trội, hỗ trợ xử l\xfd đầu v\xe0o to\xe0n bộ c\xe1c dạng thức như văn bản, h\xecnh ảnh, \xe2m thanh v\xe0 video, c\xf3 khả năng hiểu v\xe0 tạo nội dung xuy\xean m\xf4 thức."},"Qwen/Qwen3-Omni-30B-A3B-Thinking":{"description":"Qwen3-Omni-30B-A3B-Thinking l\xe0 th\xe0nh phần \\"người suy nghĩ\\" (Thinker) cốt l\xf5i trong m\xf4 h\xecnh to\xe0n m\xf4 thức Qwen3-Omni. N\xf3 chuy\xean xử l\xfd c\xe1c đầu v\xe0o đa m\xf4 thức bao gồm văn bản, \xe2m thanh, h\xecnh ảnh v\xe0 video, thực hiện suy luận chuỗi tư duy phức tạp. L\xe0 bộ n\xe3o của qu\xe1 tr\xecnh suy luận, m\xf4 h\xecnh n\xe0y thống nhất tất cả đầu v\xe0o v\xe0o kh\xf4ng gian biểu diễn chung, từ đ\xf3 đạt được khả năng hiểu s\xe2u v\xe0 suy luận phức tạp xuy\xean m\xf4 thức. Dựa tr\xean kiến tr\xfac chuy\xean gia hỗn hợp (MoE) với 30 tỷ tham số v\xe0 3 tỷ tham số k\xedch hoạt, m\xf4 h\xecnh tối ưu h\xf3a hiệu quả t\xednh to\xe1n trong khi vẫn duy tr\xec năng lực suy luận mạnh mẽ."},"Qwen/Qwen3-VL-235B-A22B-Instruct":{"description":"Qwen3-VL-235B-A22B-Instruct l\xe0 m\xf4 h\xecnh tinh chỉnh theo chỉ dẫn quy m\xf4 lớn thuộc d\xf2ng Qwen3-VL, dựa tr\xean kiến tr\xfac chuy\xean gia hỗn hợp (MoE), sở hữu khả năng hiểu v\xe0 tạo nội dung đa phương tiện vượt trội, hỗ trợ nguy\xean bản ngữ cảnh l\xean đến 256K, th\xedch hợp cho c\xe1c dịch vụ đa phương tiện cấp độ sản xuất với y\xeau cầu đồng thời cao."},"Qwen/Qwen3-VL-235B-A22B-Thinking":{"description":"Qwen3-VL-235B-A22B-Thinking l\xe0 phi\xean bản tư duy h\xe0ng đầu trong d\xf2ng Qwen3-VL, được tối ưu h\xf3a đặc biệt cho suy luận đa phương tiện phức tạp, suy luận ngữ cảnh d\xe0i v\xe0 tương t\xe1c với t\xe1c tử th\xf4ng minh, ph\xf9 hợp với c\xe1c t\xecnh huống doanh nghiệp đ\xf2i hỏi khả năng tư duy s\xe2u v\xe0 suy luận h\xecnh ảnh."},"Qwen/Qwen3-VL-30B-A3B-Instruct":{"description":"Qwen3-VL-30B-A3B-Instruct l\xe0 phi\xean bản tinh chỉnh theo chỉ dẫn của d\xf2ng Qwen3-VL, c\xf3 khả năng hiểu v\xe0 tạo nội dung ng\xf4n ngữ - h\xecnh ảnh mạnh mẽ, hỗ trợ nguy\xean bản độ d\xe0i ngữ cảnh l\xean đến 256K, ph\xf9 hợp cho c\xe1c t\xe1c vụ đối thoại đa phương tiện v\xe0 tạo nội dung c\xf3 điều kiện h\xecnh ảnh."},"Qwen/Qwen3-VL-30B-A3B-Thinking":{"description":"Qwen3-VL-30B-A3B-Thinking l\xe0 phi\xean bản tăng cường suy luận (Thinking) của Qwen3-VL, được tối ưu h\xf3a cho c\xe1c t\xe1c vụ suy luận đa phương tiện, chuyển đổi h\xecnh ảnh th\xe0nh m\xe3 v\xe0 hiểu h\xecnh ảnh phức tạp, hỗ trợ ngữ cảnh l\xean đến 256K v\xe0 c\xf3 khả năng tư duy chuỗi mạnh mẽ hơn."},"Qwen/Qwen3-VL-32B-Instruct":{"description":"Qwen3-VL-32B-Instruct l\xe0 một m\xf4 h\xecnh ng\xf4n ngữ thị gi\xe1c do nh\xf3m Tongyi Qianwen của Alibaba ph\xe1t triển, đạt hiệu suất SOTA h\xe0ng đầu trong nhiều b\xe0i kiểm tra chuẩn ng\xf4n ngữ thị gi\xe1c. M\xf4 h\xecnh hỗ trợ đầu v\xe0o h\xecnh ảnh độ ph\xe2n giải cao cấp độ megapixel, sở hữu năng lực hiểu thị gi\xe1c tổng qu\xe1t mạnh mẽ, nhận diện k\xfd tự đa ng\xf4n ngữ (OCR), định vị thị gi\xe1c chi tiết v\xe0 đối thoại thị gi\xe1c. L\xe0 một m\xf4 h\xecnh ng\xf4n ngữ thị gi\xe1c trong d\xf2ng Qwen3, n\xf3 c\xf3 thể xử l\xfd c\xe1c nhiệm vụ đa m\xf4 thức phức tạp, hỗ trợ gọi c\xf4ng cụ v\xe0 tiếp tục tiền tố."},"Qwen/Qwen3-VL-32B-Thinking":{"description":"Qwen3-VL-32B-Thinking l\xe0 phi\xean bản được tối ưu đặc biệt cho c\xe1c nhiệm vụ suy luận thị gi\xe1c phức tạp trong d\xf2ng m\xf4 h\xecnh ng\xf4n ngữ thị gi\xe1c do nh\xf3m Tongyi Qianwen của Alibaba ph\xe1t triển. M\xf4 h\xecnh t\xedch hợp chế độ \\"suy nghĩ\\", cho ph\xe9p tạo ra c\xe1c bước suy luận trung gian chi tiết trước khi trả lời c\xe2u hỏi, từ đ\xf3 n\xe2ng cao đ\xe1ng kể hiệu suất trong c\xe1c nhiệm vụ đ\xf2i hỏi logic nhiều bước, lập kế hoạch v\xe0 suy luận phức tạp. M\xf4 h\xecnh hỗ trợ đầu v\xe0o h\xecnh ảnh độ ph\xe2n giải cao cấp độ megapixel, c\xf3 năng lực hiểu thị gi\xe1c tổng qu\xe1t mạnh mẽ, nhận diện k\xfd tự đa ng\xf4n ngữ (OCR), định vị thị gi\xe1c chi tiết v\xe0 đối thoại thị gi\xe1c, đồng thời hỗ trợ gọi c\xf4ng cụ v\xe0 tiếp tục tiền tố."},"Qwen/Qwen3-VL-8B-Instruct":{"description":"Qwen3-VL-8B-Instruct l\xe0 m\xf4 h\xecnh ng\xf4n ngữ thị gi\xe1c thuộc d\xf2ng Qwen3, được ph\xe1t triển dựa tr\xean Qwen3-8B-Instruct v\xe0 huấn luyện tr\xean lượng lớn dữ liệu h\xecnh ảnh v\xe0 văn bản. M\xf4 h\xecnh n\xe0y c\xf3 thế mạnh trong hiểu thị gi\xe1c tổng qu\xe1t, đối thoại xoay quanh h\xecnh ảnh v\xe0 nhận diện văn bản đa ng\xf4n ngữ trong ảnh. Ph\xf9 hợp với c\xe1c t\xecnh huống như hỏi đ\xe1p thị gi\xe1c, m\xf4 tả h\xecnh ảnh, tu\xe2n theo chỉ dẫn đa phương thức v\xe0 gọi c\xf4ng cụ."},"Qwen/Qwen3-VL-8B-Thinking":{"description":"Qwen3-VL-8B-Thinking l\xe0 phi\xean bản tư duy thị gi\xe1c thuộc d\xf2ng Qwen3, được tối ưu h\xf3a cho c\xe1c nhiệm vụ suy luận đa bước phức tạp. Mặc định m\xf4 h\xecnh sẽ tạo ra chuỗi suy nghĩ (thinking chain) trước khi trả lời nhằm n\xe2ng cao độ ch\xednh x\xe1c trong suy luận. Ph\xf9 hợp với c\xe1c t\xecnh huống y\xeau cầu suy luận s\xe2u như hỏi đ\xe1p thị gi\xe1c, đ\xe1nh gi\xe1 nội dung h\xecnh ảnh v\xe0 đưa ra ph\xe2n t\xedch chi tiết."},"Qwen2-72B-Instruct":{"description":"Qwen2 l\xe0 d\xf2ng m\xf4 h\xecnh mới nhất của Qwen, hỗ trợ ngữ cảnh 128k, so với c\xe1c m\xf4 h\xecnh m\xe3 nguồn mở tốt nhất hiện tại, Qwen2-72B vượt trội hơn hẳn trong nhiều khả năng như hiểu ng\xf4n ngữ tự nhi\xean, kiến thức, m\xe3, to\xe1n học v\xe0 đa ng\xf4n ngữ."},"Qwen2-7B-Instruct":{"description":"Qwen2 l\xe0 d\xf2ng m\xf4 h\xecnh mới nhất của Qwen, c\xf3 khả năng vượt qua c\xe1c m\xf4 h\xecnh m\xe3 nguồn mở c\xf9ng quy m\xf4 hoặc thậm ch\xed lớn hơn, Qwen2 7B đạt được lợi thế đ\xe1ng kể trong nhiều b\xe0i kiểm tra, đặc biệt l\xe0 trong việc hiểu m\xe3 v\xe0 tiếng Trung."},"Qwen2-VL-72B":{"description":"Qwen2-VL-72B l\xe0 một m\xf4 h\xecnh ng\xf4n ngữ h\xecnh ảnh mạnh mẽ, hỗ trợ xử l\xfd đa phương thức giữa h\xecnh ảnh v\xe0 văn bản, c\xf3 khả năng nhận diện ch\xednh x\xe1c nội dung h\xecnh ảnh v\xe0 sinh ra m\xf4 tả hoặc c\xe2u trả lời li\xean quan."},"Qwen2.5-14B-Instruct":{"description":"Qwen2.5-14B-Instruct l\xe0 một m\xf4 h\xecnh ng\xf4n ngữ lớn với 14 tỷ tham số, c\xf3 hiệu suất xuất sắc, tối ưu cho c\xe1c t\xecnh huống tiếng Trung v\xe0 đa ng\xf4n ngữ, hỗ trợ c\xe1c ứng dụng như hỏi đ\xe1p th\xf4ng minh, tạo nội dung."},"Qwen2.5-32B-Instruct":{"description":"Qwen2.5-32B-Instruct l\xe0 một m\xf4 h\xecnh ng\xf4n ngữ lớn với 32 tỷ tham số, c\xf3 hiệu suất c\xe2n bằng, tối ưu cho c\xe1c t\xecnh huống tiếng Trung v\xe0 đa ng\xf4n ngữ, hỗ trợ c\xe1c ứng dụng như hỏi đ\xe1p th\xf4ng minh, tạo nội dung."},"Qwen2.5-72B-Instruct":{"description":"Qwen2.5-72B-Instruct hỗ trợ ngữ cảnh 16k, tạo ra văn bản d\xe0i hơn 8K. Hỗ trợ gọi h\xe0m v\xe0 tương t\xe1c liền mạch với hệ thống b\xean ngo\xe0i, n\xe2ng cao đ\xe1ng kể t\xednh linh hoạt v\xe0 khả năng mở rộng. Kiến thức của m\xf4 h\xecnh đ\xe3 tăng l\xean r\xf5 rệt v\xe0 khả năng m\xe3 h\xf3a cũng như to\xe1n học được cải thiện đ\xe1ng kể, hỗ trợ hơn 29 ng\xf4n ngữ."},"Qwen2.5-7B-Instruct":{"description":"Qwen2.5-7B-Instruct l\xe0 một m\xf4 h\xecnh ng\xf4n ngữ lớn với 7 tỷ tham số, hỗ trợ gọi h\xe0m v\xe0 tương t\xe1c liền mạch với c\xe1c hệ thống b\xean ngo\xe0i, n\xe2ng cao t\xednh linh hoạt v\xe0 khả năng mở rộng. Tối ưu cho c\xe1c t\xecnh huống tiếng Trung v\xe0 đa ng\xf4n ngữ, hỗ trợ c\xe1c ứng dụng như hỏi đ\xe1p th\xf4ng minh, tạo nội dung."},"Qwen2.5-Coder-14B-Instruct":{"description":"Qwen2.5-Coder-14B-Instruct l\xe0 một m\xf4 h\xecnh hướng dẫn lập tr\xecnh dựa tr\xean đ\xe0o tạo trước quy m\xf4 lớn, c\xf3 khả năng hiểu v\xe0 sinh m\xe3 mạnh mẽ, c\xf3 thể xử l\xfd hiệu quả c\xe1c nhiệm vụ lập tr\xecnh kh\xe1c nhau, đặc biệt ph\xf9 hợp cho việc viết m\xe3 th\xf4ng minh, tạo kịch bản tự động v\xe0 giải đ\xe1p c\xe1c vấn đề lập tr\xecnh."},"Qwen2.5-Coder-32B-Instruct":{"description":"Qwen2.5-Coder-32B-Instruct l\xe0 một m\xf4 h\xecnh ng\xf4n ngữ lớn được thiết kế đặc biệt cho việc tạo m\xe3, hiểu m\xe3 v\xe0 c\xe1c t\xecnh huống ph\xe1t triển hiệu quả, với quy m\xf4 32B tham số h\xe0ng đầu trong ng\xe0nh, c\xf3 thể đ\xe1p ứng nhu cầu lập tr\xecnh đa dạng."},"Qwen3-235B":{"description":"Qwen3-235B-A22B l\xe0 m\xf4 h\xecnh MoE (m\xf4 h\xecnh chuy\xean gia hỗn hợp), giới thiệu “chế độ suy luận hỗn hợp”, cho ph\xe9p người d\xf9ng chuyển đổi liền mạch giữa “chế độ suy nghĩ” v\xe0 “chế độ kh\xf4ng suy nghĩ”. M\xf4 h\xecnh hỗ trợ hiểu v\xe0 suy luận bằng 119 ng\xf4n ngữ v\xe0 phương ngữ, đồng thời c\xf3 khả năng gọi c\xf4ng cụ mạnh mẽ. Trong c\xe1c b\xe0i kiểm tra chuẩn về năng lực tổng hợp, m\xe3 h\xf3a v\xe0 to\xe1n học, đa ng\xf4n ngữ, kiến thức v\xe0 suy luận, m\xf4 h\xecnh c\xf3 thể cạnh tranh với c\xe1c m\xf4 h\xecnh lớn h\xe0ng đầu tr\xean thị trường hiện nay như DeepSeek R1, OpenAI o1, o3-mini, Grok 3 v\xe0 Google Gemini 2.5 Pro."},"Qwen3-235B-A22B-Instruct-2507-FP8":{"description":"Qwen3 235B A22B Instruct 2507: M\xf4 h\xecnh tối ưu h\xf3a cho suy luận n\xe2ng cao v\xe0 chỉ dẫn đối thoại, kiến tr\xfac chuy\xean gia hỗn hợp gi\xfap duy tr\xec hiệu quả suy luận với số lượng tham số lớn."},"Qwen3-32B":{"description":"Qwen3-32B l\xe0 m\xf4 h\xecnh đặc (Dense Model), giới thiệu “chế độ suy luận hỗn hợp”, cho ph\xe9p người d\xf9ng chuyển đổi liền mạch giữa “chế độ suy nghĩ” v\xe0 “chế độ kh\xf4ng suy nghĩ”. Nhờ cải tiến kiến tr\xfac m\xf4 h\xecnh, tăng dữ liệu huấn luyện v\xe0 phương ph\xe1p huấn luyện hiệu quả hơn, hiệu suất tổng thể tương đương với Qwen2.5-72B."},"SenseChat":{"description":"M\xf4 h\xecnh phi\xean bản cơ bản (V4), độ d\xe0i ngữ cảnh 4K, khả năng tổng qu\xe1t mạnh mẽ."},"SenseChat-128K":{"description":"M\xf4 h\xecnh phi\xean bản cơ bản (V4), độ d\xe0i ngữ cảnh 128K, thể hiện xuất sắc trong c\xe1c nhiệm vụ hiểu v\xe0 sinh văn bản d\xe0i."},"SenseChat-32K":{"description":"M\xf4 h\xecnh phi\xean bản cơ bản (V4), độ d\xe0i ngữ cảnh 32K, linh hoạt \xe1p dụng trong nhiều t\xecnh huống."},"SenseChat-5":{"description":"Phi\xean bản m\xf4 h\xecnh mới nhất (V5.5), độ d\xe0i ngữ cảnh 128K, khả năng cải thiện đ\xe1ng kể trong suy luận to\xe1n học, đối thoại tiếng Anh, theo d\xf5i chỉ dẫn v\xe0 hiểu biết văn bản d\xe0i, ngang tầm với GPT-4o."},"SenseChat-5-1202":{"description":"Phi\xean bản mới nhất dựa tr\xean V5.5, cải thiện đ\xe1ng kể về năng lực cơ bản tiếng Trung v\xe0 tiếng Anh, tr\xf2 chuyện, kiến thức khoa học tự nhi\xean, khoa học x\xe3 hội, viết l\xe1ch, logic to\xe1n học v\xe0 kiểm so\xe1t số lượng từ so với phi\xean bản trước."},"SenseChat-5-Cantonese":{"description":"Độ d\xe0i ngữ cảnh 32K, vượt qua GPT-4 trong hiểu biết đối thoại tiếng Quảng Đ\xf4ng, c\xf3 thể so s\xe1nh với GPT-4 Turbo trong nhiều lĩnh vực như kiến thức, suy luận, to\xe1n học v\xe0 lập tr\xecnh m\xe3."},"SenseChat-5-beta":{"description":"Một số hiệu suất vượt trội hơn SenseCat-5-1202"},"SenseChat-Character":{"description":"M\xf4 h\xecnh phi\xean bản ti\xeau chuẩn, độ d\xe0i ngữ cảnh 8K, tốc độ phản hồi cao."},"SenseChat-Character-Pro":{"description":"M\xf4 h\xecnh phi\xean bản cao cấp, độ d\xe0i ngữ cảnh 32K, khả năng được cải thiện to\xe0n diện, hỗ trợ đối thoại tiếng Trung/tiếng Anh."},"SenseChat-Turbo":{"description":"Ph\xf9 hợp cho c\xe1c t\xecnh huống hỏi đ\xe1p nhanh v\xe0 tinh chỉnh m\xf4 h\xecnh."},"SenseChat-Turbo-1202":{"description":"L\xe0 phi\xean bản nhẹ mới nhất của m\xf4 h\xecnh, đạt được hơn 90% khả năng của m\xf4 h\xecnh đầy đủ, giảm đ\xe1ng kể chi ph\xed suy diễn."},"SenseChat-Vision":{"description":"M\xf4 h\xecnh phi\xean bản mới nhất (V5.5), hỗ trợ đầu v\xe0o nhiều h\xecnh ảnh, ho\xe0n thiện khả năng cơ bản của m\xf4 h\xecnh, đạt được sự cải thiện lớn trong nhận diện thuộc t\xednh đối tượng, mối quan hệ kh\xf4ng gian, nhận diện sự kiện h\xe0nh động, hiểu cảnh, nhận diện cảm x\xfac, suy luận kiến thức logic v\xe0 hiểu sinh ra văn bản."},"SenseNova-V6-5-Pro":{"description":"Th\xf4ng qua việc cập nhật to\xe0n diện dữ liệu đa phương thức, ng\xf4n ngữ v\xe0 suy luận c\xf9ng với tối ưu h\xf3a chiến lược huấn luyện, m\xf4 h\xecnh mới đạt được sự cải thiện đ\xe1ng kể trong suy luận đa phương thức v\xe0 khả năng tu\xe2n theo chỉ dẫn tổng qu\xe1t, hỗ trợ cửa sổ ngữ cảnh l\xean đến 128k v\xe0 thể hiện xuất sắc trong c\xe1c nhiệm vụ chuy\xean biệt như nhận dạng OCR v\xe0 nhận diện IP du lịch văn h\xf3a."},"SenseNova-V6-5-Turbo":{"description":"Th\xf4ng qua việc cập nhật to\xe0n diện dữ liệu đa phương thức, ng\xf4n ngữ v\xe0 suy luận c\xf9ng với tối ưu h\xf3a chiến lược huấn luyện, m\xf4 h\xecnh mới đạt được sự cải thiện đ\xe1ng kể trong suy luận đa phương thức v\xe0 khả năng tu\xe2n theo chỉ dẫn tổng qu\xe1t, hỗ trợ cửa sổ ngữ cảnh l\xean đến 128k v\xe0 thể hiện xuất sắc trong c\xe1c nhiệm vụ chuy\xean biệt như nhận dạng OCR v\xe0 nhận diện IP du lịch văn h\xf3a."},"SenseNova-V6-Pro":{"description":"Thực hiện sự thống nhất nguy\xean bản giữa h\xecnh ảnh, văn bản v\xe0 video, vượt qua giới hạn ph\xe2n t\xe1ch đa phương thức truyền thống, gi\xe0nh được hai giải v\xf4 địch trong c\xe1c đ\xe1nh gi\xe1 OpenCompass v\xe0 SuperCLUE."},"SenseNova-V6-Reasoner":{"description":"Kết hợp giữa l\xfd luận s\xe2u sắc về thị gi\xe1c v\xe0 ng\xf4n ngữ, thực hiện tư duy chậm v\xe0 l\xfd luận s\xe2u, tr\xecnh b\xe0y quy tr\xecnh chuỗi tư duy ho\xe0n chỉnh."},"SenseNova-V6-Turbo":{"description":"Thực hiện sự thống nhất nguy\xean bản giữa h\xecnh ảnh, văn bản v\xe0 video, vượt qua giới hạn ph\xe2n t\xe1ch đa phương thức truyền thống, dẫn đầu to\xe0n diện trong c\xe1c kh\xeda cạnh cốt l\xf5i như khả năng đa phương thức v\xe0 khả năng ng\xf4n ngữ, vừa văn vừa l\xfd, nhiều lần đứng đầu trong c\xe1c đ\xe1nh gi\xe1 trong v\xe0 ngo\xe0i nước."},"Skylark2-lite-8k":{"description":"M\xf4 h\xecnh thế hệ thứ hai Skylark, m\xf4 h\xecnh Skylark2-lite c\xf3 tốc độ phản hồi cao, ph\xf9 hợp cho c\xe1c t\xecnh huống y\xeau cầu t\xednh thời gian thực cao, nhạy cảm với chi ph\xed, kh\xf4ng y\xeau cầu độ ch\xednh x\xe1c m\xf4 h\xecnh cao, chiều d\xe0i cửa sổ ngữ cảnh l\xe0 8k."},"Skylark2-pro-32k":{"description":"M\xf4 h\xecnh thế hệ thứ hai Skylark, phi\xean bản Skylark2-pro c\xf3 độ ch\xednh x\xe1c cao hơn, ph\xf9 hợp cho c\xe1c t\xecnh huống tạo văn bản phức tạp, như tạo nội dung chuy\xean ng\xe0nh, s\xe1ng t\xe1c tiểu thuyết, dịch thuật chất lượng cao, chiều d\xe0i cửa sổ ngữ cảnh l\xe0 32k."},"Skylark2-pro-4k":{"description":"M\xf4 h\xecnh thế hệ thứ hai Skylark, m\xf4 h\xecnh Skylark2-pro c\xf3 độ ch\xednh x\xe1c cao hơn, ph\xf9 hợp cho c\xe1c t\xecnh huống tạo văn bản phức tạp, như tạo nội dung chuy\xean ng\xe0nh, s\xe1ng t\xe1c tiểu thuyết, dịch thuật chất lượng cao, chiều d\xe0i cửa sổ ngữ cảnh l\xe0 4k."},"Skylark2-pro-character-4k":{"description":"M\xf4 h\xecnh thế hệ thứ hai Skylark, m\xf4 h\xecnh Skylark2-pro-character c\xf3 khả năng nhập vai v\xe0 tr\xf2 chuyện xuất sắc, giỏi nhập vai theo y\xeau cầu của người d\xf9ng, tạo ra những cuộc tr\xf2 chuyện tự nhi\xean, ph\xf9 hợp để x\xe2y dựng chatbot, trợ l\xfd ảo v\xe0 dịch vụ kh\xe1ch h\xe0ng trực tuyến, c\xf3 tốc độ phản hồi cao."},"Skylark2-pro-turbo-8k":{"description":"M\xf4 h\xecnh thế hệ thứ hai Skylark, m\xf4 h\xecnh Skylark2-pro-turbo-8k c\xf3 tốc độ suy diễn nhanh hơn, chi ph\xed thấp hơn, chiều d\xe0i cửa sổ ngữ cảnh l\xe0 8k."},"THUDM/GLM-4-32B-0414":{"description":"GLM-4-32B-0414 l\xe0 m\xf4 h\xecnh m\xe3 nguồn mở thế hệ mới trong d\xf2ng GLM, với 32 tỷ tham số. M\xf4 h\xecnh n\xe0y c\xf3 hiệu suất tương đương với c\xe1c d\xf2ng GPT của OpenAI v\xe0 c\xe1c d\xf2ng V3/R1 của DeepSeek."},"THUDM/GLM-4-9B-0414":{"description":"GLM-4-9B-0414 l\xe0 m\xf4 h\xecnh nhỏ trong d\xf2ng GLM, với 9 tỷ tham số. M\xf4 h\xecnh n\xe0y kế thừa c\xe1c đặc điểm kỹ thuật của d\xf2ng GLM-4-32B, nhưng cung cấp lựa chọn triển khai nhẹ hơn. Mặc d\xf9 quy m\xf4 nhỏ, GLM-4-9B-0414 vẫn thể hiện khả năng xuất sắc trong c\xe1c nhiệm vụ như tạo m\xe3, thiết kế trang web, tạo đồ họa SVG v\xe0 viết dựa tr\xean t\xecm kiếm."},"THUDM/GLM-4.1V-9B-Thinking":{"description":"GLM-4.1V-9B-Thinking l\xe0 một m\xf4 h\xecnh ng\xf4n ngữ thị gi\xe1c (VLM) m\xe3 nguồn mở được ph\xe1t h\xe0nh chung bởi Zhipu AI v\xe0 Ph\xf2ng th\xed nghiệm KEG của Đại học Thanh Hoa, được thiết kế đặc biệt để xử l\xfd c\xe1c nhiệm vụ nhận thức đa phương thức phức tạp. M\xf4 h\xecnh n\xe0y dựa tr\xean m\xf4 h\xecnh cơ sở GLM-4-9B-0414, th\xf4ng qua việc giới thiệu cơ chế suy luận “Chuỗi tư duy” (Chain-of-Thought) v\xe0 \xe1p dụng chiến lược học tăng cường, đ\xe3 n\xe2ng cao đ\xe1ng kể khả năng suy luận đa phương thức v\xe0 t\xednh ổn định của n\xf3."},"THUDM/GLM-Z1-32B-0414":{"description":"GLM-Z1-32B-0414 l\xe0 một m\xf4 h\xecnh suy luận c\xf3 khả năng suy tư s\xe2u. M\xf4 h\xecnh n\xe0y được ph\xe1t triển dựa tr\xean GLM-4-32B-0414 th\xf4ng qua khởi động lạnh v\xe0 tăng cường học tập, v\xe0 đ\xe3 được huấn luyện th\xeam trong c\xe1c nhiệm vụ to\xe1n học, m\xe3 v\xe0 logic. So với m\xf4 h\xecnh cơ sở, GLM-Z1-32B-0414 đ\xe3 n\xe2ng cao đ\xe1ng kể khả năng to\xe1n học v\xe0 khả năng giải quyết c\xe1c nhiệm vụ phức tạp."},"THUDM/GLM-Z1-9B-0414":{"description":"GLM-Z1-9B-0414 l\xe0 m\xf4 h\xecnh nhỏ trong d\xf2ng GLM, chỉ c\xf3 9 tỷ tham số, nhưng vẫn thể hiện khả năng đ\xe1ng kinh ngạc trong khi duy tr\xec truyền thống m\xe3 nguồn mở. Mặc d\xf9 quy m\xf4 nhỏ, m\xf4 h\xecnh n\xe0y vẫn thể hiện xuất sắc trong suy luận to\xe1n học v\xe0 c\xe1c nhiệm vụ chung, với hiệu suất tổng thể đứng đầu trong c\xe1c m\xf4 h\xecnh m\xe3 nguồn mở c\xf9ng quy m\xf4."},"THUDM/GLM-Z1-Rumination-32B-0414":{"description":"GLM-Z1-Rumination-32B-0414 l\xe0 một m\xf4 h\xecnh suy luận s\xe2u c\xf3 khả năng suy tư (đối thủ của Deep Research của OpenAI). Kh\xe1c với c\xe1c m\xf4 h\xecnh suy tư s\xe2u điển h\xecnh, m\xf4 h\xecnh suy tư n\xe0y sử dụng thời gian suy tư s\xe2u hơn để giải quyết c\xe1c vấn đề mở v\xe0 phức tạp hơn."},"THUDM/glm-4-9b-chat":{"description":"GLM-4 9B l\xe0 phi\xean bản m\xe3 nguồn mở, cung cấp trải nghiệm đối thoại tối ưu cho c\xe1c ứng dụng hội thoại."},"Tongyi-Zhiwen/QwenLong-L1-32B":{"description":"QwenLong-L1-32B l\xe0 m\xf4 h\xecnh suy luận lớn c\xf3 ngữ cảnh d\xe0i đầu ti\xean được huấn luyện bằng học tăng cường (LRM), tối ưu h\xf3a cho c\xe1c nhiệm vụ suy luận văn bản d\xe0i. M\xf4 h\xecnh sử dụng khung học tăng cường mở rộng ngữ cảnh tiến dần, đạt được chuyển đổi ổn định từ ngữ cảnh ngắn sang d\xe0i. Trong bảy b\xe0i kiểm tra chuẩn hỏi đ\xe1p t\xe0i liệu ngữ cảnh d\xe0i, QwenLong-L1-32B vượt qua c\xe1c m\xf4 h\xecnh h\xe0ng đầu như OpenAI-o3-mini v\xe0 Qwen3-235B-A22B, hiệu suất tương đương Claude-3.7-Sonnet-Thinking. M\xf4 h\xecnh đặc biệt mạnh về suy luận to\xe1n học, logic v\xe0 suy luận đa bước."},"Yi-34B-Chat":{"description":"Yi-1.5-34B, trong khi vẫn giữ được khả năng ng\xf4n ngữ chung xuất sắc của d\xf2ng m\xf4 h\xecnh gốc, đ\xe3 tăng cường đ\xe0o tạo với 500 tỷ token chất lượng cao, n\xe2ng cao đ\xe1ng kể khả năng logic to\xe1n học v\xe0 m\xe3."},"abab5.5-chat":{"description":"Hướng đến c\xe1c t\xecnh huống sản xuất, hỗ trợ xử l\xfd nhiệm vụ phức tạp v\xe0 sinh văn bản hiệu quả, ph\xf9 hợp cho c\xe1c ứng dụng trong lĩnh vực chuy\xean m\xf4n."},"abab5.5s-chat":{"description":"Được thiết kế đặc biệt cho c\xe1c t\xecnh huống đối thoại bằng tiếng Trung, cung cấp khả năng sinh đối thoại chất lượng cao bằng tiếng Trung, ph\xf9 hợp cho nhiều t\xecnh huống ứng dụng."},"abab6.5g-chat":{"description":"Được thiết kế đặc biệt cho c\xe1c cuộc đối thoại đa ng\xf4n ngữ, hỗ trợ sinh đối thoại chất lượng cao bằng tiếng Anh v\xe0 nhiều ng\xf4n ngữ kh\xe1c."},"abab6.5s-chat":{"description":"Ph\xf9 hợp cho nhiều nhiệm vụ xử l\xfd ng\xf4n ngữ tự nhi\xean, bao gồm sinh văn bản, hệ thống đối thoại, v.v."},"abab6.5t-chat":{"description":"Tối ưu h\xf3a cho c\xe1c t\xecnh huống đối thoại bằng tiếng Trung, cung cấp khả năng sinh đối thoại mượt m\xe0 v\xe0 ph\xf9 hợp với th\xf3i quen diễn đạt tiếng Trung."},"accounts/fireworks/models/deepseek-r1":{"description":"DeepSeek-R1 l\xe0 một m\xf4 h\xecnh ng\xf4n ngữ lớn ti\xean tiến, được tối ưu h\xf3a th\xf4ng qua học tăng cường v\xe0 dữ liệu khởi động lạnh, c\xf3 hiệu suất suy luận, to\xe1n học v\xe0 lập tr\xecnh xuất sắc."},"accounts/fireworks/models/deepseek-v3":{"description":"M\xf4 h\xecnh ng\xf4n ngữ Mixture-of-Experts (MoE) mạnh mẽ do Deepseek cung cấp, với tổng số tham số l\xe0 671B, mỗi k\xfd hiệu k\xedch hoạt 37B tham số."},"accounts/fireworks/models/llama-v3-70b-instruct":{"description":"M\xf4 h\xecnh chỉ dẫn Llama 3 70B, được tối ưu h\xf3a cho đối thoại đa ng\xf4n ngữ v\xe0 hiểu ng\xf4n ngữ tự nhi\xean, hiệu suất vượt trội hơn nhiều m\xf4 h\xecnh cạnh tranh."},"accounts/fireworks/models/llama-v3-8b-instruct":{"description":"M\xf4 h\xecnh chỉ dẫn Llama 3 8B, được tối ưu h\xf3a cho đối thoại v\xe0 c\xe1c nhiệm vụ đa ng\xf4n ngữ, thể hiện hiệu suất xuất sắc v\xe0 hiệu quả."},"accounts/fireworks/models/llama-v3-8b-instruct-hf":{"description":"M\xf4 h\xecnh chỉ dẫn Llama 3 8B (phi\xean bản HF), kết quả nhất qu\xe1n với thực hiện ch\xednh thức, c\xf3 t\xednh nhất qu\xe1n cao v\xe0 tương th\xedch đa nền tảng."},"accounts/fireworks/models/llama-v3p1-405b-instruct":{"description":"M\xf4 h\xecnh chỉ dẫn Llama 3.1 405B, c\xf3 số lượng tham số cực lớn, ph\xf9 hợp cho c\xe1c nhiệm vụ phức tạp v\xe0 theo d\xf5i chỉ dẫn trong c\xe1c t\xecnh huống tải cao."},"accounts/fireworks/models/llama-v3p1-70b-instruct":{"description":"M\xf4 h\xecnh chỉ dẫn Llama 3.1 70B, cung cấp khả năng hiểu v\xe0 sinh ng\xf4n ngữ tự nhi\xean xuất sắc, l\xe0 lựa chọn l\xfd tưởng cho c\xe1c nhiệm vụ đối thoại v\xe0 ph\xe2n t\xedch."},"accounts/fireworks/models/llama-v3p1-8b-instruct":{"description":"M\xf4 h\xecnh chỉ dẫn Llama 3.1 8B, được tối ưu h\xf3a cho đối thoại đa ng\xf4n ngữ, c\xf3 thể vượt qua hầu hết c\xe1c m\xf4 h\xecnh m\xe3 nguồn mở v\xe0 đ\xf3ng trong c\xe1c ti\xeau chuẩn ng\xe0nh phổ biến."},"accounts/fireworks/models/llama-v3p2-11b-vision-instruct":{"description":"M\xf4 h\xecnh suy luận h\xecnh ảnh chỉ dẫn với 11B tham số của Meta. M\xf4 h\xecnh n\xe0y được tối ưu h\xf3a cho nhận diện h\xecnh ảnh, suy luận h\xecnh ảnh, m\xf4 tả h\xecnh ảnh v\xe0 trả lời c\xe1c c\xe2u hỏi chung li\xean quan đến h\xecnh ảnh. M\xf4 h\xecnh c\xf3 khả năng hiểu dữ liệu h\xecnh ảnh như biểu đồ v\xe0 đồ thị, v\xe0 thu hẹp khoảng c\xe1ch giữa h\xecnh ảnh v\xe0 ng\xf4n ngữ th\xf4ng qua việc tạo m\xf4 tả văn bản về chi tiết h\xecnh ảnh."},"accounts/fireworks/models/llama-v3p2-3b-instruct":{"description":"M\xf4 h\xecnh chỉ dẫn Llama 3.2 3B l\xe0 một m\xf4 h\xecnh đa ng\xf4n ngữ nhẹ m\xe0 Meta ph\xe1t h\xe0nh. M\xf4 h\xecnh n\xe0y được thiết kế để tăng cường hiệu quả, mang lại cải tiến đ\xe1ng kể về độ trễ v\xe0 chi ph\xed so với c\xe1c m\xf4 h\xecnh lớn hơn. C\xe1c trường hợp sử dụng v\xed dụ của m\xf4 h\xecnh n\xe0y bao gồm truy vấn, viết lại th\xf4ng b\xe1o v\xe0 hỗ trợ viết."},"accounts/fireworks/models/llama-v3p2-90b-vision-instruct":{"description":"M\xf4 h\xecnh suy luận h\xecnh ảnh chỉ dẫn với 90B tham số của Meta. M\xf4 h\xecnh n\xe0y được tối ưu h\xf3a cho nhận diện h\xecnh ảnh, suy luận h\xecnh ảnh, m\xf4 tả h\xecnh ảnh v\xe0 trả lời c\xe1c c\xe2u hỏi chung li\xean quan đến h\xecnh ảnh. M\xf4 h\xecnh c\xf3 khả năng hiểu dữ liệu h\xecnh ảnh như biểu đồ v\xe0 đồ thị, v\xe0 thu hẹp khoảng c\xe1ch giữa h\xecnh ảnh v\xe0 ng\xf4n ngữ th\xf4ng qua việc tạo m\xf4 tả văn bản về chi tiết h\xecnh ảnh."},"accounts/fireworks/models/llama-v3p3-70b-instruct":{"description":"Llama 3.3 70B Instruct l\xe0 phi\xean bản cập nhật th\xe1ng 12 của Llama 3.1 70B. M\xf4 h\xecnh n\xe0y được cải tiến dựa tr\xean Llama 3.1 70B (ra mắt v\xe0o th\xe1ng 7 năm 2024), n\xe2ng cao khả năng gọi c\xf4ng cụ, hỗ trợ văn bản đa ng\xf4n ngữ, to\xe1n học v\xe0 lập tr\xecnh. M\xf4 h\xecnh n\xe0y đạt được tr\xecnh độ h\xe0ng đầu trong ng\xe0nh về suy luận, to\xe1n học v\xe0 tu\xe2n thủ hướng dẫn, đồng thời c\xf3 thể cung cấp hiệu suất tương tự như 3.1 405B, với lợi thế đ\xe1ng kể về tốc độ v\xe0 chi ph\xed."},"accounts/fireworks/models/mistral-small-24b-instruct-2501":{"description":"M\xf4 h\xecnh 24B tham số, c\xf3 khả năng ti\xean tiến tương đương với c\xe1c m\xf4 h\xecnh lớn hơn."},"accounts/fireworks/models/mixtral-8x22b-instruct":{"description":"M\xf4 h\xecnh chỉ dẫn Mixtral MoE 8x22B, với số lượng tham số lớn v\xe0 kiến tr\xfac nhiều chuy\xean gia, hỗ trợ to\xe0n diện cho việc xử l\xfd hiệu quả c\xe1c nhiệm vụ phức tạp."},"accounts/fireworks/models/mixtral-8x7b-instruct":{"description":"M\xf4 h\xecnh chỉ dẫn Mixtral MoE 8x7B, kiến tr\xfac nhiều chuy\xean gia cung cấp khả năng theo d\xf5i v\xe0 thực hiện chỉ dẫn hiệu quả."},"accounts/fireworks/models/mythomax-l2-13b":{"description":"M\xf4 h\xecnh MythoMax L2 13B, kết hợp c\xf4ng nghệ hợp nhất mới, xuất sắc trong việc kể chuyện v\xe0 đ\xf3ng vai."},"accounts/fireworks/models/phi-3-vision-128k-instruct":{"description":"M\xf4 h\xecnh chỉ dẫn Phi 3 Vision, m\xf4 h\xecnh đa m\xf4 h\xecnh nhẹ, c\xf3 khả năng xử l\xfd th\xf4ng tin h\xecnh ảnh v\xe0 văn bản phức tạp, với khả năng suy luận mạnh mẽ."},"accounts/fireworks/models/qwen-qwq-32b-preview":{"description":"M\xf4 h\xecnh QwQ l\xe0 một m\xf4 h\xecnh nghi\xean cứu thử nghiệm được ph\xe1t triển bởi đội ngũ Qwen, tập trung v\xe0o việc n\xe2ng cao khả năng suy luận của AI."},"accounts/fireworks/models/qwen2-vl-72b-instruct":{"description":"Phi\xean bản 72B của m\xf4 h\xecnh Qwen-VL l\xe0 th\xe0nh quả mới nhất của Alibaba, đại diện cho gần một năm đổi mới."},"accounts/fireworks/models/qwen2p5-72b-instruct":{"description":"Qwen2.5 l\xe0 một loạt m\xf4 h\xecnh ng\xf4n ngữ chỉ chứa bộ giải m\xe3 do đội ngũ Qwen của Alibaba Cloud ph\xe1t triển. Những m\xf4 h\xecnh n\xe0y cung cấp c\xe1c k\xedch thước kh\xe1c nhau, bao gồm 0.5B, 1.5B, 3B, 7B, 14B, 32B v\xe0 72B, v\xe0 c\xf3 hai biến thể: phi\xean bản cơ sở (base) v\xe0 phi\xean bản chỉ dẫn (instruct)."},"accounts/fireworks/models/qwen2p5-coder-32b-instruct":{"description":"Qwen2.5 Coder 32B Instruct l\xe0 phi\xean bản mới nhất trong loạt m\xf4 h\xecnh ng\xf4n ngữ lớn chuy\xean biệt cho m\xe3 do Alibaba Cloud ph\xe1t h\xe0nh. M\xf4 h\xecnh n\xe0y được cải thiện đ\xe1ng kể khả năng tạo m\xe3, suy luận v\xe0 sửa chữa th\xf4ng qua việc đ\xe0o tạo tr\xean 5.5 triệu tỷ tokens, kh\xf4ng chỉ n\xe2ng cao khả năng lập tr\xecnh m\xe0 c\xf2n duy tr\xec lợi thế về khả năng to\xe1n học v\xe0 tổng qu\xe1t. M\xf4 h\xecnh cung cấp nền tảng to\xe0n diện hơn cho c\xe1c ứng dụng thực tế như t\xe1c nh\xe2n m\xe3."},"accounts/yi-01-ai/models/yi-large":{"description":"M\xf4 h\xecnh Yi-Large, c\xf3 khả năng xử l\xfd đa ng\xf4n ngữ xuất sắc, c\xf3 thể được sử dụng cho nhiều nhiệm vụ sinh v\xe0 hiểu ng\xf4n ngữ."},"ai21-jamba-1.5-large":{"description":"M\xf4 h\xecnh đa ng\xf4n ngữ với 398B tham số (94B hoạt động), cung cấp cửa sổ ngữ cảnh d\xe0i 256K, gọi h\xe0m, đầu ra c\xf3 cấu tr\xfac v\xe0 tạo ra nội dung c\xf3 căn cứ."},"ai21-jamba-1.5-mini":{"description":"M\xf4 h\xecnh đa ng\xf4n ngữ với 52B tham số (12B hoạt động), cung cấp cửa sổ ngữ cảnh d\xe0i 256K, gọi h\xe0m, đầu ra c\xf3 cấu tr\xfac v\xe0 tạo ra nội dung c\xf3 căn cứ."},"ai21-labs/AI21-Jamba-1.5-Large":{"description":"Một m\xf4 h\xecnh đa ng\xf4n ngữ với 398 tỷ tham số (94 tỷ tham số hoạt động), cung cấp cửa sổ ngữ cảnh d\xe0i 256K, gọi h\xe0m, đầu ra c\xf3 cấu tr\xfac v\xe0 sinh dựa tr\xean sự thật."},"ai21-labs/AI21-Jamba-1.5-Mini":{"description":"Một m\xf4 h\xecnh đa ng\xf4n ngữ với 52 tỷ tham số (12 tỷ tham số hoạt động), cung cấp cửa sổ ngữ cảnh d\xe0i 256K, gọi h\xe0m, đầu ra c\xf3 cấu tr\xfac v\xe0 sinh dựa tr\xean sự thật."},"alibaba/qwen-3-14b":{"description":"Qwen3 l\xe0 thế hệ mới nhất trong d\xf2ng m\xf4 h\xecnh ng\xf4n ngữ lớn Qwen, cung cấp một bộ m\xf4 h\xecnh chuy\xean gia d\xe0y đặc v\xe0 hỗn hợp (MoE) to\xe0n diện. Được x\xe2y dựng dựa tr\xean đ\xe0o tạo rộng r\xe3i, Qwen3 mang lại bước đột ph\xe1 trong suy luận, tu\xe2n thủ chỉ dẫn, khả năng đại l\xfd v\xe0 hỗ trợ đa ng\xf4n ngữ."},"alibaba/qwen-3-235b":{"description":"Qwen3 l\xe0 thế hệ mới nhất trong d\xf2ng m\xf4 h\xecnh ng\xf4n ngữ lớn Qwen, cung cấp một bộ m\xf4 h\xecnh chuy\xean gia d\xe0y đặc v\xe0 hỗn hợp (MoE) to\xe0n diện. Được x\xe2y dựng dựa tr\xean đ\xe0o tạo rộng r\xe3i, Qwen3 mang lại bước đột ph\xe1 trong suy luận, tu\xe2n thủ chỉ dẫn, khả năng đại l\xfd v\xe0 hỗ trợ đa ng\xf4n ngữ."},"alibaba/qwen-3-30b":{"description":"Qwen3 l\xe0 thế hệ mới nhất trong d\xf2ng m\xf4 h\xecnh ng\xf4n ngữ lớn Qwen, cung cấp một bộ m\xf4 h\xecnh chuy\xean gia d\xe0y đặc v\xe0 hỗn hợp (MoE) to\xe0n diện. Được x\xe2y dựng dựa tr\xean đ\xe0o tạo rộng r\xe3i, Qwen3 mang lại bước đột ph\xe1 trong suy luận, tu\xe2n thủ chỉ dẫn, khả năng đại l\xfd v\xe0 hỗ trợ đa ng\xf4n ngữ."},"alibaba/qwen-3-32b":{"description":"Qwen3 l\xe0 thế hệ mới nhất trong d\xf2ng m\xf4 h\xecnh ng\xf4n ngữ lớn Qwen, cung cấp một bộ m\xf4 h\xecnh chuy\xean gia d\xe0y đặc v\xe0 hỗn hợp (MoE) to\xe0n diện. Được x\xe2y dựng dựa tr\xean đ\xe0o tạo rộng r\xe3i, Qwen3 mang lại bước đột ph\xe1 trong suy luận, tu\xe2n thủ chỉ dẫn, khả năng đại l\xfd v\xe0 hỗ trợ đa ng\xf4n ngữ."},"alibaba/qwen3-coder":{"description":"Qwen3-Coder-480B-A35B-Instruct l\xe0 m\xf4 h\xecnh m\xe3 h\xf3a c\xf3 khả năng đại l\xfd cao nhất của Qwen, thể hiện hiệu suất nổi bật trong m\xe3 h\xf3a đại l\xfd, sử dụng tr\xecnh duyệt đại l\xfd v\xe0 c\xe1c nhiệm vụ m\xe3 h\xf3a cơ bản kh\xe1c, đạt kết quả tương đương với Claude Sonnet."},"amazon/nova-lite":{"description":"Một m\xf4 h\xecnh đa phương thức với chi ph\xed rất thấp, xử l\xfd đầu v\xe0o h\xecnh ảnh, video v\xe0 văn bản với tốc độ cực nhanh."},"amazon/nova-micro":{"description":"Một m\xf4 h\xecnh chỉ văn bản, cung cấp phản hồi với độ trễ thấp nhất ở chi ph\xed rất thấp."},"amazon/nova-pro":{"description":"Một m\xf4 h\xecnh đa phương thức rất năng lực, kết hợp tối ưu giữa độ ch\xednh x\xe1c, tốc độ v\xe0 chi ph\xed, ph\xf9 hợp cho nhiều nhiệm vụ đa dạng."},"amazon/titan-embed-text-v2":{"description":"Amazon Titan Text Embeddings V2 l\xe0 m\xf4 h\xecnh nh\xfang đa ng\xf4n ngữ nhẹ, hiệu quả, hỗ trợ c\xe1c chiều 1024, 512 v\xe0 256."},"anthropic.claude-3-5-sonnet-20240620-v1:0":{"description":"Claude 3.5 Sonnet n\xe2ng cao ti\xeau chuẩn ng\xe0nh, hiệu suất vượt trội hơn c\xe1c m\xf4 h\xecnh cạnh tranh v\xe0 Claude 3 Opus, thể hiện xuất sắc trong nhiều đ\xe1nh gi\xe1, đồng thời c\xf3 tốc độ v\xe0 chi ph\xed của m\xf4 h\xecnh tầm trung của ch\xfang t\xf4i."},"anthropic.claude-3-5-sonnet-20241022-v2:0":{"description":"Claude 3.5 Sonnet n\xe2ng cao ti\xeau chuẩn ng\xe0nh, hiệu suất vượt trội so với c\xe1c m\xf4 h\xecnh đối thủ v\xe0 Claude 3 Opus, thể hiện xuất sắc trong c\xe1c đ\xe1nh gi\xe1 rộng r\xe3i, đồng thời c\xf3 tốc độ v\xe0 chi ph\xed tương đương với c\xe1c m\xf4 h\xecnh tầm trung của ch\xfang t\xf4i."},"anthropic.claude-3-haiku-20240307-v1:0":{"description":"Claude 3 Haiku l\xe0 m\xf4 h\xecnh nhanh nhất v\xe0 gọn nhẹ nhất của Anthropic, cung cấp tốc độ phản hồi gần như ngay lập tức. N\xf3 c\xf3 thể nhanh ch\xf3ng trả lời c\xe1c truy vấn v\xe0 y\xeau cầu đơn giản. Kh\xe1ch h\xe0ng sẽ c\xf3 thể x\xe2y dựng trải nghiệm AI liền mạch m\xf4 phỏng tương t\xe1c của con người. Claude 3 Haiku c\xf3 thể xử l\xfd h\xecnh ảnh v\xe0 trả về đầu ra văn bản, với cửa sổ ngữ cảnh 200K."},"anthropic.claude-3-opus-20240229-v1:0":{"description":"Claude 3 Opus l\xe0 m\xf4 h\xecnh AI mạnh nhất của Anthropic, c\xf3 hiệu suất ti\xean tiến trong c\xe1c nhiệm vụ phức tạp. N\xf3 c\xf3 thể xử l\xfd c\xe1c gợi \xfd mở v\xe0 c\xe1c t\xecnh huống chưa thấy, với độ tr\xf4i chảy v\xe0 khả năng hiểu giống con người xuất sắc. Claude 3 Opus thể hiện những khả năng ti\xean tiến của AI sinh. Claude 3 Opus c\xf3 thể xử l\xfd h\xecnh ảnh v\xe0 trả về đầu ra văn bản, với cửa sổ ngữ cảnh 200K."},"anthropic.claude-3-sonnet-20240229-v1:0":{"description":"Claude 3 Sonnet của Anthropic đạt được sự c\xe2n bằng l\xfd tưởng giữa tr\xed th\xf4ng minh v\xe0 tốc độ - đặc biệt ph\xf9 hợp cho khối lượng c\xf4ng việc doanh nghiệp. N\xf3 cung cấp hiệu quả tối đa với gi\xe1 thấp hơn đối thủ, được thiết kế để trở th\xe0nh một m\xe1y chủ đ\xe1ng tin cậy v\xe0 bền bỉ, ph\xf9 hợp cho triển khai AI quy m\xf4 lớn. Claude 3 Sonnet c\xf3 thể xử l\xfd h\xecnh ảnh v\xe0 trả về đầu ra văn bản, với cửa sổ ngữ cảnh 200K."},"anthropic.claude-instant-v1":{"description":"Một m\xf4 h\xecnh nhanh ch\xf3ng, kinh tế nhưng vẫn rất mạnh mẽ, c\xf3 thể xử l\xfd một loạt c\xe1c nhiệm vụ bao gồm đối thoại h\xe0ng ng\xe0y, ph\xe2n t\xedch văn bản, t\xf3m tắt v\xe0 hỏi đ\xe1p t\xe0i liệu."},"anthropic.claude-v2":{"description":"M\xf4 h\xecnh của Anthropic thể hiện khả năng cao trong nhiều nhiệm vụ từ đối thoại phức tạp v\xe0 sinh nội dung s\xe1ng tạo đến tu\xe2n thủ chỉ dẫn chi tiết."},"anthropic.claude-v2:1":{"description":"Phi\xean bản cập nhật của Claude 2, c\xf3 cửa sổ ngữ cảnh gấp đ\xf4i, c\xf9ng với độ tin cậy, tỷ lệ ảo gi\xe1c v\xe0 độ ch\xednh x\xe1c dựa tr\xean bằng chứng được cải thiện trong c\xe1c t\xe0i liệu d\xe0i v\xe0 ngữ cảnh RAG."},"anthropic/claude-3-haiku":{"description":"Claude 3 Haiku l\xe0 m\xf4 h\xecnh nhanh nhất của Anthropic cho đến nay, được thiết kế cho c\xe1c khối lượng c\xf4ng việc doanh nghiệp thường li\xean quan đến c\xe1c lời nhắc d\xe0i. Haiku c\xf3 thể ph\xe2n t\xedch nhanh lượng lớn t\xe0i liệu như b\xe1o c\xe1o qu\xfd, hợp đồng hoặc vụ kiện ph\xe1p l\xfd với chi ph\xed chỉ bằng một nửa so với c\xe1c m\xf4 h\xecnh c\xf9ng cấp hiệu suất."},"anthropic/claude-3-opus":{"description":"Claude 3 Opus l\xe0 m\xf4 h\xecnh th\xf4ng minh nhất của Anthropic, dẫn đầu thị trường trong c\xe1c nhiệm vụ phức tạp cao. N\xf3 c\xf3 khả năng xử l\xfd c\xe1c lời nhắc mở v\xe0 c\xe1c t\xecnh huống chưa từng thấy với độ tr\xf4i chảy xuất sắc v\xe0 hiểu biết gần như con người."},"anthropic/claude-3.5-haiku":{"description":"Claude 3.5 Haiku l\xe0 thế hệ tiếp theo của m\xf4 h\xecnh nhanh nhất của ch\xfang t\xf4i. Với tốc độ tương đương Claude 3 Haiku, Claude 3.5 Haiku được cải thiện tr\xean mọi kỹ năng v\xe0 vượt qua m\xf4 h\xecnh lớn nhất thế hệ trước l\xe0 Claude 3 Opus trong nhiều b\xe0i kiểm tra tr\xed tuệ."},"anthropic/claude-3.5-sonnet":{"description":"Claude 3.5 Sonnet đạt sự c\xe2n bằng l\xfd tưởng giữa tr\xed tuệ v\xe0 tốc độ — đặc biệt ph\xf9 hợp cho khối lượng c\xf4ng việc doanh nghiệp. So với c\xe1c sản phẩm c\xf9ng loại, n\xf3 cung cấp hiệu suất mạnh mẽ với chi ph\xed thấp hơn v\xe0 được thiết kế cho độ bền cao trong triển khai AI quy m\xf4 lớn."},"anthropic/claude-3.7-sonnet":{"description":"Claude 3.7 Sonnet l\xe0 m\xf4 h\xecnh suy luận hỗn hợp đầu ti\xean v\xe0 l\xe0 m\xf4 h\xecnh th\xf4ng minh nhất của Anthropic cho đến nay. N\xf3 cung cấp hiệu suất ti\xean tiến trong m\xe3 h\xf3a, tạo nội dung, ph\xe2n t\xedch dữ liệu v\xe0 lập kế hoạch, x\xe2y dựng tr\xean nền tảng khả năng kỹ thuật phần mềm v\xe0 sử dụng m\xe1y t\xednh của Claude 3.5 Sonnet."},"anthropic/claude-opus-4":{"description":"Claude Opus 4 l\xe0 m\xf4 h\xecnh mạnh mẽ nhất của Anthropic cho đến nay v\xe0 l\xe0 m\xf4 h\xecnh m\xe3 h\xf3a tốt nhất thế giới, dẫn đầu tr\xean c\xe1c bảng đ\xe1nh gi\xe1 SWE-bench (72,5%) v\xe0 Terminal-bench (43,2%). N\xf3 cung cấp hiệu suất li\xean tục cho c\xe1c nhiệm vụ d\xe0i hạn đ\xf2i hỏi sự tập trung cao v\xe0 h\xe0ng ngh\xecn bước, c\xf3 thể l\xe0m việc li\xean tục trong nhiều giờ — mở rộng đ\xe1ng kể khả năng của c\xe1c đại l\xfd AI."},"anthropic/claude-opus-4.1":{"description":"Claude Opus 4.1 l\xe0 phi\xean bản thay thế plug-and-play của Opus 4, cung cấp hiệu suất v\xe0 độ ch\xednh x\xe1c vượt trội cho c\xe1c nhiệm vụ m\xe3 h\xf3a v\xe0 đại l\xfd thực tế. Opus 4.1 n\xe2ng cao hiệu suất m\xe3 h\xf3a ti\xean tiến l\xean 74,5% tr\xean SWE-bench Verified v\xe0 xử l\xfd c\xe1c vấn đề phức tạp nhiều bước với độ nghi\xeam ngặt v\xe0 ch\xfa \xfd đến chi tiết cao hơn."},"anthropic/claude-sonnet-4":{"description":"Claude Sonnet 4 cải tiến đ\xe1ng kể dựa tr\xean khả năng dẫn đầu ng\xe0nh của Sonnet 3.7, thể hiện xuất sắc trong m\xe3 h\xf3a với điểm số ti\xean tiến 72,7% tr\xean SWE-bench. M\xf4 h\xecnh c\xe2n bằng giữa hiệu suất v\xe0 hiệu quả, ph\xf9 hợp cho c\xe1c trường hợp sử dụng nội bộ v\xe0 b\xean ngo\xe0i, đồng thời cung cấp kiểm so\xe1t lớn hơn th\xf4ng qua khả năng điều khiển n\xe2ng cao."},"anthropic/claude-sonnet-4.5":{"description":"Claude Sonnet 4.5 l\xe0 m\xf4 h\xecnh th\xf4ng minh nhất của Anthropic cho đến nay."},"ascend-tribe/pangu-pro-moe":{"description":"Pangu-Pro-MoE 72B-A16B l\xe0 một m\xf4 h\xecnh ng\xf4n ngữ lớn thưa thớt với 72 tỷ tham số v\xe0 16 tỷ tham số k\xedch hoạt, dựa tr\xean kiến tr\xfac chuy\xean gia hỗn hợp theo nh\xf3m (MoGE). N\xf3 ph\xe2n nh\xf3m c\xe1c chuy\xean gia trong giai đoạn lựa chọn chuy\xean gia v\xe0 giới hạn token k\xedch hoạt số lượng chuy\xean gia bằng nhau trong mỗi nh\xf3m, từ đ\xf3 đạt được c\xe2n bằng tải chuy\xean gia v\xe0 cải thiện đ\xe1ng kể hiệu quả triển khai m\xf4 h\xecnh tr\xean nền tảng Ascend."},"aya":{"description":"Aya 23 l\xe0 m\xf4 h\xecnh đa ng\xf4n ngữ do Cohere ph\xe1t h\xe0nh, hỗ trợ 23 ng\xf4n ngữ, tạo điều kiện thuận lợi cho c\xe1c ứng dụng ng\xf4n ngữ đa dạng."},"aya:35b":{"description":"Aya 23 l\xe0 m\xf4 h\xecnh đa ng\xf4n ngữ do Cohere ph\xe1t h\xe0nh, hỗ trợ 23 ng\xf4n ngữ, tạo điều kiện thuận lợi cho c\xe1c ứng dụng ng\xf4n ngữ đa dạng."},"azure-DeepSeek-R1-0528":{"description":"Được triển khai v\xe0 cung cấp bởi Microsoft; m\xf4 h\xecnh DeepSeek R1 đ\xe3 được n\xe2ng cấp phi\xean bản nhỏ, phi\xean bản hiện tại l\xe0 DeepSeek-R1-0528. Trong bản cập nhật mới nhất, DeepSeek R1 đ\xe3 cải thiện đ\xe1ng kể độ s\xe2u suy luận v\xe0 khả năng suy đo\xe1n bằng c\xe1ch tăng t\xe0i nguy\xean t\xednh to\xe1n v\xe0 giới thiệu cơ chế tối ưu thuật to\xe1n giai đoạn hậu huấn luyện. M\xf4 h\xecnh n\xe0y thể hiện xuất sắc trong nhiều b\xe0i kiểm tra chuẩn về to\xe1n học, lập tr\xecnh v\xe0 logic tổng qu\xe1t, hiệu suất tổng thể đ\xe3 gần đạt đến c\xe1c m\xf4 h\xecnh h\xe0ng đầu như O3 v\xe0 Gemini 2.5 Pro."},"baichuan-m2-32b":{"description":"Baichuan M2 32B l\xe0 m\xf4 h\xecnh chuy\xean gia hỗn hợp do Baichuan Intelligence ph\xe1t triển, sở hữu khả năng suy luận mạnh mẽ."},"baichuan/baichuan2-13b-chat":{"description":"Baichuan-13B l\xe0 m\xf4 h\xecnh ng\xf4n ngữ lớn m\xe3 nguồn mở c\xf3 thể thương mại h\xf3a với 130 tỷ tham số, được ph\xe1t triển bởi Baichuan Intelligence, đ\xe3 đạt được hiệu suất tốt nhất trong c\xf9ng k\xedch thước tr\xean c\xe1c benchmark tiếng Trung v\xe0 tiếng Anh."},"baidu/ERNIE-4.5-300B-A47B":{"description":"ERNIE-4.5-300B-A47B l\xe0 một m\xf4 h\xecnh ng\xf4n ngữ lớn dựa tr\xean kiến tr\xfac chuy\xean gia hỗn hợp (MoE) do c\xf4ng ty Baidu ph\xe1t triển. M\xf4 h\xecnh c\xf3 tổng số 300 tỷ tham số, nhưng trong qu\xe1 tr\xecnh suy luận mỗi token chỉ k\xedch hoạt 47 tỷ tham số, đảm bảo hiệu suất mạnh mẽ đồng thời tối ưu h\xf3a hiệu quả t\xednh to\xe1n. L\xe0 một trong những m\xf4 h\xecnh cốt l\xf5i của d\xf2ng ERNIE 4.5, n\xf3 thể hiện khả năng xuất sắc trong c\xe1c nhiệm vụ hiểu, tạo văn bản, suy luận v\xe0 lập tr\xecnh. M\xf4 h\xecnh \xe1p dụng phương ph\xe1p tiền huấn luyện MoE dị thể đa phương thức s\xe1ng tạo, th\xf4ng qua huấn luyện kết hợp văn bản v\xe0 h\xecnh ảnh, n\xe2ng cao hiệu quả tổng thể, đặc biệt nổi bật trong việc tu\xe2n thủ chỉ dẫn v\xe0 ghi nhớ kiến thức thế giới."},"c4ai-aya-expanse-32b":{"description":"Aya Expanse l\xe0 một m\xf4 h\xecnh đa ng\xf4n ngữ hiệu suất cao 32B, được thiết kế để th\xe1ch thức hiệu suất của c\xe1c m\xf4 h\xecnh đơn ng\xf4n ngữ th\xf4ng qua việc tinh chỉnh theo chỉ dẫn, khai th\xe1c dữ liệu, đ\xe0o tạo theo sở th\xedch v\xe0 hợp nhất m\xf4 h\xecnh. N\xf3 hỗ trợ 23 ng\xf4n ngữ."},"c4ai-aya-expanse-8b":{"description":"Aya Expanse l\xe0 một m\xf4 h\xecnh đa ng\xf4n ngữ hiệu suất cao 8B, được thiết kế để th\xe1ch thức hiệu suất của c\xe1c m\xf4 h\xecnh đơn ng\xf4n ngữ th\xf4ng qua việc tinh chỉnh theo chỉ dẫn, khai th\xe1c dữ liệu, đ\xe0o tạo theo sở th\xedch v\xe0 hợp nhất m\xf4 h\xecnh. N\xf3 hỗ trợ 23 ng\xf4n ngữ."},"c4ai-aya-vision-32b":{"description":"Aya Vision l\xe0 một m\xf4 h\xecnh đa phương tiện ti\xean tiến, thể hiện xuất sắc tr\xean nhiều ti\xeau chuẩn ch\xednh về khả năng ng\xf4n ngữ, văn bản v\xe0 h\xecnh ảnh. Phi\xean bản 32 tỷ tham số n\xe0y tập trung v\xe0o hiệu suất đa ng\xf4n ngữ ti\xean tiến."},"c4ai-aya-vision-8b":{"description":"Aya Vision l\xe0 một m\xf4 h\xecnh đa phương tiện ti\xean tiến, thể hiện xuất sắc tr\xean nhiều ti\xeau chuẩn ch\xednh về khả năng ng\xf4n ngữ, văn bản v\xe0 h\xecnh ảnh. Phi\xean bản 8 tỷ tham số n\xe0y tập trung v\xe0o độ trễ thấp v\xe0 hiệu suất tối ưu."},"charglm-3":{"description":"CharGLM-3 được thiết kế đặc biệt cho vai tr\xf2 v\xe0 đồng h\xe0nh cảm x\xfac, hỗ trợ tr\xed nhớ nhiều v\xf2ng si\xeau d\xe0i v\xe0 đối thoại c\xe1 nh\xe2n h\xf3a, ứng dụng rộng r\xe3i."},"charglm-4":{"description":"CharGLM-4 được thiết kế đặc biệt cho vai tr\xf2 v\xe0 sự đồng h\xe0nh cảm x\xfac, hỗ trợ tr\xed nhớ đa v\xf2ng d\xe0i v\xe0 đối thoại c\xe1 nh\xe2n h\xf3a, ứng dụng rộng r\xe3i."},"chatgpt-4o-latest":{"description":"ChatGPT-4o l\xe0 một m\xf4 h\xecnh động, được cập nhật theo thời gian thực để giữ phi\xean bản mới nhất. N\xf3 kết hợp khả năng hiểu v\xe0 sinh ng\xf4n ngữ mạnh mẽ, ph\xf9 hợp cho c\xe1c ứng dụng quy m\xf4 lớn, bao gồm dịch vụ kh\xe1ch h\xe0ng, gi\xe1o dục v\xe0 hỗ trợ kỹ thuật."},"claude-2.0":{"description":"Claude 2 cung cấp những tiến bộ quan trọng trong khả năng cho doanh nghiệp, bao gồm ngữ cảnh 200K token h\xe0ng đầu trong ng\xe0nh, giảm đ\xe1ng kể tỷ lệ ảo gi\xe1c của m\xf4 h\xecnh, nhắc nhở hệ thống v\xe0 một t\xednh năng kiểm tra mới: gọi c\xf4ng cụ."},"claude-2.1":{"description":"Claude 2 cung cấp những tiến bộ quan trọng trong khả năng cho doanh nghiệp, bao gồm ngữ cảnh 200K token h\xe0ng đầu trong ng\xe0nh, giảm đ\xe1ng kể tỷ lệ ảo gi\xe1c của m\xf4 h\xecnh, nhắc nhở hệ thống v\xe0 một t\xednh năng kiểm tra mới: gọi c\xf4ng cụ."},"claude-3-5-haiku-20241022":{"description":"Claude 3.5 Haiku l\xe0 m\xf4 h\xecnh thế hệ tiếp theo nhanh nhất của Anthropic. So với Claude 3 Haiku, Claude 3.5 Haiku đ\xe3 cải thiện ở nhiều kỹ năng v\xe0 vượt qua m\xf4 h\xecnh lớn nhất thế hệ trước l\xe0 Claude 3 Opus trong nhiều b\xe0i kiểm tra tr\xed tuệ."},"claude-3-5-haiku-latest":{"description":"Claude 3.5 Haiku cung cấp phản hồi nhanh, ph\xf9 hợp cho c\xe1c t\xe1c vụ nhẹ."},"claude-3-7-sonnet-20250219":{"description":"Claude 3.7 Sonnet l\xe0 m\xf4 h\xecnh AI mạnh nhất của Anthropic, với hiệu suất vượt trội so với c\xe1c m\xf4 h\xecnh đối thủ v\xe0 Claude 3 Opus, thể hiện xuất sắc trong nhiều đ\xe1nh gi\xe1 rộng r\xe3i, đồng thời c\xf3 tốc độ v\xe0 chi ph\xed tương đương với c\xe1c m\xf4 h\xecnh tầm trung của ch\xfang t\xf4i."},"claude-3-7-sonnet-latest":{"description":"Claude 3.7 Sonnet l\xe0 m\xf4 h\xecnh mạnh mẽ nhất mới nhất của Anthropic d\xe0nh cho c\xe1c t\xe1c vụ phức tạp cao. N\xf3 thể hiện xuất sắc về hiệu suất, tr\xed tuệ, sự mượt m\xe0 v\xe0 khả năng hiểu biết."},"claude-3-haiku-20240307":{"description":"Claude 3 Haiku l\xe0 m\xf4 h\xecnh nhanh nhất v\xe0 gọn nhẹ nhất của Anthropic, được thiết kế để đạt được phản hồi gần như ngay lập tức. N\xf3 c\xf3 hiệu suất định hướng nhanh v\xe0 ch\xednh x\xe1c."},"claude-3-opus-20240229":{"description":"Claude 3 Opus l\xe0 m\xf4 h\xecnh mạnh mẽ nhất của Anthropic để xử l\xfd c\xe1c nhiệm vụ phức tạp. N\xf3 thể hiện xuất sắc về hiệu suất, tr\xed th\xf4ng minh, sự tr\xf4i chảy v\xe0 khả năng hiểu biết."},"claude-3-sonnet-20240229":{"description":"Claude 3 Sonnet cung cấp sự c\xe2n bằng l\xfd tưởng giữa tr\xed th\xf4ng minh v\xe0 tốc độ cho khối lượng c\xf4ng việc doanh nghiệp. N\xf3 cung cấp hiệu suất tối đa với mức gi\xe1 thấp hơn, đ\xe1ng tin cậy v\xe0 ph\xf9 hợp cho triển khai quy m\xf4 lớn."},"claude-haiku-4-5-20251001":{"description":"Claude Haiku 4.5 l\xe0 m\xf4 h\xecnh Haiku nhanh nhất v\xe0 th\xf4ng minh nhất của Anthropic, với tốc độ như chớp v\xe0 khả năng tư duy mở rộng."},"claude-opus-4-1-20250805":{"description":"Claude Opus 4.1 l\xe0 m\xf4 h\xecnh mạnh mẽ nhất mới nhất của Anthropic d\xe0nh cho xử l\xfd c\xe1c nhiệm vụ phức tạp cao. N\xf3 thể hiện xuất sắc về hiệu suất, tr\xed tuệ, sự mượt m\xe0 v\xe0 khả năng hiểu biết."},"claude-opus-4-1-20250805-thinking":{"description":"M\xf4 h\xecnh suy nghĩ Claude Opus 4.1, phi\xean bản n\xe2ng cao c\xf3 thể tr\xecnh b\xe0y qu\xe1 tr\xecnh suy luận của n\xf3."},"claude-opus-4-20250514":{"description":"Claude Opus 4 l\xe0 m\xf4 h\xecnh mạnh mẽ nhất của Anthropic được sử dụng để xử l\xfd c\xe1c nhiệm vụ phức tạp cao. N\xf3 thể hiện xuất sắc về hiệu suất, tr\xed tuệ, sự tr\xf4i chảy v\xe0 khả năng hiểu biết."},"claude-sonnet-4-20250514":{"description":"Claude Sonnet 4 c\xf3 thể tạo ra phản hồi gần như tức th\xec hoặc suy nghĩ từng bước k\xe9o d\xe0i, người d\xf9ng c\xf3 thể thấy r\xf5 c\xe1c qu\xe1 tr\xecnh n\xe0y."},"claude-sonnet-4-20250514-thinking":{"description":"M\xf4 h\xecnh suy nghĩ Claude Sonnet 4 c\xf3 thể tạo ra phản hồi gần như tức th\xec hoặc suy nghĩ từng bước k\xe9o d\xe0i, người d\xf9ng c\xf3 thể thấy r\xf5 c\xe1c qu\xe1 tr\xecnh n\xe0y."},"claude-sonnet-4-5-20250929":{"description":"Claude Sonnet 4.5 l\xe0 m\xf4 h\xecnh th\xf4ng minh nhất của Anthropic cho đến nay."},"codegeex-4":{"description":"CodeGeeX-4 l\xe0 trợ l\xfd lập tr\xecnh AI mạnh mẽ, hỗ trợ nhiều ng\xf4n ngữ lập tr\xecnh với c\xe2u hỏi th\xf4ng minh v\xe0 ho\xe0n th\xe0nh m\xe3, n\xe2ng cao hiệu suất ph\xe1t triển."},"codegeex4-all-9b":{"description":"CodeGeeX4-ALL-9B l\xe0 một m\xf4 h\xecnh tạo m\xe3 đa ng\xf4n ngữ, hỗ trợ đầy đủ c\xe1c chức năng như ho\xe0n th\xe0nh v\xe0 tạo m\xe3, tr\xecnh giải th\xedch m\xe3, t\xecm kiếm tr\xean mạng, gọi h\xe0m, v\xe0 hỏi đ\xe1p m\xe3 cấp kho, bao phủ nhiều t\xecnh huống trong ph\xe1t triển phần mềm. Đ\xe2y l\xe0 m\xf4 h\xecnh tạo m\xe3 h\xe0ng đầu với số tham số dưới 10B."},"codegemma":{"description":"CodeGemma l\xe0 m\xf4 h\xecnh ng\xf4n ngữ nhẹ chuy\xean dụng cho c\xe1c nhiệm vụ lập tr\xecnh kh\xe1c nhau, hỗ trợ lặp lại v\xe0 t\xedch hợp nhanh ch\xf3ng."},"codegemma:2b":{"description":"CodeGemma l\xe0 m\xf4 h\xecnh ng\xf4n ngữ nhẹ chuy\xean dụng cho c\xe1c nhiệm vụ lập tr\xecnh kh\xe1c nhau, hỗ trợ lặp lại v\xe0 t\xedch hợp nhanh ch\xf3ng."},"codellama":{"description":"Code Llama l\xe0 một LLM tập trung v\xe0o việc sinh v\xe0 thảo luận m\xe3, kết hợp hỗ trợ cho nhiều ng\xf4n ngữ lập tr\xecnh, ph\xf9 hợp cho m\xf4i trường ph\xe1t triển."},"codellama/CodeLlama-34b-Instruct-hf":{"description":"Code Llama l\xe0 một LLM tập trung v\xe0o việc tạo m\xe3 v\xe0 thảo luận, kết hợp hỗ trợ nhiều ng\xf4n ngữ lập tr\xecnh, ph\xf9 hợp cho m\xf4i trường ph\xe1t triển."},"codellama:13b":{"description":"Code Llama l\xe0 một LLM tập trung v\xe0o việc sinh v\xe0 thảo luận m\xe3, kết hợp hỗ trợ cho nhiều ng\xf4n ngữ lập tr\xecnh, ph\xf9 hợp cho m\xf4i trường ph\xe1t triển."},"codellama:34b":{"description":"Code Llama l\xe0 một LLM tập trung v\xe0o việc sinh v\xe0 thảo luận m\xe3, kết hợp hỗ trợ cho nhiều ng\xf4n ngữ lập tr\xecnh, ph\xf9 hợp cho m\xf4i trường ph\xe1t triển."},"codellama:70b":{"description":"Code Llama l\xe0 một LLM tập trung v\xe0o việc sinh v\xe0 thảo luận m\xe3, kết hợp hỗ trợ cho nhiều ng\xf4n ngữ lập tr\xecnh, ph\xf9 hợp cho m\xf4i trường ph\xe1t triển."},"codeqwen":{"description":"CodeQwen1.5 l\xe0 m\xf4 h\xecnh ng\xf4n ngữ quy m\xf4 lớn được đ\xe0o tạo tr\xean một lượng lớn dữ liệu m\xe3, chuy\xean giải quyết c\xe1c nhiệm vụ lập tr\xecnh phức tạp."},"codestral":{"description":"Codestral l\xe0 m\xf4 h\xecnh m\xe3 đầu ti\xean của Mistral AI, cung cấp hỗ trợ xuất sắc cho c\xe1c nhiệm vụ sinh m\xe3."},"codestral-latest":{"description":"Codestral l\xe0 m\xf4 h\xecnh sinh m\xe3 ti\xean tiến tập trung v\xe0o việc sinh m\xe3, tối ưu h\xf3a cho c\xe1c nhiệm vụ điền v\xe0o khoảng trống v\xe0 ho\xe0n thiện m\xe3."},"codex-mini-latest":{"description":"codex-mini-latest l\xe0 phi\xean bản tinh chỉnh của o4-mini, được thiết kế đặc biệt cho Codex CLI. Đối với việc sử dụng trực tiếp qua API, ch\xfang t\xf4i khuyến nghị bắt đầu từ gpt-4.1."},"cogview-4":{"description":"CogView-4 l\xe0 m\xf4 h\xecnh tạo h\xecnh ảnh văn bản m\xe3 nguồn mở đầu ti\xean của Zhipu hỗ trợ tạo k\xfd tự Trung Hoa, với sự cải tiến to\xe0n diện về hiểu ngữ nghĩa, chất lượng tạo h\xecnh ảnh, khả năng tạo k\xfd tự tiếng Trung v\xe0 tiếng Anh, hỗ trợ đầu v\xe0o song ngữ Trung-Anh với độ d\xe0i t\xf9y \xfd, c\xf3 thể tạo h\xecnh ảnh với độ ph\xe2n giải bất kỳ trong phạm vi cho ph\xe9p."},"cohere-command-r":{"description":"Command R l\xe0 một m\xf4 h\xecnh sinh tạo c\xf3 thể mở rộng, nhắm đến RAG v\xe0 Sử dụng C\xf4ng cụ để cho ph\xe9p AI quy m\xf4 sản xuất cho doanh nghiệp."},"cohere-command-r-plus":{"description":"Command R+ l\xe0 m\xf4 h\xecnh tối ưu h\xf3a RAG hiện đại, được thiết kế để xử l\xfd khối lượng c\xf4ng việc cấp doanh nghiệp."},"cohere/Cohere-command-r":{"description":"Command R l\xe0 một m\xf4 h\xecnh sinh c\xf3 thể mở rộng, được thiết kế cho việc sử dụng RAG v\xe0 c\xf4ng cụ, gi\xfap doanh nghiệp triển khai AI cấp sản xuất."},"cohere/Cohere-command-r-plus":{"description":"Command R+ l\xe0 m\xf4 h\xecnh tối ưu RAG ti\xean tiến nhất, được thiết kế để xử l\xfd khối lượng c\xf4ng việc cấp doanh nghiệp."},"cohere/command-a":{"description":"Command A l\xe0 m\xf4 h\xecnh hiệu suất cao nhất của Cohere cho đến nay, xuất sắc trong việc sử dụng c\xf4ng cụ, đại l\xfd, tạo tăng cường truy xuất (RAG) v\xe0 c\xe1c trường hợp đa ng\xf4n ngữ. Command A c\xf3 độ d\xe0i ngữ cảnh 256K, chỉ cần hai GPU để vận h\xe0nh, tăng th\xf4ng lượng 150% so với Command R+ 08-2024."},"cohere/command-r":{"description":"Command R l\xe0 m\xf4 h\xecnh ng\xf4n ngữ lớn được tối ưu cho tương t\xe1c hội thoại v\xe0 c\xe1c nhiệm vụ ngữ cảnh d\xe0i. N\xf3 thuộc loại m\xf4 h\xecnh \\"c\xf3 thể mở rộng\\", c\xe2n bằng giữa hiệu suất cao v\xe0 độ ch\xednh x\xe1c mạnh mẽ, gi\xfap c\xe1c c\xf4ng ty vượt qua giai đoạn chứng minh kh\xe1i niệm v\xe0 tiến v\xe0o sản xuất."},"cohere/command-r-plus":{"description":"Command R+ l\xe0 m\xf4 h\xecnh ng\xf4n ngữ lớn mới nhất của Cohere, được tối ưu cho tương t\xe1c hội thoại v\xe0 c\xe1c nhiệm vụ ngữ cảnh d\xe0i. Mục ti\xeau của n\xf3 l\xe0 đạt hiệu suất xuất sắc, gi\xfap c\xe1c c\xf4ng ty vượt qua giai đoạn chứng minh kh\xe1i niệm v\xe0 tiến v\xe0o sản xuất."},"cohere/embed-v4.0":{"description":"M\xf4 h\xecnh cho ph\xe9p ph\xe2n loại hoặc chuyển đổi văn bản, h\xecnh ảnh hoặc nội dung hỗn hợp th\xe0nh c\xe1c vector nh\xfang."},"comfyui/flux-dev":{"description":"FLUX.1 Dev - M\xf4 h\xecnh tạo ảnh từ văn bản chất lượng cao, tạo ảnh trong 10-50 bước, ph\xf9 hợp cho s\xe1ng t\xe1c chất lượng cao v\xe0 t\xe1c phẩm nghệ thuật."},"comfyui/flux-kontext-dev":{"description":"FLUX.1 Kontext-dev - M\xf4 h\xecnh chỉnh sửa h\xecnh ảnh, hỗ trợ chỉnh sửa h\xecnh ảnh hiện c\xf3 dựa tr\xean hướng dẫn văn bản, bao gồm chỉnh sửa cục bộ v\xe0 chuyển đổi phong c\xe1ch."},"comfyui/flux-krea-dev":{"description":"FLUX.1 Krea-dev - M\xf4 h\xecnh tạo ảnh từ văn bản với t\xednh năng an to\xe0n n\xe2ng cao, ph\xe1t triển hợp t\xe1c với Krea, t\xedch hợp bộ lọc an to\xe0n."},"comfyui/flux-schnell":{"description":"FLUX.1 Schnell - M\xf4 h\xecnh tạo ảnh từ văn bản si\xeau nhanh, tạo ảnh chất lượng cao chỉ trong 1-4 bước, l\xfd tưởng cho ứng dụng thời gian thực v\xe0 tạo nguy\xean mẫu nhanh."},"comfyui/stable-diffusion-15":{"description":"Stable Diffusion 1.5 - M\xf4 h\xecnh tạo ảnh từ văn bản cổ điển với độ ph\xe2n giải 512x512, ph\xf9 hợp cho tạo nguy\xean mẫu nhanh v\xe0 thử nghiệm s\xe1ng tạo."},"comfyui/stable-diffusion-35":{"description":"Stable Diffusion 3.5 - M\xf4 h\xecnh tạo ảnh từ văn bản thế hệ mới, hỗ trợ hai phi\xean bản Large v\xe0 Medium, y\xeau cầu tệp m\xe3 h\xf3a CLIP b\xean ngo\xe0i, mang lại chất lượng h\xecnh ảnh vượt trội v\xe0 độ khớp cao với từ kh\xf3a."},"comfyui/stable-diffusion-35-inclclip":{"description":"Stable Diffusion 3.5 - Phi\xean bản t\xedch hợp m\xe3 h\xf3a CLIP/T5, kh\xf4ng cần tệp m\xe3 h\xf3a b\xean ngo\xe0i, ph\xf9 hợp với c\xe1c m\xf4 h\xecnh như sd3.5_medium_incl_clips, sử dụng \xedt t\xe0i nguy\xean hơn."},"comfyui/stable-diffusion-custom":{"description":"M\xf4 h\xecnh tạo ảnh từ văn bản SD t\xf9y chỉnh, t\xean tệp m\xf4 h\xecnh n\xean l\xe0 custom_sd_lobe.safetensors, nếu c\xf3 VAE th\xec d\xf9ng custom_sd_vae_lobe.safetensors, tệp m\xf4 h\xecnh cần được đặt đ\xfang thư mục theo y\xeau cầu của Comfy."},"comfyui/stable-diffusion-custom-refiner":{"description":"M\xf4 h\xecnh chuyển ảnh th\xe0nh ảnh SDXL t\xf9y chỉnh, t\xean tệp m\xf4 h\xecnh n\xean l\xe0 custom_sd_lobe.safetensors, nếu c\xf3 VAE th\xec d\xf9ng custom_sd_vae_lobe.safetensors, tệp m\xf4 h\xecnh cần được đặt đ\xfang thư mục theo y\xeau cầu của Comfy."},"comfyui/stable-diffusion-refiner":{"description":"M\xf4 h\xecnh chuyển ảnh th\xe0nh ảnh SDXL, chuyển đổi h\xecnh ảnh đầu v\xe0o th\xe0nh h\xecnh ảnh chất lượng cao, hỗ trợ chuyển đổi phong c\xe1ch, phục hồi h\xecnh ảnh v\xe0 biến đổi s\xe1ng tạo."},"comfyui/stable-diffusion-xl":{"description":"M\xf4 h\xecnh tạo ảnh từ văn bản SDXL, hỗ trợ tạo ảnh độ ph\xe2n giải cao 1024x1024 từ văn bản, mang lại chất lượng h\xecnh ảnh v\xe0 chi tiết vượt trội."},"command":{"description":"Một m\xf4 h\xecnh đối thoại tu\xe2n theo chỉ dẫn, thể hiện chất lượng cao v\xe0 đ\xe1ng tin cậy trong c\xe1c nhiệm vụ ng\xf4n ngữ, đồng thời c\xf3 độ d\xe0i ngữ cảnh d\xe0i hơn so với m\xf4 h\xecnh sinh cơ bản của ch\xfang t\xf4i."},"command-a-03-2025":{"description":"Command A l\xe0 m\xf4 h\xecnh mạnh nhất m\xe0 ch\xfang t\xf4i đ\xe3 ph\xe1t triển cho đến nay, thể hiện xuất sắc trong việc sử dụng c\xf4ng cụ, đại l\xfd, tạo ra th\xf4ng tin tăng cường (RAG) v\xe0 c\xe1c ứng dụng đa ng\xf4n ngữ. Command A c\xf3 độ d\xe0i ngữ cảnh 256K, chỉ cần hai GPU để vận h\xe0nh, v\xe0 so với Command R+ 08-2024, hiệu suất tăng 150%."},"command-light":{"description":"Một phi\xean bản Command nhỏ hơn, nhanh hơn, gần như mạnh mẽ tương đương nhưng c\xf3 tốc độ nhanh hơn."},"command-light-nightly":{"description":"Để r\xfat ngắn khoảng c\xe1ch thời gian giữa c\xe1c phi\xean bản ch\xednh, ch\xfang t\xf4i đ\xe3 ph\xe1t h\xe0nh phi\xean bản h\xe0ng đ\xeam của m\xf4 h\xecnh Command. Đối với d\xf2ng command-light, phi\xean bản n\xe0y được gọi l\xe0 command-light-nightly. Xin lưu \xfd rằng command-light-nightly l\xe0 phi\xean bản mới nhất, mang t\xednh thử nghiệm cao v\xe0 (c\xf3 thể) kh\xf4ng ổn định. Phi\xean bản h\xe0ng đ\xeam sẽ được cập nhật định kỳ m\xe0 kh\xf4ng c\xf3 th\xf4ng b\xe1o trước, v\xec vậy kh\xf4ng n\xean sử dụng trong m\xf4i trường sản xuất."},"command-nightly":{"description":"Để r\xfat ngắn khoảng c\xe1ch thời gian giữa c\xe1c phi\xean bản ch\xednh, ch\xfang t\xf4i đ\xe3 ph\xe1t h\xe0nh phi\xean bản h\xe0ng đ\xeam của m\xf4 h\xecnh Command. Đối với d\xf2ng Command, phi\xean bản n\xe0y được gọi l\xe0 command-cightly. Xin lưu \xfd rằng command-nightly l\xe0 phi\xean bản mới nhất, mang t\xednh thử nghiệm cao v\xe0 (c\xf3 thể) kh\xf4ng ổn định. Phi\xean bản h\xe0ng đ\xeam sẽ được cập nhật định kỳ m\xe0 kh\xf4ng c\xf3 th\xf4ng b\xe1o trước, v\xec vậy kh\xf4ng n\xean sử dụng trong m\xf4i trường sản xuất."},"command-r":{"description":"Command R l\xe0 LLM được tối ưu h\xf3a cho c\xe1c nhiệm vụ đối thoại v\xe0 ngữ cảnh d\xe0i, đặc biệt ph\xf9 hợp cho tương t\xe1c động v\xe0 quản l\xfd kiến thức."},"command-r-03-2024":{"description":"Command R l\xe0 một m\xf4 h\xecnh đối thoại tu\xe2n theo chỉ dẫn, thể hiện chất lượng cao hơn v\xe0 đ\xe1ng tin cậy hơn trong c\xe1c nhiệm vụ ng\xf4n ngữ, đồng thời c\xf3 độ d\xe0i ngữ cảnh d\xe0i hơn so với c\xe1c m\xf4 h\xecnh trước đ\xe2y. N\xf3 c\xf3 thể được sử dụng cho c\xe1c quy tr\xecnh phức tạp như tạo m\xe3, tạo ra th\xf4ng tin tăng cường (RAG), sử dụng c\xf4ng cụ v\xe0 đại l\xfd."},"command-r-08-2024":{"description":"command-r-08-2024 l\xe0 phi\xean bản cập nhật của m\xf4 h\xecnh Command R, được ph\xe1t h\xe0nh v\xe0o th\xe1ng 8 năm 2024."},"command-r-plus":{"description":"Command R+ l\xe0 một m\xf4 h\xecnh ng\xf4n ngữ lớn hiệu suất cao, được thiết kế cho c\xe1c t\xecnh huống doanh nghiệp thực tế v\xe0 ứng dụng phức tạp."},"command-r-plus-04-2024":{"description":"Command R+ l\xe0 một m\xf4 h\xecnh đối thoại tu\xe2n theo chỉ dẫn, thể hiện chất lượng cao hơn v\xe0 đ\xe1ng tin cậy hơn trong c\xe1c nhiệm vụ ng\xf4n ngữ, đồng thời c\xf3 độ d\xe0i ngữ cảnh d\xe0i hơn so với c\xe1c m\xf4 h\xecnh trước đ\xe2y. N\xf3 ph\xf9 hợp nhất cho c\xe1c quy tr\xecnh RAG phức tạp v\xe0 việc sử dụng c\xf4ng cụ nhiều bước."},"command-r-plus-08-2024":{"description":"Command R+ l\xe0 một m\xf4 h\xecnh đối thoại tu\xe2n theo hướng dẫn, thể hiện chất lượng cao hơn trong c\xe1c nhiệm vụ ng\xf4n ngữ, đ\xe1ng tin cậy hơn v\xe0 c\xf3 độ d\xe0i ngữ cảnh d\xe0i hơn so với c\xe1c m\xf4 h\xecnh trước đ\xe2y. N\xf3 ph\xf9 hợp nhất cho c\xe1c quy tr\xecnh l\xe0m việc RAG phức tạp v\xe0 việc sử dụng c\xf4ng cụ nhiều bước."},"command-r7b-12-2024":{"description":"command-r7b-12-2024 l\xe0 một phi\xean bản cập nhật nhỏ gọn v\xe0 hiệu quả, được ph\xe1t h\xe0nh v\xe0o th\xe1ng 12 năm 2024. N\xf3 thể hiện xuất sắc trong c\xe1c nhiệm vụ cần suy luận phức tạp v\xe0 xử l\xfd nhiều bước như RAG, sử dụng c\xf4ng cụ v\xe0 đại l\xfd."},"computer-use-preview":{"description":"M\xf4 h\xecnh computer-use-preview được thiết kế chuy\xean biệt cho “c\xf4ng cụ sử dụng m\xe1y t\xednh”, được huấn luyện để hiểu v\xe0 thực hiện c\xe1c nhiệm vụ li\xean quan đến m\xe1y t\xednh."},"dall-e-2":{"description":"M\xf4 h\xecnh DALL\xb7E thế hệ thứ hai, hỗ trợ tạo h\xecnh ảnh ch\xe2n thực v\xe0 ch\xednh x\xe1c hơn, với độ ph\xe2n giải gấp 4 lần thế hệ đầu ti\xean."},"dall-e-3":{"description":"M\xf4 h\xecnh DALL\xb7E mới nhất, ph\xe1t h\xe0nh v\xe0o th\xe1ng 11 năm 2023. Hỗ trợ tạo h\xecnh ảnh ch\xe2n thực v\xe0 ch\xednh x\xe1c hơn, với khả năng thể hiện chi tiết mạnh mẽ hơn."},"databricks/dbrx-instruct":{"description":"DBRX Instruct cung cấp khả năng xử l\xfd chỉ dẫn đ\xe1ng tin cậy, hỗ trợ nhiều ứng dụng trong ng\xe0nh."},"deepseek-ai/DeepSeek-OCR":{"description":"DeepSeek-OCR l\xe0 một m\xf4 h\xecnh ng\xf4n ngữ thị gi\xe1c do DeepSeek AI ph\xe1t triển, tập trung v\xe0o nhận diện k\xfd tự quang học (OCR) v\xe0 \\"n\xe9n quang học theo ngữ cảnh\\". M\xf4 h\xecnh n\xe0y nhằm kh\xe1m ph\xe1 giới hạn của việc n\xe9n th\xf4ng tin ngữ cảnh từ h\xecnh ảnh, c\xf3 khả năng xử l\xfd t\xe0i liệu hiệu quả v\xe0 chuyển đổi ch\xfang th\xe0nh c\xe1c định dạng văn bản c\xf3 cấu tr\xfac như Markdown. N\xf3 c\xf3 thể nhận diện ch\xednh x\xe1c nội dung văn bản trong h\xecnh ảnh, đặc biệt ph\xf9 hợp với c\xe1c ứng dụng số h\xf3a t\xe0i liệu, tr\xedch xuất văn bản v\xe0 xử l\xfd c\xf3 cấu tr\xfac."},"deepseek-ai/DeepSeek-R1":{"description":"DeepSeek-R1 l\xe0 một m\xf4 h\xecnh suy diễn được điều khiển bởi học tăng cường (RL), giải quyết c\xe1c vấn đề về t\xednh lặp lại v\xe0 khả năng đọc hiểu trong m\xf4 h\xecnh. Trước khi \xe1p dụng RL, DeepSeek-R1 đ\xe3 giới thiệu dữ liệu khởi động lạnh, tối ưu h\xf3a th\xeam hiệu suất suy diễn. N\xf3 thể hiện hiệu suất tương đương với OpenAI-o1 trong c\xe1c nhiệm vụ to\xe1n học, m\xe3 v\xe0 suy diễn, v\xe0 th\xf4ng qua phương ph\xe1p đ\xe0o tạo được thiết kế cẩn thận, n\xe2ng cao hiệu quả tổng thể."},"deepseek-ai/DeepSeek-R1-0528":{"description":"DeepSeek R1 đ\xe3 n\xe2ng cao đ\xe1ng kể chiều s\xe2u khả năng suy luận v\xe0 ph\xe1n đo\xe1n nhờ tận dụng t\xe0i nguy\xean t\xednh to\xe1n tăng th\xeam v\xe0 cơ chế tối ưu thuật to\xe1n trong qu\xe1 tr\xecnh huấn luyện sau. M\xf4 h\xecnh thể hiện xuất sắc trong nhiều b\xe0i đ\xe1nh gi\xe1 chuẩn, bao gồm to\xe1n học, lập tr\xecnh v\xe0 logic chung. Hiệu suất tổng thể hiện gần đạt c\xe1c m\xf4 h\xecnh h\xe0ng đầu như O3 v\xe0 Gemini 2.5 Pro."},"deepseek-ai/DeepSeek-R1-0528-Qwen3-8B":{"description":"DeepSeek-R1-0528-Qwen3-8B l\xe0 m\xf4 h\xecnh được chưng cất chuỗi suy nghĩ từ DeepSeek-R1-0528 sang Qwen3 8B Base. M\xf4 h\xecnh đạt hiệu suất ti\xean tiến nhất (SOTA) trong c\xe1c m\xf4 h\xecnh m\xe3 nguồn mở, vượt Qwen3 8B 10% trong b\xe0i kiểm tra AIME 2024 v\xe0 đạt mức hiệu suất của Qwen3-235B-thinking. M\xf4 h\xecnh thể hiện xuất sắc trong suy luận to\xe1n học, lập tr\xecnh v\xe0 logic chung, c\xf3 kiến tr\xfac giống Qwen3-8B nhưng d\xf9ng chung cấu h\xecnh tokenizer của DeepSeek-R1-0528."},"deepseek-ai/DeepSeek-R1-Distill-Llama-70B":{"description":"M\xf4 h\xecnh chưng cất DeepSeek-R1, tối ưu h\xf3a hiệu suất suy luận th\xf4ng qua học tăng cường v\xe0 dữ liệu khởi động lạnh, m\xf4 h\xecnh m\xe3 nguồn mở l\xe0m mới ti\xeau chuẩn đa nhiệm."},"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B":{"description":"M\xf4 h\xecnh chưng cất DeepSeek-R1, tối ưu h\xf3a hiệu suất suy luận th\xf4ng qua học tăng cường v\xe0 dữ liệu khởi động lạnh, m\xf4 h\xecnh m\xe3 nguồn mở l\xe0m mới ti\xeau chuẩn đa nhiệm."},"deepseek-ai/DeepSeek-R1-Distill-Qwen-14B":{"description":"M\xf4 h\xecnh chưng cất DeepSeek-R1, tối ưu h\xf3a hiệu suất suy luận th\xf4ng qua học tăng cường v\xe0 dữ liệu khởi động lạnh, m\xf4 h\xecnh m\xe3 nguồn mở l\xe0m mới ti\xeau chuẩn đa nhiệm."},"deepseek-ai/DeepSeek-R1-Distill-Qwen-32B":{"description":"DeepSeek-R1-Distill-Qwen-32B l\xe0 m\xf4 h\xecnh được tạo ra từ Qwen2.5-32B th\xf4ng qua chưng cất kiến thức. M\xf4 h\xecnh n\xe0y sử dụng 800.000 mẫu được chọn lọc từ DeepSeek-R1 để tinh chỉnh, thể hiện hiệu suất xuất sắc trong nhiều lĩnh vực như to\xe1n học, lập tr\xecnh v\xe0 suy luận. Trong nhiều b\xe0i kiểm tra chuẩn như AIME 2024, MATH-500, GPQA Diamond, n\xf3 đ\xe3 đạt được kết quả xuất sắc, trong đ\xf3 đạt 94.3% độ ch\xednh x\xe1c tr\xean MATH-500, thể hiện khả năng suy luận to\xe1n học mạnh mẽ."},"deepseek-ai/DeepSeek-R1-Distill-Qwen-7B":{"description":"DeepSeek-R1-Distill-Qwen-7B l\xe0 m\xf4 h\xecnh được tạo ra từ Qwen2.5-Math-7B th\xf4ng qua chưng cất kiến thức. M\xf4 h\xecnh n\xe0y sử dụng 800.000 mẫu được chọn lọc từ DeepSeek-R1 để tinh chỉnh, thể hiện khả năng suy luận xuất sắc. Trong nhiều b\xe0i kiểm tra chuẩn, n\xf3 đ\xe3 thể hiện xuất sắc, trong đ\xf3 đạt 92.8% độ ch\xednh x\xe1c tr\xean MATH-500, đạt 55.5% tỷ lệ vượt qua tr\xean AIME 2024, v\xe0 đạt điểm 1189 tr\xean CodeForces, thể hiện khả năng to\xe1n học v\xe0 lập tr\xecnh mạnh mẽ cho m\xf4 h\xecnh quy m\xf4 7B."},"deepseek-ai/DeepSeek-V2.5":{"description":"DeepSeek V2.5 kết hợp c\xe1c đặc điểm xuất sắc của c\xe1c phi\xean bản trước, tăng cường khả năng tổng qu\xe1t v\xe0 m\xe3 h\xf3a."},"deepseek-ai/DeepSeek-V3":{"description":"DeepSeek-V3 l\xe0 một m\xf4 h\xecnh ng\xf4n ngữ hỗn hợp chuy\xean gia (MoE) với 6710 tỷ tham số, sử dụng ch\xfa \xfd tiềm ẩn đa đầu (MLA) v\xe0 kiến tr\xfac DeepSeekMoE, kết hợp với chiến lược c\xe2n bằng tải kh\xf4ng c\xf3 tổn thất phụ trợ, tối ưu h\xf3a hiệu suất suy diễn v\xe0 đ\xe0o tạo. Th\xf4ng qua việc được tiền huấn luyện tr\xean 14.8 triệu tỷ token chất lượng cao, v\xe0 thực hiện tinh chỉnh gi\xe1m s\xe1t v\xe0 học tăng cường, DeepSeek-V3 vượt trội về hiệu suất so với c\xe1c m\xf4 h\xecnh m\xe3 nguồn mở kh\xe1c, gần gũi với c\xe1c m\xf4 h\xecnh đ\xf3ng nguồn h\xe0ng đầu."},"deepseek-ai/DeepSeek-V3.1":{"description":"M\xf4 h\xecnh DeepSeek V3.1 l\xe0 m\xf4 h\xecnh kiến tr\xfac suy luận hỗn hợp, hỗ trợ cả chế độ tư duy v\xe0 kh\xf4ng tư duy."},"deepseek-ai/DeepSeek-V3.1-Terminus":{"description":"DeepSeek-V3.1-Terminus l\xe0 phi\xean bản cập nhật của m\xf4 h\xecnh V3.1 do DeepSeek ph\xe1t h\xe0nh, được định vị l\xe0 m\xf4 h\xecnh ng\xf4n ngữ lớn với tr\xed tuệ hỗn hợp. Bản cập nhật n\xe0y tập trung sửa c\xe1c vấn đề phản hồi từ người d\xf9ng v\xe0 n\xe2ng cao độ ổn định trong khi vẫn giữ nguy\xean khả năng của m\xf4 h\xecnh. N\xf3 cải thiện đ\xe1ng kể t\xednh nhất qu\xe1n ng\xf4n ngữ, giảm thiểu việc sử dụng lẫn lộn tiếng Trung v\xe0 tiếng Anh cũng như c\xe1c k\xfd tự bất thường. M\xf4 h\xecnh t\xedch hợp \\"Chế độ suy nghĩ\\" (Thinking Mode) v\xe0 \\"Chế độ kh\xf4ng suy nghĩ\\" (Non-thinking Mode), người d\xf9ng c\xf3 thể linh hoạt chuyển đổi qua c\xe1c mẫu tr\xf2 chuyện để ph\xf9 hợp với c\xe1c nhiệm vụ kh\xe1c nhau. Một tối ưu quan trọng l\xe0 V3.1-Terminus tăng cường hiệu suất của Agent m\xe3 (Code Agent) v\xe0 Agent t\xecm kiếm (Search Agent), gi\xfap ch\xfang đ\xe1ng tin cậy hơn trong việc gọi c\xf4ng cụ v\xe0 thực hiện c\xe1c nhiệm vụ phức tạp nhiều bước."},"deepseek-ai/DeepSeek-V3.2-Exp":{"description":"DeepSeek-V3.2-Exp l\xe0 phi\xean bản thử nghiệm V3.2 do DeepSeek ph\xe1t h\xe0nh, đ\xf3ng vai tr\xf2 l\xe0 bước chuyển tiếp trong h\xe0nh tr\xecnh hướng tới kiến tr\xfac thế hệ tiếp theo. Dựa tr\xean nền tảng của V3.1-Terminus, phi\xean bản n\xe0y t\xedch hợp cơ chế Ch\xfa \xfd Thưa (DeepSeek Sparse Attention - DSA) nhằm n\xe2ng cao hiệu quả huấn luyện v\xe0 suy luận trong ngữ cảnh d\xe0i. N\xf3 được tối ưu h\xf3a đặc biệt cho việc gọi c\xf4ng cụ, hiểu t\xe0i liệu d\xe0i v\xe0 suy luận nhiều bước. V3.2-Exp l\xe0 cầu nối giữa nghi\xean cứu v\xe0 ứng dụng thực tế, ph\xf9 hợp với người d\xf9ng mong muốn kh\xe1m ph\xe1 hiệu suất suy luận cao hơn trong c\xe1c t\xecnh huống c\xf3 ng\xe2n s\xe1ch ngữ cảnh lớn."},"deepseek-ai/deepseek-llm-67b-chat":{"description":"DeepSeek 67B l\xe0 m\xf4 h\xecnh ti\xean tiến được huấn luyện cho c\xe1c cuộc đối thoại phức tạp."},"deepseek-ai/deepseek-r1":{"description":"LLM hiệu quả ti\xean tiến, xuất sắc trong suy luận, to\xe1n học v\xe0 lập tr\xecnh."},"deepseek-ai/deepseek-v3.1":{"description":"DeepSeek V3.1: M\xf4 h\xecnh suy luận thế hệ tiếp theo, n\xe2ng cao khả năng suy luận phức tạp v\xe0 tư duy chuỗi, ph\xf9 hợp cho c\xe1c t\xe1c vụ cần ph\xe2n t\xedch s\xe2u."},"deepseek-ai/deepseek-v3.1-terminus":{"description":"DeepSeek V3.1: M\xf4 h\xecnh suy luận thế hệ mới, n\xe2ng cao khả năng suy luận phức tạp v\xe0 tư duy chuỗi, ph\xf9 hợp với c\xe1c nhiệm vụ cần ph\xe2n t\xedch chuy\xean s\xe2u."},"deepseek-ai/deepseek-vl2":{"description":"DeepSeek-VL2 l\xe0 một m\xf4 h\xecnh ng\xf4n ngữ h\xecnh ảnh hỗn hợp chuy\xean gia (MoE) được ph\xe1t triển dựa tr\xean DeepSeekMoE-27B, sử dụng kiến tr\xfac MoE với k\xedch hoạt thưa, đạt được hiệu suất xuất sắc chỉ với 4.5B tham số được k\xedch hoạt. M\xf4 h\xecnh n\xe0y thể hiện xuất sắc trong nhiều nhiệm vụ như hỏi đ\xe1p h\xecnh ảnh, nhận diện k\xfd tự quang học, hiểu t\xe0i liệu/bảng/biểu đồ v\xe0 định vị h\xecnh ảnh."},"deepseek-chat":{"description":"M\xf4 h\xecnh m\xe3 nguồn mở mới kết hợp khả năng tổng qu\xe1t v\xe0 m\xe3, kh\xf4ng chỉ giữ lại khả năng đối thoại tổng qu\xe1t của m\xf4 h\xecnh Chat ban đầu v\xe0 khả năng xử l\xfd m\xe3 mạnh mẽ của m\xf4 h\xecnh Coder, m\xe0 c\xf2n tốt hơn trong việc ph\xf9 hợp với sở th\xedch của con người. Hơn nữa, DeepSeek-V2.5 cũng đ\xe3 đạt được sự cải thiện lớn trong nhiều kh\xeda cạnh như nhiệm vụ viết, theo d\xf5i chỉ dẫn."},"deepseek-coder-33B-instruct":{"description":"DeepSeek Coder 33B l\xe0 một m\xf4 h\xecnh ng\xf4n ngữ m\xe3, được đ\xe0o tạo tr\xean 20 triệu tỷ dữ liệu, trong đ\xf3 87% l\xe0 m\xe3 v\xe0 13% l\xe0 ng\xf4n ngữ Trung v\xe0 Anh. M\xf4 h\xecnh n\xe0y giới thiệu k\xedch thước cửa sổ 16K v\xe0 nhiệm vụ điền chỗ trống, cung cấp chức năng ho\xe0n th\xe0nh m\xe3 v\xe0 điền đoạn m\xe3 ở cấp độ dự \xe1n."},"deepseek-coder-v2":{"description":"DeepSeek Coder V2 l\xe0 m\xf4 h\xecnh m\xe3 nguồn mở hỗn hợp chuy\xean gia, thể hiện xuất sắc trong c\xe1c nhiệm vụ m\xe3, tương đương với GPT4-Turbo."},"deepseek-coder-v2:236b":{"description":"DeepSeek Coder V2 l\xe0 m\xf4 h\xecnh m\xe3 nguồn mở hỗn hợp chuy\xean gia, thể hiện xuất sắc trong c\xe1c nhiệm vụ m\xe3, tương đương với GPT4-Turbo."},"deepseek-r1":{"description":"DeepSeek-R1 l\xe0 một m\xf4 h\xecnh suy diễn được điều khiển bởi học tăng cường (RL), giải quyết c\xe1c vấn đề về t\xednh lặp lại v\xe0 khả năng đọc hiểu trong m\xf4 h\xecnh. Trước khi \xe1p dụng RL, DeepSeek-R1 đ\xe3 giới thiệu dữ liệu khởi động lạnh, tối ưu h\xf3a th\xeam hiệu suất suy diễn. N\xf3 thể hiện hiệu suất tương đương với OpenAI-o1 trong c\xe1c nhiệm vụ to\xe1n học, m\xe3 v\xe0 suy diễn, v\xe0 th\xf4ng qua phương ph\xe1p đ\xe0o tạo được thiết kế cẩn thận, n\xe2ng cao hiệu quả tổng thể."},"deepseek-r1-0528":{"description":"M\xf4 h\xecnh phi\xean bản đầy đủ 685 tỷ tham số, ph\xe1t h\xe0nh ng\xe0y 28 th\xe1ng 5 năm 2025. DeepSeek-R1 sử dụng rộng r\xe3i kỹ thuật học tăng cường trong giai đoạn huấn luyện sau, n\xe2ng cao đ\xe1ng kể khả năng suy luận của m\xf4 h\xecnh d\xf9 c\xf3 rất \xedt dữ liệu g\xe1n nh\xe3n. Hiệu suất cao v\xe0 năng lực mạnh mẽ trong c\xe1c nhiệm vụ to\xe1n học, lập tr\xecnh, suy luận ng\xf4n ngữ tự nhi\xean."},"deepseek-r1-250528":{"description":"DeepSeek R1 250528, phi\xean bản đầy đủ của m\xf4 h\xecnh suy luận DeepSeek-R1, ph\xf9 hợp với c\xe1c nhiệm vụ to\xe1n học v\xe0 logic phức tạp."},"deepseek-r1-70b-fast-online":{"description":"DeepSeek R1 70B phi\xean bản nhanh, hỗ trợ t\xecm kiếm trực tuyến theo thời gian thực, cung cấp tốc độ phản hồi nhanh hơn trong khi vẫn giữ hiệu suất của m\xf4 h\xecnh."},"deepseek-r1-70b-online":{"description":"DeepSeek R1 70B phi\xean bản ti\xeau chuẩn, hỗ trợ t\xecm kiếm trực tuyến theo thời gian thực, ph\xf9 hợp cho c\xe1c nhiệm vụ đối thoại v\xe0 xử l\xfd văn bản cần th\xf4ng tin mới nhất."},"deepseek-r1-distill-llama":{"description":"deepseek-r1-distill-llama l\xe0 m\xf4 h\xecnh được chưng cất từ DeepSeek-R1 dựa tr\xean Llama."},"deepseek-r1-distill-llama-70b":{"description":"DeepSeek R1 Distill Llama 70B, m\xf4 h\xecnh chưng cất kết hợp khả năng suy luận R1 với hệ sinh th\xe1i Llama."},"deepseek-r1-distill-llama-8b":{"description":"DeepSeek-R1-Distill-Llama-8B l\xe0 m\xf4 h\xecnh ng\xf4n ngữ lớn chưng cất dựa tr\xean Llama-3.1-8B, sử dụng đầu ra từ DeepSeek R1."},"deepseek-r1-distill-qianfan-70b":{"description":"DeepSeek R1 Distill Qianfan 70B, m\xf4 h\xecnh chưng cất R1 dựa tr\xean Qianfan-70B, hiệu quả về chi ph\xed."},"deepseek-r1-distill-qianfan-8b":{"description":"DeepSeek R1 Distill Qianfan 8B, m\xf4 h\xecnh chưng cất R1 dựa tr\xean Qianfan-8B, ph\xf9 hợp với c\xe1c ứng dụng vừa v\xe0 nhỏ."},"deepseek-r1-distill-qianfan-llama-70b":{"description":"DeepSeek R1 Distill Qianfan Llama 70B, m\xf4 h\xecnh chưng cất R1 dựa tr\xean Llama-70B."},"deepseek-r1-distill-qwen":{"description":"deepseek-r1-distill-qwen l\xe0 m\xf4 h\xecnh được chưng cất từ DeepSeek-R1 dựa tr\xean Qwen."},"deepseek-r1-distill-qwen-1.5b":{"description":"DeepSeek R1 Distill Qwen 1.5B, m\xf4 h\xecnh chưng cất R1 si\xeau nhẹ, ph\xf9 hợp với m\xf4i trường t\xe0i nguy\xean cực thấp."},"deepseek-r1-distill-qwen-14b":{"description":"DeepSeek R1 Distill Qwen 14B, m\xf4 h\xecnh chưng cất R1 quy m\xf4 trung b\xecnh, ph\xf9 hợp với triển khai đa kịch bản."},"deepseek-r1-distill-qwen-32b":{"description":"DeepSeek R1 Distill Qwen 32B, m\xf4 h\xecnh chưng cất R1 dựa tr\xean Qwen-32B, c\xe2n bằng giữa hiệu năng v\xe0 chi ph\xed."},"deepseek-r1-distill-qwen-7b":{"description":"DeepSeek R1 Distill Qwen 7B, m\xf4 h\xecnh chưng cất R1 nhẹ, ph\xf9 hợp với m\xf4i trường bi\xean v\xe0 triển khai nội bộ doanh nghiệp."},"deepseek-r1-fast-online":{"description":"DeepSeek R1 phi\xean bản nhanh đầy đủ, hỗ trợ t\xecm kiếm trực tuyến theo thời gian thực, kết hợp sức mạnh của 671B tham số với tốc độ phản hồi nhanh hơn."},"deepseek-r1-online":{"description":"DeepSeek R1 phi\xean bản đầy đủ, c\xf3 671B tham số, hỗ trợ t\xecm kiếm trực tuyến theo thời gian thực, c\xf3 khả năng hiểu v\xe0 tạo ra mạnh mẽ hơn."},"deepseek-reasoner":{"description":"Chế độ suy nghĩ của DeepSeek V3.2. Trước khi đưa ra c\xe2u trả lời cuối c\xf9ng, m\xf4 h\xecnh sẽ xuất ra một chuỗi suy nghĩ nhằm n\xe2ng cao độ ch\xednh x\xe1c của c\xe2u trả lời."},"deepseek-v2":{"description":"DeepSeek V2 l\xe0 m\xf4 h\xecnh ng\xf4n ngữ Mixture-of-Experts hiệu quả, ph\xf9 hợp cho c\xe1c nhu cầu xử l\xfd tiết kiệm."},"deepseek-v2:236b":{"description":"DeepSeek V2 236B l\xe0 m\xf4 h\xecnh m\xe3 thiết kế của DeepSeek, cung cấp khả năng sinh m\xe3 mạnh mẽ."},"deepseek-v3":{"description":"DeepSeek-V3 l\xe0 m\xf4 h\xecnh MoE tự ph\xe1t triển của C\xf4ng ty Nghi\xean cứu C\xf4ng nghệ AI Độ S\xe2u H\xe0ng Ch\xe2u, c\xf3 nhiều th\xe0nh t\xedch xuất sắc trong c\xe1c b\xe0i kiểm tra, đứng đầu bảng xếp hạng m\xf4 h\xecnh m\xe3 nguồn mở. V3 so với m\xf4 h\xecnh V2.5 đ\xe3 cải thiện tốc độ tạo ra gấp 3 lần, mang đến trải nghiệm sử dụng nhanh ch\xf3ng v\xe0 mượt m\xe0 hơn cho người d\xf9ng."},"deepseek-v3-0324":{"description":"DeepSeek-V3-0324 l\xe0 m\xf4 h\xecnh MoE với 671B tham số, nổi bật trong khả năng lập tr\xecnh v\xe0 kỹ thuật, hiểu ngữ cảnh v\xe0 xử l\xfd văn bản d\xe0i."},"deepseek-v3.1":{"description":"DeepSeek-V3.1 l\xe0 m\xf4 h\xecnh suy luận hỗn hợp ho\xe0n to\xe0n mới do DeepSeek ph\xe1t h\xe0nh, hỗ trợ hai chế độ suy luận: suy nghĩ v\xe0 kh\xf4ng suy nghĩ, với hiệu quả suy nghĩ cao hơn so với DeepSeek-R1-0528. Sau khi tối ưu h\xf3a Post-Training, việc sử dụng c\xf4ng cụ Agent v\xe0 hiệu suất nhiệm vụ của t\xe1c nh\xe2n được cải thiện đ\xe1ng kể. Hỗ trợ cửa sổ ngữ cảnh 128k, độ d\xe0i đầu ra tối đa l\xean đến 64k tokens."},"deepseek-v3.1-terminus":{"description":"DeepSeek-V3.1-Terminus l\xe0 phi\xean bản tối ưu h\xf3a cho thiết bị đầu cuối của m\xf4 h\xecnh ng\xf4n ngữ lớn do DeepSeek ph\xe1t triển, được thiết kế đặc biệt cho c\xe1c thiết bị đầu cuối."},"deepseek-v3.1-think-250821":{"description":"DeepSeek V3.1 Think 250821, m\xf4 h\xecnh tư duy s\xe2u phi\xean bản Terminus, ph\xf9 hợp với c\xe1c t\xecnh huống suy luận hiệu năng cao."},"deepseek-v3.1:671b":{"description":"DeepSeek V3.1: M\xf4 h\xecnh suy luận thế hệ tiếp theo, n\xe2ng cao khả năng suy luận phức tạp v\xe0 tư duy chuỗi, ph\xf9 hợp cho c\xe1c t\xe1c vụ cần ph\xe2n t\xedch s\xe2u."},"deepseek-v3.2-exp":{"description":"deepseek-v3.2-exp giới thiệu cơ chế ch\xfa \xfd thưa thớt, nhằm n\xe2ng cao hiệu quả đ\xe0o tạo v\xe0 suy luận khi xử l\xfd văn bản d\xe0i, với gi\xe1 thấp hơn deepseek-v3.1."},"deepseek-v3.2-think":{"description":"DeepSeek V3.2 Think, phi\xean bản đầy đủ của m\xf4 h\xecnh tư duy s\xe2u, tăng cường khả năng suy luận chuỗi d\xe0i."},"deepseek-vl2":{"description":"DeepSeek VL2, m\xf4 h\xecnh đa phương thức, hỗ trợ hiểu h\xecnh ảnh v\xe0 văn bản c\xf9ng hỏi đ\xe1p thị gi\xe1c chi tiết."},"deepseek-vl2-small":{"description":"DeepSeek VL2 Small, phi\xean bản đa phương thức nhẹ, ph\xf9 hợp với m\xf4i trường t\xe0i nguy\xean hạn chế v\xe0 y\xeau cầu đồng thời cao."},"deepseek/deepseek-chat-v3-0324":{"description":"DeepSeek V3 l\xe0 một m\xf4 h\xecnh hỗn hợp chuy\xean gia với 685B tham số, l\xe0 phi\xean bản mới nhất trong d\xf2ng m\xf4 h\xecnh tr\xf2 chuyện flagship của đội ngũ DeepSeek.\\n\\nN\xf3 kế thừa m\xf4 h\xecnh [DeepSeek V3](/deepseek/deepseek-chat-v3) v\xe0 thể hiện xuất sắc trong nhiều nhiệm vụ."},"deepseek/deepseek-chat-v3-0324:free":{"description":"DeepSeek V3 l\xe0 một m\xf4 h\xecnh hỗn hợp chuy\xean gia với 685B tham số, l\xe0 phi\xean bản mới nhất trong d\xf2ng m\xf4 h\xecnh tr\xf2 chuyện flagship của đội ngũ DeepSeek.\\n\\nN\xf3 kế thừa m\xf4 h\xecnh [DeepSeek V3](/deepseek/deepseek-chat-v3) v\xe0 thể hiện xuất sắc trong nhiều nhiệm vụ."},"deepseek/deepseek-chat-v3.1":{"description":"DeepSeek-V3.1 l\xe0 m\xf4 h\xecnh suy luận hỗn hợp lớn hỗ trợ ngữ cảnh d\xe0i 128K v\xe0 chuyển đổi chế độ hiệu quả, đạt hiệu suất v\xe0 tốc độ xuất sắc trong việc gọi c\xf4ng cụ, tạo m\xe3 v\xe0 c\xe1c nhiệm vụ suy luận phức tạp."},"deepseek/deepseek-r1":{"description":"M\xf4 h\xecnh DeepSeek R1 đ\xe3 được n\xe2ng cấp phi\xean bản nhỏ, hiện tại l\xe0 DeepSeek-R1-0528. Trong bản cập nhật mới nhất, DeepSeek R1 đ\xe3 cải thiện đ\xe1ng kể độ s\xe2u v\xe0 khả năng suy luận bằng c\xe1ch tận dụng t\xe0i nguy\xean t\xednh to\xe1n tăng v\xe0 cơ chế tối ưu thuật to\xe1n sau đ\xe0o tạo. M\xf4 h\xecnh thể hiện xuất sắc trong c\xe1c b\xe0i đ\xe1nh gi\xe1 chuẩn về to\xe1n học, lập tr\xecnh v\xe0 logic chung, hiệu suất tổng thể hiện gần bằng c\xe1c m\xf4 h\xecnh h\xe0ng đầu như O3 v\xe0 Gemini 2.5 Pro."},"deepseek/deepseek-r1-0528":{"description":"DeepSeek-R1 đ\xe3 cải thiện đ\xe1ng kể khả năng suy luận của m\xf4 h\xecnh ngay cả khi c\xf3 rất \xedt dữ liệu g\xe1n nh\xe3n. Trước khi đưa ra c\xe2u trả lời cuối c\xf9ng, m\xf4 h\xecnh sẽ xuất ra một chuỗi suy nghĩ nhằm n\xe2ng cao độ ch\xednh x\xe1c của c\xe2u trả lời cuối."},"deepseek/deepseek-r1-0528:free":{"description":"DeepSeek-R1 đ\xe3 cải thiện đ\xe1ng kể khả năng suy luận của m\xf4 h\xecnh ngay cả khi c\xf3 rất \xedt dữ liệu g\xe1n nh\xe3n. Trước khi đưa ra c\xe2u trả lời cuối c\xf9ng, m\xf4 h\xecnh sẽ xuất ra một chuỗi suy nghĩ nhằm n\xe2ng cao độ ch\xednh x\xe1c của c\xe2u trả lời cuối."},"deepseek/deepseek-r1-distill-llama-70b":{"description":"DeepSeek R1 Distill Llama 70B l\xe0 một m\xf4 h\xecnh ng\xf4n ngữ lớn dựa tr\xean Llama3.3 70B, được tinh chỉnh bằng đầu ra từ DeepSeek R1, mang lại hiệu suất cạnh tranh tương đương với c\xe1c m\xf4 h\xecnh ti\xean tiến quy m\xf4 lớn."},"deepseek/deepseek-r1-distill-llama-8b":{"description":"DeepSeek R1 Distill Llama 8B l\xe0 một m\xf4 h\xecnh ng\xf4n ngữ lớn đ\xe3 được tinh chế dựa tr\xean Llama-3.1-8B-Instruct, được đ\xe0o tạo bằng c\xe1ch sử dụng đầu ra từ DeepSeek R1."},"deepseek/deepseek-r1-distill-qwen-14b":{"description":"DeepSeek R1 Distill Qwen 14B l\xe0 một m\xf4 h\xecnh ng\xf4n ngữ lớn đ\xe3 được tinh chế dựa tr\xean Qwen 2.5 14B, được đ\xe0o tạo bằng c\xe1ch sử dụng đầu ra từ DeepSeek R1. M\xf4 h\xecnh n\xe0y đ\xe3 vượt qua o1-mini của OpenAI trong nhiều b\xe0i kiểm tra chuẩn, đạt được những th\xe0nh tựu c\xf4ng nghệ ti\xean tiến nhất trong c\xe1c m\xf4 h\xecnh d\xe0y đặc (dense models). Dưới đ\xe2y l\xe0 một số kết quả từ c\xe1c b\xe0i kiểm tra chuẩn:\\nAIME 2024 pass@1: 69.7\\nMATH-500 pass@1: 93.9\\nCodeForces Rating: 1481\\nM\xf4 h\xecnh n\xe0y đ\xe3 thể hiện hiệu suất cạnh tranh tương đương với c\xe1c m\xf4 h\xecnh ti\xean tiến lớn hơn th\xf4ng qua việc tinh chỉnh từ đầu ra của DeepSeek R1."},"deepseek/deepseek-r1-distill-qwen-32b":{"description":"DeepSeek R1 Distill Qwen 32B l\xe0 một m\xf4 h\xecnh ng\xf4n ngữ lớn đ\xe3 được tinh chế dựa tr\xean Qwen 2.5 32B, được đ\xe0o tạo bằng c\xe1ch sử dụng đầu ra từ DeepSeek R1. M\xf4 h\xecnh n\xe0y đ\xe3 vượt qua o1-mini của OpenAI trong nhiều b\xe0i kiểm tra chuẩn, đạt được những th\xe0nh tựu c\xf4ng nghệ ti\xean tiến nhất trong c\xe1c m\xf4 h\xecnh d\xe0y đặc (dense models). Dưới đ\xe2y l\xe0 một số kết quả từ c\xe1c b\xe0i kiểm tra chuẩn:\\nAIME 2024 pass@1: 72.6\\nMATH-500 pass@1: 94.3\\nCodeForces Rating: 1691\\nM\xf4 h\xecnh n\xe0y đ\xe3 thể hiện hiệu suất cạnh tranh tương đương với c\xe1c m\xf4 h\xecnh ti\xean tiến lớn hơn th\xf4ng qua việc tinh chỉnh từ đầu ra của DeepSeek R1."},"deepseek/deepseek-r1/community":{"description":"DeepSeek R1 l\xe0 m\xf4 h\xecnh m\xe3 nguồn mở mới nhất được ph\xe1t h\xe0nh bởi đội ngũ DeepSeek, c\xf3 hiệu suất suy diễn rất mạnh mẽ, đặc biệt trong c\xe1c nhiệm vụ to\xe1n học, lập tr\xecnh v\xe0 suy luận, đạt được mức độ tương đương với m\xf4 h\xecnh o1 của OpenAI."},"deepseek/deepseek-r1:free":{"description":"DeepSeek-R1 đ\xe3 n\xe2ng cao khả năng suy luận của m\xf4 h\xecnh một c\xe1ch đ\xe1ng kể với rất \xedt dữ liệu được g\xe1n nh\xe3n. Trước khi đưa ra c\xe2u trả lời cuối c\xf9ng, m\xf4 h\xecnh sẽ xuất ra một chuỗi suy nghĩ để n\xe2ng cao độ ch\xednh x\xe1c của c\xe2u trả lời cuối c\xf9ng."},"deepseek/deepseek-v3":{"description":"M\xf4 h\xecnh ng\xf4n ngữ lớn đa năng nhanh với khả năng suy luận n\xe2ng cao."},"deepseek/deepseek-v3.1-base":{"description":"DeepSeek V3.1 Base l\xe0 phi\xean bản cải tiến của m\xf4 h\xecnh DeepSeek V3."},"deepseek/deepseek-v3/community":{"description":"DeepSeek-V3 đ\xe3 đạt được bước đột ph\xe1 lớn về tốc độ suy diễn so với c\xe1c m\xf4 h\xecnh trước đ\xf3. N\xf3 đứng đầu trong số c\xe1c m\xf4 h\xecnh m\xe3 nguồn mở v\xe0 c\xf3 thể so s\xe1nh với c\xe1c m\xf4 h\xecnh đ\xf3ng nguồn ti\xean tiến nhất tr\xean to\xe0n cầu. DeepSeek-V3 sử dụng kiến tr\xfac Attention đa đầu (MLA) v\xe0 DeepSeekMoE, những kiến tr\xfac n\xe0y đ\xe3 được x\xe1c thực to\xe0n diện trong DeepSeek-V2. Hơn nữa, DeepSeek-V3 đ\xe3 s\xe1ng tạo ra một chiến lược phụ trợ kh\xf4ng mất m\xe1t cho c\xe2n bằng tải v\xe0 thiết lập mục ti\xeau đ\xe0o tạo dự đo\xe1n đa nh\xe3n để đạt được hiệu suất mạnh mẽ hơn."},"deepseek_r1":{"description":"DeepSeek-R1 l\xe0 một m\xf4 h\xecnh suy luận được điều khiển bởi học tăng cường (RL), giải quyết c\xe1c vấn đề về t\xednh lặp lại v\xe0 khả năng đọc hiểu trong m\xf4 h\xecnh. Trước khi \xe1p dụng RL, DeepSeek-R1 đ\xe3 giới thiệu dữ liệu khởi động lạnh, tối ưu h\xf3a th\xeam hiệu suất suy luận. N\xf3 thể hiện hiệu suất tương đương với OpenAI-o1 trong c\xe1c nhiệm vụ to\xe1n học, m\xe3 v\xe0 suy luận, v\xe0 đ\xe3 n\xe2ng cao hiệu quả tổng thể th\xf4ng qua phương ph\xe1p huấn luyện được thiết kế cẩn thận."},"deepseek_r1_distill_llama_70b":{"description":"DeepSeek-R1-Distill-Llama-70B l\xe0 m\xf4 h\xecnh được ph\xe1t triển từ Llama-3.3-70B-Instruct th\xf4ng qua qu\xe1 tr\xecnh tinh chế. M\xf4 h\xecnh n\xe0y l\xe0 một phần của d\xf2ng DeepSeek-R1, thể hiện hiệu suất xuất sắc trong nhiều lĩnh vực như to\xe1n học, lập tr\xecnh v\xe0 suy luận th\xf4ng qua việc tinh chỉnh bằng c\xe1c mẫu được tạo ra từ DeepSeek-R1."},"deepseek_r1_distill_qwen_14b":{"description":"DeepSeek-R1-Distill-Qwen-14B l\xe0 m\xf4 h\xecnh được ph\xe1t triển từ Qwen2.5-14B th\xf4ng qua qu\xe1 tr\xecnh tinh chế kiến thức. M\xf4 h\xecnh n\xe0y được tinh chỉnh bằng 800.000 mẫu được chọn từ DeepSeek-R1, thể hiện khả năng suy luận xuất sắc."},"deepseek_r1_distill_qwen_32b":{"description":"DeepSeek-R1-Distill-Qwen-32B l\xe0 m\xf4 h\xecnh được ph\xe1t triển từ Qwen2.5-32B th\xf4ng qua qu\xe1 tr\xecnh tinh chế kiến thức. M\xf4 h\xecnh n\xe0y được tinh chỉnh bằng 800.000 mẫu được chọn từ DeepSeek-R1, thể hiện hiệu suất xuất sắc trong nhiều lĩnh vực như to\xe1n học, lập tr\xecnh v\xe0 suy luận."},"doubao-1.5-lite-32k":{"description":"Doubao-1.5-lite l\xe0 m\xf4 h\xecnh phi\xean bản nhẹ thế hệ mới, tốc độ phản hồi cực nhanh, hiệu quả v\xe0 độ trễ đạt ti\xeau chuẩn h\xe0ng đầu thế giới."},"doubao-1.5-pro-256k":{"description":"Doubao-1.5-pro-256k l\xe0 phi\xean bản n\xe2ng cấp to\xe0n diện dựa tr\xean Doubao-1.5-Pro, hiệu quả tổng thể tăng 10%. Hỗ trợ suy luận với cửa sổ ngữ cảnh 256k, độ d\xe0i đầu ra tối đa l\xean đến 12k tokens. Hiệu suất cao hơn, cửa sổ lớn hơn, gi\xe1 trị vượt trội, ph\xf9 hợp với nhiều ứng dụng kh\xe1c nhau."},"doubao-1.5-pro-32k":{"description":"Doubao-1.5-pro l\xe0 m\xf4 h\xecnh chủ lực thế hệ mới, hiệu suất được n\xe2ng cấp to\xe0n diện, thể hiện xuất sắc trong c\xe1c lĩnh vực kiến thức, m\xe3 nguồn, suy luận, v\xe0 nhiều hơn nữa."},"doubao-1.5-thinking-pro":{"description":"M\xf4 h\xecnh tư duy s\xe2u mới Doubao-1.5, nổi bật trong c\xe1c lĩnh vực chuy\xean m\xf4n như to\xe1n học, lập tr\xecnh, suy luận khoa học v\xe0 c\xe1c nhiệm vụ viết s\xe1ng tạo, đạt hoặc gần đạt tr\xecnh độ h\xe0ng đầu trong ng\xe0nh tr\xean nhiều ti\xeau chuẩn uy t\xedn như AIME 2024, Codeforces, GPQA. Hỗ trợ cửa sổ ngữ cảnh 128k, đầu ra 16k."},"doubao-1.5-thinking-pro-m":{"description":"Doubao-1.5 l\xe0 m\xf4 h\xecnh tư duy s\xe2u ho\xe0n to\xe0n mới (phi\xean bản m c\xf3 khả năng suy luận đa phương thức s\xe2u nguy\xean bản), thể hiện xuất sắc trong c\xe1c lĩnh vực chuy\xean m\xf4n như to\xe1n học, lập tr\xecnh, suy luận khoa học v\xe0 c\xe1c nhiệm vụ s\xe1ng tạo chung. Đạt hoặc gần đạt tr\xecnh độ h\xe0ng đầu ng\xe0nh tr\xean nhiều chuẩn đ\xe1nh gi\xe1 uy t\xedn như AIME 2024, Codeforces, GPQA. Hỗ trợ cửa sổ ngữ cảnh 128k, đầu ra 16k."},"doubao-1.5-thinking-vision-pro":{"description":"M\xf4 h\xecnh tư duy s\xe2u đa phương thức ho\xe0n to\xe0n mới, c\xf3 khả năng hiểu v\xe0 suy luận đa phương thức tổng qu\xe1t mạnh mẽ, đạt hiệu suất SOTA tr\xean 37 trong số 59 chuẩn đ\xe1nh gi\xe1 c\xf4ng khai."},"doubao-1.5-ui-tars":{"description":"Doubao-1.5-UI-TARS l\xe0 m\xf4 h\xecnh Agent nguy\xean bản hướng tới tương t\xe1c giao diện đồ họa (GUI). Th\xf4ng qua khả năng nhận thức, suy luận v\xe0 h\xe0nh động giống con người, tương t\xe1c liền mạch với GUI."},"doubao-1.5-vision-lite":{"description":"Doubao-1.5-vision-lite l\xe0 m\xf4 h\xecnh đa phương tiện lớn được n\xe2ng cấp mới, hỗ trợ nhận diện h\xecnh ảnh với bất kỳ độ ph\xe2n giải n\xe0o v\xe0 tỷ lệ d\xe0i rộng cực đoan, tăng cường khả năng suy luận h\xecnh ảnh, nhận diện t\xe0i liệu, hiểu th\xf4ng tin chi tiết v\xe0 tu\xe2n thủ hướng dẫn. Hỗ trợ cửa sổ ngữ cảnh 128k, độ d\xe0i đầu ra tối đa 16k tokens."},"doubao-1.5-vision-pro":{"description":"Doubao-1.5-vision-pro l\xe0 m\xf4 h\xecnh đa phương thức lớn được n\xe2ng cấp ho\xe0n to\xe0n mới, hỗ trợ nhận dạng h\xecnh ảnh với độ ph\xe2n giải t\xf9y \xfd v\xe0 tỷ lệ khung h\xecnh cực đoan, tăng cường khả năng suy luận thị gi\xe1c, nhận dạng t\xe0i liệu, hiểu th\xf4ng tin chi tiết v\xe0 tu\xe2n thủ chỉ dẫn."},"doubao-1.5-vision-pro-32k":{"description":"Doubao-1.5-vision-pro l\xe0 m\xf4 h\xecnh đa phương thức lớn được n\xe2ng cấp ho\xe0n to\xe0n mới, hỗ trợ nhận dạng h\xecnh ảnh với độ ph\xe2n giải t\xf9y \xfd v\xe0 tỷ lệ khung h\xecnh cực đoan, tăng cường khả năng suy luận thị gi\xe1c, nhận dạng t\xe0i liệu, hiểu th\xf4ng tin chi tiết v\xe0 tu\xe2n thủ chỉ dẫn."},"doubao-lite-128k":{"description":"Sở hữu tốc độ phản hồi tối ưu, hiệu quả chi ph\xed tốt hơn, cung cấp lựa chọn linh hoạt hơn cho c\xe1c kịch bản kh\xe1c nhau của kh\xe1ch h\xe0ng. Hỗ trợ suy luận v\xe0 tinh chỉnh với cửa sổ ngữ cảnh 128k."},"doubao-lite-32k":{"description":"Sở hữu tốc độ phản hồi tối ưu, hiệu quả chi ph\xed tốt hơn, cung cấp lựa chọn linh hoạt hơn cho c\xe1c kịch bản kh\xe1c nhau của kh\xe1ch h\xe0ng. Hỗ trợ suy luận v\xe0 tinh chỉnh với cửa sổ ngữ cảnh 32k."},"doubao-lite-4k":{"description":"Sở hữu tốc độ phản hồi tối ưu, hiệu quả chi ph\xed tốt hơn, cung cấp lựa chọn linh hoạt hơn cho c\xe1c kịch bản kh\xe1c nhau của kh\xe1ch h\xe0ng. Hỗ trợ suy luận v\xe0 tinh chỉnh với cửa sổ ngữ cảnh 4k."},"doubao-pro-256k":{"description":"M\xf4 h\xecnh chủ lực với hiệu quả tốt nhất, ph\xf9 hợp xử l\xfd c\xe1c nhiệm vụ phức tạp, c\xf3 hiệu quả xuất sắc trong c\xe1c kịch bản như hỏi đ\xe1p tham khảo, t\xf3m tắt, s\xe1ng tạo, ph\xe2n loại văn bản, nhập vai. Hỗ trợ suy luận v\xe0 tinh chỉnh với cửa sổ ngữ cảnh 256k."},"doubao-pro-32k":{"description":"M\xf4 h\xecnh chủ lực với hiệu quả tốt nhất, ph\xf9 hợp xử l\xfd c\xe1c nhiệm vụ phức tạp, c\xf3 hiệu quả xuất sắc trong c\xe1c kịch bản như hỏi đ\xe1p tham khảo, t\xf3m tắt, s\xe1ng tạo, ph\xe2n loại văn bản, nhập vai. Hỗ trợ suy luận v\xe0 tinh chỉnh với cửa sổ ngữ cảnh 32k."},"doubao-seed-1.6":{"description":"Doubao-Seed-1.6 l\xe0 m\xf4 h\xecnh suy nghĩ s\xe2u đa phương thức ho\xe0n to\xe0n mới, hỗ trợ ba chế độ suy nghĩ auto/thinking/non-thinking. Ở chế độ non-thinking, hiệu quả m\xf4 h\xecnh cải thiện đ\xe1ng kể so với Doubao-1.5-pro/250115. Hỗ trợ cửa sổ ngữ cảnh 256k, độ d\xe0i đầu ra tối đa 16k tokens."},"doubao-seed-1.6-flash":{"description":"Doubao-Seed-1.6-flash l\xe0 m\xf4 h\xecnh suy nghĩ s\xe2u đa phương thức với tốc độ suy luận tối ưu, TPOT chỉ cần 10ms; đồng thời hỗ trợ hiểu văn bản v\xe0 h\xecnh ảnh, khả năng hiểu văn bản vượt trội so với thế hệ lite trước, khả năng hiểu h\xecnh ảnh s\xe1nh ngang với c\xe1c m\xf4 h\xecnh pro của đối thủ. Hỗ trợ cửa sổ ngữ cảnh 256k, độ d\xe0i đầu ra tối đa 16k tokens."},"doubao-seed-1.6-lite":{"description":"Doubao-Seed-1.6-lite l\xe0 m\xf4 h\xecnh tư duy s\xe2u đa phương thức ho\xe0n to\xe0n mới, hỗ trợ điều chỉnh mức độ suy luận (reasoning effort) với bốn chế độ: Tối thiểu, Thấp, Trung b\xecnh v\xe0 Cao. Đ\xe2y l\xe0 lựa chọn tối ưu cho c\xe1c t\xe1c vụ phổ biến với hiệu suất vượt trội v\xe0 cửa sổ ngữ cảnh l\xean đến 256k."},"doubao-seed-1.6-thinking":{"description":"M\xf4 h\xecnh Doubao-Seed-1.6-thinking c\xf3 khả năng suy nghĩ được tăng cường đ\xe1ng kể, so với Doubao-1.5-thinking-pro, n\xe2ng cao hơn nữa c\xe1c năng lực cơ bản như lập tr\xecnh, to\xe1n học, suy luận logic, đồng thời hỗ trợ hiểu h\xecnh ảnh. Hỗ trợ cửa sổ ngữ cảnh 256k, độ d\xe0i đầu ra tối đa 16k tokens."},"doubao-seed-1.6-vision":{"description":"Doubao-Seed-1.6-vision l\xe0 m\xf4 h\xecnh suy nghĩ s\xe2u về thị gi\xe1c, thể hiện khả năng hiểu v\xe0 suy luận đa phương thức tổng qu\xe1t mạnh mẽ hơn trong c\xe1c kịch bản như gi\xe1o dục, kiểm duyệt h\xecnh ảnh, kiểm tra v\xe0 an ninh, cũng như t\xecm kiếm v\xe0 hỏi đ\xe1p AI. Hỗ trợ cửa sổ ngữ cảnh 256k, độ d\xe0i đầu ra tối đa l\xean đến 64k token."},"doubao-seededit-3-0-i2i-250628":{"description":"M\xf4 h\xecnh tạo ảnh Doubao do đội Seed của ByteDance ph\xe1t triển, hỗ trợ đầu v\xe0o văn bản v\xe0 h\xecnh ảnh, cung cấp trải nghiệm tạo ảnh chất lượng cao v\xe0 kiểm so\xe1t tốt. Hỗ trợ chỉnh sửa h\xecnh ảnh qua chỉ dẫn văn bản, k\xedch thước ảnh tạo ra từ 512 đến 1536 pixel."},"doubao-seedream-3-0-t2i-250415":{"description":"M\xf4 h\xecnh tạo ảnh Seedream 3.0 do đội Seed của ByteDance ph\xe1t triển, hỗ trợ đầu v\xe0o văn bản v\xe0 h\xecnh ảnh, cung cấp trải nghiệm tạo ảnh chất lượng cao v\xe0 kiểm so\xe1t tốt. Tạo ảnh dựa tr\xean từ kh\xf3a văn bản."},"doubao-seedream-4-0-250828":{"description":"M\xf4 h\xecnh tạo ảnh Seedream 4.0 do đội Seed của ByteDance ph\xe1t triển, hỗ trợ đầu v\xe0o văn bản v\xe0 h\xecnh ảnh, cung cấp trải nghiệm tạo ảnh chất lượng cao v\xe0 kiểm so\xe1t tốt. Tạo ảnh dựa tr\xean từ kh\xf3a văn bản."},"doubao-vision-lite-32k":{"description":"M\xf4 h\xecnh Doubao-vision l\xe0 m\xf4 h\xecnh đa phương thức lớn do Doubao ph\xe1t triển, c\xf3 khả năng hiểu v\xe0 suy luận h\xecnh ảnh mạnh mẽ, c\xf9ng khả năng hiểu chỉ dẫn ch\xednh x\xe1c. M\xf4 h\xecnh thể hiện hiệu suất vượt trội trong việc tr\xedch xuất th\xf4ng tin văn bản từ h\xecnh ảnh v\xe0 c\xe1c nhiệm vụ suy luận dựa tr\xean h\xecnh ảnh, c\xf3 thể ứng dụng trong c\xe1c nhiệm vụ hỏi đ\xe1p thị gi\xe1c phức tạp v\xe0 đa dạng hơn."},"doubao-vision-pro-32k":{"description":"M\xf4 h\xecnh Doubao-vision l\xe0 m\xf4 h\xecnh đa phương thức lớn do Doubao ph\xe1t triển, c\xf3 khả năng hiểu v\xe0 suy luận h\xecnh ảnh mạnh mẽ, c\xf9ng khả năng hiểu chỉ dẫn ch\xednh x\xe1c. M\xf4 h\xecnh thể hiện hiệu suất vượt trội trong việc tr\xedch xuất th\xf4ng tin văn bản từ h\xecnh ảnh v\xe0 c\xe1c nhiệm vụ suy luận dựa tr\xean h\xecnh ảnh, c\xf3 thể ứng dụng trong c\xe1c nhiệm vụ hỏi đ\xe1p thị gi\xe1c phức tạp v\xe0 đa dạng hơn."},"emohaa":{"description":"Emohaa l\xe0 m\xf4 h\xecnh t\xe2m l\xfd, c\xf3 khả năng tư vấn chuy\xean nghiệp, gi\xfap người d\xf9ng hiểu c\xe1c vấn đề cảm x\xfac."},"ernie-4.5-0.3b":{"description":"ERNIE 4.5 0.3B, m\xf4 h\xecnh m\xe3 nguồn mở nhẹ, ph\xf9 hợp cho triển khai cục bộ v\xe0 t\xf9y chỉnh."},"ernie-4.5-21b-a3b":{"description":"ERNIE 4.5 21B A3B, m\xf4 h\xecnh lớn m\xe3 nguồn mở, thể hiện hiệu suất vượt trội trong c\xe1c nhiệm vụ hiểu v\xe0 sinh văn bản."},"ernie-4.5-300b-a47b":{"description":"ERNIE 4.5 300B A47B l\xe0 m\xf4 h\xecnh chuy\xean gia hỗn hợp quy m\xf4 si\xeau lớn do Wenxin của Baidu ph\xe1t triển, nổi bật với khả năng suy luận vượt trội."},"ernie-4.5-8k-preview":{"description":"ERNIE 4.5 8K Preview, m\xf4 h\xecnh xem trước ngữ cảnh 8K, d\xf9ng để trải nghiệm v\xe0 kiểm thử khả năng của Wenxin 4.5."},"ernie-4.5-turbo-128k":{"description":"ERNIE 4.5 Turbo 128K, m\xf4 h\xecnh đa năng hiệu suất cao, hỗ trợ tăng cường t\xecm kiếm v\xe0 gọi c\xf4ng cụ, ph\xf9 hợp với hỏi đ\xe1p, lập tr\xecnh, t\xe1c tử th\xf4ng minh v\xe0 nhiều t\xecnh huống kh\xe1c."},"ernie-4.5-turbo-128k-preview":{"description":"ERNIE 4.5 Turbo 128K Preview, phi\xean bản xem trước với trải nghiệm tương đương bản ch\xednh thức, ph\xf9 hợp cho kiểm thử v\xe0 t\xedch hợp."},"ernie-4.5-turbo-32k":{"description":"ERNIE 4.5 Turbo 32K, phi\xean bản ngữ cảnh trung b\xecnh đến d\xe0i, ph\xf9 hợp với hỏi đ\xe1p, truy vấn tri thức v\xe0 hội thoại nhiều lượt."},"ernie-4.5-turbo-latest":{"description":"ERNIE 4.5 Turbo Phi\xean bản mới nhất, tối ưu h\xf3a to\xe0n diện hiệu suất, ph\xf9 hợp l\xe0m m\xf4 h\xecnh ch\xednh trong m\xf4i trường sản xuất."},"ernie-4.5-turbo-vl":{"description":"ERNIE 4.5 Turbo VL, m\xf4 h\xecnh đa phương thức trưởng th\xe0nh, ph\xf9 hợp với c\xe1c nhiệm vụ hiểu v\xe0 nhận diện h\xecnh ảnh-văn bản trong m\xf4i trường sản xuất."},"ernie-4.5-turbo-vl-32k":{"description":"ERNIE 4.5 Turbo VL 32K, phi\xean bản đa phương thức văn bản d\xe0i, ph\xf9 hợp với hiểu kết hợp t\xe0i liệu d\xe0i v\xe0 h\xecnh ảnh."},"ernie-4.5-turbo-vl-32k-preview":{"description":"ERNIE 4.5 Turbo VL 32K Preview, phi\xean bản xem trước đa phương thức 32K, thuận tiện để đ\xe1nh gi\xe1 khả năng thị gi\xe1c ngữ cảnh d\xe0i."},"ernie-4.5-turbo-vl-latest":{"description":"ERNIE 4.5 Turbo VL Phi\xean bản mới nhất, phi\xean bản đa phương thức mới nhất, cung cấp khả năng hiểu v\xe0 suy luận h\xecnh ảnh-văn bản tốt hơn."},"ernie-4.5-turbo-vl-preview":{"description":"ERNIE 4.5 Turbo VL Preview, m\xf4 h\xecnh đa phương thức xem trước, hỗ trợ hiểu v\xe0 sinh h\xecnh ảnh-văn bản, ph\xf9 hợp với hỏi đ\xe1p thị gi\xe1c v\xe0 trải nghiệm hiểu nội dung."},"ernie-4.5-vl-28b-a3b":{"description":"ERNIE 4.5 VL 28B A3B, m\xf4 h\xecnh đa phương thức m\xe3 nguồn mở, hỗ trợ c\xe1c nhiệm vụ hiểu v\xe0 suy luận h\xecnh ảnh-văn bản."},"ernie-5.0-thinking-preview":{"description":"Wenxin 5.0 Thinking Preview, m\xf4 h\xecnh h\xe0ng đầu to\xe0n phương thức nguy\xean bản, hỗ trợ m\xf4 h\xecnh h\xf3a thống nhất văn bản, h\xecnh ảnh, \xe2m thanh v\xe0 video, n\xe2ng cấp to\xe0n diện năng lực tổng hợp, ph\xf9 hợp với hỏi đ\xe1p phức tạp, s\xe1ng tạo v\xe0 t\xe1c tử th\xf4ng minh."},"ernie-char-8k":{"description":"ERNIE Character 8K, m\xf4 h\xecnh hội thoại nh\xe2n c\xe1ch nh\xe2n vật, ph\xf9 hợp với x\xe2y dựng nh\xe2n vật IP v\xe0 hội thoại đồng h\xe0nh d\xe0i hạn."},"ernie-char-fiction-8k":{"description":"ERNIE Character Fiction 8K, m\xf4 h\xecnh nh\xe2n c\xe1ch d\xe0nh cho s\xe1ng t\xe1c tiểu thuyết v\xe0 cốt truyện, ph\xf9 hợp với sinh truyện d\xe0i."},"ernie-char-fiction-8k-preview":{"description":"ERNIE Character Fiction 8K Preview, phi\xean bản xem trước m\xf4 h\xecnh s\xe1ng t\xe1c nh\xe2n vật v\xe0 cốt truyện, d\xf9ng để trải nghiệm v\xe0 kiểm thử t\xednh năng."},"ernie-irag-edit":{"description":"ERNIE iRAG Edit, m\xf4 h\xecnh chỉnh sửa h\xecnh ảnh hỗ trợ x\xf3a, vẽ lại v\xe0 tạo biến thể h\xecnh ảnh."},"ernie-lite-8k":{"description":"ERNIE Lite 8K, m\xf4 h\xecnh đa năng nhẹ, ph\xf9 hợp với c\xe1c t\xecnh huống hỏi đ\xe1p h\xe0ng ng\xe0y v\xe0 sinh nội dung nhạy cảm về chi ph\xed."},"ernie-lite-pro-128k":{"description":"ERNIE Lite Pro 128K, m\xf4 h\xecnh nhẹ hiệu suất cao, ph\xf9 hợp với c\xe1c t\xecnh huống kinh doanh nhạy cảm về độ trễ v\xe0 chi ph\xed."},"ernie-novel-8k":{"description":"ERNIE Novel 8K, m\xf4 h\xecnh s\xe1ng t\xe1c tiểu thuyết d\xe0i v\xe0 cốt truyện IP, giỏi trong kể chuyện đa nh\xe2n vật v\xe0 đa tuyến."},"ernie-speed-128k":{"description":"ERNIE Speed 128K, m\xf4 h\xecnh lớn kh\xf4ng t\xednh ph\xed nhập/xuất, ph\xf9 hợp với hiểu văn bản d\xe0i v\xe0 thử nghiệm quy m\xf4 lớn."},"ernie-speed-8k":{"description":"ERNIE Speed 8K, m\xf4 h\xecnh miễn ph\xed v\xe0 nhanh, ph\xf9 hợp với hội thoại h\xe0ng ng\xe0y v\xe0 nhiệm vụ văn bản nhẹ."},"ernie-speed-pro-128k":{"description":"ERNIE Speed Pro 128K, m\xf4 h\xecnh hiệu suất cao v\xe0 chi ph\xed thấp, ph\xf9 hợp với dịch vụ trực tuyến quy m\xf4 lớn v\xe0 ứng dụng doanh nghiệp."},"ernie-tiny-8k":{"description":"ERNIE Tiny 8K, m\xf4 h\xecnh si\xeau nhẹ, ph\xf9 hợp với c\xe1c t\xecnh huống suy luận chi ph\xed thấp như hỏi đ\xe1p đơn giản v\xe0 ph\xe2n loại."},"ernie-x1-turbo-32k":{"description":"ERNIE X1 Turbo 32K, m\xf4 h\xecnh tư duy tốc độ cao, ngữ cảnh d\xe0i 32K, ph\xf9 hợp với suy luận phức tạp v\xe0 hội thoại nhiều lượt."},"ernie-x1.1-preview":{"description":"ERNIE X1.1 Preview, phi\xean bản xem trước m\xf4 h\xecnh tư duy ERNIE X1.1, ph\xf9 hợp với kiểm thử v\xe0 x\xe1c minh năng lực."},"fal-ai/bytedance/seedream/v4":{"description":"M\xf4 h\xecnh tạo ảnh Seedream 4.0 do đội Seed của ByteDance ph\xe1t triển, hỗ trợ đầu v\xe0o văn bản v\xe0 h\xecnh ảnh, cung cấp trải nghiệm tạo ảnh chất lượng cao v\xe0 kiểm so\xe1t tốt. Tạo ảnh dựa tr\xean từ kh\xf3a văn bản."},"fal-ai/flux-kontext/dev":{"description":"M\xf4 h\xecnh FLUX.1 tập trung v\xe0o nhiệm vụ chỉnh sửa h\xecnh ảnh, hỗ trợ đầu v\xe0o văn bản v\xe0 h\xecnh ảnh."},"fal-ai/flux-pro/kontext":{"description":"FLUX.1 Kontext [pro] c\xf3 khả năng xử l\xfd đầu v\xe0o l\xe0 văn bản v\xe0 h\xecnh ảnh tham khảo, thực hiện chỉnh sửa cục bộ mục ti\xeau v\xe0 biến đổi cảnh phức tạp một c\xe1ch liền mạch."},"fal-ai/flux/krea":{"description":"Flux Krea [dev] l\xe0 m\xf4 h\xecnh tạo ảnh c\xf3 sở th\xedch thẩm mỹ, nhằm tạo ra h\xecnh ảnh ch\xe2n thực v\xe0 tự nhi\xean hơn."},"fal-ai/flux/schnell":{"description":"FLUX.1 [schnell] l\xe0 m\xf4 h\xecnh tạo ảnh với 12 tỷ tham số, tập trung v\xe0o việc tạo ảnh chất lượng cao nhanh ch\xf3ng."},"fal-ai/hunyuan-image/v3":{"description":"Một m\xf4 h\xecnh tạo h\xecnh ảnh đa phương thức gốc mạnh mẽ"},"fal-ai/imagen4/preview":{"description":"M\xf4 h\xecnh tạo ảnh chất lượng cao do Google cung cấp."},"fal-ai/nano-banana":{"description":"Nano Banana l\xe0 m\xf4 h\xecnh đa phương thức nguy\xean bản mới nhất, nhanh nhất v\xe0 hiệu quả nhất của Google, cho ph\xe9p bạn tạo v\xe0 chỉnh sửa h\xecnh ảnh qua đối thoại."},"fal-ai/qwen-image":{"description":"M\xf4 h\xecnh ảnh th\xf4 mạnh mẽ do đội Qwen ph\xe1t triển, c\xf3 khả năng tạo văn bản tiếng Trung ấn tượng v\xe0 đa dạng phong c\xe1ch h\xecnh ảnh."},"fal-ai/qwen-image-edit":{"description":"M\xf4 h\xecnh chỉnh sửa h\xecnh ảnh chuy\xean nghiệp do đội Qwen ph\xe1t h\xe0nh, hỗ trợ chỉnh sửa ngữ nghĩa v\xe0 ngoại h\xecnh, c\xf3 thể chỉnh sửa ch\xednh x\xe1c văn bản tiếng Trung v\xe0 tiếng Anh, thực hiện chuyển đổi phong c\xe1ch, xoay đối tượng v\xe0 c\xe1c chỉnh sửa h\xecnh ảnh chất lượng cao kh\xe1c."},"flux-1-schnell":{"description":"M\xf4 h\xecnh tạo h\xecnh ảnh từ văn bản 12 tỷ tham số do Black Forest Labs ph\xe1t triển, sử dụng kỹ thuật chưng cất khuếch t\xe1n đối kh\xe1ng tiềm ẩn, c\xf3 thể tạo h\xecnh ảnh chất lượng cao trong 1 đến 4 bước. M\xf4 h\xecnh c\xf3 hiệu suất tương đương c\xe1c sản phẩm đ\xf3ng nguồn v\xe0 được ph\xe1t h\xe0nh dưới giấy ph\xe9p Apache-2.0, ph\xf9 hợp cho c\xe1 nh\xe2n, nghi\xean cứu v\xe0 thương mại."},"flux-dev":{"description":"FLUX.1 [dev] l\xe0 m\xf4 h\xecnh tinh luyện m\xe3 nguồn mở d\xe0nh cho ứng dụng phi thương mại. FLUX.1 [dev] duy tr\xec chất lượng h\xecnh ảnh v\xe0 khả năng tu\xe2n thủ chỉ dẫn gần tương đương phi\xean bản chuy\xean nghiệp FLUX, đồng thời c\xf3 hiệu suất vận h\xe0nh cao hơn. So với m\xf4 h\xecnh chuẩn c\xf9ng k\xedch thước, n\xf3 sử dụng t\xe0i nguy\xean hiệu quả hơn."},"flux-kontext-max":{"description":"Tạo v\xe0 chỉnh sửa h\xecnh ảnh theo ngữ cảnh ti\xean tiến nhất — kết hợp văn bản v\xe0 h\xecnh ảnh để c\xf3 kết quả ch\xednh x\xe1c, mạch lạc."},"flux-kontext-pro":{"description":"Tạo v\xe0 chỉnh sửa h\xecnh ảnh theo ngữ cảnh ti\xean tiến nhất — kết hợp văn bản v\xe0 h\xecnh ảnh để đạt được kết quả ch\xednh x\xe1c, mạch lạc."},"flux-merged":{"description":"M\xf4 h\xecnh FLUX.1-merged kết hợp c\xe1c đặc t\xednh s\xe2u sắc được kh\xe1m ph\xe1 trong giai đoạn ph\xe1t triển của \\"DEV\\" v\xe0 ưu thế thực thi nhanh của \\"Schnell\\". Qua đ\xf3, FLUX.1-merged kh\xf4ng chỉ n\xe2ng cao giới hạn hiệu suất m\xe0 c\xf2n mở rộng phạm vi ứng dụng."},"flux-pro":{"description":"M\xf4 h\xecnh tạo ảnh AI thương mại h\xe0ng đầu — chất lượng h\xecnh ảnh v\xf4 song v\xe0 độ đa dạng đầu ra vượt trội."},"flux-pro-1.1":{"description":"M\xf4 h\xecnh tạo ảnh AI chuy\xean nghiệp phi\xean bản n\xe2ng cấp — cung cấp chất lượng h\xecnh ảnh vượt trội v\xe0 khả năng tu\xe2n thủ ch\xednh x\xe1c c\xe1c gợi \xfd."},"flux-pro-1.1-ultra":{"description":"Tạo ảnh AI độ ph\xe2n giải cực cao — hỗ trợ xuất ảnh 4 megapixel, tạo ảnh si\xeau n\xe9t trong v\xf2ng 10 gi\xe2y."},"flux-schnell":{"description":"FLUX.1 [schnell] l\xe0 m\xf4 h\xecnh \xedt bước ti\xean tiến nhất m\xe3 nguồn mở hiện nay, vượt trội so với c\xe1c đối thủ c\xf9ng loại v\xe0 thậm ch\xed hơn cả c\xe1c m\xf4 h\xecnh kh\xf4ng tinh luyện mạnh như Midjourney v6.0 v\xe0 DALL\xb7E 3 (HD). M\xf4 h\xecnh được tinh chỉnh đặc biệt để giữ lại to\xe0n bộ đa dạng đầu ra giai đoạn tiền huấn luyện, so với c\xe1c m\xf4 h\xecnh ti\xean tiến tr\xean thị trường, FLUX.1 [schnell] cải thiện đ\xe1ng kể chất lượng h\xecnh ảnh, tu\xe2n thủ chỉ dẫn, thay đổi k\xedch thước/tỷ lệ, xử l\xfd ph\xf4ng chữ v\xe0 đa dạng đầu ra, mang đến trải nghiệm tạo h\xecnh ảnh s\xe1ng tạo phong ph\xfa hơn cho người d\xf9ng."},"flux.1-schnell":{"description":"FLUX.1-schnell, m\xf4 h\xecnh tạo h\xecnh ảnh hiệu suất cao, ph\xf9 hợp với tạo nhanh h\xecnh ảnh đa phong c\xe1ch."},"gemini-1.0-pro-001":{"description":"Gemini 1.0 Pro 001 (Tuning) cung cấp hiệu suất ổn định v\xe0 c\xf3 thể điều chỉnh, l\xe0 lựa chọn l\xfd tưởng cho c\xe1c giải ph\xe1p nhiệm vụ phức tạp."},"gemini-1.0-pro-002":{"description":"Gemini 1.0 Pro 002 (Tuning) cung cấp hỗ trợ đa phương thức xuất sắc, tập trung v\xe0o việc giải quyết hiệu quả c\xe1c nhiệm vụ phức tạp."},"gemini-1.0-pro-latest":{"description":"Gemini 1.0 Pro l\xe0 m\xf4 h\xecnh AI hiệu suất cao của Google, được thiết kế để mở rộng cho nhiều nhiệm vụ."},"gemini-1.5-flash-001":{"description":"Gemini 1.5 Flash 001 l\xe0 một m\xf4 h\xecnh đa phương thức hiệu quả, hỗ trợ mở rộng cho nhiều ứng dụng."},"gemini-1.5-flash-002":{"description":"Gemini 1.5 Flash 002 l\xe0 một m\xf4 h\xecnh đa phương thức hiệu quả, hỗ trợ mở rộng cho nhiều ứng dụng."},"gemini-1.5-flash-8b":{"description":"Gemini 1.5 Flash 8B l\xe0 một m\xf4 h\xecnh đa phương thức hiệu quả, hỗ trợ mở rộng cho nhiều ứng dụng."},"gemini-1.5-flash-8b-exp-0924":{"description":"Gemini 1.5 Flash 8B 0924 l\xe0 m\xf4 h\xecnh thử nghiệm mới nhất, c\xf3 sự cải thiện đ\xe1ng kể về hiệu suất trong c\xe1c trường hợp sử dụng văn bản v\xe0 đa phương thức."},"gemini-1.5-flash-8b-latest":{"description":"Gemini 1.5 Flash 8B l\xe0 một m\xf4 h\xecnh đa chế độ hiệu quả, hỗ trợ mở rộng ứng dụng rộng r\xe3i."},"gemini-1.5-flash-exp-0827":{"description":"Gemini 1.5 Flash 0827 cung cấp khả năng xử l\xfd đa phương tiện tối ưu, \xe1p dụng cho nhiều t\xecnh huống t\xe1c vụ phức tạp."},"gemini-1.5-flash-latest":{"description":"Gemini 1.5 Flash l\xe0 m\xf4 h\xecnh AI đa phương thức mới nhất của Google, c\xf3 khả năng xử l\xfd nhanh, hỗ trợ đầu v\xe0o văn bản, h\xecnh ảnh v\xe0 video, ph\xf9 hợp cho việc mở rộng hiệu quả cho nhiều nhiệm vụ."},"gemini-1.5-pro-001":{"description":"Gemini 1.5 Pro 001 l\xe0 giải ph\xe1p AI đa phương thức c\xf3 thể mở rộng, hỗ trợ nhiều nhiệm vụ phức tạp."},"gemini-1.5-pro-002":{"description":"Gemini 1.5 Pro 002 l\xe0 m\xf4 h\xecnh sẵn s\xe0ng cho sản xuất mới nhất, cung cấp đầu ra chất lượng cao hơn, đặc biệt l\xe0 trong c\xe1c nhiệm vụ to\xe1n học, ngữ cảnh d\xe0i v\xe0 thị gi\xe1c."},"gemini-1.5-pro-exp-0801":{"description":"Gemini 1.5 Pro 0801 cung cấp khả năng xử l\xfd đa phương tiện xuất sắc, mang lại t\xednh linh hoạt cao hơn cho việc ph\xe1t triển ứng dụng."},"gemini-1.5-pro-exp-0827":{"description":"Gemini 1.5 Pro 0827 kết hợp c\xf4ng nghệ tối ưu h\xf3a mới nhất, mang lại khả năng xử l\xfd dữ liệu đa phương tiện hiệu quả hơn."},"gemini-1.5-pro-latest":{"description":"Gemini 1.5 Pro hỗ trợ l\xean đến 2 triệu tokens, l\xe0 lựa chọn l\xfd tưởng cho m\xf4 h\xecnh đa phương thức trung b\xecnh, ph\xf9 hợp cho hỗ trợ đa diện cho c\xe1c nhiệm vụ phức tạp."},"gemini-2.0-flash":{"description":"Gemini 2.0 Flash cung cấp c\xe1c t\xednh năng v\xe0 cải tiến thế hệ tiếp theo, bao gồm tốc độ vượt trội, sử dụng c\xf4ng cụ bản địa, tạo đa phương tiện v\xe0 cửa sổ ngữ cảnh 1M token."},"gemini-2.0-flash-001":{"description":"Gemini 2.0 Flash cung cấp c\xe1c t\xednh năng v\xe0 cải tiến thế hệ tiếp theo, bao gồm tốc độ vượt trội, sử dụng c\xf4ng cụ bản địa, tạo đa phương tiện v\xe0 cửa sổ ngữ cảnh 1M token."},"gemini-2.0-flash-exp":{"description":"Biến thể m\xf4 h\xecnh Gemini 2.0 Flash, được tối ưu h\xf3a cho hiệu quả chi ph\xed v\xe0 độ trễ thấp."},"gemini-2.0-flash-exp-image-generation":{"description":"M\xf4 h\xecnh thử nghiệm Gemini 2.0 Flash, hỗ trợ tạo h\xecnh ảnh"},"gemini-2.0-flash-lite":{"description":"Biến thể m\xf4 h\xecnh Gemini 2.0 Flash được tối ưu h\xf3a cho hiệu quả chi ph\xed v\xe0 độ trễ thấp."},"gemini-2.0-flash-lite-001":{"description":"Biến thể m\xf4 h\xecnh Gemini 2.0 Flash được tối ưu h\xf3a cho hiệu quả chi ph\xed v\xe0 độ trễ thấp."},"gemini-2.5-flash":{"description":"Gemini 2.5 Flash l\xe0 m\xf4 h\xecnh c\xf3 hiệu suất chi ph\xed tốt nhất của Google, cung cấp đầy đủ c\xe1c chức năng."},"gemini-2.5-flash-image":{"description":"Nano Banana l\xe0 m\xf4 h\xecnh đa phương thức nguy\xean bản mới nhất, nhanh nhất v\xe0 hiệu quả nhất của Google, cho ph\xe9p bạn tạo v\xe0 chỉnh sửa h\xecnh ảnh th\xf4ng qua đối thoại."},"gemini-2.5-flash-image-preview":{"description":"Nano Banana l\xe0 m\xf4 h\xecnh đa phương thức nguy\xean bản mới nhất, nhanh nhất v\xe0 hiệu quả nhất của Google, cho ph\xe9p bạn tạo v\xe0 chỉnh sửa h\xecnh ảnh th\xf4ng qua đối thoại."},"gemini-2.5-flash-image-preview:image":{"description":"Nano Banana l\xe0 m\xf4 h\xecnh đa phương thức nguy\xean bản mới nhất, nhanh nhất v\xe0 hiệu quả nhất của Google, cho ph\xe9p bạn tạo v\xe0 chỉnh sửa h\xecnh ảnh th\xf4ng qua đối thoại."},"gemini-2.5-flash-image:image":{"description":"Nano Banana l\xe0 m\xf4 h\xecnh đa phương thức nguy\xean bản mới nhất, nhanh nhất v\xe0 hiệu quả nhất của Google, cho ph\xe9p bạn tạo v\xe0 chỉnh sửa h\xecnh ảnh th\xf4ng qua đối thoại."},"gemini-2.5-flash-lite":{"description":"Gemini 2.5 Flash-Lite l\xe0 m\xf4 h\xecnh nhỏ nhất v\xe0 c\xf3 hiệu suất chi ph\xed tốt nhất của Google, được thiết kế d\xe0nh cho việc sử dụng quy m\xf4 lớn."},"gemini-2.5-flash-lite-preview-06-17":{"description":"Gemini 2.5 Flash-Lite Preview l\xe0 m\xf4 h\xecnh nhỏ nhất v\xe0 c\xf3 hiệu suất chi ph\xed tốt nhất của Google, được thiết kế d\xe0nh cho sử dụng quy m\xf4 lớn."},"gemini-2.5-flash-lite-preview-09-2025":{"description":"Phi\xean bản xem trước (25 th\xe1ng 9 năm 2025) của Gemini 2.5 Flash-Lite"},"gemini-2.5-flash-preview-04-17":{"description":"Gemini 2.5 Flash Preview l\xe0 m\xf4 h\xecnh c\xf3 gi\xe1 trị tốt nhất của Google, cung cấp đầy đủ c\xe1c t\xednh năng."},"gemini-2.5-flash-preview-09-2025":{"description":"Phi\xean bản xem trước (25 th\xe1ng 9 năm 2025) của Gemini 2.5 Flash"},"gemini-2.5-pro":{"description":"Gemini 2.5 Pro l\xe0 m\xf4 h\xecnh tư duy ti\xean tiến nhất của Google, c\xf3 khả năng suy luận c\xe1c vấn đề phức tạp trong lĩnh vực m\xe3 nguồn, to\xe1n học v\xe0 STEM, cũng như ph\xe2n t\xedch c\xe1c bộ dữ liệu lớn, kho m\xe3 v\xe0 t\xe0i liệu bằng ngữ cảnh d\xe0i."},"gemini-2.5-pro-preview-03-25":{"description":"Gemini 2.5 Pro Preview l\xe0 m\xf4 h\xecnh tư duy ti\xean tiến nhất của Google, c\xf3 khả năng suy luận về m\xe3, to\xe1n học v\xe0 c\xe1c vấn đề phức tạp trong lĩnh vực STEM, cũng như ph\xe2n t\xedch c\xe1c tập dữ liệu lớn, kho m\xe3 v\xe0 t\xe0i liệu bằng c\xe1ch sử dụng ngữ cảnh d\xe0i."},"gemini-2.5-pro-preview-05-06":{"description":"Gemini 2.5 Pro Preview l\xe0 m\xf4 h\xecnh tư duy ti\xean tiến nhất của Google, c\xf3 khả năng suy luận về m\xe3, to\xe1n học v\xe0 c\xe1c vấn đề phức tạp trong lĩnh vực STEM, cũng như ph\xe2n t\xedch c\xe1c tập dữ liệu lớn, kho m\xe3 v\xe0 t\xe0i liệu bằng c\xe1ch sử dụng ngữ cảnh d\xe0i."},"gemini-2.5-pro-preview-06-05":{"description":"Gemini 2.5 Pro Preview l\xe0 m\xf4 h\xecnh tư duy ti\xean tiến nhất của Google, c\xf3 khả năng suy luận c\xe1c vấn đề phức tạp trong lĩnh vực m\xe3 nguồn, to\xe1n học v\xe0 STEM, cũng như ph\xe2n t\xedch dữ liệu lớn, kho m\xe3 v\xe0 t\xe0i liệu với ngữ cảnh d\xe0i."},"gemini-3-pro-preview":{"description":"Gemini 3 Pro l\xe0 m\xf4 h\xecnh th\xf4ng minh nhất của Google, với khả năng suy luận ti\xean tiến h\xe0ng đầu v\xe0 hiểu đa phương thức, c\xf9ng với c\xe1c t\xednh năng đại l\xfd mạnh mẽ v\xe0 m\xe3 h\xf3a ngữ cảnh vượt trội."},"gemini-flash-latest":{"description":"Phi\xean bản mới nhất của Gemini Flash"},"gemini-flash-lite-latest":{"description":"Phi\xean bản mới nhất của Gemini Flash-Lite"},"gemini-pro-latest":{"description":"Phi\xean bản mới nhất của Gemini Pro"},"gemma-7b-it":{"description":"Gemma 7B ph\xf9 hợp cho việc xử l\xfd c\xe1c nhiệm vụ quy m\xf4 vừa v\xe0 nhỏ, đồng thời mang lại hiệu quả chi ph\xed."},"gemma2":{"description":"Gemma 2 l\xe0 m\xf4 h\xecnh hiệu quả do Google ph\xe1t h\xe0nh, bao gồm nhiều ứng dụng từ nhỏ đến xử l\xfd dữ liệu phức tạp."},"gemma2-9b-it":{"description":"Gemma 2 9B l\xe0 một m\xf4 h\xecnh được tối ưu h\xf3a cho c\xe1c nhiệm vụ cụ thể v\xe0 t\xedch hợp c\xf4ng cụ."},"gemma2:27b":{"description":"Gemma 2 l\xe0 m\xf4 h\xecnh hiệu quả do Google ph\xe1t h\xe0nh, bao gồm nhiều ứng dụng từ nhỏ đến xử l\xfd dữ liệu phức tạp."},"gemma2:2b":{"description":"Gemma 2 l\xe0 m\xf4 h\xecnh hiệu quả do Google ph\xe1t h\xe0nh, bao gồm nhiều ứng dụng từ nhỏ đến xử l\xfd dữ liệu phức tạp."},"generalv3":{"description":"Spark Pro l\xe0 một m\xf4 h\xecnh ng\xf4n ngữ lớn hiệu suất cao được tối ưu h\xf3a cho c\xe1c lĩnh vực chuy\xean m\xf4n, tập trung v\xe0o to\xe1n học, lập tr\xecnh, y tế, gi\xe1o dục v\xe0 nhiều lĩnh vực kh\xe1c, đồng thời hỗ trợ t\xecm kiếm trực tuyến v\xe0 c\xe1c plugin t\xedch hợp như thời tiết, ng\xe0y th\xe1ng. M\xf4 h\xecnh đ\xe3 được tối ưu h\xf3a thể hiện xuất sắc v\xe0 hiệu suất cao trong c\xe1c nhiệm vụ hỏi đ\xe1p kiến thức phức tạp, hiểu ng\xf4n ngữ v\xe0 s\xe1ng tạo văn bản cấp cao, l\xe0 lựa chọn l\xfd tưởng cho c\xe1c t\xecnh huống ứng dụng chuy\xean nghiệp."},"generalv3.5":{"description":"Spark3.5 Max l\xe0 phi\xean bản to\xe0n diện nhất, hỗ trợ t\xecm kiếm trực tuyến v\xe0 nhiều plugin t\xedch hợp. Khả năng cốt l\xf5i đ\xe3 được tối ưu h\xf3a to\xe0n diện c\xf9ng với thiết lập vai tr\xf2 hệ thống v\xe0 chức năng gọi h\xe0m, gi\xfap n\xf3 thể hiện xuất sắc v\xe0 nổi bật trong nhiều t\xecnh huống ứng dụng phức tạp."},"glm-4":{"description":"GLM-4 l\xe0 phi\xean bản flagship cũ ph\xe1t h\xe0nh v\xe0o th\xe1ng 1 năm 2024, hiện đ\xe3 được GLM-4-0520 mạnh mẽ hơn thay thế."},"glm-4-0520":{"description":"GLM-4-0520 l\xe0 phi\xean bản m\xf4 h\xecnh mới nhất, được thiết kế cho c\xe1c nhiệm vụ phức tạp v\xe0 đa dạng, thể hiện xuất sắc."},"glm-4-32b-0414":{"description":"GLM-4 32B 0414, phi\xean bản m\xf4 h\xecnh lớn đa năng d\xf2ng GLM, hỗ trợ sinh v\xe0 hiểu văn bản đa nhiệm vụ."},"glm-4-9b-chat":{"description":"GLM-4-9B-Chat thể hiện hiệu suất cao trong c\xe1c lĩnh vực như ngữ nghĩa, to\xe1n học, suy luận, lập tr\xecnh v\xe0 tri thức. Ngo\xe0i ra c\xf2n hỗ trợ duyệt web, thực thi m\xe3, gọi c\xf4ng cụ t\xf9y chỉnh v\xe0 suy luận văn bản d\xe0i. Hỗ trợ 26 ng\xf4n ngữ bao gồm tiếng Nhật, tiếng H\xe0n, tiếng Đức."},"glm-4-air":{"description":"GLM-4-Air l\xe0 phi\xean bản c\xf3 gi\xe1 trị sử dụng cao, hiệu suất gần giống GLM-4, cung cấp tốc độ nhanh v\xe0 gi\xe1 cả phải chăng."},"glm-4-air-250414":{"description":"GLM-4-Air l\xe0 phi\xean bản c\xf3 gi\xe1 trị cao, hiệu suất gần tương đương với GLM-4, cung cấp tốc độ nhanh v\xe0 gi\xe1 cả phải chăng."},"glm-4-airx":{"description":"GLM-4-AirX cung cấp phi\xean bản hiệu quả của GLM-4-Air, tốc độ suy luận c\xf3 thể đạt 2.6 lần."},"glm-4-alltools":{"description":"GLM-4-AllTools l\xe0 một m\xf4 h\xecnh t\xe1c nh\xe2n đa chức năng, được tối ưu h\xf3a để hỗ trợ lập kế hoạch chỉ dẫn phức tạp v\xe0 gọi c\xf4ng cụ, như duyệt web, giải th\xedch m\xe3 v\xe0 sinh văn bản, ph\xf9 hợp cho thực hiện nhiều nhiệm vụ."},"glm-4-flash":{"description":"GLM-4-Flash l\xe0 lựa chọn l\xfd tưởng cho c\xe1c nhiệm vụ đơn giản, tốc độ nhanh nhất v\xe0 gi\xe1 cả phải chăng nhất."},"glm-4-flash-250414":{"description":"GLM-4-Flash l\xe0 lựa chọn l\xfd tưởng cho c\xe1c nhiệm vụ đơn giản, nhanh nhất v\xe0 miễn ph\xed."},"glm-4-flashx":{"description":"GLM-4-FlashX l\xe0 phi\xean bản n\xe2ng cấp của Flash, với tốc độ suy diễn si\xeau nhanh."},"glm-4-long":{"description":"GLM-4-Long hỗ trợ đầu v\xe0o văn bản si\xeau d\xe0i, ph\xf9 hợp cho c\xe1c nhiệm vụ ghi nhớ v\xe0 xử l\xfd t\xe0i liệu quy m\xf4 lớn."},"glm-4-plus":{"description":"GLM-4-Plus l\xe0 m\xf4 h\xecnh flagship th\xf4ng minh cao, c\xf3 khả năng xử l\xfd văn bản d\xe0i v\xe0 nhiệm vụ phức tạp, hiệu suất được n\xe2ng cao to\xe0n diện."},"glm-4.1v-thinking-flash":{"description":"D\xf2ng m\xf4 h\xecnh GLM-4.1V-Thinking l\xe0 m\xf4 h\xecnh VLM cấp 10 tỷ tham số mạnh nhất hiện biết, t\xedch hợp c\xe1c nhiệm vụ ng\xf4n ngữ thị gi\xe1c SOTA c\xf9ng cấp, bao gồm hiểu video, hỏi đ\xe1p h\xecnh ảnh, giải b\xe0i tập chuy\xean ng\xe0nh, nhận dạng k\xfd tự quang học (OCR), ph\xe2n t\xedch t\xe0i liệu v\xe0 biểu đồ, t\xe1c nh\xe2n GUI, lập tr\xecnh giao diện web frontend, định vị (Grounding) v\xe0 nhiều nhiệm vụ kh\xe1c, với khả năng vượt trội so với Qwen2.5-VL-72B c\xf3 tham số gấp 8 lần. Th\xf4ng qua c\xf4ng nghệ học tăng cường ti\xean tiến, m\xf4 h\xecnh nắm vững phương ph\xe1p suy luận chuỗi tư duy để n\xe2ng cao độ ch\xednh x\xe1c v\xe0 sự phong ph\xfa của c\xe2u trả lời, vượt trội r\xf5 rệt so với c\xe1c m\xf4 h\xecnh truyền thống kh\xf4ng c\xf3 t\xednh năng thinking về hiệu quả cuối c\xf9ng v\xe0 khả năng giải th\xedch."},"glm-4.1v-thinking-flashx":{"description":"D\xf2ng m\xf4 h\xecnh GLM-4.1V-Thinking l\xe0 m\xf4 h\xecnh VLM cấp 10 tỷ tham số mạnh nhất hiện biết, t\xedch hợp c\xe1c nhiệm vụ ng\xf4n ngữ thị gi\xe1c SOTA c\xf9ng cấp, bao gồm hiểu video, hỏi đ\xe1p h\xecnh ảnh, giải b\xe0i tập chuy\xean ng\xe0nh, nhận dạng k\xfd tự quang học (OCR), ph\xe2n t\xedch t\xe0i liệu v\xe0 biểu đồ, t\xe1c nh\xe2n GUI, lập tr\xecnh giao diện web frontend, định vị (Grounding) v\xe0 nhiều nhiệm vụ kh\xe1c, với khả năng vượt trội so với Qwen2.5-VL-72B c\xf3 tham số gấp 8 lần. Th\xf4ng qua c\xf4ng nghệ học tăng cường ti\xean tiến, m\xf4 h\xecnh nắm vững phương ph\xe1p suy luận chuỗi tư duy để n\xe2ng cao độ ch\xednh x\xe1c v\xe0 sự phong ph\xfa của c\xe2u trả lời, vượt trội r\xf5 rệt so với c\xe1c m\xf4 h\xecnh truyền thống kh\xf4ng c\xf3 t\xednh năng thinking về hiệu quả cuối c\xf9ng v\xe0 khả năng giải th\xedch."},"glm-4.5":{"description":"M\xf4 h\xecnh chủ lực của Zhipu, hỗ trợ chuyển đổi chế độ suy nghĩ, năng lực tổng hợp đạt mức SOTA của c\xe1c m\xf4 h\xecnh m\xe3 nguồn mở, độ d\xe0i ngữ cảnh l\xean đến 128K."},"glm-4.5-air":{"description":"Phi\xean bản nhẹ của GLM-4.5, c\xe2n bằng giữa hiệu suất v\xe0 chi ph\xed, c\xf3 thể linh hoạt chuyển đổi m\xf4 h\xecnh suy nghĩ hỗn hợp."},"glm-4.5-airx":{"description":"Phi\xean bản tốc độ cao của GLM-4.5-Air, phản hồi nhanh hơn, thiết kế cho nhu cầu quy m\xf4 lớn v\xe0 tốc độ cao."},"glm-4.5-flash":{"description":"Phi\xean bản miễn ph\xed của GLM-4.5, thể hiện tốt trong c\xe1c t\xe1c vụ suy luận, lập tr\xecnh v\xe0 t\xe1c nh\xe2n."},"glm-4.5-x":{"description":"Phi\xean bản tốc độ cao của GLM-4.5, vừa mạnh mẽ về hiệu suất, vừa đạt tốc độ tạo 100 token/gi\xe2y."},"glm-4.5v":{"description":"M\xf4 h\xecnh suy luận thị gi\xe1c thế hệ mới của Zhipu dựa tr\xean kiến tr\xfac MOE, với tổng số tham số 106B v\xe0 12B tham số k\xedch hoạt, đạt SOTA trong số c\xe1c m\xf4 h\xecnh đa phương thức m\xe3 nguồn mở c\xf9ng cấp tr\xean to\xe0n cầu tr\xean nhiều bộ đ\xe1nh gi\xe1, bao gồm c\xe1c nhiệm vụ phổ biến như hiểu ảnh, video, t\xe0i liệu v\xe0 giao diện người d\xf9ng (GUI)."},"glm-4.6":{"description":"M\xf4 h\xecnh chủ lực mới nhất của Zhipu GLM-4.6 (355B) vượt trội to\xe0n diện so với thế hệ trước về m\xe3 h\xf3a n\xe2ng cao, xử l\xfd văn bản d\xe0i, suy luận v\xe0 khả năng t\xe1c nh\xe2n, đặc biệt về năng lực lập tr\xecnh đ\xe3 đạt chuẩn Claude Sonnet 4, trở th\xe0nh m\xf4 h\xecnh Coding h\xe0ng đầu trong nước."},"glm-4v":{"description":"GLM-4V cung cấp khả năng hiểu v\xe0 suy luận h\xecnh ảnh mạnh mẽ, hỗ trợ nhiều nhiệm vụ h\xecnh ảnh."},"glm-4v-flash":{"description":"GLM-4V-Flash tập trung v\xe0o hiểu h\xecnh ảnh đơn lẻ một c\xe1ch hiệu quả, ph\xf9 hợp cho c\xe1c t\xecnh huống ph\xe2n t\xedch h\xecnh ảnh nhanh ch\xf3ng, chẳng hạn như ph\xe2n t\xedch h\xecnh ảnh theo thời gian thực hoặc xử l\xfd h\xecnh ảnh h\xe0ng loạt."},"glm-4v-plus":{"description":"GLM-4V-Plus c\xf3 khả năng hiểu nội dung video v\xe0 nhiều h\xecnh ảnh, ph\xf9 hợp cho c\xe1c nhiệm vụ đa phương tiện."},"glm-4v-plus-0111":{"description":"GLM-4V-Plus c\xf3 khả năng hiểu nội dung video v\xe0 nhiều h\xecnh ảnh, ph\xf9 hợp cho c\xe1c nhiệm vụ đa phương tiện."},"glm-z1-air":{"description":"M\xf4 h\xecnh suy luận: c\xf3 khả năng suy luận mạnh mẽ, ph\xf9 hợp cho c\xe1c nhiệm vụ cần suy luận s\xe2u."},"glm-z1-airx":{"description":"Suy luận si\xeau tốc: c\xf3 tốc độ suy luận cực nhanh v\xe0 hiệu quả suy luận mạnh mẽ."},"glm-z1-flash":{"description":"D\xf2ng GLM-Z1 c\xf3 khả năng suy luận phức tạp mạnh mẽ, thể hiện xuất sắc trong c\xe1c lĩnh vực suy luận logic, to\xe1n học v\xe0 lập tr\xecnh."},"glm-z1-flashx":{"description":"Tốc độ cao, gi\xe1 thấp: Phi\xean bản tăng cường Flash, tốc độ suy luận si\xeau nhanh, đảm bảo đồng thời nhanh hơn."},"glm-zero-preview":{"description":"GLM-Zero-Preview c\xf3 khả năng suy luận phức tạp mạnh mẽ, thể hiện xuất sắc trong c\xe1c lĩnh vực suy luận logic, to\xe1n học, lập tr\xecnh."},"google/gemini-2.0-flash":{"description":"Gemini 2.0 Flash cung cấp c\xe1c t\xednh năng thế hệ tiếp theo v\xe0 cải tiến, bao gồm tốc độ vượt trội, sử dụng c\xf4ng cụ t\xedch hợp, tạo đa phương thức v\xe0 cửa sổ ngữ cảnh 1 triệu token."},"google/gemini-2.0-flash-001":{"description":"Gemini 2.0 Flash cung cấp c\xe1c t\xednh năng v\xe0 cải tiến thế hệ tiếp theo, bao gồm tốc độ vượt trội, sử dụng c\xf4ng cụ bản địa, tạo đa phương tiện v\xe0 cửa sổ ngữ cảnh 1M token."},"google/gemini-2.0-flash-exp:free":{"description":"Gemini 2.0 Flash Experimental l\xe0 m\xf4 h\xecnh AI đa phương tiện thử nghiệm mới nhất của Google, c\xf3 sự cải thiện về chất lượng so với c\xe1c phi\xean bản trước, đặc biệt l\xe0 đối với kiến thức thế giới, m\xe3 v\xe0 ngữ cảnh d\xe0i."},"google/gemini-2.0-flash-lite":{"description":"Gemini 2.0 Flash Lite cung cấp c\xe1c t\xednh năng thế hệ tiếp theo v\xe0 cải tiến, bao gồm tốc độ vượt trội, sử dụng c\xf4ng cụ t\xedch hợp, tạo đa phương thức v\xe0 cửa sổ ngữ cảnh 1 triệu token."},"google/gemini-2.5-flash":{"description":"Gemini 2.5 Flash l\xe0 m\xf4 h\xecnh tư duy cung cấp khả năng to\xe0n diện xuất sắc. N\xf3 được thiết kế để c\xe2n bằng giữa gi\xe1 cả v\xe0 hiệu suất, hỗ trợ đa phương thức v\xe0 cửa sổ ngữ cảnh 1 triệu token."},"google/gemini-2.5-flash-image-preview":{"description":"M\xf4 h\xecnh thử nghiệm Gemini 2.5 Flash, hỗ trợ tạo h\xecnh ảnh."},"google/gemini-2.5-flash-lite":{"description":"Gemini 2.5 Flash-Lite l\xe0 m\xf4 h\xecnh c\xe2n bằng, độ trễ thấp với ng\xe2n s\xe1ch tư duy v\xe0 kết nối c\xf4ng cụ c\xf3 thể cấu h\xecnh (v\xed dụ: Google Search c\xf3 căn cứ v\xe0 thực thi m\xe3). N\xf3 hỗ trợ đầu v\xe0o đa phương thức v\xe0 cung cấp cửa sổ ngữ cảnh 1 triệu token."},"google/gemini-2.5-flash-preview":{"description":"Gemini 2.5 Flash l\xe0 m\xf4 h\xecnh chủ lực ti\xean tiến nhất của Google, được thiết kế cho suy luận n\xe2ng cao, lập tr\xecnh, to\xe1n học v\xe0 c\xe1c nhiệm vụ khoa học. N\xf3 bao gồm khả năng \'suy nghĩ\' t\xedch hợp, cho ph\xe9p n\xf3 cung cấp phản hồi với độ ch\xednh x\xe1c cao hơn v\xe0 xử l\xfd ngữ cảnh chi tiết hơn.\\n\\nLưu \xfd: M\xf4 h\xecnh n\xe0y c\xf3 hai biến thể: suy nghĩ v\xe0 kh\xf4ng suy nghĩ. Gi\xe1 đầu ra c\xf3 sự kh\xe1c biệt đ\xe1ng kể t\xf9y thuộc v\xe0o việc khả năng suy nghĩ c\xf3 được k\xedch hoạt hay kh\xf4ng. Nếu bạn chọn biến thể ti\xeau chuẩn (kh\xf4ng c\xf3 hậu tố \':thinking\'), m\xf4 h\xecnh sẽ r\xf5 r\xe0ng tr\xe1nh việc tạo ra c\xe1c token suy nghĩ.\\n\\nĐể tận dụng khả năng suy nghĩ v\xe0 nhận c\xe1c token suy nghĩ, bạn phải chọn biến thể \':thinking\', điều n\xe0y sẽ tạo ra gi\xe1 đầu ra suy nghĩ cao hơn.\\n\\nNgo\xe0i ra, Gemini 2.5 Flash c\xf3 thể được cấu h\xecnh th\xf4ng qua tham số \'số token tối đa cho suy luận\', như đ\xe3 m\xf4 tả trong t\xe0i liệu (https://openrouter.ai/docs/use-cases/reasoning-tokens#max-tokens-for-reasoning)."},"google/gemini-2.5-flash-preview:thinking":{"description":"Gemini 2.5 Flash l\xe0 m\xf4 h\xecnh chủ lực ti\xean tiến nhất của Google, được thiết kế cho suy luận n\xe2ng cao, lập tr\xecnh, to\xe1n học v\xe0 c\xe1c nhiệm vụ khoa học. N\xf3 bao gồm khả năng \'suy nghĩ\' t\xedch hợp, cho ph\xe9p n\xf3 cung cấp phản hồi với độ ch\xednh x\xe1c cao hơn v\xe0 xử l\xfd ngữ cảnh chi tiết hơn.\\n\\nLưu \xfd: M\xf4 h\xecnh n\xe0y c\xf3 hai biến thể: suy nghĩ v\xe0 kh\xf4ng suy nghĩ. Gi\xe1 đầu ra c\xf3 sự kh\xe1c biệt đ\xe1ng kể t\xf9y thuộc v\xe0o việc khả năng suy nghĩ c\xf3 được k\xedch hoạt hay kh\xf4ng. Nếu bạn chọn biến thể ti\xeau chuẩn (kh\xf4ng c\xf3 hậu tố \':thinking\'), m\xf4 h\xecnh sẽ r\xf5 r\xe0ng tr\xe1nh việc tạo ra c\xe1c token suy nghĩ.\\n\\nĐể tận dụng khả năng suy nghĩ v\xe0 nhận c\xe1c token suy nghĩ, bạn phải chọn biến thể \':thinking\', điều n\xe0y sẽ tạo ra gi\xe1 đầu ra suy nghĩ cao hơn.\\n\\nNgo\xe0i ra, Gemini 2.5 Flash c\xf3 thể được cấu h\xecnh th\xf4ng qua tham số \'số token tối đa cho suy luận\', như đ\xe3 m\xf4 tả trong t\xe0i liệu (https://openrouter.ai/docs/use-cases/reasoning-tokens#max-tokens-for-reasoning)."},"google/gemini-2.5-pro":{"description":"Gemini 2.5 Pro l\xe0 m\xf4 h\xecnh Gemini suy luận ti\xean tiến nhất của ch\xfang t\xf4i, c\xf3 khả năng giải quyết c\xe1c vấn đề phức tạp. N\xf3 c\xf3 cửa sổ ngữ cảnh 2 triệu token, hỗ trợ đầu v\xe0o đa phương thức bao gồm văn bản, h\xecnh ảnh, \xe2m thanh, video v\xe0 t\xe0i liệu PDF."},"google/gemini-2.5-pro-preview":{"description":"Gemini 2.5 Pro Preview l\xe0 m\xf4 h\xecnh tư duy ti\xean tiến nhất của Google, c\xf3 khả năng suy luận c\xe1c vấn đề phức tạp trong lĩnh vực m\xe3 h\xf3a, to\xe1n học v\xe0 STEM, cũng như ph\xe2n t\xedch c\xe1c bộ dữ liệu lớn, kho m\xe3 v\xe0 t\xe0i liệu bằng ngữ cảnh d\xe0i."},"google/gemini-embedding-001":{"description":"M\xf4 h\xecnh nh\xfang ti\xean tiến, thể hiện hiệu suất xuất sắc trong c\xe1c nhiệm vụ tiếng Anh, đa ng\xf4n ngữ v\xe0 m\xe3 h\xf3a."},"google/gemini-flash-1.5":{"description":"Gemini 1.5 Flash cung cấp khả năng xử l\xfd đa phương thức được tối ưu h\xf3a, ph\xf9 hợp cho nhiều t\xecnh huống nhiệm vụ phức tạp."},"google/gemini-pro-1.5":{"description":"Gemini 1.5 Pro kết hợp c\xf4ng nghệ tối ưu h\xf3a mới nhất, mang lại khả năng xử l\xfd dữ liệu đa phương thức hiệu quả hơn."},"google/gemma-2-27b":{"description":"Gemma 2 l\xe0 m\xf4 h\xecnh hiệu quả do Google ph\xe1t h\xe0nh, bao gồm nhiều ứng dụng từ ứng dụng nhỏ đến xử l\xfd dữ liệu phức tạp."},"google/gemma-2-27b-it":{"description":"Gemma 2 tiếp tục triết l\xfd thiết kế nhẹ v\xe0 hiệu quả."},"google/gemma-2-2b-it":{"description":"M\xf4 h\xecnh tinh chỉnh hướng dẫn nhẹ của Google"},"google/gemma-2-9b":{"description":"Gemma 2 l\xe0 m\xf4 h\xecnh hiệu quả do Google ph\xe1t h\xe0nh, bao gồm nhiều ứng dụng từ ứng dụng nhỏ đến xử l\xfd dữ liệu phức tạp."},"google/gemma-2-9b-it":{"description":"Gemma 2 l\xe0 một loạt m\xf4 h\xecnh văn bản m\xe3 nguồn mở nhẹ của Google."},"google/gemma-2-9b-it:free":{"description":"Gemma 2 l\xe0 loạt m\xf4 h\xecnh văn bản m\xe3 nguồn mở nhẹ của Google."},"google/gemma-2b-it":{"description":"Gemma Instruct (2B) cung cấp khả năng xử l\xfd chỉ dẫn cơ bản, ph\xf9 hợp cho c\xe1c ứng dụng nhẹ."},"google/gemma-3-12b-it":{"description":"Gemma 3 12B l\xe0 một m\xf4 h\xecnh ng\xf4n ngữ m\xe3 nguồn mở của Google, thiết lập ti\xeau chuẩn mới về hiệu quả v\xe0 hiệu suất."},"google/gemma-3-27b-it":{"description":"Gemma 3 27B l\xe0 một m\xf4 h\xecnh ng\xf4n ngữ m\xe3 nguồn mở của Google, thiết lập ti\xeau chuẩn mới về hiệu suất v\xe0 hiệu quả."},"google/text-embedding-005":{"description":"M\xf4 h\xecnh nh\xfang văn bản tập trung v\xe0o tiếng Anh, được tối ưu cho c\xe1c nhiệm vụ m\xe3 h\xf3a v\xe0 ng\xf4n ngữ tiếng Anh."},"google/text-multilingual-embedding-002":{"description":"M\xf4 h\xecnh nh\xfang văn bản đa ng\xf4n ngữ được tối ưu cho c\xe1c nhiệm vụ đa ng\xf4n ngữ, hỗ trợ nhiều ng\xf4n ngữ."},"gpt-3.5-turbo":{"description":"GPT 3.5 Turbo, ph\xf9 hợp cho nhiều nhiệm vụ sinh v\xe0 hiểu văn bản, hiện tại trỏ đến gpt-3.5-turbo-0125."},"gpt-3.5-turbo-0125":{"description":"GPT 3.5 Turbo, ph\xf9 hợp cho nhiều nhiệm vụ sinh v\xe0 hiểu văn bản, hiện tại trỏ đến gpt-3.5-turbo-0125."},"gpt-3.5-turbo-1106":{"description":"GPT 3.5 Turbo, ph\xf9 hợp cho nhiều nhiệm vụ sinh v\xe0 hiểu văn bản, hiện tại trỏ đến gpt-3.5-turbo-0125."},"gpt-3.5-turbo-instruct":{"description":"GPT 3.5 Turbo, ph\xf9 hợp cho nhiều nhiệm vụ sinh v\xe0 hiểu văn bản, hiện tại trỏ đến gpt-3.5-turbo-0125."},"gpt-35-turbo":{"description":"GPT 3.5 Turbo, m\xf4 h\xecnh hiệu quả do OpenAI cung cấp, ph\xf9 hợp cho c\xe1c t\xe1c vụ tr\xf2 chuyện v\xe0 tạo văn bản, hỗ trợ gọi h\xe0m song song."},"gpt-35-turbo-16k":{"description":"GPT 3.5 Turbo 16k, m\xf4 h\xecnh tạo văn bản dung lượng cao, ph\xf9 hợp cho c\xe1c nhiệm vụ phức tạp."},"gpt-4":{"description":"GPT-4 cung cấp một cửa sổ ngữ cảnh lớn hơn, c\xf3 khả năng xử l\xfd c\xe1c đầu v\xe0o văn bản d\xe0i hơn, ph\xf9 hợp cho c\xe1c t\xecnh huống cần t\xedch hợp th\xf4ng tin rộng r\xe3i v\xe0 ph\xe2n t\xedch dữ liệu."},"gpt-4-0125-preview":{"description":"M\xf4 h\xecnh GPT-4 Turbo mới nhất c\xf3 chức năng h\xecnh ảnh. Hiện tại, c\xe1c y\xeau cầu h\xecnh ảnh c\xf3 thể sử dụng chế độ JSON v\xe0 gọi h\xe0m. GPT-4 Turbo l\xe0 một phi\xean bản n\xe2ng cao, cung cấp hỗ trợ chi ph\xed hiệu quả cho c\xe1c nhiệm vụ đa phương tiện. N\xf3 t\xecm thấy sự c\xe2n bằng giữa độ ch\xednh x\xe1c v\xe0 hiệu quả, ph\xf9 hợp cho c\xe1c ứng dụng cần tương t\xe1c theo thời gian thực."},"gpt-4-0613":{"description":"GPT-4 cung cấp một cửa sổ ngữ cảnh lớn hơn, c\xf3 khả năng xử l\xfd c\xe1c đầu v\xe0o văn bản d\xe0i hơn, ph\xf9 hợp cho c\xe1c t\xecnh huống cần t\xedch hợp th\xf4ng tin rộng r\xe3i v\xe0 ph\xe2n t\xedch dữ liệu."},"gpt-4-1106-preview":{"description":"M\xf4 h\xecnh GPT-4 Turbo mới nhất c\xf3 chức năng h\xecnh ảnh. Hiện tại, c\xe1c y\xeau cầu h\xecnh ảnh c\xf3 thể sử dụng chế độ JSON v\xe0 gọi h\xe0m. GPT-4 Turbo l\xe0 một phi\xean bản n\xe2ng cao, cung cấp hỗ trợ chi ph\xed hiệu quả cho c\xe1c nhiệm vụ đa phương tiện. N\xf3 t\xecm thấy sự c\xe2n bằng giữa độ ch\xednh x\xe1c v\xe0 hiệu quả, ph\xf9 hợp cho c\xe1c ứng dụng cần tương t\xe1c theo thời gian thực."},"gpt-4-32k":{"description":"GPT-4 cung cấp một cửa sổ ngữ cảnh lớn hơn, c\xf3 khả năng xử l\xfd c\xe1c đầu v\xe0o văn bản d\xe0i hơn, ph\xf9 hợp cho c\xe1c t\xecnh huống cần t\xedch hợp th\xf4ng tin rộng r\xe3i v\xe0 ph\xe2n t\xedch dữ liệu."},"gpt-4-32k-0613":{"description":"GPT-4 cung cấp một cửa sổ ngữ cảnh lớn hơn, c\xf3 khả năng xử l\xfd c\xe1c đầu v\xe0o văn bản d\xe0i hơn, ph\xf9 hợp cho c\xe1c t\xecnh huống cần t\xedch hợp th\xf4ng tin rộng r\xe3i v\xe0 ph\xe2n t\xedch dữ liệu."},"gpt-4-turbo":{"description":"M\xf4 h\xecnh GPT-4 Turbo mới nhất c\xf3 chức năng h\xecnh ảnh. Hiện tại, c\xe1c y\xeau cầu h\xecnh ảnh c\xf3 thể sử dụng chế độ JSON v\xe0 gọi h\xe0m. GPT-4 Turbo l\xe0 một phi\xean bản n\xe2ng cao, cung cấp hỗ trợ chi ph\xed hiệu quả cho c\xe1c nhiệm vụ đa phương tiện. N\xf3 t\xecm thấy sự c\xe2n bằng giữa độ ch\xednh x\xe1c v\xe0 hiệu quả, ph\xf9 hợp cho c\xe1c ứng dụng cần tương t\xe1c theo thời gian thực."},"gpt-4-turbo-2024-04-09":{"description":"M\xf4 h\xecnh GPT-4 Turbo mới nhất c\xf3 chức năng h\xecnh ảnh. Hiện tại, c\xe1c y\xeau cầu h\xecnh ảnh c\xf3 thể sử dụng chế độ JSON v\xe0 gọi h\xe0m. GPT-4 Turbo l\xe0 một phi\xean bản n\xe2ng cao, cung cấp hỗ trợ chi ph\xed hiệu quả cho c\xe1c nhiệm vụ đa phương tiện. N\xf3 t\xecm thấy sự c\xe2n bằng giữa độ ch\xednh x\xe1c v\xe0 hiệu quả, ph\xf9 hợp cho c\xe1c ứng dụng cần tương t\xe1c theo thời gian thực."},"gpt-4-turbo-preview":{"description":"M\xf4 h\xecnh GPT-4 Turbo mới nhất c\xf3 chức năng h\xecnh ảnh. Hiện tại, c\xe1c y\xeau cầu h\xecnh ảnh c\xf3 thể sử dụng chế độ JSON v\xe0 gọi h\xe0m. GPT-4 Turbo l\xe0 một phi\xean bản n\xe2ng cao, cung cấp hỗ trợ chi ph\xed hiệu quả cho c\xe1c nhiệm vụ đa phương tiện. N\xf3 t\xecm thấy sự c\xe2n bằng giữa độ ch\xednh x\xe1c v\xe0 hiệu quả, ph\xf9 hợp cho c\xe1c ứng dụng cần tương t\xe1c theo thời gian thực."},"gpt-4-vision-preview":{"description":"M\xf4 h\xecnh GPT-4 Turbo mới nhất c\xf3 chức năng h\xecnh ảnh. Hiện tại, c\xe1c y\xeau cầu h\xecnh ảnh c\xf3 thể sử dụng chế độ JSON v\xe0 gọi h\xe0m. GPT-4 Turbo l\xe0 một phi\xean bản n\xe2ng cao, cung cấp hỗ trợ chi ph\xed hiệu quả cho c\xe1c nhiệm vụ đa phương tiện. N\xf3 t\xecm thấy sự c\xe2n bằng giữa độ ch\xednh x\xe1c v\xe0 hiệu quả, ph\xf9 hợp cho c\xe1c ứng dụng cần tương t\xe1c theo thời gian thực."},"gpt-4.1":{"description":"GPT-4.1 l\xe0 m\xf4 h\xecnh h\xe0ng đầu của ch\xfang t\xf4i cho c\xe1c nhiệm vụ phức tạp. N\xf3 rất ph\xf9 hợp để giải quyết vấn đề đa lĩnh vực."},"gpt-4.1-mini":{"description":"GPT-4.1 mini cung cấp sự c\xe2n bằng giữa tr\xed tuệ, tốc độ v\xe0 chi ph\xed, khiến n\xf3 trở th\xe0nh m\xf4 h\xecnh hấp dẫn cho nhiều trường hợp sử dụng."},"gpt-4.1-nano":{"description":"GPT-4.1 mini cung cấp sự c\xe2n bằng giữa tr\xed tuệ, tốc độ v\xe0 chi ph\xed, khiến n\xf3 trở th\xe0nh m\xf4 h\xecnh hấp dẫn cho nhiều trường hợp sử dụng."},"gpt-4.5-preview":{"description":"GPT-4.5-preview l\xe0 m\xf4 h\xecnh tổng qu\xe1t mới nhất, sở hữu kiến thức to\xe0n cầu s\xe2u rộng v\xe0 khả năng hiểu \xfd định người d\xf9ng tốt hơn, mạnh trong c\xe1c nhiệm vụ s\xe1ng tạo v\xe0 trong việc lập kế hoạch cho c\xe1c t\xe1c nh\xe2n. Kiến thức của m\xf4 h\xecnh được cập nhật đến th\xe1ng 10 năm 2023."},"gpt-4o":{"description":"ChatGPT-4o l\xe0 một m\xf4 h\xecnh động, được cập nhật theo thời gian thực để giữ phi\xean bản mới nhất. N\xf3 kết hợp khả năng hiểu v\xe0 sinh ng\xf4n ngữ mạnh mẽ, ph\xf9 hợp cho c\xe1c ứng dụng quy m\xf4 lớn, bao gồm dịch vụ kh\xe1ch h\xe0ng, gi\xe1o dục v\xe0 hỗ trợ kỹ thuật."},"gpt-4o-2024-05-13":{"description":"ChatGPT-4o l\xe0 một m\xf4 h\xecnh động, được cập nhật theo thời gian thực để giữ phi\xean bản mới nhất. N\xf3 kết hợp khả năng hiểu v\xe0 sinh ng\xf4n ngữ mạnh mẽ, ph\xf9 hợp cho c\xe1c ứng dụng quy m\xf4 lớn, bao gồm dịch vụ kh\xe1ch h\xe0ng, gi\xe1o dục v\xe0 hỗ trợ kỹ thuật."},"gpt-4o-2024-08-06":{"description":"ChatGPT-4o l\xe0 một m\xf4 h\xecnh động, được cập nhật theo thời gian thực để giữ phi\xean bản mới nhất. N\xf3 kết hợp khả năng hiểu v\xe0 sinh ng\xf4n ngữ mạnh mẽ, ph\xf9 hợp cho c\xe1c ứng dụng quy m\xf4 lớn, bao gồm dịch vụ kh\xe1ch h\xe0ng, gi\xe1o dục v\xe0 hỗ trợ kỹ thuật."},"gpt-4o-2024-11-20":{"description":"ChatGPT-4o l\xe0 một m\xf4 h\xecnh động, được cập nhật li\xean tục để giữ phi\xean bản mới nhất. N\xf3 kết hợp khả năng hiểu v\xe0 tạo ng\xf4n ngữ mạnh mẽ, ph\xf9 hợp cho nhiều ứng dụng quy m\xf4 lớn, bao gồm dịch vụ kh\xe1ch h\xe0ng, gi\xe1o dục v\xe0 hỗ trợ kỹ thuật."},"gpt-4o-audio-preview":{"description":"M\xf4 h\xecnh GPT-4o Audio Preview, hỗ trợ đầu v\xe0o v\xe0 đầu ra \xe2m thanh."},"gpt-4o-mini":{"description":"GPT-4o mini l\xe0 m\xf4 h\xecnh mới nhất do OpenAI ph\xe1t h\xe0nh sau GPT-4 Omni, hỗ trợ đầu v\xe0o h\xecnh ảnh v\xe0 đầu ra văn bản. L\xe0 m\xf4 h\xecnh nhỏ gọn ti\xean tiến nhất của họ, n\xf3 rẻ hơn nhiều so với c\xe1c m\xf4 h\xecnh ti\xean tiến gần đ\xe2y kh\xe1c v\xe0 rẻ hơn hơn 60% so với GPT-3.5 Turbo. N\xf3 giữ lại tr\xed th\xf4ng minh ti\xean tiến nhất trong khi c\xf3 gi\xe1 trị sử dụng đ\xe1ng kể. GPT-4o mini đạt 82% điểm trong b\xe0i kiểm tra MMLU v\xe0 hiện đứng cao hơn GPT-4 về sở th\xedch tr\xf2 chuyện."},"gpt-4o-mini-audio-preview":{"description":"M\xf4 h\xecnh GPT-4o mini Audio, hỗ trợ đầu v\xe0o v\xe0 đầu ra \xe2m thanh."},"gpt-4o-mini-realtime-preview":{"description":"Phi\xean bản thời gian thực của GPT-4o-mini, hỗ trợ đầu v\xe0o v\xe0 đầu ra \xe2m thanh v\xe0 văn bản theo thời gian thực."},"gpt-4o-mini-search-preview":{"description":"GPT-4o mini phi\xean bản xem trước t\xecm kiếm l\xe0 m\xf4 h\xecnh được huấn luyện chuy\xean biệt để hiểu v\xe0 thực thi c\xe1c truy vấn t\xecm kiếm tr\xean web, sử dụng API Chat Completions. Ngo\xe0i ph\xed token, truy vấn t\xecm kiếm tr\xean web c\xf2n t\xednh ph\xed theo mỗi lần gọi c\xf4ng cụ."},"gpt-4o-mini-transcribe":{"description":"GPT-4o Mini Transcribe l\xe0 m\xf4 h\xecnh chuyển đổi giọng n\xf3i th\xe0nh văn bản sử dụng GPT-4o để phi\xean \xe2m \xe2m thanh. So với m\xf4 h\xecnh Whisper gốc, n\xf3 cải thiện tỷ lệ lỗi từ v\xe0 n\xe2ng cao khả năng nhận diện ng\xf4n ngữ cũng như độ ch\xednh x\xe1c. Sử dụng n\xf3 để c\xf3 bản phi\xean \xe2m ch\xednh x\xe1c hơn."},"gpt-4o-mini-tts":{"description":"GPT-4o mini TTS l\xe0 m\xf4 h\xecnh chuyển văn bản th\xe0nh giọng n\xf3i dựa tr\xean GPT-4o mini, cung cấp sinh \xe2m thanh cao cấp với chi ph\xed thấp hơn."},"gpt-4o-realtime-preview":{"description":"Phi\xean bản thời gian thực của GPT-4o, hỗ trợ đầu v\xe0o v\xe0 đầu ra \xe2m thanh v\xe0 văn bản theo thời gian thực."},"gpt-4o-realtime-preview-2024-10-01":{"description":"Phi\xean bản thời gian thực của GPT-4o, hỗ trợ đầu v\xe0o v\xe0 đầu ra \xe2m thanh v\xe0 văn bản theo thời gian thực."},"gpt-4o-realtime-preview-2025-06-03":{"description":"Phi\xean bản thời gian thực của GPT-4o, hỗ trợ nhập xuất \xe2m thanh v\xe0 văn bản theo thời gian thực."},"gpt-4o-search-preview":{"description":"GPT-4o phi\xean bản xem trước t\xecm kiếm l\xe0 m\xf4 h\xecnh được huấn luyện chuy\xean biệt để hiểu v\xe0 thực thi c\xe1c truy vấn t\xecm kiếm tr\xean web, sử dụng API Chat Completions. Ngo\xe0i ph\xed token, truy vấn t\xecm kiếm tr\xean web c\xf2n t\xednh ph\xed theo mỗi lần gọi c\xf4ng cụ."},"gpt-4o-transcribe":{"description":"GPT-4o Transcribe l\xe0 m\xf4 h\xecnh chuyển đổi giọng n\xf3i th\xe0nh văn bản sử dụng GPT-4o để phi\xean \xe2m \xe2m thanh. So với m\xf4 h\xecnh Whisper gốc, n\xf3 cải thiện tỷ lệ lỗi từ v\xe0 n\xe2ng cao khả năng nhận diện ng\xf4n ngữ cũng như độ ch\xednh x\xe1c. Sử dụng n\xf3 để c\xf3 bản phi\xean \xe2m ch\xednh x\xe1c hơn."},"gpt-5":{"description":"M\xf4 h\xecnh tốt nhất cho c\xe1c nhiệm vụ m\xe3 h\xf3a v\xe0 đại diện đa lĩnh vực. GPT-5 đạt bước tiến vượt bậc về độ ch\xednh x\xe1c, tốc độ, suy luận, nhận diện ngữ cảnh, tư duy c\xf3 cấu tr\xfac v\xe0 giải quyết vấn đề."},"gpt-5-chat":{"description":"GPT-5 Chat l\xe0 phi\xean bản xem trước được tối ưu h\xf3a cho c\xe1c t\xecnh huống hội thoại. Hỗ trợ đầu v\xe0o văn bản v\xe0 h\xecnh ảnh, chỉ xuất ra văn bản, ph\xf9 hợp cho chatbot v\xe0 c\xe1c ứng dụng AI đối thoại."},"gpt-5-chat-latest":{"description":"M\xf4 h\xecnh GPT-5 được sử dụng trong ChatGPT. Kết hợp khả năng hiểu v\xe0 tạo ng\xf4n ngữ mạnh mẽ, ph\xf9 hợp cho c\xe1c ứng dụng tương t\xe1c đối thoại."},"gpt-5-codex":{"description":"GPT-5 Codex l\xe0 phi\xean bản GPT-5 được tối ưu cho c\xe1c t\xe1c vụ m\xe3 h\xf3a đại diện trong m\xf4i trường Codex hoặc tương tự."},"gpt-5-mini":{"description":"Phi\xean bản GPT-5 nhanh hơn v\xe0 tiết kiệm chi ph\xed hơn, ph\xf9 hợp cho c\xe1c nhiệm vụ được x\xe1c định r\xf5 r\xe0ng. Cung cấp tốc độ phản hồi nhanh hơn trong khi vẫn giữ chất lượng đầu ra cao."},"gpt-5-nano":{"description":"Phi\xean bản GPT-5 nhanh nhất v\xe0 tiết kiệm chi ph\xed nhất. Rất ph\xf9 hợp cho c\xe1c ứng dụng cần phản hồi nhanh v\xe0 nhạy cảm về chi ph\xed."},"gpt-5-pro":{"description":"GPT-5 pro sử dụng nhiều t\xe0i nguy\xean t\xednh to\xe1n hơn để suy nghĩ s\xe2u sắc hơn v\xe0 li\xean tục cung cấp c\xe1c c\xe2u trả lời tốt hơn."},"gpt-5.1":{"description":"GPT-5.1 — M\xf4 h\xecnh h\xe0ng đầu được tối ưu h\xf3a cho c\xe1c t\xe1c vụ lập tr\xecnh v\xe0 agent, hỗ trợ cường độ suy luận c\xf3 thể cấu h\xecnh v\xe0 ngữ cảnh d\xe0i hơn."},"gpt-5.1-chat-latest":{"description":"GPT-5.1 Chat: Biến thể GPT-5.1 d\xe0nh cho ChatGPT, ph\xf9 hợp với c\xe1c t\xecnh huống tr\xf2 chuyện."},"gpt-5.1-codex":{"description":"GPT-5.1 Codex: Phi\xean bản GPT-5.1 được tối ưu h\xf3a cho c\xe1c t\xe1c vụ lập tr\xecnh mang t\xednh agent, c\xf3 thể sử dụng trong Responses API cho c\xe1c quy tr\xecnh l\xe0m việc m\xe3 h\xf3a/đại l\xfd phức tạp hơn."},"gpt-5.1-codex-mini":{"description":"GPT-5.1 Codex mini: Biến thể Codex nhỏ gọn hơn v\xe0 tiết kiệm chi ph\xed hơn, được tối ưu h\xf3a cho c\xe1c t\xe1c vụ lập tr\xecnh mang t\xednh agent."},"gpt-audio":{"description":"GPT Audio l\xe0 m\xf4 h\xecnh tr\xf2 chuyện chung hỗ trợ đầu v\xe0o v\xe0 đầu ra \xe2m thanh, c\xf3 thể sử dụng \xe2m thanh I/O trong API Chat Completions."},"gpt-image-1":{"description":"M\xf4 h\xecnh tạo h\xecnh ảnh đa phương thức nguy\xean bản của ChatGPT"},"gpt-image-1-mini":{"description":"Phi\xean bản tiết kiệm chi ph\xed hơn của GPT Image 1, hỗ trợ gốc đầu v\xe0o văn bản v\xe0 h\xecnh ảnh, đồng thời tạo đầu ra h\xecnh ảnh."},"gpt-oss-120b":{"description":"Cần đăng k\xfd để trải nghiệm. GPT-OSS-120B l\xe0 m\xf4 h\xecnh ng\xf4n ngữ m\xe3 nguồn mở quy m\xf4 lớn do OpenAI ph\xe1t h\xe0nh, c\xf3 khả năng tạo văn bản mạnh mẽ."},"gpt-oss-20b":{"description":"Cần đăng k\xfd để trải nghiệm. GPT-OSS-20B l\xe0 m\xf4 h\xecnh ng\xf4n ngữ m\xe3 nguồn mở quy m\xf4 trung b\xecnh do OpenAI ph\xe1t h\xe0nh, c\xf3 khả năng tạo văn bản hiệu quả."},"gpt-oss:120b":{"description":"GPT-OSS 120B l\xe0 m\xf4 h\xecnh ng\xf4n ngữ lớn m\xe3 nguồn mở do OpenAI ph\xe1t h\xe0nh, sử dụng c\xf4ng nghệ lượng tử h\xf3a MXFP4, thuộc d\xf2ng m\xf4 h\xecnh h\xe0ng đầu. Cần m\xf4i trường đa GPU hoặc m\xe1y trạm hiệu năng cao để vận h\xe0nh, c\xf3 hiệu suất vượt trội trong suy luận phức tạp, tạo m\xe3 v\xe0 xử l\xfd đa ng\xf4n ngữ, hỗ trợ gọi h\xe0m n\xe2ng cao v\xe0 t\xedch hợp bộ c\xf4ng cụ."},"gpt-oss:20b":{"description":"GPT-OSS 20B l\xe0 m\xf4 h\xecnh ng\xf4n ngữ lớn m\xe3 nguồn mở do OpenAI ph\xe1t h\xe0nh, sử dụng kỹ thuật lượng tử h\xf3a MXFP4, ph\xf9 hợp chạy tr\xean GPU ti\xeau d\xf9ng cao cấp hoặc Apple Silicon Mac. M\xf4 h\xecnh n\xe0y thể hiện xuất sắc trong tạo hội thoại, viết m\xe3 v\xe0 c\xe1c t\xe1c vụ suy luận, hỗ trợ gọi h\xe0m v\xe0 sử dụng c\xf4ng cụ."},"gpt-realtime":{"description":"M\xf4 h\xecnh thời gian thực chung, hỗ trợ đầu v\xe0o v\xe0 đầu ra văn bản, \xe2m thanh theo thời gian thực, đồng thời hỗ trợ đầu v\xe0o h\xecnh ảnh."},"grok-2-image-1212":{"description":"M\xf4 h\xecnh tạo h\xecnh ảnh mới nhất của ch\xfang t\xf4i c\xf3 thể tạo ra h\xecnh ảnh sống động v\xe0 ch\xe2n thực dựa tr\xean gợi \xfd văn bản. N\xf3 thể hiện xuất sắc trong c\xe1c lĩnh vực marketing, mạng x\xe3 hội v\xe0 giải tr\xed."},"grok-2-vision-1212":{"description":"M\xf4 h\xecnh n\xe0y đ\xe3 được cải thiện về độ ch\xednh x\xe1c, khả năng tu\xe2n thủ hướng dẫn v\xe0 khả năng đa ng\xf4n ngữ."},"grok-3":{"description":"M\xf4 h\xecnh chủ lực, xuất sắc trong tr\xedch xuất dữ liệu, lập tr\xecnh v\xe0 t\xf3m tắt văn bản cho c\xe1c ứng dụng doanh nghiệp, sở hữu kiến thức s\xe2u rộng trong c\xe1c lĩnh vực t\xe0i ch\xednh, y tế, ph\xe1p l\xfd v\xe0 khoa học."},"grok-3-mini":{"description":"M\xf4 h\xecnh nhẹ, suy nghĩ trước khi trả lời. Chạy nhanh, th\xf4ng minh, ph\xf9 hợp cho c\xe1c nhiệm vụ logic kh\xf4ng đ\xf2i hỏi kiến thức chuy\xean s\xe2u v\xe0 c\xf3 thể truy xuất được chuỗi suy nghĩ gốc."},"grok-4":{"description":"M\xf4 h\xecnh h\xe0ng đầu mới nhất v\xe0 mạnh mẽ nhất của ch\xfang t\xf4i, thể hiện xuất sắc trong xử l\xfd ng\xf4n ngữ tự nhi\xean, t\xednh to\xe1n to\xe1n học v\xe0 suy luận — một lựa chọn to\xe0n diện ho\xe0n hảo."},"grok-4-0709":{"description":"Grok 4 của xAI, c\xf3 khả năng suy luận mạnh mẽ."},"grok-4-1-fast-non-reasoning":{"description":"M\xf4 h\xecnh đa phương thức ti\xean tiến, được tối ưu h\xf3a đặc biệt để gọi c\xf4ng cụ đại diện hiệu suất cao."},"grok-4-1-fast-reasoning":{"description":"M\xf4 h\xecnh đa phương thức ti\xean tiến, được tối ưu h\xf3a đặc biệt để gọi c\xf4ng cụ đại diện hiệu suất cao."},"grok-4-fast-non-reasoning":{"description":"Ch\xfang t\xf4i rất vui mừng giới thiệu Grok 4 Fast, bước tiến mới nhất của ch\xfang t\xf4i trong c\xe1c m\xf4 h\xecnh suy luận hiệu quả về chi ph\xed."},"grok-4-fast-reasoning":{"description":"Ch\xfang t\xf4i rất vui mừng giới thiệu Grok 4 Fast, bước tiến mới nhất của ch\xfang t\xf4i trong c\xe1c m\xf4 h\xecnh suy luận hiệu quả về chi ph\xed."},"grok-code-fast-1":{"description":"Ch\xfang t\xf4i rất vui mừng giới thiệu grok-code-fast-1, một m\xf4 h\xecnh suy luận nhanh v\xe0 tiết kiệm chi ph\xed, thể hiện xuất sắc trong việc m\xe3 h\xf3a đại l\xfd."},"groq/compound":{"description":"Compound l\xe0 một hệ thống AI tổng hợp, được hỗ trợ bởi nhiều m\xf4 h\xecnh c\xf4ng khai c\xf3 sẵn trong GroqCloud, c\xf3 khả năng sử dụng c\xf4ng cụ một c\xe1ch th\xf4ng minh v\xe0 chọn lọc để trả lời c\xe1c truy vấn của người d\xf9ng."},"groq/compound-mini":{"description":"Compound-mini l\xe0 một hệ thống AI tổng hợp, được hỗ trợ bởi c\xe1c m\xf4 h\xecnh c\xf4ng khai c\xf3 sẵn trong GroqCloud, c\xf3 khả năng sử dụng c\xf4ng cụ một c\xe1ch th\xf4ng minh v\xe0 chọn lọc để trả lời c\xe1c truy vấn của người d\xf9ng."},"gryphe/mythomax-l2-13b":{"description":"MythoMax l2 13B l\xe0 m\xf4 h\xecnh ng\xf4n ngữ kết hợp giữa s\xe1ng tạo v\xe0 tr\xed th\xf4ng minh, kết hợp nhiều m\xf4 h\xecnh h\xe0ng đầu."},"hunyuan-a13b":{"description":"Hunyuan l\xe0 m\xf4 h\xecnh suy luận hỗn hợp đầu ti\xean, phi\xean bản n\xe2ng cấp của hunyuan-standard-256K, với tổng số tham số 80 tỷ v\xe0 13 tỷ tham số k\xedch hoạt. Mặc định ở chế độ suy nghĩ chậm, hỗ trợ chuyển đổi giữa chế độ suy nghĩ nhanh v\xe0 chậm qua tham số hoặc chỉ thị, c\xe1ch chuyển đổi l\xe0 th\xeam / no_think trước truy vấn; năng lực tổng thể được cải thiện to\xe0n diện so với thế hệ trước, đặc biệt l\xe0 về to\xe1n học, khoa học, hiểu văn bản d\xe0i v\xe0 năng lực t\xe1c nh\xe2n."},"hunyuan-code":{"description":"M\xf4 h\xecnh sinh m\xe3 mới nhất của Hunyuan, được huấn luyện tr\xean 200B dữ liệu m\xe3 chất lượng cao, trải qua nửa năm huấn luyện dữ liệu SFT chất lượng cao, độ d\xe0i cửa sổ ngữ cảnh tăng l\xean 8K, đứng đầu trong c\xe1c chỉ số đ\xe1nh gi\xe1 tự động sinh m\xe3 cho năm ng\xf4n ngữ lớn; trong đ\xe1nh gi\xe1 chất lượng cao của 10 ti\xeau ch\xed m\xe3 tổng hợp cho năm ng\xf4n ngữ, hiệu suất nằm trong nh\xf3m đầu."},"hunyuan-functioncall":{"description":"M\xf4 h\xecnh FunctionCall với cấu tr\xfac MOE mới nhất của Hunyuan, được huấn luyện tr\xean dữ liệu FunctionCall chất lượng cao, với cửa sổ ngữ cảnh đạt 32K, dẫn đầu trong nhiều chỉ số đ\xe1nh gi\xe1."},"hunyuan-large":{"description":"M\xf4 h\xecnh Hunyuan-large c\xf3 tổng số tham số khoảng 389B, số tham số k\xedch hoạt khoảng 52B, l\xe0 m\xf4 h\xecnh MoE m\xe3 nguồn mở c\xf3 quy m\xf4 tham số lớn nhất v\xe0 hiệu quả nhất trong ng\xe0nh hiện nay."},"hunyuan-large-longcontext":{"description":"Chuy\xean xử l\xfd c\xe1c nhiệm vụ văn bản d\xe0i như t\xf3m tắt t\xe0i liệu v\xe0 hỏi đ\xe1p t\xe0i liệu, đồng thời cũng c\xf3 khả năng xử l\xfd c\xe1c nhiệm vụ tạo văn bản chung. Thể hiện xuất sắc trong ph\xe2n t\xedch v\xe0 tạo nội dung văn bản d\xe0i, c\xf3 thể đ\xe1p ứng hiệu quả c\xe1c y\xeau cầu xử l\xfd nội dung d\xe0i phức tạp v\xe0 chi tiết."},"hunyuan-large-vision":{"description":"M\xf4 h\xecnh n\xe0y ph\xf9 hợp với c\xe1c kịch bản hiểu h\xecnh ảnh v\xe0 văn bản, l\xe0 m\xf4 h\xecnh ng\xf4n ngữ thị gi\xe1c lớn dựa tr\xean Hunyuan Large, hỗ trợ đầu v\xe0o nhiều h\xecnh ảnh với độ ph\xe2n giải t\xf9y \xfd c\xf9ng văn bản, tạo ra nội dung văn bản, tập trung v\xe0o c\xe1c nhiệm vụ li\xean quan đến hiểu h\xecnh ảnh v\xe0 văn bản, c\xf3 sự cải thiện đ\xe1ng kể về khả năng hiểu đa ng\xf4n ngữ h\xecnh ảnh v\xe0 văn bản."},"hunyuan-lite":{"description":"N\xe2ng cấp l\xean cấu tr\xfac MOE, với cửa sổ ngữ cảnh 256k, dẫn đầu nhiều m\xf4 h\xecnh m\xe3 nguồn mở trong c\xe1c bộ đ\xe1nh gi\xe1 NLP, m\xe3, to\xe1n học, ng\xe0nh nghề, v.v."},"hunyuan-lite-vision":{"description":"M\xf4 h\xecnh đa phương thức mới nhất 7B của Hunyuan, cửa sổ ngữ cảnh 32K, hỗ trợ đối thoại đa phương thức trong c\xe1c t\xecnh huống tiếng Trung v\xe0 tiếng Anh, nhận diện đối tượng h\xecnh ảnh, hiểu biết t\xe0i liệu v\xe0 bảng biểu, to\xe1n học đa phương thức, v.v., với c\xe1c chỉ số đ\xe1nh gi\xe1 vượt trội hơn c\xe1c m\xf4 h\xecnh cạnh tranh 7B ở nhiều kh\xeda cạnh."},"hunyuan-pro":{"description":"M\xf4 h\xecnh văn bản d\xe0i MOE-32K với quy m\xf4 h\xe0ng triệu tham số. Đạt được mức độ dẫn đầu tuyệt đối tr\xean nhiều benchmark, c\xf3 khả năng xử l\xfd c\xe1c lệnh phức tạp v\xe0 suy diễn, c\xf3 khả năng to\xe1n học phức tạp, hỗ trợ functioncall, được tối ưu h\xf3a cho c\xe1c lĩnh vực dịch thuật đa ng\xf4n ngữ, t\xe0i ch\xednh, ph\xe1p l\xfd v\xe0 y tế."},"hunyuan-role":{"description":"M\xf4 h\xecnh đ\xf3ng vai tr\xf2 mới nhất của Hunyuan, được tinh chỉnh v\xe0 huấn luyện bởi Hunyuan, dựa tr\xean m\xf4 h\xecnh Hunyuan kết hợp với bộ dữ liệu t\xecnh huống đ\xf3ng vai tr\xf2 để tăng cường huấn luyện, c\xf3 hiệu suất cơ bản tốt hơn trong c\xe1c t\xecnh huống đ\xf3ng vai tr\xf2."},"hunyuan-standard":{"description":"Sử dụng chiến lược định tuyến tốt hơn, đồng thời giảm thiểu vấn đề c\xe2n bằng tải v\xe0 đồng nhất chuy\xean gia. Về mặt văn bản d\xe0i, chỉ số t\xecm kiếm đạt 99.9%. MOE-32K c\xf3 gi\xe1 trị hiệu suất tương đối cao, c\xe2n bằng giữa hiệu quả v\xe0 gi\xe1 cả, c\xf3 thể xử l\xfd đầu v\xe0o văn bản d\xe0i."},"hunyuan-standard-256K":{"description":"Sử dụng chiến lược định tuyến tốt hơn, đồng thời giảm thiểu vấn đề c\xe2n bằng tải v\xe0 đồng nhất chuy\xean gia. Về mặt văn bản d\xe0i, chỉ số t\xecm kiếm đạt 99.9%. MOE-256K đ\xe3 c\xf3 bước đột ph\xe1 về độ d\xe0i v\xe0 hiệu quả, mở rộng đ\xe1ng kể độ d\xe0i đầu v\xe0o c\xf3 thể."},"hunyuan-standard-vision":{"description":"M\xf4 h\xecnh đa phương thức mới nhất của Hunyuan, hỗ trợ trả lời đa ng\xf4n ngữ, khả năng tiếng Trung v\xe0 tiếng Anh c\xe2n bằng."},"hunyuan-t1-20250321":{"description":"X\xe2y dựng to\xe0n diện khả năng m\xf4 h\xecnh cho cả khoa học tự nhi\xean v\xe0 khoa học x\xe3 hội, khả năng nắm bắt th\xf4ng tin văn bản d\xe0i mạnh mẽ. Hỗ trợ suy luận v\xe0 giải đ\xe1p c\xe1c vấn đề khoa học như to\xe1n học, logic, khoa học v\xe0 m\xe3 với nhiều độ kh\xf3 kh\xe1c nhau."},"hunyuan-t1-20250403":{"description":"N\xe2ng cao khả năng tạo m\xe3 cấp dự \xe1n; cải thiện chất lượng viết văn bản; n\xe2ng cao khả năng hiểu chủ đề văn bản đa v\xf2ng, tu\xe2n thủ chỉ thị toB v\xe0 hiểu từ ngữ; tối ưu h\xf3a vấn đề đầu ra hỗn hợp phồn thể v\xe0 giản thể, cũng như hỗn hợp tiếng Trung v\xe0 tiếng Anh."},"hunyuan-t1-20250529":{"description":"Tối ưu h\xf3a s\xe1ng tạo văn bản, viết luận, cải thiện khả năng lập tr\xecnh frontend, to\xe1n học, suy luận logic v\xe0 c\xe1c kỹ năng khoa học tự nhi\xean, n\xe2ng cao khả năng tu\xe2n thủ chỉ dẫn."},"hunyuan-t1-20250711":{"description":"N\xe2ng cao đ\xe1ng kể khả năng to\xe1n học, logic v\xe0 m\xe3 h\xf3a kh\xf3, tối ưu độ ổn định đầu ra m\xf4 h\xecnh, cải thiện khả năng xử l\xfd văn bản d\xe0i."},"hunyuan-t1-latest":{"description":"N\xe2ng cao đ\xe1ng kể năng lực của m\xf4 h\xecnh ch\xednh v\xe0 m\xf4 h\xecnh suy nghĩ chậm trong c\xe1c lĩnh vực to\xe1n học kh\xf3, suy luận phức tạp, m\xe3 h\xf3a kh\xf3, tu\xe2n thủ chỉ thị v\xe0 chất lượng s\xe1ng tạo văn bản."},"hunyuan-t1-vision-20250619":{"description":"Phi\xean bản mới nhất của Hunyuan t1-vision l\xe0 m\xf4 h\xecnh suy nghĩ s\xe2u đa phương thức, hỗ trợ chuỗi tư duy d\xe0i nguy\xean bản đa phương thức, cải thiện to\xe0n diện so với phi\xean bản mặc định thế hệ trước."},"hunyuan-t1-vision-20250916":{"description":"Phi\xean bản mới nhất của m\xf4 h\xecnh tư duy thị gi\xe1c Hunyuan t1-vision đ\xe3 được n\xe2ng cấp to\xe0n diện so với phi\xean bản trước trong c\xe1c nhiệm vụ như hỏi đ\xe1p h\xecnh ảnh, định vị thị gi\xe1c, OCR, biểu đồ, giải b\xe0i tập qua ảnh v\xe0 s\xe1ng tạo từ h\xecnh ảnh. Khả năng xử l\xfd tiếng Anh v\xe0 c\xe1c ng\xf4n ngữ \xedt phổ biến cũng được cải thiện r\xf5 rệt."},"hunyuan-turbo":{"description":"Phi\xean bản xem trước của thế hệ mới m\xf4 h\xecnh ng\xf4n ngữ lớn Hunyuan, sử dụng cấu tr\xfac m\xf4 h\xecnh chuy\xean gia hỗn hợp (MoE) ho\xe0n to\xe0n mới, so với hunyuan-pro, hiệu suất suy diễn nhanh hơn v\xe0 hiệu quả mạnh mẽ hơn."},"hunyuan-turbo-20241223":{"description":"Phi\xean bản n\xe0y tối ưu h\xf3a: quy m\xf4 chỉ thị dữ liệu, n\xe2ng cao đ\xe1ng kể khả năng tổng qu\xe1t của m\xf4 h\xecnh; n\xe2ng cao đ\xe1ng kể khả năng to\xe1n học, lập tr\xecnh, v\xe0 suy luận logic; tối ưu h\xf3a khả năng hiểu biết văn bản v\xe0 từ ngữ; tối ưu h\xf3a chất lượng tạo nội dung văn bản."},"hunyuan-turbo-latest":{"description":"Tối ưu h\xf3a trải nghiệm chung, bao gồm hiểu biết NLP, s\xe1ng tạo văn bản, tr\xf2 chuyện, hỏi đ\xe1p kiến thức, dịch thuật, v\xe0 c\xe1c lĩnh vực kh\xe1c; n\xe2ng cao t\xednh nh\xe2n văn, tối ưu h\xf3a tr\xed tuệ cảm x\xfac của m\xf4 h\xecnh; cải thiện khả năng l\xe0m r\xf5 khi \xfd định kh\xf4ng r\xf5 r\xe0ng; n\xe2ng cao khả năng xử l\xfd c\xe1c vấn đề ph\xe2n t\xedch từ ngữ; n\xe2ng cao chất lượng v\xe0 khả năng tương t\xe1c trong s\xe1ng tạo; cải thiện trải nghiệm đa v\xf2ng."},"hunyuan-turbo-vision":{"description":"M\xf4 h\xecnh ng\xf4n ngữ h\xecnh ảnh thế hệ mới của Hunyuan, sử dụng cấu tr\xfac m\xf4 h\xecnh chuy\xean gia hỗn hợp (MoE) ho\xe0n to\xe0n mới, n\xe2ng cao to\xe0n diện khả năng nhận diện cơ bản, s\xe1ng tạo nội dung, hỏi đ\xe1p kiến thức, v\xe0 ph\xe2n t\xedch suy luận so với m\xf4 h\xecnh thế hệ trước."},"hunyuan-turbos-20250313":{"description":"Thống nhất phong c\xe1ch c\xe1c bước giải to\xe1n, tăng cường hỏi đ\xe1p to\xe1n học đa v\xf2ng. Tối ưu h\xf3a phong c\xe1ch trả lời trong s\xe1ng t\xe1c văn bản, loại bỏ cảm gi\xe1c AI, tăng th\xeam t\xednh văn chương."},"hunyuan-turbos-20250416":{"description":"N\xe2ng cấp nền tảng tiền huấn luyện, tăng cường khả năng hiểu v\xe0 tu\xe2n thủ chỉ thị của nền tảng; tăng cường năng lực c\xe1c m\xf4n khoa học tự nhi\xean như to\xe1n học, lập tr\xecnh, logic, khoa học trong giai đoạn căn chỉnh; cải thiện chất lượng s\xe1ng tạo văn học, hiểu văn bản, độ ch\xednh x\xe1c dịch thuật, hỏi đ\xe1p kiến thức v\xe0 c\xe1c năng lực khoa học x\xe3 hội; tăng cường năng lực Agent trong c\xe1c lĩnh vực, đặc biệt l\xe0 khả năng hiểu đối thoại đa v\xf2ng."},"hunyuan-turbos-20250604":{"description":"N\xe2ng cấp nền tảng tiền huấn luyện, cải thiện khả năng viết v\xe0 đọc hiểu, tăng cường đ\xe1ng kể năng lực lập tr\xecnh v\xe0 khoa học tự nhi\xean, tiếp tục n\xe2ng cao khả năng tu\xe2n thủ c\xe1c chỉ dẫn phức tạp."},"hunyuan-turbos-20250926":{"description":"N\xe2ng cấp chất lượng dữ liệu nền tiền huấn luyện. Tối ưu chiến lược huấn luyện giai đoạn posttrain, li\xean tục n\xe2ng cao khả năng Agent, tiếng Anh v\xe0 c\xe1c ng\xf4n ngữ nhỏ, tu\xe2n thủ chỉ thị, m\xe3 h\xf3a v\xe0 năng lực khoa học tự nhi\xean."},"hunyuan-turbos-latest":{"description":"hunyuan-TurboS l\xe0 phi\xean bản mới nhất của m\xf4 h\xecnh lớn hỗn hợp Hunyuan, c\xf3 khả năng tư duy mạnh mẽ hơn v\xe0 trải nghiệm tốt hơn."},"hunyuan-turbos-longtext-128k-20250325":{"description":"Chuy\xean xử l\xfd c\xe1c nhiệm vụ văn bản d\xe0i như t\xf3m tắt t\xe0i liệu v\xe0 hỏi đ\xe1p t\xe0i liệu, đồng thời cũng c\xf3 khả năng xử l\xfd c\xe1c nhiệm vụ tạo văn bản chung. N\xf3 thể hiện xuất sắc trong việc ph\xe2n t\xedch v\xe0 tạo ra văn bản d\xe0i, c\xf3 khả năng đ\xe1p ứng hiệu quả c\xe1c y\xeau cầu xử l\xfd nội dung d\xe0i phức tạp v\xe0 chi tiết."},"hunyuan-turbos-role-plus":{"description":"M\xf4 h\xecnh nhập vai phi\xean bản mới nhất của Hunyuan, được tinh chỉnh ch\xednh thức bởi Hunyuan, dựa tr\xean m\xf4 h\xecnh Hunyuan kết hợp với bộ dữ liệu kịch bản nhập vai để tăng cường huấn luyện, mang lại hiệu quả cơ bản tốt hơn trong c\xe1c kịch bản nhập vai."},"hunyuan-turbos-vision":{"description":"M\xf4 h\xecnh n\xe0y ph\xf9 hợp với c\xe1c kịch bản hiểu h\xecnh ảnh v\xe0 văn bản, l\xe0 m\xf4 h\xecnh ng\xf4n ngữ thị gi\xe1c h\xe0ng đầu thế hệ mới dựa tr\xean Hunyuan turbos mới nhất, tập trung v\xe0o c\xe1c nhiệm vụ li\xean quan đến hiểu h\xecnh ảnh v\xe0 văn bản, bao gồm nhận dạng thực thể dựa tr\xean h\xecnh ảnh, hỏi đ\xe1p kiến thức, s\xe1ng tạo nội dung, giải b\xe0i tập qua ảnh chụp, với cải tiến to\xe0n diện so với thế hệ trước."},"hunyuan-turbos-vision-20250619":{"description":"Phi\xean bản mới nhất của Hunyuan turbos-vision l\xe0 m\xf4 h\xecnh ng\xf4n ngữ thị gi\xe1c h\xe0ng đầu, cải thiện to\xe0n diện so với phi\xean bản mặc định thế hệ trước trong c\xe1c nhiệm vụ li\xean quan đến hiểu h\xecnh ảnh v\xe0 văn bản, bao gồm nhận dạng thực thể dựa tr\xean h\xecnh ảnh, hỏi đ\xe1p kiến thức, s\xe1ng tạo nội dung, giải b\xe0i tập qua ảnh chụp."},"hunyuan-vision":{"description":"M\xf4 h\xecnh đa phương thức mới nhất của Hunyuan, hỗ trợ đầu v\xe0o h\xecnh ảnh + văn bản để tạo ra nội dung văn bản."},"image-01":{"description":"M\xf4 h\xecnh tạo h\xecnh ảnh ho\xe0n to\xe0n mới, thể hiện h\xecnh ảnh tinh tế, hỗ trợ tạo h\xecnh ảnh từ văn bản v\xe0 h\xecnh ảnh."},"image-01-live":{"description":"M\xf4 h\xecnh tạo h\xecnh ảnh với chất lượng tinh tế, hỗ trợ tạo h\xecnh ảnh từ văn bản v\xe0 thiết lập phong c\xe1ch h\xecnh ảnh."},"imagen-4.0-fast-generate-001":{"description":"Imagen — d\xf2ng m\xf4 h\xecnh tạo ảnh từ văn bản thế hệ thứ 4, phi\xean bản nhanh."},"imagen-4.0-generate-001":{"description":"D\xf2ng m\xf4 h\xecnh Imagen thế hệ thứ tư chuyển văn bản th\xe0nh h\xecnh ảnh"},"imagen-4.0-generate-preview-06-06":{"description":"D\xf2ng m\xf4 h\xecnh tạo h\xecnh ảnh từ văn bản thế hệ thứ tư của Imagen"},"imagen-4.0-ultra-generate-001":{"description":"Imagen thế hệ thứ 4, d\xf2ng m\xf4 h\xecnh chuyển văn bản sang h\xecnh ảnh — phi\xean bản Ultra"},"imagen-4.0-ultra-generate-preview-06-06":{"description":"Phi\xean bản Ultra của d\xf2ng m\xf4 h\xecnh tạo h\xecnh ảnh từ văn bản thế hệ thứ tư của Imagen"},"inception/mercury-coder-small":{"description":"Mercury Coder Small l\xe0 lựa chọn l\xfd tưởng cho c\xe1c nhiệm vụ tạo m\xe3, gỡ lỗi v\xe0 t\xe1i cấu tr\xfac với độ trễ tối thiểu."},"inclusionAI/Ling-1T":{"description":"Ling-1T l\xe0 m\xf4 h\xecnh non-thinking h\xe0ng đầu đầu ti\xean trong d\xf2ng sản phẩm \\"Linh 2.0\\", sở hữu tổng cộng 1 ngh\xecn tỷ tham số v\xe0 khoảng 50 tỷ tham số hoạt động cho mỗi token. Được x\xe2y dựng tr\xean kiến tr\xfac Linh 2.0, Ling-1T hướng đến việc vượt qua giới hạn của suy luận hiệu quả v\xe0 nhận thức c\xf3 thể mở rộng. Ling-1T-base được huấn luyện tr\xean hơn 20 ngh\xecn tỷ token chất lượng cao, đ\xf2i hỏi suy luận chuy\xean s\xe2u."},"inclusionAI/Ling-flash-2.0":{"description":"Ling-flash-2.0 l\xe0 m\xf4 h\xecnh thứ ba trong d\xf2ng kiến tr\xfac Ling 2.0 do đội ngũ Bailing của Ant Group ph\xe1t h\xe0nh. Đ\xe2y l\xe0 m\xf4 h\xecnh chuy\xean gia hỗn hợp (MoE) với tổng số tham số l\xean đến 100 tỷ, nhưng mỗi token chỉ k\xedch hoạt 6.1 tỷ tham số (kh\xf4ng bao gồm embedding l\xe0 4.8 tỷ). L\xe0 m\xf4 h\xecnh cấu h\xecnh nhẹ, Ling-flash-2.0 thể hiện hiệu năng ngang hoặc vượt trội so với c\xe1c m\xf4 h\xecnh d\xe0y đặc (Dense) 40 tỷ tham số v\xe0 c\xe1c m\xf4 h\xecnh MoE quy m\xf4 lớn hơn trong nhiều b\xe0i đ\xe1nh gi\xe1 uy t\xedn. M\xf4 h\xecnh n\xe0y nhằm kh\xe1m ph\xe1 con đường hiệu quả trong bối cảnh quan niệm “m\xf4 h\xecnh lớn đồng nghĩa với tham số lớn” th\xf4ng qua thiết kế kiến tr\xfac v\xe0 chiến lược huấn luyện tối ưu."},"inclusionAI/Ling-mini-2.0":{"description":"Ling-mini-2.0 l\xe0 m\xf4 h\xecnh ng\xf4n ngữ lớn hiệu năng cao k\xedch thước nhỏ dựa tr\xean kiến tr\xfac MoE. N\xf3 c\xf3 tổng số 16 tỷ tham số, nhưng mỗi token chỉ k\xedch hoạt 1.4 tỷ tham số (kh\xf4ng bao gồm embedding l\xe0 789 triệu), từ đ\xf3 đạt tốc độ sinh nhanh vượt trội. Nhờ thiết kế MoE hiệu quả v\xe0 dữ liệu huấn luyện quy m\xf4 lớn, chất lượng cao, mặc d\xf9 tham số k\xedch hoạt chỉ 1.4 tỷ, Ling-mini-2.0 vẫn thể hiện hiệu năng h\xe0ng đầu trong c\xe1c t\xe1c vụ hạ nguồn, c\xf3 thể so s\xe1nh với c\xe1c m\xf4 h\xecnh dense dưới 10 tỷ tham số v\xe0 c\xe1c m\xf4 h\xecnh MoE quy m\xf4 lớn hơn."},"inclusionAI/Ring-1T":{"description":"Ring-1T l\xe0 m\xf4 h\xecnh tư duy m\xe3 nguồn mở quy m\xf4 ngh\xecn tỷ tham số do nh\xf3m Bailing ph\xe1t triển. Dựa tr\xean kiến tr\xfac Linh 2.0 v\xe0 m\xf4 h\xecnh nền tảng Ling-1T-base, m\xf4 h\xecnh n\xe0y c\xf3 tổng cộng 1 ngh\xecn tỷ tham số v\xe0 50 tỷ tham số hoạt động, hỗ trợ cửa sổ ngữ cảnh l\xean đến 128K. M\xf4 h\xecnh được tối ưu h\xf3a th\xf4ng qua học tăng cường với phần thưởng c\xf3 thể x\xe1c minh ở quy m\xf4 lớn."},"inclusionAI/Ring-flash-2.0":{"description":"Ring-flash-2.0 l\xe0 m\xf4 h\xecnh tư duy hiệu năng cao được tối ưu s\xe2u dựa tr\xean Ling-flash-2.0-base. N\xf3 sử dụng kiến tr\xfac chuy\xean gia hỗn hợp (MoE) với tổng số 100 tỷ tham số, nhưng mỗi lần suy luận chỉ k\xedch hoạt 6.1 tỷ tham số. M\xf4 h\xecnh n\xe0y \xe1p dụng thuật to\xe1n độc quyền icepop, giải quyết vấn đề kh\xf4ng ổn định trong huấn luyện tăng cường (RL) của c\xe1c m\xf4 h\xecnh MoE lớn, gi\xfap năng lực suy luận phức tạp được cải thiện li\xean tục trong qu\xe1 tr\xecnh huấn luyện d\xe0i hạn. Ring-flash-2.0 đạt bước đột ph\xe1 đ\xe1ng kể trong c\xe1c b\xe0i kiểm tra chuẩn kh\xf3 như thi to\xe1n, tạo m\xe3 v\xe0 suy luận logic, hiệu năng kh\xf4ng chỉ vượt c\xe1c m\xf4 h\xecnh dense h\xe0ng đầu dưới 40 tỷ tham số m\xe0 c\xf2n c\xf3 thể s\xe1nh ngang c\xe1c m\xf4 h\xecnh MoE m\xe3 nguồn mở quy m\xf4 lớn v\xe0 c\xe1c m\xf4 h\xecnh tư duy hiệu năng cao đ\xf3ng nguồn. Mặc d\xf9 tập trung v\xe0o suy luận phức tạp, m\xf4 h\xecnh cũng thể hiện tốt trong c\xe1c t\xe1c vụ s\xe1ng tạo viết l\xe1ch. Ngo\xe0i ra, nhờ thiết kế kiến tr\xfac hiệu quả, Ring-flash-2.0 vừa cung cấp hiệu năng mạnh mẽ vừa đạt tốc độ suy luận cao, giảm đ\xe1ng kể chi ph\xed triển khai m\xf4 h\xecnh tư duy trong c\xe1c kịch bản tải cao."},"internlm/internlm2_5-7b-chat":{"description":"InternLM2.5 cung cấp giải ph\xe1p đối thoại th\xf4ng minh cho nhiều t\xecnh huống."},"internlm2.5-latest":{"description":"D\xf2ng m\xf4 h\xecnh mới nhất của ch\xfang t\xf4i, c\xf3 hiệu suất suy luận xuất sắc, hỗ trợ độ d\xe0i ngữ cảnh 1M v\xe0 khả năng theo d\xf5i chỉ dẫn v\xe0 gọi c\xf4ng cụ mạnh mẽ hơn."},"internlm3-latest":{"description":"D\xf2ng m\xf4 h\xecnh mới nhất của ch\xfang t\xf4i, c\xf3 hiệu suất suy luận xuất sắc, dẫn đầu trong số c\xe1c m\xf4 h\xecnh m\xe3 nguồn mở c\xf9ng cấp. Mặc định chỉ đến m\xf4 h\xecnh InternLM3 mới nhất m\xe0 ch\xfang t\xf4i đ\xe3 ph\xe1t h\xe0nh."},"internvl2.5-38b-mpo":{"description":"InternVL2.5 38B MPO, m\xf4 h\xecnh tiền huấn luyện đa phương thức, hỗ trợ c\xe1c nhiệm vụ suy luận h\xecnh ảnh-văn bản phức tạp."},"internvl2.5-latest":{"description":"Phi\xean bản InternVL2.5 m\xe0 ch\xfang t\xf4i vẫn đang duy tr\xec, c\xf3 hiệu suất xuất sắc v\xe0 ổn định. Mặc định chỉ đến m\xf4 h\xecnh InternVL2.5 mới nhất của ch\xfang t\xf4i, hiện tại chỉ đến internvl2.5-78b."},"internvl3-14b":{"description":"InternVL3 14B, m\xf4 h\xecnh đa phương thức quy m\xf4 trung b\xecnh, c\xe2n bằng giữa hiệu suất v\xe0 chi ph\xed."},"internvl3-1b":{"description":"InternVL3 1B, m\xf4 h\xecnh đa phương thức nhẹ, ph\xf9 hợp với triển khai trong m\xf4i trường t\xe0i nguy\xean hạn chế."},"internvl3-38b":{"description":"InternVL3 38B, m\xf4 h\xecnh đa phương thức m\xe3 nguồn mở quy m\xf4 lớn, ph\xf9 hợp với c\xe1c nhiệm vụ hiểu h\xecnh ảnh-văn bản độ ch\xednh x\xe1c cao."},"internvl3-latest":{"description":"Ch\xfang t\xf4i vừa ph\xe1t h\xe0nh m\xf4 h\xecnh lớn đa phương thức mới nhất, c\xf3 khả năng hiểu h\xecnh ảnh v\xe0 văn bản mạnh mẽ hơn, khả năng hiểu h\xecnh ảnh theo chuỗi thời gian d\xe0i, hiệu suất tương đương với c\xe1c m\xf4 h\xecnh đ\xf3ng nguồn h\xe0ng đầu. Mặc định chỉ đến m\xf4 h\xecnh InternVL mới nhất của ch\xfang t\xf4i, hiện tại chỉ đến internvl3-78b."},"irag-1.0":{"description":"ERNIE iRAG, m\xf4 h\xecnh sinh tăng cường truy xuất h\xecnh ảnh, hỗ trợ t\xecm kiếm bằng h\xecnh ảnh, truy xuất h\xecnh ảnh-văn bản v\xe0 sinh nội dung."},"jamba-large":{"description":"M\xf4 h\xecnh mạnh mẽ v\xe0 ti\xean tiến nhất của ch\xfang t\xf4i, được thiết kế đặc biệt để xử l\xfd c\xe1c nhiệm vụ phức tạp cấp doanh nghiệp, với hiệu suất xuất sắc."},"jamba-mini":{"description":"M\xf4 h\xecnh hiệu quả nhất trong c\xf9ng ph\xe2n kh\xfac, c\xe2n bằng giữa tốc độ v\xe0 chất lượng, c\xf3 k\xedch thước nhỏ hơn."},"jina-deepsearch-v1":{"description":"T\xecm kiếm s\xe2u kết hợp t\xecm kiếm tr\xean mạng, đọc v\xe0 suy luận, c\xf3 thể thực hiện điều tra to\xe0n diện. Bạn c\xf3 thể coi n\xf3 như một đại l\xfd, nhận nhiệm vụ nghi\xean cứu của bạn - n\xf3 sẽ thực hiện t\xecm kiếm rộng r\xe3i v\xe0 qua nhiều lần lặp lại trước khi đưa ra c\xe2u trả lời. Qu\xe1 tr\xecnh n\xe0y li\xean quan đến nghi\xean cứu li\xean tục, suy luận v\xe0 giải quyết vấn đề từ nhiều g\xf3c độ. Điều n\xe0y kh\xe1c biệt ho\xe0n to\xe0n với việc tạo ra c\xe2u trả lời trực tiếp từ dữ liệu đ\xe3 được huấn luyện trước của c\xe1c m\xf4 h\xecnh lớn ti\xeau chuẩn v\xe0 c\xe1c hệ thống RAG truyền thống dựa v\xe0o t\xecm kiếm bề mặt một lần."},"kimi-k2":{"description":"Kimi-K2 l\xe0 m\xf4 h\xecnh nền tảng kiến tr\xfac MoE do Moonshot AI ph\xe1t h\xe0nh, c\xf3 khả năng m\xe3 h\xf3a v\xe0 đại l\xfd vượt trội, tổng tham số 1T, tham số k\xedch hoạt 32B. Trong c\xe1c b\xe0i kiểm tra chuẩn về suy luận kiến thức chung, lập tr\xecnh, to\xe1n học v\xe0 đại l\xfd, hiệu suất của m\xf4 h\xecnh K2 vượt trội so với c\xe1c m\xf4 h\xecnh m\xe3 nguồn mở phổ biến kh\xe1c."},"kimi-k2-0711-preview":{"description":"kimi-k2 l\xe0 m\xf4 h\xecnh cơ sở kiến tr\xfac MoE với khả năng m\xe3 h\xf3a v\xe0 Agent cực mạnh, tổng số tham số 1T, tham số k\xedch hoạt 32B. Trong c\xe1c b\xe0i kiểm tra hiệu năng chuẩn về suy luận kiến thức chung, lập tr\xecnh, to\xe1n học, Agent v\xe0 c\xe1c lĩnh vực ch\xednh kh\xe1c, m\xf4 h\xecnh K2 vượt trội hơn c\xe1c m\xf4 h\xecnh m\xe3 nguồn mở phổ biến kh\xe1c."},"kimi-k2-0905-preview":{"description":"M\xf4 h\xecnh kimi-k2-0905-preview c\xf3 độ d\xe0i ngữ cảnh 256k, sở hữu năng lực Agentic Coding mạnh mẽ hơn, m\xe3 front-end đẹp mắt v\xe0 thực dụng hơn, c\xf9ng khả năng hiểu ngữ cảnh tốt hơn."},"kimi-k2-instruct":{"description":"Kimi K2 Instruct, m\xf4 h\xecnh suy luận ch\xednh thức của Kimi, hỗ trợ ngữ cảnh d\xe0i, m\xe3 nguồn, hỏi đ\xe1p v\xe0 nhiều t\xecnh huống kh\xe1c."},"kimi-k2-turbo-preview":{"description":"kimi-k2 l\xe0 một m\xf4 h\xecnh nền tảng kiến tr\xfac MoE với khả năng xử l\xfd m\xe3 v\xe0 Agent rất mạnh, tổng số tham số 1T, tham số k\xedch hoạt 32B. Trong c\xe1c b\xe0i kiểm tra chuẩn về hiệu năng ở c\xe1c hạng mục ch\xednh như suy luận kiến thức tổng qu\xe1t, lập tr\xecnh, to\xe1n học v\xe0 Agent, m\xf4 h\xecnh K2 cho hiệu năng vượt trội so với c\xe1c m\xf4 h\xecnh m\xe3 nguồn mở phổ biến kh\xe1c."},"kimi-k2:1t":{"description":"Kimi K2 l\xe0 m\xf4 h\xecnh ng\xf4n ngữ chuy\xean gia hỗn hợp quy m\xf4 lớn (MoE) do AI Mặt Trăng Tối ph\xe1t triển, với tổng cộng 1 ngh\xecn tỷ tham số v\xe0 32 tỷ tham số k\xedch hoạt mỗi lần truyền tiến. N\xf3 được tối ưu h\xf3a cho khả năng đại l\xfd, bao gồm sử dụng c\xf4ng cụ n\xe2ng cao, suy luận v\xe0 tổng hợp m\xe3."},"kimi-latest":{"description":"Sản phẩm trợ l\xfd th\xf4ng minh Kimi sử dụng m\xf4 h\xecnh lớn Kimi mới nhất, c\xf3 thể chứa c\xe1c t\xednh năng chưa ổn định. Hỗ trợ hiểu h\xecnh ảnh, đồng thời tự động chọn m\xf4 h\xecnh 8k/32k/128k l\xe0m m\xf4 h\xecnh t\xednh ph\xed dựa tr\xean độ d\xe0i ngữ cảnh y\xeau cầu."},"kimi-thinking-preview":{"description":"M\xf4 h\xecnh kimi-thinking-preview do Moon\'s Dark Side cung cấp, c\xf3 khả năng suy luận đa phương thức v\xe0 suy luận tổng qu\xe1t, nổi bật với khả năng suy luận s\xe2u, gi\xfap giải quyết nhiều vấn đề kh\xf3 khăn hơn."},"learnlm-1.5-pro-experimental":{"description":"LearnLM l\xe0 một m\xf4 h\xecnh ng\xf4n ngữ thử nghiệm, chuy\xean biệt cho c\xe1c nhiệm vụ, được đ\xe0o tạo để tu\xe2n theo c\xe1c nguy\xean tắc khoa học học tập, c\xf3 thể tu\xe2n theo c\xe1c chỉ dẫn hệ thống trong c\xe1c t\xecnh huống giảng dạy v\xe0 học tập, đ\xf3ng vai tr\xf2 như một người hướng dẫn chuy\xean gia."},"learnlm-2.0-flash-experimental":{"description":"LearnLM l\xe0 một m\xf4 h\xecnh ng\xf4n ngữ thử nghiệm, chuy\xean biệt cho nhiệm vụ, được đ\xe0o tạo để tu\xe2n theo c\xe1c nguy\xean tắc khoa học học tập, c\xf3 thể tu\xe2n theo hướng dẫn hệ thống trong c\xe1c t\xecnh huống giảng dạy v\xe0 học tập, đ\xf3ng vai tr\xf2 như một người hướng dẫn chuy\xean gia."},"lite":{"description":"Spark Lite l\xe0 một m\xf4 h\xecnh ng\xf4n ngữ lớn nhẹ, c\xf3 độ trễ cực thấp v\xe0 khả năng xử l\xfd hiệu quả, ho\xe0n to\xe0n miễn ph\xed v\xe0 mở, hỗ trợ chức năng t\xecm kiếm trực tuyến theo thời gian thực. Đặc điểm phản hồi nhanh của n\xf3 gi\xfap n\xf3 nổi bật trong c\xe1c ứng dụng suy diễn tr\xean thiết bị c\xf3 c\xf4ng suất thấp v\xe0 tinh chỉnh m\xf4 h\xecnh, mang lại hiệu quả chi ph\xed v\xe0 trải nghiệm th\xf4ng minh xuất sắc cho người d\xf9ng, đặc biệt trong c\xe1c t\xecnh huống hỏi đ\xe1p kiến thức, tạo nội dung v\xe0 t\xecm kiếm."},"llama-3.1-70b-versatile":{"description":"Llama 3.1 70B cung cấp khả năng suy luận AI mạnh mẽ hơn, ph\xf9 hợp cho c\xe1c ứng dụng phức tạp, hỗ trợ xử l\xfd t\xednh to\xe1n cực lớn v\xe0 đảm bảo hiệu quả v\xe0 độ ch\xednh x\xe1c cao."},"llama-3.1-8b-instant":{"description":"Llama 3.1 8B l\xe0 một m\xf4 h\xecnh hiệu suất cao, cung cấp khả năng sinh văn bản nhanh ch\xf3ng, rất ph\xf9 hợp cho c\xe1c t\xecnh huống ứng dụng cần hiệu quả quy m\xf4 lớn v\xe0 tiết kiệm chi ph\xed."},"llama-3.1-instruct":{"description":"M\xf4 h\xecnh Llama 3.1 được tối ưu h\xf3a cho c\xe1c t\xecnh huống đối thoại, vượt trội hơn nhiều m\xf4 h\xecnh tr\xf2 chuyện nguồn mở hiện c\xf3 trong c\xe1c b\xe0i kiểm tra chuẩn ng\xe0nh phổ biến."},"llama-3.2-11b-vision-instruct":{"description":"Khả năng suy luận h\xecnh ảnh xuất sắc tr\xean h\xecnh ảnh độ ph\xe2n giải cao, ph\xf9 hợp cho c\xe1c ứng dụng hiểu biết h\xecnh ảnh."},"llama-3.2-11b-vision-preview":{"description":"Llama 3.2 được thiết kế để xử l\xfd c\xe1c nhiệm vụ kết hợp dữ liệu h\xecnh ảnh v\xe0 văn bản. N\xf3 thể hiện xuất sắc trong c\xe1c nhiệm vụ m\xf4 tả h\xecnh ảnh v\xe0 hỏi đ\xe1p h\xecnh ảnh, vượt qua r\xe0o cản giữa tạo ng\xf4n ngữ v\xe0 suy luận h\xecnh ảnh."},"llama-3.2-90b-vision-instruct":{"description":"Khả năng suy luận h\xecnh ảnh ti\xean tiến d\xe0nh cho c\xe1c ứng dụng đại l\xfd hiểu biết h\xecnh ảnh."},"llama-3.2-90b-vision-preview":{"description":"Llama 3.2 được thiết kế để xử l\xfd c\xe1c nhiệm vụ kết hợp dữ liệu h\xecnh ảnh v\xe0 văn bản. N\xf3 thể hiện xuất sắc trong c\xe1c nhiệm vụ m\xf4 tả h\xecnh ảnh v\xe0 hỏi đ\xe1p h\xecnh ảnh, vượt qua r\xe0o cản giữa tạo ng\xf4n ngữ v\xe0 suy luận h\xecnh ảnh."},"llama-3.2-vision-instruct":{"description":"M\xf4 h\xecnh Llama 3.2-Vision đ\xe3 được tối ưu h\xf3a để nhận dạng h\xecnh ảnh, suy luận h\xecnh ảnh, m\xf4 tả h\xecnh ảnh v\xe0 trả lời c\xe1c c\xe2u hỏi th\xf4ng thường li\xean quan đến h\xecnh ảnh."},"llama-3.3-70b":{"description":"Llama 3.3 70B: M\xf4 h\xecnh Llama cỡ trung, c\xe2n bằng giữa khả năng suy luận v\xe0 hiệu suất xử l\xfd."},"llama-3.3-70b-versatile":{"description":"M\xf4 h\xecnh ng\xf4n ngữ lớn Meta Llama 3.3 (LLM) đa ng\xf4n ngữ l\xe0 m\xf4 h\xecnh tạo ra dựa tr\xean 70B (đầu v\xe0o/đầu ra văn bản) đ\xe3 được huấn luyện v\xe0 điều chỉnh theo chỉ dẫn. M\xf4 h\xecnh thuần văn bản Llama 3.3 được tối ưu h\xf3a cho c\xe1c trường hợp hội thoại đa ng\xf4n ngữ v\xe0 vượt trội hơn nhiều m\xf4 h\xecnh tr\xf2 chuyện m\xe3 nguồn mở v\xe0 đ\xf3ng kh\xe1c tr\xean c\xe1c ti\xeau chuẩn ng\xe0nh th\xf4ng thường."},"llama-3.3-instruct":{"description":"M\xf4 h\xecnh Llama 3.3 được tối ưu h\xf3a cho c\xe1c t\xecnh huống đối thoại, v\xe0 đ\xe3 vượt qua nhiều m\xf4 h\xecnh tr\xf2 chuyện nguồn mở hiện c\xf3 trong c\xe1c b\xe0i kiểm tra chuẩn ng\xe0nh phổ biến."},"llama-4-scout-17b-16e-instruct":{"description":"Llama 4 Scout: M\xf4 h\xecnh hiệu suất cao thuộc d\xf2ng Llama, l\xfd tưởng cho c\xe1c t\xecnh huống y\xeau cầu th\xf4ng lượng cao v\xe0 độ trễ thấp."},"llama3-70b-8192":{"description":"Meta Llama 3 70B cung cấp khả năng xử l\xfd phức tạp v\xf4 song, được thiết kế ri\xeang cho c\xe1c dự \xe1n y\xeau cầu cao."},"llama3-8b-8192":{"description":"Meta Llama 3 8B mang lại hiệu suất suy luận chất lượng cao, ph\xf9 hợp cho nhu cầu ứng dụng đa dạng."},"llama3-groq-70b-8192-tool-use-preview":{"description":"Llama 3 Groq 70B Tool Use cung cấp khả năng gọi c\xf4ng cụ mạnh mẽ, hỗ trợ xử l\xfd hiệu quả cho c\xe1c nhiệm vụ phức tạp."},"llama3-groq-8b-8192-tool-use-preview":{"description":"Llama 3 Groq 8B Tool Use l\xe0 m\xf4 h\xecnh được tối ưu h\xf3a cho việc sử dụng c\xf4ng cụ hiệu quả, hỗ trợ t\xednh to\xe1n song song nhanh ch\xf3ng."},"llama3.1":{"description":"Llama 3.1 l\xe0 m\xf4 h\xecnh ti\xean tiến do Meta ph\xe1t h\xe0nh, hỗ trợ l\xean đến 405B tham số, c\xf3 thể \xe1p dụng cho c\xe1c cuộc đối thoại phức tạp, dịch đa ng\xf4n ngữ v\xe0 ph\xe2n t\xedch dữ liệu."},"llama3.1-8b":{"description":"Llama 3.1 8B: Phi\xean bản Llama nhỏ gọn, độ trễ thấp, ph\xf9 hợp với c\xe1c t\xecnh huống suy luận trực tuyến nhẹ v\xe0 tương t\xe1c thời gian thực."},"llama3.1:405b":{"description":"Llama 3.1 l\xe0 m\xf4 h\xecnh ti\xean tiến do Meta ph\xe1t h\xe0nh, hỗ trợ l\xean đến 405B tham số, c\xf3 thể \xe1p dụng cho c\xe1c cuộc đối thoại phức tạp, dịch đa ng\xf4n ngữ v\xe0 ph\xe2n t\xedch dữ liệu."},"llama3.1:70b":{"description":"Llama 3.1 l\xe0 m\xf4 h\xecnh ti\xean tiến do Meta ph\xe1t h\xe0nh, hỗ trợ l\xean đến 405B tham số, c\xf3 thể \xe1p dụng cho c\xe1c cuộc đối thoại phức tạp, dịch đa ng\xf4n ngữ v\xe0 ph\xe2n t\xedch dữ liệu."},"llava":{"description":"LLaVA l\xe0 m\xf4 h\xecnh đa phương thức kết hợp bộ m\xe3 h\xf3a h\xecnh ảnh v\xe0 Vicuna, phục vụ cho việc hiểu biết mạnh mẽ về h\xecnh ảnh v\xe0 ng\xf4n ngữ."},"llava-v1.5-7b-4096-preview":{"description":"LLaVA 1.5 7B cung cấp khả năng xử l\xfd h\xecnh ảnh t\xedch hợp, tạo ra đầu ra phức tạp th\xf4ng qua đầu v\xe0o th\xf4ng tin h\xecnh ảnh."},"llava:13b":{"description":"LLaVA l\xe0 m\xf4 h\xecnh đa phương thức kết hợp bộ m\xe3 h\xf3a h\xecnh ảnh v\xe0 Vicuna, phục vụ cho việc hiểu biết mạnh mẽ về h\xecnh ảnh v\xe0 ng\xf4n ngữ."},"llava:34b":{"description":"LLaVA l\xe0 m\xf4 h\xecnh đa phương thức kết hợp bộ m\xe3 h\xf3a h\xecnh ảnh v\xe0 Vicuna, phục vụ cho việc hiểu biết mạnh mẽ về h\xecnh ảnh v\xe0 ng\xf4n ngữ."},"magistral-medium-latest":{"description":"Magistral Medium 1.2 l\xe0 m\xf4 h\xecnh suy luận ti\xean tiến do Mistral AI ph\xe1t h\xe0nh v\xe0o th\xe1ng 9 năm 2025, c\xf3 hỗ trợ thị gi\xe1c."},"magistral-small-2509":{"description":"Magistral Small 1.2 l\xe0 m\xf4 h\xecnh suy luận nhỏ m\xe3 nguồn mở do Mistral AI ph\xe1t h\xe0nh v\xe0o th\xe1ng 9 năm 2025, c\xf3 hỗ trợ thị gi\xe1c."},"mathstral":{"description":"MathΣtral được thiết kế cho nghi\xean cứu khoa học v\xe0 suy luận to\xe1n học, cung cấp khả năng t\xednh to\xe1n hiệu quả v\xe0 giải th\xedch kết quả."},"max-32k":{"description":"Spark Max 32K được cấu h\xecnh với khả năng xử l\xfd ngữ cảnh lớn, c\xf3 khả năng hiểu ngữ cảnh v\xe0 suy luận logic mạnh mẽ hơn, hỗ trợ đầu v\xe0o văn bản 32K tokens, ph\xf9 hợp cho việc đọc t\xe0i liệu d\xe0i, hỏi đ\xe1p kiến thức ri\xeang tư v\xe0 c\xe1c t\xecnh huống kh\xe1c."},"megrez-3b-instruct":{"description":"Megrez 3B Instruct l\xe0 m\xf4 h\xecnh hiệu quả với số lượng tham số nhỏ do Wuwen Xinqiong ph\xe1t triển."},"meituan/longcat-flash-chat":{"description":"Longcat Flash Chat l\xe0 m\xf4 h\xecnh nền kh\xf4ng tư duy do Meituan m\xe3 nguồn mở, được tối ưu h\xf3a cho tương t\xe1c hội thoại v\xe0 nhiệm vụ của t\xe1c nh\xe2n, nổi bật trong việc gọi c\xf4ng cụ v\xe0 c\xe1c t\xecnh huống tương t\xe1c nhiều v\xf2ng phức tạp."},"meta-llama-3-70b-instruct":{"description":"M\xf4 h\xecnh 70 tỷ tham số mạnh mẽ, xuất sắc trong l\xfd luận, lập tr\xecnh v\xe0 c\xe1c ứng dụng ng\xf4n ngữ rộng lớn."},"meta-llama-3-8b-instruct":{"description":"M\xf4 h\xecnh 8 tỷ tham số đa năng, tối ưu h\xf3a cho c\xe1c t\xe1c vụ đối thoại v\xe0 tạo văn bản."},"meta-llama-3.1-405b-instruct":{"description":"C\xe1c m\xf4 h\xecnh văn bản chỉ được tinh chỉnh theo hướng dẫn Llama 3.1 được tối ưu h\xf3a cho c\xe1c trường hợp sử dụng đối thoại đa ng\xf4n ngữ v\xe0 vượt trội hơn nhiều m\xf4 h\xecnh tr\xf2 chuyện m\xe3 nguồn mở v\xe0 đ\xf3ng c\xf3 sẵn tr\xean c\xe1c ti\xeau chuẩn ng\xe0nh phổ biến."},"meta-llama-3.1-70b-instruct":{"description":"C\xe1c m\xf4 h\xecnh văn bản chỉ được tinh chỉnh theo hướng dẫn Llama 3.1 được tối ưu h\xf3a cho c\xe1c trường hợp sử dụng đối thoại đa ng\xf4n ngữ v\xe0 vượt trội hơn nhiều m\xf4 h\xecnh tr\xf2 chuyện m\xe3 nguồn mở v\xe0 đ\xf3ng c\xf3 sẵn tr\xean c\xe1c ti\xeau chuẩn ng\xe0nh phổ biến."},"meta-llama-3.1-8b-instruct":{"description":"C\xe1c m\xf4 h\xecnh văn bản chỉ được tinh chỉnh theo hướng dẫn Llama 3.1 được tối ưu h\xf3a cho c\xe1c trường hợp sử dụng đối thoại đa ng\xf4n ngữ v\xe0 vượt trội hơn nhiều m\xf4 h\xecnh tr\xf2 chuyện m\xe3 nguồn mở v\xe0 đ\xf3ng c\xf3 sẵn tr\xean c\xe1c ti\xeau chuẩn ng\xe0nh phổ biến."},"meta-llama/Llama-2-13b-chat-hf":{"description":"LLaMA-2 Chat (13B) cung cấp khả năng xử l\xfd ng\xf4n ngữ xuất sắc v\xe0 trải nghiệm tương t\xe1c tuyệt vời."},"meta-llama/Llama-2-70b-hf":{"description":"LLaMA-2 cung cấp khả năng xử l\xfd ng\xf4n ngữ tuyệt vời v\xe0 trải nghiệm tương t\xe1c xuất sắc."},"meta-llama/Llama-3-70b-chat-hf":{"description":"LLaMA-3 Chat (70B) l\xe0 m\xf4 h\xecnh tr\xf2 chuyện mạnh mẽ, hỗ trợ c\xe1c nhu cầu đối thoại phức tạp."},"meta-llama/Llama-3-8b-chat-hf":{"description":"LLaMA-3 Chat (8B) cung cấp hỗ trợ đa ng\xf4n ngữ, bao gồm nhiều lĩnh vực kiến thức phong ph\xfa."},"meta-llama/Llama-3.2-11B-Vision-Instruct-Turbo":{"description":"LLaMA 3.2 được thiết kế để xử l\xfd c\xe1c t\xe1c vụ kết hợp dữ liệu h\xecnh ảnh v\xe0 văn bản. N\xf3 c\xf3 khả năng xuất sắc trong c\xe1c t\xe1c vụ m\xf4 tả h\xecnh ảnh v\xe0 trả lời c\xe2u hỏi h\xecnh ảnh, vượt qua khoảng c\xe1ch giữa tạo ng\xf4n ngữ v\xe0 suy luận h\xecnh ảnh."},"meta-llama/Llama-3.2-3B-Instruct-Turbo":{"description":"LLaMA 3.2 được thiết kế để xử l\xfd c\xe1c t\xe1c vụ kết hợp dữ liệu h\xecnh ảnh v\xe0 văn bản. N\xf3 c\xf3 khả năng xuất sắc trong c\xe1c t\xe1c vụ m\xf4 tả h\xecnh ảnh v\xe0 trả lời c\xe2u hỏi h\xecnh ảnh, vượt qua khoảng c\xe1ch giữa tạo ng\xf4n ngữ v\xe0 suy luận h\xecnh ảnh."},"meta-llama/Llama-3.2-90B-Vision-Instruct-Turbo":{"description":"LLaMA 3.2 được thiết kế để xử l\xfd c\xe1c t\xe1c vụ kết hợp dữ liệu h\xecnh ảnh v\xe0 văn bản. N\xf3 c\xf3 khả năng xuất sắc trong c\xe1c t\xe1c vụ m\xf4 tả h\xecnh ảnh v\xe0 trả lời c\xe2u hỏi h\xecnh ảnh, vượt qua khoảng c\xe1ch giữa tạo ng\xf4n ngữ v\xe0 suy luận h\xecnh ảnh."},"meta-llama/Llama-3.3-70B-Instruct-Turbo":{"description":"M\xf4 h\xecnh ng\xf4n ngữ lớn đa ng\xf4n ngữ Meta Llama 3.3 (LLM) l\xe0 m\xf4 h\xecnh sinh ra từ 70B (đầu v\xe0o văn bản/đầu ra văn bản) với việc điều chỉnh trước v\xe0 điều chỉnh theo lệnh. M\xf4 h\xecnh điều chỉnh theo lệnh Llama 3.3 được tối ưu h\xf3a cho c\xe1c trường hợp sử dụng đối thoại đa ng\xf4n ngữ v\xe0 vượt trội hơn nhiều m\xf4 h\xecnh tr\xf2 chuyện m\xe3 nguồn mở v\xe0 đ\xf3ng kh\xe1c tr\xean c\xe1c b\xe0i kiểm tra chuẩn ng\xe0nh phổ biến."},"meta-llama/Llama-Vision-Free":{"description":"LLaMA 3.2 được thiết kế để xử l\xfd c\xe1c t\xe1c vụ kết hợp dữ liệu h\xecnh ảnh v\xe0 văn bản. N\xf3 c\xf3 khả năng xuất sắc trong c\xe1c t\xe1c vụ m\xf4 tả h\xecnh ảnh v\xe0 trả lời c\xe2u hỏi h\xecnh ảnh, vượt qua khoảng c\xe1ch giữa tạo ng\xf4n ngữ v\xe0 suy luận h\xecnh ảnh."},"meta-llama/Meta-Llama-3-70B-Instruct-Lite":{"description":"Llama 3 70B Instruct Lite ph\xf9 hợp cho c\xe1c m\xf4i trường cần hiệu suất cao v\xe0 độ trễ thấp."},"meta-llama/Meta-Llama-3-70B-Instruct-Turbo":{"description":"Llama 3 70B Instruct Turbo cung cấp khả năng hiểu v\xe0 sinh ng\xf4n ngữ xuất sắc, ph\xf9 hợp cho c\xe1c nhiệm vụ t\xednh to\xe1n khắt khe nhất."},"meta-llama/Meta-Llama-3-8B-Instruct-Lite":{"description":"Llama 3 8B Instruct Lite ph\xf9 hợp cho c\xe1c m\xf4i trường hạn chế t\xe0i nguy\xean, cung cấp hiệu suất c\xe2n bằng xuất sắc."},"meta-llama/Meta-Llama-3-8B-Instruct-Turbo":{"description":"Llama 3 8B Instruct Turbo l\xe0 một m\xf4 h\xecnh ng\xf4n ngữ lớn hiệu suất cao, hỗ trợ nhiều t\xecnh huống ứng dụng."},"meta-llama/Meta-Llama-3.1-405B-Instruct":{"description":"LLaMA 3.1 405B l\xe0 m\xf4 h\xecnh mạnh mẽ cho việc đ\xe0o tạo trước v\xe0 điều chỉnh theo hướng dẫn."},"meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo":{"description":"M\xf4 h\xecnh Llama 3.1 Turbo 405B cung cấp hỗ trợ ngữ cảnh dung lượng lớn cho xử l\xfd dữ liệu lớn, thể hiện xuất sắc trong c\xe1c ứng dụng tr\xed tuệ nh\xe2n tạo quy m\xf4 lớn."},"meta-llama/Meta-Llama-3.1-70B":{"description":"Llama 3.1 l\xe0 m\xf4 h\xecnh h\xe0ng đầu do Meta ph\xe1t h\xe0nh, hỗ trợ l\xean đến 405B tham số, c\xf3 thể \xe1p dụng cho cuộc đối thoại phức tạp, dịch đa ng\xf4n ngữ v\xe0 ph\xe2n t\xedch dữ liệu."},"meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo":{"description":"M\xf4 h\xecnh Llama 3.1 70B được tinh chỉnh để ph\xf9 hợp với c\xe1c ứng dụng tải cao, định lượng đến FP8 cung cấp khả năng t\xednh to\xe1n v\xe0 độ ch\xednh x\xe1c hiệu quả hơn, đảm bảo hiệu suất xuất sắc trong c\xe1c t\xecnh huống phức tạp."},"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo":{"description":"M\xf4 h\xecnh Llama 3.1 8B sử dụng định lượng FP8, hỗ trợ l\xean đến 131,072 m\xe3 ngữ cảnh, l\xe0 một trong những m\xf4 h\xecnh m\xe3 nguồn mở h\xe0ng đầu, ph\xf9 hợp cho c\xe1c nhiệm vụ phức tạp, vượt trội hơn nhiều ti\xeau chuẩn ng\xe0nh."},"meta-llama/llama-3-70b-instruct":{"description":"Llama 3 70B Instruct được tối ưu h\xf3a cho c\xe1c t\xecnh huống đối thoại chất lượng cao, thể hiện xuất sắc trong nhiều đ\xe1nh gi\xe1 của con người."},"meta-llama/llama-3-8b-instruct":{"description":"Llama 3 8B Instruct tối ưu h\xf3a cho c\xe1c t\xecnh huống đối thoại chất lượng cao, hiệu suất vượt trội hơn nhiều m\xf4 h\xecnh đ\xf3ng nguồn."},"meta-llama/llama-3.1-70b-instruct":{"description":"Llama 3.1 70B Instruct được thiết kế đặc biệt cho c\xe1c cuộc đối thoại chất lượng cao, thể hiện xuất sắc trong c\xe1c đ\xe1nh gi\xe1 của con người, đặc biệt ph\xf9 hợp cho c\xe1c t\xecnh huống tương t\xe1c cao."},"meta-llama/llama-3.1-8b-instruct":{"description":"Llama 3.1 8B Instruct l\xe0 phi\xean bản mới nhất do Meta ph\xe1t h\xe0nh, tối ưu h\xf3a cho c\xe1c t\xecnh huống đối thoại chất lượng cao, vượt trội hơn nhiều m\xf4 h\xecnh đ\xf3ng nguồn h\xe0ng đầu."},"meta-llama/llama-3.1-8b-instruct:free":{"description":"LLaMA 3.1 cung cấp hỗ trợ đa ng\xf4n ngữ, l\xe0 một trong những m\xf4 h\xecnh sinh h\xe0ng đầu trong ng\xe0nh."},"meta-llama/llama-3.2-11b-vision-instruct":{"description":"LLaMA 3.2 được thiết kế để xử l\xfd c\xe1c nhiệm vụ kết hợp dữ liệu h\xecnh ảnh v\xe0 văn bản. N\xf3 thể hiện xuất sắc trong c\xe1c nhiệm vụ m\xf4 tả h\xecnh ảnh v\xe0 hỏi đ\xe1p h\xecnh ảnh, vượt qua ranh giới giữa sinh ng\xf4n ngữ v\xe0 suy diễn h\xecnh ảnh."},"meta-llama/llama-3.2-3b-instruct":{"description":"meta-llama/llama-3.2-3b-instruct"},"meta-llama/llama-3.2-90b-vision-instruct":{"description":"LLaMA 3.2 được thiết kế để xử l\xfd c\xe1c nhiệm vụ kết hợp dữ liệu h\xecnh ảnh v\xe0 văn bản. N\xf3 thể hiện xuất sắc trong c\xe1c nhiệm vụ m\xf4 tả h\xecnh ảnh v\xe0 hỏi đ\xe1p h\xecnh ảnh, vượt qua ranh giới giữa sinh ng\xf4n ngữ v\xe0 suy diễn h\xecnh ảnh."},"meta-llama/llama-3.3-70b-instruct":{"description":"Llama 3.3 l\xe0 m\xf4 h\xecnh ng\xf4n ngữ lớn m\xe3 nguồn mở đa ng\xf4n ngữ ti\xean tiến nhất trong d\xf2ng Llama, mang đến trải nghiệm hiệu suất tương đương với m\xf4 h\xecnh 405B với chi ph\xed cực thấp. Dựa tr\xean cấu tr\xfac Transformer, v\xe0 được cải thiện t\xednh hữu \xedch v\xe0 an to\xe0n th\xf4ng qua tinh chỉnh gi\xe1m s\xe1t (SFT) v\xe0 học tăng cường từ phản hồi của con người (RLHF). Phi\xean bản tinh chỉnh theo chỉ dẫn của n\xf3 được tối ưu h\xf3a cho đối thoại đa ng\xf4n ngữ, thể hiện tốt hơn nhiều m\xf4 h\xecnh tr\xf2 chuyện m\xe3 nguồn mở v\xe0 đ\xf3ng k\xedn trong nhiều ti\xeau chuẩn ng\xe0nh. Ng\xe0y cắt đứt kiến thức l\xe0 th\xe1ng 12 năm 2023."},"meta-llama/llama-3.3-70b-instruct:free":{"description":"Llama 3.3 l\xe0 m\xf4 h\xecnh ng\xf4n ngữ lớn m\xe3 nguồn mở đa ng\xf4n ngữ ti\xean tiến nhất trong d\xf2ng Llama, mang đến trải nghiệm hiệu suất tương đương với m\xf4 h\xecnh 405B với chi ph\xed cực thấp. Dựa tr\xean cấu tr\xfac Transformer, v\xe0 được cải thiện t\xednh hữu \xedch v\xe0 an to\xe0n th\xf4ng qua tinh chỉnh gi\xe1m s\xe1t (SFT) v\xe0 học tăng cường từ phản hồi của con người (RLHF). Phi\xean bản tinh chỉnh theo chỉ dẫn của n\xf3 được tối ưu h\xf3a cho đối thoại đa ng\xf4n ngữ, thể hiện tốt hơn nhiều m\xf4 h\xecnh tr\xf2 chuyện m\xe3 nguồn mở v\xe0 đ\xf3ng k\xedn trong nhiều ti\xeau chuẩn ng\xe0nh. Ng\xe0y cắt đứt kiến thức l\xe0 th\xe1ng 12 năm 2023."},"meta.llama3-1-405b-instruct-v1:0":{"description":"Meta Llama 3.1 405B Instruct l\xe0 m\xf4 h\xecnh lớn nhất v\xe0 mạnh mẽ nhất trong m\xf4 h\xecnh Llama 3.1 Instruct, l\xe0 một m\xf4 h\xecnh sinh dữ liệu v\xe0 suy luận đối thoại ti\xean tiến, cũng c\xf3 thể được sử dụng l\xe0m nền tảng cho việc tiền huấn luyện hoặc tinh chỉnh chuy\xean s\xe2u trong c\xe1c lĩnh vực cụ thể. C\xe1c m\xf4 h\xecnh ng\xf4n ngữ lớn đa ng\xf4n ngữ (LLMs) m\xe0 Llama 3.1 cung cấp l\xe0 một tập hợp c\xe1c m\xf4 h\xecnh sinh đ\xe3 được tiền huấn luyện v\xe0 điều chỉnh theo chỉ dẫn, bao gồm k\xedch thước 8B, 70B v\xe0 405B (đầu v\xe0o/đầu ra văn bản). C\xe1c m\xf4 h\xecnh văn bản điều chỉnh theo chỉ dẫn của Llama 3.1 (8B, 70B, 405B) được tối ưu h\xf3a cho c\xe1c trường hợp đối thoại đa ng\xf4n ngữ v\xe0 đ\xe3 vượt qua nhiều m\xf4 h\xecnh tr\xf2 chuyện m\xe3 nguồn mở c\xf3 sẵn trong c\xe1c b\xe0i kiểm tra chuẩn ng\xe0nh phổ biến. Llama 3.1 được thiết kế để sử dụng cho nhiều mục đ\xedch thương mại v\xe0 nghi\xean cứu bằng nhiều ng\xf4n ngữ. C\xe1c m\xf4 h\xecnh văn bản điều chỉnh theo chỉ dẫn ph\xf9 hợp cho c\xe1c cuộc tr\xf2 chuyện giống như trợ l\xfd, trong khi c\xe1c m\xf4 h\xecnh đ\xe3 được tiền huấn luyện c\xf3 thể th\xedch ứng với nhiều nhiệm vụ sinh ng\xf4n ngữ tự nhi\xean kh\xe1c nhau. M\xf4 h\xecnh Llama 3.1 cũng hỗ trợ việc cải thiện c\xe1c m\xf4 h\xecnh kh\xe1c bằng c\xe1ch sử dụng đầu ra của n\xf3, bao gồm sinh dữ liệu tổng hợp v\xe0 tinh chỉnh. Llama 3.1 l\xe0 một m\xf4 h\xecnh ng\xf4n ngữ tự hồi quy sử dụng kiến tr\xfac biến \xe1p tối ưu. Phi\xean bản điều chỉnh sử dụng tinh chỉnh c\xf3 gi\xe1m s\xe1t (SFT) v\xe0 học tăng cường c\xf3 phản hồi từ con người (RLHF) để ph\xf9 hợp với sở th\xedch của con người về t\xednh hữu \xedch v\xe0 an to\xe0n."},"meta.llama3-1-70b-instruct-v1:0":{"description":"Phi\xean bản cập nhật của Meta Llama 3.1 70B Instruct, bao gồm độ d\xe0i ngữ cảnh mở rộng 128K, t\xednh đa ng\xf4n ngữ v\xe0 khả năng suy luận cải tiến. C\xe1c m\xf4 h\xecnh ng\xf4n ngữ lớn (LLMs) đa ng\xf4n ngữ do Llama 3.1 cung cấp l\xe0 một tập hợp c\xe1c m\xf4 h\xecnh sinh đ\xe3 được huấn luyện trước v\xe0 điều chỉnh theo chỉ dẫn, bao gồm k\xedch thước 8B, 70B v\xe0 405B (đầu v\xe0o/đầu ra văn bản). C\xe1c m\xf4 h\xecnh văn bản điều chỉnh theo chỉ dẫn của Llama 3.1 (8B, 70B, 405B) được tối ưu h\xf3a cho c\xe1c trường hợp đối thoại đa ng\xf4n ngữ v\xe0 đ\xe3 vượt qua nhiều m\xf4 h\xecnh tr\xf2 chuyện m\xe3 nguồn mở c\xf3 sẵn trong c\xe1c b\xe0i kiểm tra chuẩn ng\xe0nh phổ biến. Llama 3.1 được thiết kế cho c\xe1c mục đ\xedch thương mại v\xe0 nghi\xean cứu đa ng\xf4n ngữ. C\xe1c m\xf4 h\xecnh văn bản điều chỉnh theo chỉ dẫn ph\xf9 hợp cho c\xe1c cuộc tr\xf2 chuyện giống như trợ l\xfd, trong khi c\xe1c m\xf4 h\xecnh đ\xe3 được huấn luyện trước c\xf3 thể th\xedch ứng với nhiều nhiệm vụ sinh ng\xf4n ngữ tự nhi\xean kh\xe1c nhau. M\xf4 h\xecnh Llama 3.1 cũng hỗ trợ việc sử dụng đầu ra của m\xf4 h\xecnh để cải thiện c\xe1c m\xf4 h\xecnh kh\xe1c, bao gồm tạo dữ liệu tổng hợp v\xe0 tinh chỉnh. Llama 3.1 l\xe0 m\xf4 h\xecnh ng\xf4n ngữ tự hồi quy sử dụng kiến tr\xfac biến \xe1p được tối ưu h\xf3a. Phi\xean bản điều chỉnh sử dụng tinh chỉnh gi\xe1m s\xe1t (SFT) v\xe0 học tăng cường c\xf3 phản hồi của con người (RLHF) để ph\xf9 hợp với sở th\xedch của con người về t\xednh hữu \xedch v\xe0 an to\xe0n."},"meta.llama3-1-8b-instruct-v1:0":{"description":"Phi\xean bản cập nhật của Meta Llama 3.1 8B Instruct, bao gồm độ d\xe0i ngữ cảnh mở rộng 128K, t\xednh đa ng\xf4n ngữ v\xe0 khả năng suy luận cải tiến. C\xe1c m\xf4 h\xecnh ng\xf4n ngữ lớn (LLMs) đa ng\xf4n ngữ do Llama 3.1 cung cấp l\xe0 một tập hợp c\xe1c m\xf4 h\xecnh sinh đ\xe3 được huấn luyện trước v\xe0 điều chỉnh theo chỉ dẫn, bao gồm k\xedch thước 8B, 70B v\xe0 405B (đầu v\xe0o/đầu ra văn bản). C\xe1c m\xf4 h\xecnh văn bản điều chỉnh theo chỉ dẫn của Llama 3.1 (8B, 70B, 405B) được tối ưu h\xf3a cho c\xe1c trường hợp đối thoại đa ng\xf4n ngữ v\xe0 đ\xe3 vượt qua nhiều m\xf4 h\xecnh tr\xf2 chuyện m\xe3 nguồn mở c\xf3 sẵn trong c\xe1c b\xe0i kiểm tra chuẩn ng\xe0nh phổ biến. Llama 3.1 được thiết kế cho c\xe1c mục đ\xedch thương mại v\xe0 nghi\xean cứu đa ng\xf4n ngữ. C\xe1c m\xf4 h\xecnh văn bản điều chỉnh theo chỉ dẫn ph\xf9 hợp cho c\xe1c cuộc tr\xf2 chuyện giống như trợ l\xfd, trong khi c\xe1c m\xf4 h\xecnh đ\xe3 được huấn luyện trước c\xf3 thể th\xedch ứng với nhiều nhiệm vụ sinh ng\xf4n ngữ tự nhi\xean kh\xe1c nhau. M\xf4 h\xecnh Llama 3.1 cũng hỗ trợ việc sử dụng đầu ra của m\xf4 h\xecnh để cải thiện c\xe1c m\xf4 h\xecnh kh\xe1c, bao gồm tạo dữ liệu tổng hợp v\xe0 tinh chỉnh. Llama 3.1 l\xe0 m\xf4 h\xecnh ng\xf4n ngữ tự hồi quy sử dụng kiến tr\xfac biến \xe1p được tối ưu h\xf3a. Phi\xean bản điều chỉnh sử dụng tinh chỉnh gi\xe1m s\xe1t (SFT) v\xe0 học tăng cường c\xf3 phản hồi của con người (RLHF) để ph\xf9 hợp với sở th\xedch của con người về t\xednh hữu \xedch v\xe0 an to\xe0n."},"meta.llama3-70b-instruct-v1:0":{"description":"Meta Llama 3 l\xe0 một m\xf4 h\xecnh ng\xf4n ngữ lớn (LLM) mở d\xe0nh cho c\xe1c nh\xe0 ph\xe1t triển, nh\xe0 nghi\xean cứu v\xe0 doanh nghiệp, nhằm gi\xfap họ x\xe2y dựng, thử nghiệm v\xe0 mở rộng \xfd tưởng AI sinh một c\xe1ch c\xf3 tr\xe1ch nhiệm. L\xe0 một phần của hệ thống cơ sở hạ tầng đổi mới to\xe0n cầu, n\xf3 rất ph\xf9 hợp cho việc tạo nội dung, AI đối thoại, hiểu ng\xf4n ngữ, nghi\xean cứu v\xe0 ứng dụng doanh nghiệp."},"meta.llama3-8b-instruct-v1:0":{"description":"Meta Llama 3 l\xe0 một m\xf4 h\xecnh ng\xf4n ngữ lớn (LLM) mở d\xe0nh cho c\xe1c nh\xe0 ph\xe1t triển, nh\xe0 nghi\xean cứu v\xe0 doanh nghiệp, nhằm gi\xfap họ x\xe2y dựng, thử nghiệm v\xe0 mở rộng \xfd tưởng AI sinh một c\xe1ch c\xf3 tr\xe1ch nhiệm. L\xe0 một phần của hệ thống cơ sở hạ tầng đổi mới to\xe0n cầu, n\xf3 rất ph\xf9 hợp cho c\xe1c thiết bị bi\xean v\xe0 thời gian huấn luyện nhanh hơn với khả năng t\xednh to\xe1n v\xe0 t\xe0i nguy\xean hạn chế."},"meta/Llama-3.2-11B-Vision-Instruct":{"description":"Khả năng suy luận h\xecnh ảnh xuất sắc tr\xean h\xecnh ảnh độ ph\xe2n giải cao, ph\xf9 hợp cho c\xe1c ứng dụng hiểu biết thị gi\xe1c."},"meta/Llama-3.2-90B-Vision-Instruct":{"description":"Khả năng suy luận h\xecnh ảnh n\xe2ng cao d\xe0nh cho c\xe1c ứng dụng đại l\xfd hiểu biết thị gi\xe1c."},"meta/Llama-3.3-70B-Instruct":{"description":"Llama 3.3 l\xe0 m\xf4 h\xecnh ng\xf4n ngữ lớn đa ng\xf4n ngữ m\xe3 nguồn mở ti\xean tiến nhất trong d\xf2ng Llama, mang lại hiệu suất tương đương m\xf4 h\xecnh 405 tỷ tham số với chi ph\xed rất thấp. Dựa tr\xean kiến tr\xfac Transformer, được cải thiện qua huấn luyện gi\xe1m s\xe1t (SFT) v\xe0 học tăng cường từ phản hồi con người (RLHF) để n\xe2ng cao t\xednh hữu \xedch v\xe0 an to\xe0n. Phi\xean bản tinh chỉnh chỉ dẫn được tối ưu cho đối thoại đa ng\xf4n ngữ, vượt trội tr\xean nhiều chuẩn mực ng\xe0nh so với nhiều m\xf4 h\xecnh tr\xf2 chuyện m\xe3 nguồn mở v\xe0 đ\xf3ng. Kiến thức cập nhật đến th\xe1ng 12 năm 2023."},"meta/Meta-Llama-3-70B-Instruct":{"description":"Một m\xf4 h\xecnh mạnh mẽ với 70 tỷ tham số, thể hiện xuất sắc trong suy luận, m\xe3 h\xf3a v\xe0 c\xe1c ứng dụng ng\xf4n ngữ đa dạng."},"meta/Meta-Llama-3-8B-Instruct":{"description":"Một m\xf4 h\xecnh đa năng với 8 tỷ tham số, được tối ưu cho c\xe1c nhiệm vụ đối thoại v\xe0 tạo văn bản."},"meta/Meta-Llama-3.1-405B-Instruct":{"description":"M\xf4 h\xecnh văn bản Llama 3.1 được tinh chỉnh chỉ dẫn, tối ưu cho c\xe1c trường hợp sử dụng đối thoại đa ng\xf4n ngữ, thể hiện xuất sắc tr\xean nhiều chuẩn mực ng\xe0nh so với nhiều m\xf4 h\xecnh tr\xf2 chuyện m\xe3 nguồn mở v\xe0 đ\xf3ng hiện c\xf3."},"meta/Meta-Llama-3.1-70B-Instruct":{"description":"M\xf4 h\xecnh văn bản Llama 3.1 được tinh chỉnh chỉ dẫn, tối ưu cho c\xe1c trường hợp sử dụng đối thoại đa ng\xf4n ngữ, thể hiện xuất sắc tr\xean nhiều chuẩn mực ng\xe0nh so với nhiều m\xf4 h\xecnh tr\xf2 chuyện m\xe3 nguồn mở v\xe0 đ\xf3ng hiện c\xf3."},"meta/Meta-Llama-3.1-8B-Instruct":{"description":"M\xf4 h\xecnh văn bản Llama 3.1 được tinh chỉnh chỉ dẫn, tối ưu cho c\xe1c trường hợp sử dụng đối thoại đa ng\xf4n ngữ, thể hiện xuất sắc tr\xean nhiều chuẩn mực ng\xe0nh so với nhiều m\xf4 h\xecnh tr\xf2 chuyện m\xe3 nguồn mở v\xe0 đ\xf3ng hiện c\xf3."},"meta/llama-3-70b":{"description":"M\xf4 h\xecnh m\xe3 nguồn mở 70 tỷ tham số được Meta tinh chỉnh kỹ lưỡng cho mục đ\xedch tu\xe2n thủ chỉ dẫn. Được Groq phục vụ bằng phần cứng đơn vị xử l\xfd ng\xf4n ngữ (LPU) t\xf9y chỉnh để cung cấp suy luận nhanh v\xe0 hiệu quả."},"meta/llama-3-8b":{"description":"M\xf4 h\xecnh m\xe3 nguồn mở 8 tỷ tham số được Meta tinh chỉnh kỹ lưỡng cho mục đ\xedch tu\xe2n thủ chỉ dẫn. Được Groq phục vụ bằng phần cứng đơn vị xử l\xfd ng\xf4n ngữ (LPU) t\xf9y chỉnh để cung cấp suy luận nhanh v\xe0 hiệu quả."},"meta/llama-3.1-405b-instruct":{"description":"LLM cao cấp, hỗ trợ tạo dữ liệu tổng hợp, chưng cất kiến thức v\xe0 suy luận, ph\xf9 hợp cho chatbot, lập tr\xecnh v\xe0 c\xe1c nhiệm vụ chuy\xean biệt."},"meta/llama-3.1-70b":{"description":"Phi\xean bản cập nhật của Meta Llama 3 70B Instruct, bao gồm độ d\xe0i ngữ cảnh mở rộng 128K, đa ng\xf4n ngữ v\xe0 khả năng suy luận cải tiến."},"meta/llama-3.1-70b-instruct":{"description":"Tăng cường cuộc đối thoại phức tạp, c\xf3 khả năng hiểu ngữ cảnh xuất sắc, suy luận v\xe0 sinh văn bản."},"meta/llama-3.1-8b":{"description":"Llama 3.1 8B hỗ trợ cửa sổ ngữ cảnh 128K, l\xe0 lựa chọn l\xfd tưởng cho giao diện đối thoại thời gian thực v\xe0 ph\xe2n t\xedch dữ liệu, đồng thời tiết kiệm chi ph\xed đ\xe1ng kể so với c\xe1c m\xf4 h\xecnh lớn hơn. Được Groq phục vụ bằng phần cứng đơn vị xử l\xfd ng\xf4n ngữ (LPU) t\xf9y chỉnh để cung cấp suy luận nhanh v\xe0 hiệu quả."},"meta/llama-3.1-8b-instruct":{"description":"M\xf4 h\xecnh ti\xean tiến h\xe0ng đầu, c\xf3 khả năng hiểu ng\xf4n ngữ, suy luận xuất sắc v\xe0 khả năng sinh văn bản."},"meta/llama-3.2-11b":{"description":"M\xf4 h\xecnh tạo suy luận h\xecnh ảnh được điều chỉnh chỉ dẫn (đầu v\xe0o văn bản + h\xecnh ảnh / đầu ra văn bản), tối ưu cho nhận dạng h\xecnh ảnh, suy luận h\xecnh ảnh, tạo ch\xfa th\xedch v\xe0 trả lời c\xe1c c\xe2u hỏi chung về h\xecnh ảnh."},"meta/llama-3.2-11b-vision-instruct":{"description":"M\xf4 h\xecnh thị gi\xe1c-ng\xf4n ngữ ti\xean tiến, xuất sắc trong việc suy luận chất lượng cao từ h\xecnh ảnh."},"meta/llama-3.2-1b":{"description":"M\xf4 h\xecnh chỉ văn bản, hỗ trợ c\xe1c trường hợp sử dụng tr\xean thiết bị như truy xuất kiến thức địa phương đa ng\xf4n ngữ, t\xf3m tắt v\xe0 viết lại."},"meta/llama-3.2-1b-instruct":{"description":"M\xf4 h\xecnh ng\xf4n ngữ nhỏ ti\xean tiến h\xe0ng đầu, c\xf3 khả năng hiểu ng\xf4n ngữ, suy luận xuất sắc v\xe0 khả năng sinh văn bản."},"meta/llama-3.2-3b":{"description":"M\xf4 h\xecnh chỉ văn bản, được tinh chỉnh kỹ lưỡng để hỗ trợ c\xe1c trường hợp sử dụng tr\xean thiết bị như truy xuất kiến thức địa phương đa ng\xf4n ngữ, t\xf3m tắt v\xe0 viết lại."},"meta/llama-3.2-3b-instruct":{"description":"M\xf4 h\xecnh ng\xf4n ngữ nhỏ ti\xean tiến h\xe0ng đầu, c\xf3 khả năng hiểu ng\xf4n ngữ, suy luận xuất sắc v\xe0 khả năng sinh văn bản."},"meta/llama-3.2-90b":{"description":"M\xf4 h\xecnh tạo suy luận h\xecnh ảnh được điều chỉnh chỉ dẫn (đầu v\xe0o văn bản + h\xecnh ảnh / đầu ra văn bản), tối ưu cho nhận dạng h\xecnh ảnh, suy luận h\xecnh ảnh, tạo ch\xfa th\xedch v\xe0 trả lời c\xe1c c\xe2u hỏi chung về h\xecnh ảnh."},"meta/llama-3.2-90b-vision-instruct":{"description":"M\xf4 h\xecnh thị gi\xe1c-ng\xf4n ngữ ti\xean tiến, xuất sắc trong việc suy luận chất lượng cao từ h\xecnh ảnh."},"meta/llama-3.3-70b":{"description":"Sự kết hợp ho\xe0n hảo giữa hiệu suất v\xe0 hiệu quả. M\xf4 h\xecnh hỗ trợ AI đối thoại hiệu suất cao, được thiết kế cho tạo nội dung, ứng dụng doanh nghiệp v\xe0 nghi\xean cứu, cung cấp khả năng hiểu ng\xf4n ngữ ti\xean tiến bao gồm t\xf3m tắt văn bản, ph\xe2n loại, ph\xe2n t\xedch cảm x\xfac v\xe0 tạo m\xe3."},"meta/llama-3.3-70b-instruct":{"description":"M\xf4 h\xecnh LLM ti\xean tiến, xuất sắc trong suy luận, to\xe1n học, kiến thức chung v\xe0 gọi h\xe0m."},"meta/llama-4-maverick":{"description":"Bộ m\xf4 h\xecnh Llama 4 l\xe0 c\xe1c m\xf4 h\xecnh AI đa phương thức nguy\xean bản, hỗ trợ trải nghiệm văn bản v\xe0 đa phương thức. C\xe1c m\xf4 h\xecnh n\xe0y sử dụng kiến tr\xfac chuy\xean gia hỗn hợp để cung cấp hiệu suất h\xe0ng đầu ng\xe0nh trong hiểu văn bản v\xe0 h\xecnh ảnh. Llama 4 Maverick, m\xf4 h\xecnh 17 tỷ tham số với 128 chuy\xean gia. Được DeepInfra phục vụ."},"meta/llama-4-scout":{"description":"Bộ m\xf4 h\xecnh Llama 4 l\xe0 c\xe1c m\xf4 h\xecnh AI đa phương thức nguy\xean bản, hỗ trợ trải nghiệm văn bản v\xe0 đa phương thức. C\xe1c m\xf4 h\xecnh n\xe0y sử dụng kiến tr\xfac chuy\xean gia hỗn hợp để cung cấp hiệu suất h\xe0ng đầu ng\xe0nh trong hiểu văn bản v\xe0 h\xecnh ảnh. Llama 4 Scout, m\xf4 h\xecnh 17 tỷ tham số với 16 chuy\xean gia. Được DeepInfra phục vụ."},"microsoft/Phi-3-medium-128k-instruct":{"description":"C\xf9ng m\xf4 h\xecnh Phi-3-medium nhưng với k\xedch thước ngữ cảnh lớn hơn, ph\xf9 hợp cho RAG hoặc \xedt gợi \xfd."},"microsoft/Phi-3-medium-4k-instruct":{"description":"M\xf4 h\xecnh 14 tỷ tham số, chất lượng vượt trội so với Phi-3-mini, tập trung v\xe0o dữ liệu suy luận chất lượng cao."},"microsoft/Phi-3-mini-128k-instruct":{"description":"C\xf9ng m\xf4 h\xecnh Phi-3-mini nhưng với k\xedch thước ngữ cảnh lớn hơn, ph\xf9 hợp cho RAG hoặc \xedt gợi \xfd."},"microsoft/Phi-3-mini-4k-instruct":{"description":"Th\xe0nh vi\xean nhỏ nhất trong gia đ\xecnh Phi-3, được tối ưu cho chất lượng v\xe0 độ trễ thấp."},"microsoft/Phi-3-small-128k-instruct":{"description":"C\xf9ng m\xf4 h\xecnh Phi-3-small nhưng với k\xedch thước ngữ cảnh lớn hơn, ph\xf9 hợp cho RAG hoặc \xedt gợi \xfd."},"microsoft/Phi-3-small-8k-instruct":{"description":"M\xf4 h\xecnh 7 tỷ tham số, chất lượng vượt trội so với Phi-3-mini, tập trung v\xe0o dữ liệu suy luận chất lượng cao."},"microsoft/Phi-3.5-mini-instruct":{"description":"Phi\xean bản cập nhật của m\xf4 h\xecnh Phi-3-mini."},"microsoft/Phi-3.5-vision-instruct":{"description":"Phi\xean bản cập nhật của m\xf4 h\xecnh Phi-3-vision."},"microsoft/WizardLM-2-8x22B":{"description":"WizardLM 2 l\xe0 m\xf4 h\xecnh ng\xf4n ngữ do AI của Microsoft cung cấp, thể hiện xuất sắc trong c\xe1c lĩnh vực đối thoại phức tạp, đa ng\xf4n ngữ, suy luận v\xe0 trợ l\xfd th\xf4ng minh."},"microsoft/wizardlm-2-8x22b":{"description":"WizardLM-2 8x22B l\xe0 m\xf4 h\xecnh Wizard ti\xean tiến nhất của Microsoft AI, thể hiện hiệu suất cực kỳ cạnh tranh."},"minicpm-v":{"description":"MiniCPM-V l\xe0 m\xf4 h\xecnh đa phương thức thế hệ mới do OpenBMB ph\xe1t triển, c\xf3 khả năng nhận diện OCR xuất sắc v\xe0 hiểu biết đa phương thức, hỗ trợ nhiều ứng dụng kh\xe1c nhau."},"minimax-m2":{"description":"MiniMax M2 l\xe0 một m\xf4 h\xecnh ng\xf4n ngữ lớn hiệu quả, được x\xe2y dựng d\xe0nh ri\xeang cho quy tr\xecnh l\xe0m việc li\xean quan đến lập tr\xecnh v\xe0 t\xe1c vụ đại l\xfd."},"minimax/minimax-m2":{"description":"Được sinh ra để phục vụ m\xe3 h\xf3a hiệu quả v\xe0 quy tr\xecnh l\xe0m việc của Agent."},"minimaxai/minimax-m2":{"description":"MiniMax-M2 l\xe0 một m\xf4 h\xecnh chuy\xean gia hỗn hợp (MoE) nhỏ gọn, nhanh ch\xf3ng v\xe0 tiết kiệm chi ph\xed, với tổng số 230 tỷ tham số v\xe0 10 tỷ tham số k\xedch hoạt, được thiết kế để đạt hiệu suất h\xe0ng đầu trong c\xe1c t\xe1c vụ m\xe3 h\xf3a v\xe0 t\xe1c nh\xe2n, đồng thời duy tr\xec tr\xed tuệ nh\xe2n tạo tổng qu\xe1t mạnh mẽ. M\xf4 h\xecnh n\xe0y thể hiện xuất sắc trong chỉnh sửa nhiều tệp, v\xf2ng lặp m\xe3 h\xf3a-chạy-sửa lỗi, kiểm thử v\xe0 sửa lỗi, cũng như c\xe1c chuỗi c\xf4ng cụ li\xean kết d\xe0i phức tạp, l\xe0 lựa chọn l\xfd tưởng cho quy tr\xecnh l\xe0m việc của nh\xe0 ph\xe1t triển."},"ministral-3b-latest":{"description":"Ministral 3B l\xe0 m\xf4 h\xecnh h\xe0ng đầu thế giới của Mistral về hiệu suất cạnh bi\xean."},"ministral-8b-latest":{"description":"Ministral 8B l\xe0 m\xf4 h\xecnh cạnh bi\xean cực kỳ tiết kiệm chi ph\xed của Mistral."},"mistral":{"description":"Mistral l\xe0 m\xf4 h\xecnh 7B do Mistral AI ph\xe1t h\xe0nh, ph\xf9 hợp cho c\xe1c nhu cầu xử l\xfd ng\xf4n ngữ đa dạng."},"mistral-ai/Mistral-Large-2411":{"description":"M\xf4 h\xecnh chủ lực của Mistral, ph\xf9 hợp cho c\xe1c nhiệm vụ phức tạp cần khả năng suy luận quy m\xf4 lớn hoặc chuy\xean m\xf4n cao (tổng hợp văn bản, tạo m\xe3, RAG hoặc đại l\xfd)."},"mistral-ai/Mistral-Nemo":{"description":"Mistral Nemo l\xe0 một m\xf4 h\xecnh ng\xf4n ngữ ti\xean tiến (LLM), sở hữu khả năng suy luận, kiến thức thế giới v\xe0 m\xe3 h\xf3a h\xe0ng đầu trong ph\xe2n kh\xfac k\xedch thước của n\xf3."},"mistral-ai/mistral-small-2503":{"description":"Mistral Small ph\xf9 hợp cho bất kỳ nhiệm vụ dựa tr\xean ng\xf4n ngữ n\xe0o cần hiệu quả cao v\xe0 độ trễ thấp."},"mistral-large":{"description":"Mixtral Large l\xe0 m\xf4 h\xecnh h\xe0ng đầu của Mistral, kết hợp khả năng sinh m\xe3, to\xe1n học v\xe0 suy luận, hỗ trợ cửa sổ ngữ cảnh 128k."},"mistral-large-instruct":{"description":"Mistral-Large-Instruct-2407 l\xe0 một m\xf4 h\xecnh ng\xf4n ngữ lớn (LLM) ti\xean tiến, c\xf3 123 tỷ tham số, với khả năng suy luận, kiến thức v\xe0 lập tr\xecnh h\xe0ng đầu."},"mistral-large-latest":{"description":"Mistral Large l\xe0 m\xf4 h\xecnh lớn h\xe0ng đầu, chuy\xean về c\xe1c nhiệm vụ đa ng\xf4n ngữ, suy luận phức tạp v\xe0 sinh m\xe3, l\xe0 lựa chọn l\xfd tưởng cho c\xe1c ứng dụng cao cấp."},"mistral-medium-latest":{"description":"Mistral Medium 3 cung cấp hiệu suất ti\xean tiến với chi ph\xed gấp 8 lần v\xe0 đơn giản h\xf3a việc triển khai doanh nghiệp."},"mistral-nemo":{"description":"Mistral Nemo được ph\xe1t triển hợp t\xe1c giữa Mistral AI v\xe0 NVIDIA, l\xe0 m\xf4 h\xecnh 12B hiệu suất cao."},"mistral-nemo-instruct":{"description":"M\xf4 h\xecnh ng\xf4n ngữ lớn Mistral-Nemo-Instruct-2407 (LLM) l\xe0 phi\xean bản điều chỉnh lệnh của Mistral-Nemo-Base-2407."},"mistral-small":{"description":"Mistral Small c\xf3 thể được sử dụng cho bất kỳ nhiệm vụ n\xe0o dựa tr\xean ng\xf4n ngữ y\xeau cầu hiệu suất cao v\xe0 độ trễ thấp."},"mistral-small-latest":{"description":"Mistral Small l\xe0 lựa chọn hiệu quả về chi ph\xed, nhanh ch\xf3ng v\xe0 đ\xe1ng tin cậy, ph\xf9 hợp cho c\xe1c trường hợp như dịch thuật, t\xf3m tắt v\xe0 ph\xe2n t\xedch cảm x\xfac."},"mistral/codestral":{"description":"Mistral Codestral 25.01 l\xe0 m\xf4 h\xecnh m\xe3 h\xf3a ti\xean tiến, được tối ưu cho c\xe1c trường hợp sử dụng độ trễ thấp v\xe0 tần suất cao. Th\xe0nh thạo hơn 80 ng\xf4n ngữ lập tr\xecnh, n\xf3 thể hiện xuất sắc trong c\xe1c nhiệm vụ như điền giữa (FIM), sửa lỗi m\xe3 v\xe0 tạo kiểm thử."},"mistral/codestral-embed":{"description":"M\xf4 h\xecnh nh\xfang m\xe3 để t\xedch hợp v\xe0o cơ sở dữ liệu v\xe0 kho lưu trữ m\xe3, hỗ trợ trợ l\xfd m\xe3 h\xf3a."},"mistral/devstral-small":{"description":"Devstral l\xe0 m\xf4 h\xecnh ng\xf4n ngữ lớn đại l\xfd cho c\xe1c nhiệm vụ kỹ thuật phần mềm, l\xe0 lựa chọn tuyệt vời cho đại l\xfd kỹ thuật phần mềm."},"mistral/magistral-medium":{"description":"Tư duy phức tạp được hỗ trợ bởi sự hiểu biết s\xe2u sắc, với suy luận minh bạch m\xe0 bạn c\xf3 thể theo d\xf5i v\xe0 x\xe1c minh. M\xf4 h\xecnh duy tr\xec suy luận độ trung thực cao tr\xean nhiều ng\xf4n ngữ ngay cả khi chuyển đổi ng\xf4n ngữ giữa chừng trong nhiệm vụ."},"mistral/magistral-small":{"description":"Tư duy phức tạp được hỗ trợ bởi sự hiểu biết s\xe2u sắc, với suy luận minh bạch m\xe0 bạn c\xf3 thể theo d\xf5i v\xe0 x\xe1c minh. M\xf4 h\xecnh duy tr\xec suy luận độ trung thực cao tr\xean nhiều ng\xf4n ngữ ngay cả khi chuyển đổi ng\xf4n ngữ giữa chừng trong nhiệm vụ."},"mistral/ministral-3b":{"description":"M\xf4 h\xecnh nhỏ gọn, hiệu quả cho c\xe1c nhiệm vụ tr\xean thiết bị như trợ l\xfd th\xf4ng minh v\xe0 ph\xe2n t\xedch cục bộ, cung cấp hiệu suất độ trễ thấp."},"mistral/ministral-8b":{"description":"M\xf4 h\xecnh mạnh mẽ hơn với suy luận nhanh hơn v\xe0 tiết kiệm bộ nhớ, l\xe0 lựa chọn l\xfd tưởng cho c\xe1c quy tr\xecnh l\xe0m việc phức tạp v\xe0 ứng dụng bi\xean đ\xf2i hỏi cao."},"mistral/mistral-embed":{"description":"M\xf4 h\xecnh nh\xfang văn bản đa năng cho t\xecm kiếm ngữ nghĩa, tương đồng, ph\xe2n cụm v\xe0 quy tr\xecnh l\xe0m việc RAG."},"mistral/mistral-large":{"description":"Mistral Large l\xe0 lựa chọn l\xfd tưởng cho c\xe1c nhiệm vụ phức tạp đ\xf2i hỏi khả năng suy luận lớn hoặc chuy\xean m\xf4n cao — như tạo văn bản tổng hợp, tạo m\xe3, RAG hoặc đại l\xfd."},"mistral/mistral-small":{"description":"Mistral Small l\xe0 lựa chọn l\xfd tưởng cho c\xe1c nhiệm vụ đơn giản c\xf3 thể xử l\xfd theo l\xf4 — như ph\xe2n loại, hỗ trợ kh\xe1ch h\xe0ng hoặc tạo văn bản. N\xf3 cung cấp hiệu suất xuất sắc với mức gi\xe1 phải chăng."},"mistral/mixtral-8x22b-instruct":{"description":"M\xf4 h\xecnh 8x22b Instruct. 8x22b l\xe0 m\xf4 h\xecnh chuy\xean gia hỗn hợp m\xe3 nguồn mở được Mistral phục vụ."},"mistral/pixtral-12b":{"description":"M\xf4 h\xecnh 12B c\xf3 khả năng hiểu h\xecnh ảnh c\xf9ng với văn bản."},"mistral/pixtral-large":{"description":"Pixtral Large l\xe0 m\xf4 h\xecnh thứ hai trong gia đ\xecnh đa phương thức của ch\xfang t\xf4i, thể hiện khả năng hiểu h\xecnh ảnh ti\xean tiến. Đặc biệt, m\xf4 h\xecnh c\xf3 thể hiểu t\xe0i liệu, biểu đồ v\xe0 h\xecnh ảnh tự nhi\xean, đồng thời duy tr\xec khả năng hiểu văn bản h\xe0ng đầu của Mistral Large 2."},"mistralai/Mistral-7B-Instruct-v0.1":{"description":"Mistral (7B) Instruct nổi bật với hiệu suất cao, ph\xf9 hợp cho nhiều nhiệm vụ ng\xf4n ngữ."},"mistralai/Mistral-7B-Instruct-v0.2":{"description":"Mistral 7B l\xe0 m\xf4 h\xecnh fine-tuning theo y\xeau cầu, cung cấp giải ph\xe1p tối ưu cho c\xe1c nhiệm vụ."},"mistralai/Mistral-7B-Instruct-v0.3":{"description":"Mistral (7B) Instruct v0.3 cung cấp khả năng t\xednh to\xe1n hiệu quả v\xe0 hiểu ng\xf4n ngữ tự nhi\xean, ph\xf9 hợp cho nhiều ứng dụng."},"mistralai/Mistral-7B-v0.1":{"description":"Mistral 7B l\xe0 một m\xf4 h\xecnh nhỏ gọn nhưng hiệu suất cao, chuy\xean về xử l\xfd h\xe0ng loạt v\xe0 c\xe1c t\xe1c vụ đơn giản như ph\xe2n loại v\xe0 sinh văn bản, với khả năng suy luận tốt."},"mistralai/Mixtral-8x22B-Instruct-v0.1":{"description":"Mixtral-8x22B Instruct (141B) l\xe0 một m\xf4 h\xecnh ng\xf4n ngữ lớn si\xeau cấp, hỗ trợ nhu cầu xử l\xfd cực cao."},"mistralai/Mixtral-8x7B-Instruct-v0.1":{"description":"Mixtral 8x7B l\xe0 m\xf4 h\xecnh chuy\xean gia hỗn hợp thưa được tiền huấn luyện, d\xf9ng cho c\xe1c nhiệm vụ văn bản tổng qu\xe1t."},"mistralai/Mixtral-8x7B-v0.1":{"description":"Mixtral 8x7B l\xe0 một m\xf4 h\xecnh chuy\xean gia thưa thớt, tận dụng nhiều tham số để tăng tốc độ suy luận, ph\xf9 hợp để xử l\xfd đa ng\xf4n ngữ v\xe0 tạo m\xe3."},"mistralai/mistral-nemo":{"description":"Mistral Nemo l\xe0 m\xf4 h\xecnh 7.3B tham số hỗ trợ đa ng\xf4n ngữ v\xe0 lập tr\xecnh hiệu suất cao."},"mixtral":{"description":"Mixtral l\xe0 m\xf4 h\xecnh chuy\xean gia của Mistral AI, c\xf3 trọng số m\xe3 nguồn mở v\xe0 cung cấp hỗ trợ cho việc sinh m\xe3 v\xe0 hiểu ng\xf4n ngữ."},"mixtral-8x7b-32768":{"description":"Mixtral 8x7B cung cấp khả năng t\xednh to\xe1n song song c\xf3 độ dung sai cao, ph\xf9 hợp cho c\xe1c nhiệm vụ phức tạp."},"mixtral:8x22b":{"description":"Mixtral l\xe0 m\xf4 h\xecnh chuy\xean gia của Mistral AI, c\xf3 trọng số m\xe3 nguồn mở v\xe0 cung cấp hỗ trợ cho việc sinh m\xe3 v\xe0 hiểu ng\xf4n ngữ."},"moonshot-v1-128k":{"description":"Moonshot V1 128K l\xe0 một m\xf4 h\xecnh c\xf3 khả năng xử l\xfd ngữ cảnh si\xeau d\xe0i, ph\xf9 hợp cho việc sinh văn bản si\xeau d\xe0i, đ\xe1p ứng nhu cầu nhiệm vụ sinh phức tạp, c\xf3 thể xử l\xfd nội dung l\xean đến 128.000 tokens, rất ph\xf9 hợp cho nghi\xean cứu, học thuật v\xe0 sinh t\xe0i liệu lớn."},"moonshot-v1-128k-vision-preview":{"description":"M\xf4 h\xecnh h\xecnh ảnh Kimi (bao gồm moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-preview, v.v.) c\xf3 khả năng hiểu nội dung h\xecnh ảnh, bao gồm văn bản h\xecnh ảnh, m\xe0u sắc h\xecnh ảnh v\xe0 h\xecnh dạng vật thể."},"moonshot-v1-32k":{"description":"Moonshot V1 32K cung cấp khả năng xử l\xfd ngữ cảnh độ d\xe0i trung b\xecnh, c\xf3 thể xử l\xfd 32.768 tokens, đặc biệt ph\xf9 hợp cho việc sinh c\xe1c t\xe0i liệu d\xe0i v\xe0 đối thoại phức tạp, ứng dụng trong s\xe1ng tạo nội dung, sinh b\xe1o c\xe1o v\xe0 hệ thống đối thoại."},"moonshot-v1-32k-vision-preview":{"description":"M\xf4 h\xecnh h\xecnh ảnh Kimi (bao gồm moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-preview, v.v.) c\xf3 khả năng hiểu nội dung h\xecnh ảnh, bao gồm văn bản h\xecnh ảnh, m\xe0u sắc h\xecnh ảnh v\xe0 h\xecnh dạng vật thể."},"moonshot-v1-8k":{"description":"Moonshot V1 8K được thiết kế đặc biệt cho c\xe1c nhiệm vụ sinh văn bản ngắn, c\xf3 hiệu suất xử l\xfd cao, c\xf3 thể xử l\xfd 8.192 tokens, rất ph\xf9 hợp cho c\xe1c cuộc đối thoại ngắn, ghi ch\xfa nhanh v\xe0 sinh nội dung nhanh ch\xf3ng."},"moonshot-v1-8k-vision-preview":{"description":"M\xf4 h\xecnh h\xecnh ảnh Kimi (bao gồm moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-preview, v.v.) c\xf3 khả năng hiểu nội dung h\xecnh ảnh, bao gồm văn bản h\xecnh ảnh, m\xe0u sắc h\xecnh ảnh v\xe0 h\xecnh dạng vật thể."},"moonshot-v1-auto":{"description":"Moonshot V1 Auto c\xf3 thể chọn m\xf4 h\xecnh ph\xf9 hợp dựa tr\xean số lượng Tokens hiện tại đang chiếm dụng trong ngữ cảnh."},"moonshotai/Kimi-Dev-72B":{"description":"Kimi-Dev-72B l\xe0 một m\xf4 h\xecnh m\xe3 nguồn mở lớn, được tối ưu h\xf3a qua học tăng cường quy m\xf4 lớn, c\xf3 khả năng tạo ra c\xe1c bản v\xe1 ổn định v\xe0 c\xf3 thể triển khai trực tiếp. M\xf4 h\xecnh n\xe0y đ\xe3 đạt điểm cao kỷ lục 60,4% tr\xean SWE-bench Verified, ph\xe1 vỡ c\xe1c kỷ lục của m\xf4 h\xecnh m\xe3 nguồn mở trong c\xe1c nhiệm vụ kỹ thuật phần mềm tự động như sửa lỗi v\xe0 đ\xe1nh gi\xe1 m\xe3."},"moonshotai/Kimi-K2-Instruct-0905":{"description":"Kimi K2-Instruct-0905 l\xe0 phi\xean bản mới nhất v\xe0 mạnh mẽ nhất của Kimi K2. Đ\xe2y l\xe0 một m\xf4 h\xecnh ng\xf4n ngữ chuy\xean gia hỗn hợp (MoE) h\xe0ng đầu với tổng số tham số l\xean đến 1 ngh\xecn tỷ v\xe0 32 tỷ tham số k\xedch hoạt. C\xe1c đặc điểm ch\xednh của m\xf4 h\xecnh bao gồm: tăng cường tr\xed tuệ m\xe3 h\xf3a t\xe1c nh\xe2n, thể hiện sự cải thiện đ\xe1ng kể trong c\xe1c b\xe0i kiểm tra chuẩn c\xf4ng khai v\xe0 c\xe1c nhiệm vụ m\xe3 h\xf3a t\xe1c nh\xe2n trong thế giới thực; cải tiến trải nghiệm m\xe3 h\xf3a giao diện người d\xf9ng, n\xe2ng cao cả về t\xednh thẩm mỹ v\xe0 t\xednh thực tiễn trong lập tr\xecnh giao diện."},"moonshotai/kimi-k2":{"description":"Kimi K2 l\xe0 m\xf4 h\xecnh ng\xf4n ngữ chuy\xean gia hỗn hợp (MoE) quy m\xf4 lớn do Moonshot AI ph\xe1t triển, với tổng số tham số l\xean đến 1 ngh\xecn tỷ v\xe0 32 tỷ tham số k\xedch hoạt mỗi lần truyền tiến. N\xf3 được tối ưu cho khả năng đại l\xfd, bao gồm sử dụng c\xf4ng cụ n\xe2ng cao, suy luận v\xe0 tổng hợp m\xe3."},"moonshotai/kimi-k2-0905":{"description":"M\xf4 h\xecnh kimi-k2-0905-preview c\xf3 độ d\xe0i ngữ cảnh 256k, sở hữu năng lực Agentic Coding mạnh mẽ hơn, m\xe3 front-end đẹp mắt v\xe0 thực dụng hơn, c\xf9ng khả năng hiểu ngữ cảnh tốt hơn."},"moonshotai/kimi-k2-instruct-0905":{"description":"M\xf4 h\xecnh kimi-k2-0905-preview c\xf3 độ d\xe0i ngữ cảnh 256k, sở hữu năng lực Agentic Coding mạnh mẽ hơn, m\xe3 front-end đẹp mắt v\xe0 thực dụng hơn, c\xf9ng khả năng hiểu ngữ cảnh tốt hơn."},"morph/morph-v3-fast":{"description":"Morph cung cấp m\xf4 h\xecnh AI chuy\xean biệt, \xe1p dụng c\xe1c thay đổi m\xe3 được đề xuất bởi c\xe1c m\xf4 h\xecnh ti\xean tiến như Claude hoặc GPT-4o v\xe0o c\xe1c tệp m\xe3 hiện c\xf3 của bạn với tốc độ nhanh — hơn 4500 token/gi\xe2y. N\xf3 đ\xf3ng vai tr\xf2 l\xe0 bước cuối c\xf9ng trong quy tr\xecnh l\xe0m việc m\xe3 h\xf3a AI. Hỗ trợ 16k token đầu v\xe0o v\xe0 16k token đầu ra."},"morph/morph-v3-large":{"description":"Morph cung cấp m\xf4 h\xecnh AI chuy\xean biệt, \xe1p dụng c\xe1c thay đổi m\xe3 được đề xuất bởi c\xe1c m\xf4 h\xecnh ti\xean tiến như Claude hoặc GPT-4o v\xe0o c\xe1c tệp m\xe3 hiện c\xf3 của bạn với tốc độ nhanh — hơn 2500 token/gi\xe2y. N\xf3 đ\xf3ng vai tr\xf2 l\xe0 bước cuối c\xf9ng trong quy tr\xecnh l\xe0m việc m\xe3 h\xf3a AI. Hỗ trợ 16k token đầu v\xe0o v\xe0 16k token đầu ra."},"nousresearch/hermes-2-pro-llama-3-8b":{"description":"Hermes 2 Pro Llama 3 8B l\xe0 phi\xean bản n\xe2ng cấp của Nous Hermes 2, bao gồm bộ dữ liệu ph\xe1t triển nội bộ mới nhất."},"nvidia/Llama-3.1-Nemotron-70B-Instruct-HF":{"description":"Llama 3.1 Nemotron 70B l\xe0 một m\xf4 h\xecnh ng\xf4n ngữ quy m\xf4 lớn t\xf9y chỉnh bởi NVIDIA, nhằm n\xe2ng cao mức độ hỗ trợ của phản hồi do LLM tạo ra đối với c\xe1c truy vấn của người d\xf9ng. M\xf4 h\xecnh n\xe0y đ\xe3 thể hiện xuất sắc trong c\xe1c b\xe0i kiểm tra chuẩn như Arena Hard, AlpacaEval 2 LC v\xe0 GPT-4-Turbo MT-Bench, đứng đầu trong cả ba b\xe0i kiểm tra tự động cho đến ng\xe0y 1 th\xe1ng 10 năm 2024. M\xf4 h\xecnh sử dụng RLHF (đặc biệt l\xe0 REINFORCE), Llama-3.1-Nemotron-70B-Reward v\xe0 HelpSteer2-Preference để đ\xe0o tạo tr\xean cơ sở m\xf4 h\xecnh Llama-3.1-70B-Instruct."},"nvidia/llama-3.1-nemotron-51b-instruct":{"description":"M\xf4 h\xecnh ng\xf4n ngữ độc đ\xe1o, cung cấp độ ch\xednh x\xe1c v\xe0 hiệu suất kh\xf4ng thể s\xe1nh kịp."},"nvidia/llama-3.1-nemotron-70b-instruct":{"description":"Llama-3.1-Nemotron-70B l\xe0 m\xf4 h\xecnh ng\xf4n ngữ lớn t\xf9y chỉnh của NVIDIA, nhằm n\xe2ng cao t\xednh hữu \xedch của c\xe1c phản hồi do LLM tạo ra."},"o1":{"description":"Tập trung v\xe0o suy diễn n\xe2ng cao v\xe0 giải quyết c\xe1c vấn đề phức tạp, bao gồm c\xe1c nhiệm vụ to\xe1n học v\xe0 khoa học. Rất ph\xf9 hợp cho c\xe1c ứng dụng cần hiểu biết s\xe2u sắc về ngữ cảnh v\xe0 quy tr\xecnh l\xe0m việc đại diện."},"o1-mini":{"description":"o1-mini l\xe0 một m\xf4 h\xecnh suy diễn nhanh ch\xf3ng v\xe0 tiết kiệm chi ph\xed, được thiết kế cho c\xe1c ứng dụng lập tr\xecnh, to\xe1n học v\xe0 khoa học. M\xf4 h\xecnh n\xe0y c\xf3 ngữ cảnh 128K v\xe0 thời điểm cắt kiến thức v\xe0o th\xe1ng 10 năm 2023."},"o1-preview":{"description":"Tập trung v\xe0o suy luận n\xe2ng cao v\xe0 giải quyết c\xe1c vấn đề phức tạp, bao gồm c\xe1c b\xe0i to\xe1n v\xe0 nhiệm vụ khoa học. Rất ph\xf9 hợp cho những ứng dụng cần khả năng hiểu biết ngữ cảnh s\xe2u sắc v\xe0 quy tr\xecnh l\xe0m việc tự chủ."},"o1-pro":{"description":"D\xf2ng m\xf4 h\xecnh o1 được huấn luyện qua học tăng cường, c\xf3 khả năng suy nghĩ trước khi trả lời v\xe0 thực hiện c\xe1c nhiệm vụ suy luận phức tạp. M\xf4 h\xecnh o1-pro sử dụng nhiều t\xe0i nguy\xean t\xednh to\xe1n hơn để suy nghĩ s\xe2u hơn, từ đ\xf3 li\xean tục cung cấp c\xe2u trả lời chất lượng cao hơn."},"o3":{"description":"o3 l\xe0 một m\xf4 h\xecnh to\xe0n năng mạnh mẽ, thể hiện xuất sắc trong nhiều lĩnh vực. N\xf3 thiết lập ti\xeau chuẩn mới cho c\xe1c nhiệm vụ to\xe1n học, khoa học, lập tr\xecnh v\xe0 suy luận h\xecnh ảnh. N\xf3 cũng giỏi trong việc viết kỹ thuật v\xe0 tu\xe2n thủ hướng dẫn. Người d\xf9ng c\xf3 thể sử dụng n\xf3 để ph\xe2n t\xedch văn bản, m\xe3 v\xe0 h\xecnh ảnh, giải quyết c\xe1c vấn đề phức tạp nhiều bước."},"o3-2025-04-16":{"description":"o3 l\xe0 m\xf4 h\xecnh suy luận mới của OpenAI, hỗ trợ đầu v\xe0o h\xecnh ảnh v\xe0 văn bản, xuất ra văn bản, ph\xf9 hợp cho c\xe1c t\xe1c vụ phức tạp cần kiến thức phổ qu\xe1t rộng."},"o3-deep-research":{"description":"o3-deep-research l\xe0 m\xf4 h\xecnh nghi\xean cứu s\xe2u ti\xean tiến nhất của ch\xfang t\xf4i, được thiết kế đặc biệt để xử l\xfd c\xe1c nhiệm vụ nghi\xean cứu phức tạp nhiều bước. N\xf3 c\xf3 thể t\xecm kiếm v\xe0 tổng hợp th\xf4ng tin từ Internet, cũng như truy cập v\xe0 tận dụng dữ liệu ri\xeang của bạn th\xf4ng qua kết nối MCP."},"o3-mini":{"description":"o3-mini l\xe0 m\xf4 h\xecnh suy diễn nhỏ gọn mới nhất của ch\xfang t\xf4i, cung cấp tr\xed th\xf4ng minh cao với chi ph\xed v\xe0 độ trễ tương tự như o1-mini."},"o3-pro":{"description":"M\xf4 h\xecnh o3-pro sử dụng nhiều t\xe0i nguy\xean t\xednh to\xe1n hơn để suy nghĩ s\xe2u sắc hơn v\xe0 lu\xf4n cung cấp c\xe2u trả lời tốt hơn, chỉ hỗ trợ sử dụng dưới API Responses."},"o3-pro-2025-06-10":{"description":"o3 Pro l\xe0 m\xf4 h\xecnh suy luận mới của OpenAI, hỗ trợ đầu v\xe0o h\xecnh ảnh v\xe0 văn bản, xuất ra văn bản, ph\xf9 hợp cho c\xe1c t\xe1c vụ phức tạp cần kiến thức phổ qu\xe1t rộng."},"o4-mini":{"description":"o4-mini l\xe0 m\xf4 h\xecnh nhỏ gọn mới nhất trong d\xf2ng o của ch\xfang t\xf4i. N\xf3 được tối ưu h\xf3a cho suy luận nhanh ch\xf3ng v\xe0 hiệu quả, thể hiện hiệu suất v\xe0 hiệu quả cao trong c\xe1c nhiệm vụ m\xe3 h\xf3a v\xe0 h\xecnh ảnh."},"o4-mini-2025-04-16":{"description":"o4-mini l\xe0 m\xf4 h\xecnh suy luận của OpenAI, hỗ trợ đầu v\xe0o h\xecnh ảnh v\xe0 văn bản, xuất ra văn bản, ph\xf9 hợp cho c\xe1c t\xe1c vụ phức tạp cần kiến thức phổ qu\xe1t rộng. M\xf4 h\xecnh n\xe0y c\xf3 ngữ cảnh 200K."},"o4-mini-deep-research":{"description":"o4-mini-deep-research l\xe0 m\xf4 h\xecnh nghi\xean cứu s\xe2u nhanh hơn v\xe0 tiết kiệm hơn của ch\xfang t\xf4i — rất ph\xf9 hợp để xử l\xfd c\xe1c nhiệm vụ nghi\xean cứu phức tạp nhiều bước. N\xf3 c\xf3 thể t\xecm kiếm v\xe0 tổng hợp th\xf4ng tin từ Internet, cũng như truy cập v\xe0 tận dụng dữ liệu ri\xeang của bạn th\xf4ng qua kết nối MCP."},"open-codestral-mamba":{"description":"Codestral Mamba l\xe0 m\xf4 h\xecnh ng\xf4n ngữ Mamba 2 tập trung v\xe0o sinh m\xe3, cung cấp hỗ trợ mạnh mẽ cho c\xe1c nhiệm vụ m\xe3 v\xe0 suy luận ti\xean tiến."},"open-mistral-7b":{"description":"Mistral 7B l\xe0 một m\xf4 h\xecnh nhỏ gọn nhưng hiệu suất cao, chuy\xean về xử l\xfd h\xe0ng loạt v\xe0 c\xe1c nhiệm vụ đơn giản như ph\xe2n loại v\xe0 sinh văn bản, c\xf3 khả năng suy luận tốt."},"open-mistral-nemo":{"description":"Mistral Nemo l\xe0 một m\xf4 h\xecnh 12B được ph\xe1t triển hợp t\xe1c với Nvidia, cung cấp hiệu suất suy luận v\xe0 m\xe3 h\xf3a xuất sắc, dễ d\xe0ng t\xedch hợp v\xe0 thay thế."},"open-mixtral-8x22b":{"description":"Mixtral 8x22B l\xe0 một m\xf4 h\xecnh chuy\xean gia lớn hơn, tập trung v\xe0o c\xe1c nhiệm vụ phức tạp, cung cấp khả năng suy luận xuất sắc v\xe0 th\xf4ng lượng cao hơn."},"open-mixtral-8x7b":{"description":"Mixtral 8x7B l\xe0 một m\xf4 h\xecnh chuy\xean gia thưa thớt, sử dụng nhiều tham số để tăng tốc độ suy luận, ph\xf9 hợp cho việc xử l\xfd đa ng\xf4n ngữ v\xe0 sinh m\xe3."},"openai/gpt-3.5-turbo":{"description":"M\xf4 h\xecnh hiệu quả nhất v\xe0 tiết kiệm chi ph\xed nhất trong d\xf2ng GPT-3.5 của OpenAI, được tối ưu cho mục đ\xedch tr\xf2 chuyện nhưng cũng hoạt động tốt trong c\xe1c nhiệm vụ ho\xe0n th\xe0nh truyền thống."},"openai/gpt-3.5-turbo-instruct":{"description":"Khả năng tương tự c\xe1c m\xf4 h\xecnh thời GPT-3. Tương th\xedch với điểm cuối ho\xe0n th\xe0nh truyền thống thay v\xec điểm cuối ho\xe0n th\xe0nh tr\xf2 chuyện."},"openai/gpt-4-turbo":{"description":"gpt-4-turbo của OpenAI c\xf3 kiến thức tổng qu\xe1t rộng v\xe0 chuy\xean m\xf4n lĩnh vực, cho ph\xe9p tu\xe2n theo c\xe1c chỉ dẫn ng\xf4n ngữ tự nhi\xean phức tạp v\xe0 giải quyết ch\xednh x\xe1c c\xe1c vấn đề kh\xf3. Kiến thức cập nhật đến th\xe1ng 4 năm 2023, cửa sổ ngữ cảnh 128.000 token."},"openai/gpt-4.1":{"description":"GPT 4.1 l\xe0 m\xf4 h\xecnh h\xe0ng đầu của OpenAI, ph\xf9 hợp cho c\xe1c nhiệm vụ phức tạp. N\xf3 rất th\xedch hợp để giải quyết vấn đề đa lĩnh vực."},"openai/gpt-4.1-mini":{"description":"GPT 4.1 mini c\xe2n bằng giữa tr\xed tuệ, tốc độ v\xe0 chi ph\xed, l\xe0 m\xf4 h\xecnh hấp dẫn cho nhiều trường hợp sử dụng."},"openai/gpt-4.1-nano":{"description":"GPT-4.1 nano l\xe0 m\xf4 h\xecnh GPT 4.1 nhanh nhất v\xe0 tiết kiệm chi ph\xed nhất."},"openai/gpt-4o":{"description":"GPT-4o của OpenAI c\xf3 kiến thức tổng qu\xe1t rộng v\xe0 chuy\xean m\xf4n lĩnh vực, c\xf3 khả năng tu\xe2n theo c\xe1c chỉ dẫn ng\xf4n ngữ tự nhi\xean phức tạp v\xe0 giải quyết ch\xednh x\xe1c c\xe1c vấn đề kh\xf3. N\xf3 cung cấp hiệu suất tương đương GPT-4 Turbo với API nhanh hơn v\xe0 rẻ hơn."},"openai/gpt-4o-mini":{"description":"GPT-4o mini của OpenAI l\xe0 m\xf4 h\xecnh nhỏ ti\xean tiến v\xe0 tiết kiệm chi ph\xed nhất của họ. N\xf3 đa phương thức (chấp nhận đầu v\xe0o văn bản hoặc h\xecnh ảnh v\xe0 xuất ra văn bản), th\xf4ng minh hơn gpt-3.5-turbo nhưng tốc độ tương đương."},"openai/gpt-5":{"description":"GPT-5 l\xe0 m\xf4 h\xecnh ng\xf4n ngữ h\xe0ng đầu của OpenAI, xuất sắc trong suy luận phức tạp, kiến thức thực tế rộng lớn, c\xe1c nhiệm vụ m\xe3 h\xf3a chuy\xean s\xe2u v\xe0 đại l\xfd đa bước."},"openai/gpt-5-mini":{"description":"GPT-5 mini l\xe0 m\xf4 h\xecnh tối ưu chi ph\xed, thể hiện tốt trong c\xe1c nhiệm vụ suy luận/tr\xf2 chuyện. N\xf3 cung cấp sự c\xe2n bằng tốt nhất giữa tốc độ, chi ph\xed v\xe0 khả năng."},"openai/gpt-5-nano":{"description":"GPT-5 nano l\xe0 m\xf4 h\xecnh c\xf3 th\xf4ng lượng cao, thể hiện tốt trong c\xe1c nhiệm vụ chỉ dẫn đơn giản hoặc ph\xe2n loại."},"openai/gpt-oss-120b":{"description":"M\xf4 h\xecnh ng\xf4n ngữ lớn đa năng cực kỳ năng lực, với khả năng suy luận mạnh mẽ v\xe0 c\xf3 thể kiểm so\xe1t."},"openai/gpt-oss-20b":{"description":"M\xf4 h\xecnh ng\xf4n ngữ trọng số m\xe3 nguồn mở nhỏ gọn, được tối ưu cho độ trễ thấp v\xe0 m\xf4i trường t\xe0i nguy\xean hạn chế, bao gồm triển khai cục bộ v\xe0 bi\xean."},"openai/o1":{"description":"o1 của OpenAI l\xe0 m\xf4 h\xecnh suy luận h\xe0ng đầu, được thiết kế cho c\xe1c vấn đề phức tạp đ\xf2i hỏi suy nghĩ s\xe2u sắc. N\xf3 cung cấp khả năng suy luận mạnh mẽ v\xe0 độ ch\xednh x\xe1c cao cho c\xe1c nhiệm vụ đa bước phức tạp."},"openai/o1-mini":{"description":"o1-mini l\xe0 một m\xf4 h\xecnh suy diễn nhanh ch\xf3ng v\xe0 tiết kiệm chi ph\xed, được thiết kế cho c\xe1c ứng dụng lập tr\xecnh, to\xe1n học v\xe0 khoa học. M\xf4 h\xecnh n\xe0y c\xf3 ngữ cảnh 128K v\xe0 thời điểm cắt kiến thức v\xe0o th\xe1ng 10 năm 2023."},"openai/o1-preview":{"description":"o1 l\xe0 m\xf4 h\xecnh suy diễn mới của OpenAI, ph\xf9 hợp cho c\xe1c nhiệm vụ phức tạp cần kiến thức tổng qu\xe1t rộng r\xe3i. M\xf4 h\xecnh n\xe0y c\xf3 ngữ cảnh 128K v\xe0 thời điểm cắt kiến thức v\xe0o th\xe1ng 10 năm 2023."},"openai/o3":{"description":"o3 của OpenAI l\xe0 m\xf4 h\xecnh suy luận mạnh nhất, thiết lập c\xe1c ti\xeau chuẩn mới trong m\xe3 h\xf3a, to\xe1n học, khoa học v\xe0 nhận thức thị gi\xe1c. N\xf3 xuất sắc trong c\xe1c truy vấn phức tạp đ\xf2i hỏi ph\xe2n t\xedch đa chiều, c\xf3 lợi thế đặc biệt trong ph\xe2n t\xedch h\xecnh ảnh, biểu đồ v\xe0 đồ họa."},"openai/o3-mini":{"description":"o3-mini l\xe0 m\xf4 h\xecnh suy luận nhỏ mới nhất của OpenAI, cung cấp tr\xed tuệ cao với chi ph\xed v\xe0 độ trễ tương đương o1-mini."},"openai/o3-mini-high":{"description":"o3-mini phi\xean bản cao cấp về suy luận, cung cấp tr\xed tuệ cao với c\xf9ng chi ph\xed v\xe0 mục ti\xeau độ trễ như o1-mini."},"openai/o4-mini":{"description":"o4-mini của OpenAI cung cấp suy luận nhanh v\xe0 tiết kiệm chi ph\xed, với hiệu suất xuất sắc trong k\xedch thước của n\xf3, đặc biệt trong to\xe1n học (đạt điểm cao nhất trong b\xe0i kiểm tra chuẩn AIME), m\xe3 h\xf3a v\xe0 c\xe1c nhiệm vụ thị gi\xe1c."},"openai/o4-mini-high":{"description":"o4-mini phi\xean bản cao cấp, được tối ưu h\xf3a cho suy luận nhanh ch\xf3ng v\xe0 hiệu quả, thể hiện hiệu suất v\xe0 hiệu quả cao trong c\xe1c nhiệm vụ m\xe3 h\xf3a v\xe0 h\xecnh ảnh."},"openai/text-embedding-3-large":{"description":"M\xf4 h\xecnh nh\xfang hiệu quả nhất của OpenAI, ph\xf9 hợp cho c\xe1c nhiệm vụ tiếng Anh v\xe0 phi tiếng Anh."},"openai/text-embedding-3-small":{"description":"Phi\xean bản cải tiến v\xe0 hiệu suất cao hơn của m\xf4 h\xecnh nh\xfang ada của OpenAI."},"openai/text-embedding-ada-002":{"description":"M\xf4 h\xecnh nh\xfang văn bản truyền thống của OpenAI."},"openrouter/auto":{"description":"Dựa tr\xean độ d\xe0i ngữ cảnh, chủ đề v\xe0 độ phức tạp, y\xeau cầu của bạn sẽ được gửi đến Llama 3 70B Instruct, Claude 3.5 Sonnet (tự điều chỉnh) hoặc GPT-4o."},"perplexity/sonar":{"description":"Sản phẩm nhẹ của Perplexity với khả năng t\xecm kiếm c\xf3 căn cứ, nhanh hơn v\xe0 rẻ hơn Sonar Pro."},"perplexity/sonar-pro":{"description":"Sản phẩm h\xe0ng đầu của Perplexity với khả năng t\xecm kiếm c\xf3 căn cứ, hỗ trợ truy vấn n\xe2ng cao v\xe0 c\xe1c thao t\xe1c tiếp theo."},"perplexity/sonar-reasoning":{"description":"M\xf4 h\xecnh tập trung v\xe0o suy luận, xuất ra chuỗi suy nghĩ (CoT) trong phản hồi, cung cấp giải th\xedch chi tiết c\xf3 căn cứ t\xecm kiếm."},"perplexity/sonar-reasoning-pro":{"description":"M\xf4 h\xecnh tập trung suy luận n\xe2ng cao, xuất ra chuỗi suy nghĩ (CoT) trong phản hồi, cung cấp giải th\xedch to\xe0n diện với khả năng t\xecm kiếm n\xe2ng cao v\xe0 nhiều truy vấn t\xecm kiếm cho mỗi y\xeau cầu."},"phi3":{"description":"Phi-3 l\xe0 m\xf4 h\xecnh mở nhẹ do Microsoft ph\xe1t h\xe0nh, ph\xf9 hợp cho việc t\xedch hợp hiệu quả v\xe0 suy luận kiến thức quy m\xf4 lớn."},"phi3:14b":{"description":"Phi-3 l\xe0 m\xf4 h\xecnh mở nhẹ do Microsoft ph\xe1t h\xe0nh, ph\xf9 hợp cho việc t\xedch hợp hiệu quả v\xe0 suy luận kiến thức quy m\xf4 lớn."},"pixtral-12b-2409":{"description":"M\xf4 h\xecnh Pixtral thể hiện khả năng mạnh mẽ trong c\xe1c nhiệm vụ như hiểu biểu đồ v\xe0 h\xecnh ảnh, hỏi đ\xe1p t\xe0i liệu, suy luận đa phương tiện v\xe0 tu\xe2n thủ hướng dẫn, c\xf3 khả năng tiếp nhận h\xecnh ảnh với độ ph\xe2n giải v\xe0 tỷ lệ khung h\xecnh tự nhi\xean, cũng như xử l\xfd bất kỳ số lượng h\xecnh ảnh n\xe0o trong cửa sổ ngữ cảnh d\xe0i l\xean đến 128K token."},"pixtral-large-latest":{"description":"Pixtral Large l\xe0 một m\xf4 h\xecnh đa phương thức m\xe3 nguồn mở với 1240 tỷ tham số, được x\xe2y dựng dựa tr\xean Mistral Large 2. Đ\xe2y l\xe0 m\xf4 h\xecnh thứ hai trong gia đ\xecnh đa phương thức của ch\xfang t\xf4i, thể hiện khả năng hiểu h\xecnh ảnh ở mức ti\xean tiến."},"pro-128k":{"description":"Spark Pro 128K được cấu h\xecnh với khả năng xử l\xfd ngữ cảnh cực lớn, c\xf3 thể xử l\xfd tới 128K th\xf4ng tin ngữ cảnh, đặc biệt ph\xf9 hợp cho việc ph\xe2n t\xedch to\xe0n bộ v\xe0 xử l\xfd mối li\xean hệ logic l\xe2u d\xe0i trong nội dung văn bản d\xe0i, c\xf3 thể cung cấp logic mạch lạc v\xe0 hỗ trợ tr\xedch dẫn đa dạng trong giao tiếp văn bản phức tạp."},"pro-deepseek-r1":{"description":"M\xf4 h\xecnh chuy\xean dụng cho dịch vụ doanh nghiệp, hỗ trợ dịch vụ đồng thời."},"pro-deepseek-v3":{"description":"M\xf4 h\xecnh chuy\xean dụng cho dịch vụ doanh nghiệp, hỗ trợ dịch vụ đồng thời."},"qianfan-70b":{"description":"Qianfan 70B, m\xf4 h\xecnh tiếng Trung với tham số lớn, ph\xf9 hợp cho việc tạo nội dung chất lượng cao v\xe0 c\xe1c nhiệm vụ suy luận phức tạp."},"qianfan-8b":{"description":"Qianfan 8B, m\xf4 h\xecnh đa năng cỡ trung, c\xe2n bằng giữa chi ph\xed v\xe0 hiệu quả trong tạo văn bản v\xe0 hỏi đ\xe1p."},"qianfan-agent-intent-32k":{"description":"Qianfan Agent Intent 32K, m\xf4 h\xecnh nhận diện \xfd định v\xe0 điều phối t\xe1c tử, hỗ trợ ngữ cảnh d\xe0i."},"qianfan-agent-lite-8k":{"description":"Qianfan Agent Lite 8K, m\xf4 h\xecnh t\xe1c tử nhẹ, ph\xf9 hợp cho hội thoại đa lượt chi ph\xed thấp v\xe0 điều phối nghiệp vụ."},"qianfan-agent-speed-32k":{"description":"Qianfan Agent Speed 32K, m\xf4 h\xecnh t\xe1c tử kiểm so\xe1t lưu lượng cao, th\xedch hợp cho ứng dụng Agent quy m\xf4 lớn v\xe0 đa nhiệm."},"qianfan-agent-speed-8k":{"description":"Qianfan Agent Speed 8K, m\xf4 h\xecnh t\xe1c tử hiệu suất cao cho hội thoại ngắn v\xe0 phản hồi nhanh với khả năng xử l\xfd đồng thời cao."},"qianfan-check-vl":{"description":"Qianfan Check VL, m\xf4 h\xecnh kiểm duyệt v\xe0 ph\xe1t hiện nội dung đa phương tiện, hỗ trợ kiểm tra tu\xe2n thủ v\xe0 nhận diện h\xecnh ảnh-văn bản."},"qianfan-composition":{"description":"Qianfan Composition, m\xf4 h\xecnh s\xe1ng tạo đa phương tiện, hỗ trợ hiểu v\xe0 tạo nội dung kết hợp h\xecnh ảnh v\xe0 văn bản."},"qianfan-engcard-vl":{"description":"Qianfan EngCard VL, m\xf4 h\xecnh nhận diện đa phương tiện chuy\xean biệt cho ngữ cảnh tiếng Anh."},"qianfan-lightning-128b-a19b":{"description":"Qianfan Lightning 128B A19B, m\xf4 h\xecnh tiếng Trung hiệu suất cao, ph\xf9 hợp cho hỏi đ\xe1p phức tạp v\xe0 suy luận quy m\xf4 lớn."},"qianfan-llama-vl-8b":{"description":"Qianfan Llama VL 8B, m\xf4 h\xecnh đa phương tiện dựa tr\xean Llama, hướng đến nhiệm vụ hiểu h\xecnh ảnh-văn bản tổng qu\xe1t."},"qianfan-multipicocr":{"description":"Qianfan MultiPicOCR, m\xf4 h\xecnh OCR cho nhiều h\xecnh ảnh, hỗ trợ ph\xe1t hiện v\xe0 nhận diện văn bản từ nhiều ảnh."},"qianfan-qi-vl":{"description":"Qianfan QI VL, m\xf4 h\xecnh hỏi đ\xe1p đa phương tiện, hỗ trợ truy xuất v\xe0 trả lời ch\xednh x\xe1c trong c\xe1c ngữ cảnh h\xecnh ảnh-văn bản phức tạp."},"qianfan-singlepicocr":{"description":"Qianfan SinglePicOCR, m\xf4 h\xecnh OCR cho một h\xecnh ảnh, hỗ trợ nhận diện k\xfd tự với độ ch\xednh x\xe1c cao."},"qianfan-vl-70b":{"description":"Qianfan VL 70B, m\xf4 h\xecnh ng\xf4n ngữ thị gi\xe1c với tham số lớn, ph\xf9 hợp cho c\xe1c t\xecnh huống hiểu h\xecnh ảnh-văn bản phức tạp."},"qianfan-vl-8b":{"description":"Qianfan VL 8B, m\xf4 h\xecnh ng\xf4n ngữ thị gi\xe1c nhẹ, th\xedch hợp cho hỏi đ\xe1p v\xe0 ph\xe2n t\xedch h\xecnh ảnh-văn bản h\xe0ng ng\xe0y."},"qvq-72b-preview":{"description":"M\xf4 h\xecnh QVQ l\xe0 m\xf4 h\xecnh nghi\xean cứu thử nghiệm do đội ngũ Qwen ph\xe1t triển, tập trung v\xe0o việc n\xe2ng cao khả năng suy luận h\xecnh ảnh, đặc biệt trong lĩnh vực suy luận to\xe1n học."},"qvq-max":{"description":"M\xf4 h\xecnh suy luận thị gi\xe1c QVQ của Tongyi Qianwen, hỗ trợ đầu v\xe0o thị gi\xe1c v\xe0 xuất ra chuỗi suy nghĩ, thể hiện năng lực mạnh mẽ trong to\xe1n học, lập tr\xecnh, ph\xe2n t\xedch thị gi\xe1c, s\xe1ng tạo v\xe0 c\xe1c nhiệm vụ chung."},"qvq-plus":{"description":"M\xf4 h\xecnh suy luận thị gi\xe1c. Hỗ trợ đầu v\xe0o h\xecnh ảnh v\xe0 đầu ra chuỗi suy nghĩ, phi\xean bản plus ra mắt sau m\xf4 h\xecnh qvq-max, với tốc độ suy luận nhanh hơn, hiệu quả v\xe0 chi ph\xed c\xe2n bằng hơn so với qvq-max."},"qwen-3-32b":{"description":"Qwen 3 32B: M\xf4 h\xecnh d\xf2ng Qwen c\xf3 hiệu suất tốt trong c\xe1c nhiệm vụ đa ng\xf4n ngữ v\xe0 lập tr\xecnh, th\xedch hợp cho c\xe1c ứng dụng sản xuất quy m\xf4 trung b\xecnh."},"qwen-3-coder-480b":{"description":"Qwen 3 Coder 480B: M\xf4 h\xecnh ngữ cảnh d\xe0i d\xe0nh cho sinh m\xe3 v\xe0 c\xe1c nhiệm vụ lập tr\xecnh phức tạp."},"qwen-coder-plus":{"description":"M\xf4 h\xecnh m\xe3 h\xf3a Tongyi Qianwen."},"qwen-coder-turbo":{"description":"M\xf4 h\xecnh m\xe3 h\xf3a Tongyi Qianwen."},"qwen-coder-turbo-latest":{"description":"M\xf4 h\xecnh m\xe3 Qwen."},"qwen-flash":{"description":"C\xe1c m\xf4 h\xecnh thuộc d\xf2ng 通义千问 c\xf3 tốc độ nhanh nhất v\xe0 chi ph\xed rất thấp, ph\xf9 hợp cho c\xe1c nhiệm vụ đơn giản."},"qwen-image":{"description":"Qwen-Image l\xe0 một m\xf4 h\xecnh sinh h\xecnh ảnh đa dụng, hỗ trợ nhiều phong c\xe1ch nghệ thuật v\xe0 đặc biệt giỏi trong việc t\xe1i hiện văn bản phức tạp, nhất l\xe0 văn bản tiếng Trung v\xe0 tiếng Anh. M\xf4 h\xecnh hỗ trợ bố cục nhiều d\xf2ng, sinh văn bản ở cấp đoạn v\xe0 khắc họa c\xe1c chi tiết tinh tế, cho ph\xe9p thực hiện c\xe1c thiết kế bố cục kết hợp h\xecnh ảnh v\xe0 văn bản phức tạp."},"qwen-image-edit":{"description":"Qwen Image Edit l\xe0 một m\xf4 h\xecnh tạo h\xecnh ảnh từ h\xecnh ảnh, hỗ trợ chỉnh sửa v\xe0 thay đổi h\xecnh ảnh dựa tr\xean h\xecnh ảnh đầu v\xe0o v\xe0 c\xe1c gợi \xfd văn bản, c\xf3 khả năng điều chỉnh ch\xednh x\xe1c v\xe0 s\xe1ng tạo h\xecnh ảnh gốc theo y\xeau cầu của người d\xf9ng."},"qwen-long":{"description":"M\xf4 h\xecnh ng\xf4n ngữ quy m\xf4 lớn Qwen, hỗ trợ ngữ cảnh văn bản d\xe0i v\xe0 chức năng đối thoại dựa tr\xean t\xe0i liệu d\xe0i, nhiều t\xe0i liệu."},"qwen-math-plus":{"description":"M\xf4 h\xecnh to\xe1n học Tongyi Qianwen được thiết kế chuy\xean biệt cho việc giải to\xe1n."},"qwen-math-plus-latest":{"description":"M\xf4 h\xecnh to\xe1n học Qwen được thiết kế đặc biệt để giải quyết c\xe1c b\xe0i to\xe1n to\xe1n học."},"qwen-math-turbo":{"description":"M\xf4 h\xecnh to\xe1n học Tongyi Qianwen được thiết kế chuy\xean biệt cho việc giải to\xe1n."},"qwen-math-turbo-latest":{"description":"M\xf4 h\xecnh to\xe1n học Qwen được thiết kế đặc biệt để giải quyết c\xe1c b\xe0i to\xe1n to\xe1n học."},"qwen-max":{"description":"M\xf4 h\xecnh ng\xf4n ngữ quy m\xf4 lớn Qwen cấp tỷ, hỗ trợ đầu v\xe0o bằng tiếng Trung, tiếng Anh v\xe0 nhiều ng\xf4n ngữ kh\xe1c, l\xe0 m\xf4 h\xecnh API đằng sau phi\xean bản sản phẩm Qwen 2.5 hiện tại."},"qwen-omni-turbo":{"description":"D\xf2ng m\xf4 h\xecnh Qwen-Omni hỗ trợ đầu v\xe0o đa dạng c\xe1c loại dữ liệu đa phương thức, bao gồm video, \xe2m thanh, h\xecnh ảnh, văn bản, v\xe0 xuất ra \xe2m thanh c\xf9ng văn bản."},"qwen-plus":{"description":"M\xf4 h\xecnh ng\xf4n ngữ quy m\xf4 lớn Qwen phi\xean bản n\xe2ng cao, hỗ trợ đầu v\xe0o bằng tiếng Trung, tiếng Anh v\xe0 nhiều ng\xf4n ngữ kh\xe1c."},"qwen-turbo":{"description":"通义千问 Turbo 将不再更新，建议替换为通义千问 Flash。通义千问是一款超大规模的语言模型，支持中文、英文及其他语言的输入。"},"qwen-vl-chat-v1":{"description":"M\xf4 h\xecnh Qwen VL hỗ trợ c\xe1c phương thức tương t\xe1c linh hoạt, bao gồm nhiều h\xecnh ảnh, nhiều v\xf2ng hỏi đ\xe1p, s\xe1ng tạo, v.v."},"qwen-vl-max":{"description":"M\xf4 h\xecnh ng\xf4n ngữ thị gi\xe1c quy m\xf4 si\xeau lớn Tongyi Qianwen. So với phi\xean bản n\xe2ng cao, tiếp tục cải thiện khả năng suy luận thị gi\xe1c v\xe0 tu\xe2n thủ chỉ thị, cung cấp mức độ nhận thức v\xe0 cảm nhận thị gi\xe1c cao hơn."},"qwen-vl-max-latest":{"description":"M\xf4 h\xecnh ng\xf4n ngữ h\xecnh ảnh quy m\xf4 si\xeau lớn của Tongyi Qianwen. So với phi\xean bản n\xe2ng cao, n\xf3 lại n\xe2ng cao khả năng suy luận h\xecnh ảnh v\xe0 khả năng tu\xe2n thủ chỉ dẫn, cung cấp mức độ nhận thức v\xe0 cảm nhận h\xecnh ảnh cao hơn."},"qwen-vl-ocr":{"description":"Tongyi Qianwen OCR l\xe0 m\xf4 h\xecnh chuy\xean biệt cho tr\xedch xuất văn bản, tập trung v\xe0o khả năng tr\xedch xuất chữ viết từ c\xe1c loại h\xecnh ảnh như t\xe0i liệu, bảng biểu, đề thi, chữ viết tay. M\xf4 h\xecnh c\xf3 thể nhận diện nhiều ng\xf4n ngữ, hiện hỗ trợ: tiếng Trung, tiếng Anh, tiếng Ph\xe1p, tiếng Nhật, tiếng H\xe0n, tiếng Đức, tiếng Nga, tiếng \xdd, tiếng Việt, tiếng Ả Rập."},"qwen-vl-plus":{"description":"Phi\xean bản n\xe2ng cao của m\xf4 h\xecnh ng\xf4n ngữ thị gi\xe1c quy m\xf4 lớn Tongyi Qianwen. N\xe2ng cao đ\xe1ng kể khả năng nhận diện chi tiết v\xe0 nhận dạng văn bản, hỗ trợ h\xecnh ảnh c\xf3 độ ph\xe2n giải tr\xean một triệu điểm ảnh v\xe0 tỷ lệ khung h\xecnh t\xf9y \xfd."},"qwen-vl-plus-latest":{"description":"M\xf4 h\xecnh ng\xf4n ngữ h\xecnh ảnh quy m\xf4 lớn phi\xean bản n\xe2ng cao của Tongyi Qianwen. N\xe2ng cao khả năng nhận diện chi tiết v\xe0 nhận diện văn bản, hỗ trợ độ ph\xe2n giải tr\xean một triệu pixel v\xe0 c\xe1c tỷ lệ chiều d\xe0i v\xe0 chiều rộng t\xf9y \xfd."},"qwen-vl-v1":{"description":"M\xf4 h\xecnh được khởi tạo bằng m\xf4 h\xecnh ng\xf4n ngữ Qwen-7B, th\xeam m\xf4 h\xecnh h\xecnh ảnh, m\xf4 h\xecnh được huấn luyện trước với độ ph\xe2n giải đầu v\xe0o h\xecnh ảnh l\xe0 448."},"qwen/qwen-2-7b-instruct":{"description":"Qwen2 l\xe0 d\xf2ng m\xf4 h\xecnh ng\xf4n ngữ lớn ho\xe0n to\xe0n mới. Qwen2 7B l\xe0 một m\xf4 h\xecnh dựa tr\xean transformer, thể hiện xuất sắc trong việc hiểu ng\xf4n ngữ, khả năng đa ng\xf4n ngữ, lập tr\xecnh, to\xe1n học v\xe0 suy luận."},"qwen/qwen-2-7b-instruct:free":{"description":"Qwen2 l\xe0 một loạt m\xf4 h\xecnh ng\xf4n ngữ lớn ho\xe0n to\xe0n mới, c\xf3 khả năng hiểu v\xe0 sinh mạnh mẽ hơn."},"qwen/qwen-2-vl-72b-instruct":{"description":"Qwen2-VL l\xe0 phi\xean bản cải tiến mới nhất của m\xf4 h\xecnh Qwen-VL, đ\xe3 đạt được hiệu suất ti\xean tiến trong c\xe1c b\xe0i kiểm tra hiểu biết thị gi\xe1c, bao gồm MathVista, DocVQA, RealWorldQA v\xe0 MTVQA. Qwen2-VL c\xf3 khả năng hiểu video d\xe0i hơn 20 ph\xfat, phục vụ cho c\xe1c c\xe2u hỏi, đối thoại v\xe0 s\xe1ng tạo nội dung dựa tr\xean video chất lượng cao. N\xf3 cũng c\xf3 khả năng suy luận v\xe0 ra quyết định phức tạp, c\xf3 thể t\xedch hợp với c\xe1c thiết bị di động, robot, v.v., để thực hiện c\xe1c thao t\xe1c tự động dựa tr\xean m\xf4i trường thị gi\xe1c v\xe0 hướng dẫn văn bản. Ngo\xe0i tiếng Anh v\xe0 tiếng Trung, Qwen2-VL hiện cũng hỗ trợ hiểu văn bản trong h\xecnh ảnh bằng nhiều ng\xf4n ngữ kh\xe1c nhau, bao gồm hầu hết c\xe1c ng\xf4n ngữ ch\xe2u \xc2u, tiếng Nhật, tiếng H\xe0n, tiếng Ả Rập v\xe0 tiếng Việt."},"qwen/qwen-2.5-72b-instruct":{"description":"Qwen2.5-72B-Instruct l\xe0 một trong những m\xf4 h\xecnh ng\xf4n ngữ lớn mới nhất được ph\xe1t h\xe0nh bởi Alibaba Cloud. M\xf4 h\xecnh 72B n\xe0y c\xf3 khả năng cải thiện đ\xe1ng kể trong c\xe1c lĩnh vực như m\xe3 h\xf3a v\xe0 to\xe1n học. M\xf4 h\xecnh cũng cung cấp hỗ trợ đa ng\xf4n ngữ, bao gồm hơn 29 ng\xf4n ngữ, bao gồm tiếng Trung, tiếng Anh, v.v. M\xf4 h\xecnh đ\xe3 c\xf3 sự cải thiện đ\xe1ng kể trong việc theo d\xf5i hướng dẫn, hiểu dữ liệu c\xf3 cấu tr\xfac v\xe0 tạo ra đầu ra c\xf3 cấu tr\xfac (đặc biệt l\xe0 JSON)."},"qwen/qwen2.5-32b-instruct":{"description":"Qwen2.5-32B-Instruct l\xe0 một trong những m\xf4 h\xecnh ng\xf4n ngữ lớn mới nhất được ph\xe1t h\xe0nh bởi Alibaba Cloud. M\xf4 h\xecnh 32B n\xe0y c\xf3 khả năng cải thiện đ\xe1ng kể trong c\xe1c lĩnh vực như m\xe3 h\xf3a v\xe0 to\xe1n học. M\xf4 h\xecnh cung cấp hỗ trợ đa ng\xf4n ngữ, bao gồm hơn 29 ng\xf4n ngữ, bao gồm tiếng Trung, tiếng Anh, v.v. M\xf4 h\xecnh đ\xe3 c\xf3 sự cải thiện đ\xe1ng kể trong việc theo d\xf5i hướng dẫn, hiểu dữ liệu c\xf3 cấu tr\xfac v\xe0 tạo ra đầu ra c\xf3 cấu tr\xfac (đặc biệt l\xe0 JSON)."},"qwen/qwen2.5-7b-instruct":{"description":"LLM hướng đến tiếng Trung v\xe0 tiếng Anh, tập trung v\xe0o ng\xf4n ngữ, lập tr\xecnh, to\xe1n học, suy luận v\xe0 c\xe1c lĩnh vực kh\xe1c."},"qwen/qwen2.5-coder-32b-instruct":{"description":"LLM cao cấp, hỗ trợ tạo m\xe3, suy luận v\xe0 sửa chữa, bao gồm c\xe1c ng\xf4n ngữ lập tr\xecnh phổ biến."},"qwen/qwen2.5-coder-7b-instruct":{"description":"M\xf4 h\xecnh m\xe3 mạnh mẽ cỡ trung, hỗ trợ độ d\xe0i ngữ cảnh 32K, xuất sắc trong lập tr\xecnh đa ng\xf4n ngữ."},"qwen/qwen3-14b":{"description":"Qwen3-14B l\xe0 một m\xf4 h\xecnh ng\xf4n ngữ nguy\xean nh\xe2n d\xe0y đặc với 14,8 tỷ tham số trong d\xf2ng Qwen3, được thiết kế cho suy luận phức tạp v\xe0 đối thoại hiệu quả. N\xf3 hỗ trợ chuyển đổi liền mạch giữa chế độ \\"suy nghĩ\\" cho c\xe1c nhiệm vụ như to\xe1n học, lập tr\xecnh v\xe0 suy luận logic với chế độ \\"kh\xf4ng suy nghĩ\\" cho đối thoại th\xf4ng thường. M\xf4 h\xecnh n\xe0y đ\xe3 được tinh chỉnh để sử dụng cho việc tu\xe2n theo chỉ dẫn, sử dụng c\xf4ng cụ đại l\xfd, viết s\xe1ng tạo v\xe0 c\xe1c nhiệm vụ đa ng\xf4n ngữ tr\xean hơn 100 ng\xf4n ngữ v\xe0 phương ngữ. N\xf3 xử l\xfd ngữ cảnh 32K token một c\xe1ch tự nhi\xean v\xe0 c\xf3 thể mở rộng l\xean 131K token bằng c\xe1ch sử dụng mở rộng dựa tr\xean YaRN."},"qwen/qwen3-14b:free":{"description":"Qwen3-14B l\xe0 một m\xf4 h\xecnh ng\xf4n ngữ nguy\xean nh\xe2n d\xe0y đặc với 14,8 tỷ tham số trong d\xf2ng Qwen3, được thiết kế cho suy luận phức tạp v\xe0 đối thoại hiệu quả. N\xf3 hỗ trợ chuyển đổi liền mạch giữa chế độ \\"suy nghĩ\\" cho c\xe1c nhiệm vụ như to\xe1n học, lập tr\xecnh v\xe0 suy luận logic với chế độ \\"kh\xf4ng suy nghĩ\\" cho đối thoại th\xf4ng thường. M\xf4 h\xecnh n\xe0y đ\xe3 được tinh chỉnh để sử dụng cho việc tu\xe2n theo chỉ dẫn, sử dụng c\xf4ng cụ đại l\xfd, viết s\xe1ng tạo v\xe0 c\xe1c nhiệm vụ đa ng\xf4n ngữ tr\xean hơn 100 ng\xf4n ngữ v\xe0 phương ngữ. N\xf3 xử l\xfd ngữ cảnh 32K token một c\xe1ch tự nhi\xean v\xe0 c\xf3 thể mở rộng l\xean 131K token bằng c\xe1ch sử dụng mở rộng dựa tr\xean YaRN."},"qwen/qwen3-235b-a22b":{"description":"Qwen3-235B-A22B l\xe0 m\xf4 h\xecnh hỗn hợp chuy\xean gia (MoE) với 235B tham số được ph\xe1t triển bởi Qwen, k\xedch hoạt 22B tham số mỗi lần truyền tiến. N\xf3 hỗ trợ chuyển đổi liền mạch giữa chế độ \\"suy nghĩ\\" cho suy luận phức tạp, to\xe1n học v\xe0 c\xe1c nhiệm vụ m\xe3 với chế độ \\"kh\xf4ng suy nghĩ\\" cho hiệu suất đối thoại th\xf4ng thường. M\xf4 h\xecnh n\xe0y thể hiện khả năng suy luận mạnh mẽ, hỗ trợ đa ng\xf4n ngữ (hơn 100 ng\xf4n ngữ v\xe0 phương ngữ), tu\xe2n theo chỉ dẫn n\xe2ng cao v\xe0 khả năng gọi c\xf4ng cụ đại l\xfd. N\xf3 xử l\xfd cửa sổ ngữ cảnh 32K token một c\xe1ch tự nhi\xean v\xe0 c\xf3 thể mở rộng l\xean 131K token bằng c\xe1ch sử dụng mở rộng dựa tr\xean YaRN."},"qwen/qwen3-235b-a22b:free":{"description":"Qwen3-235B-A22B l\xe0 m\xf4 h\xecnh hỗn hợp chuy\xean gia (MoE) với 235B tham số được ph\xe1t triển bởi Qwen, k\xedch hoạt 22B tham số mỗi lần truyền tiến. N\xf3 hỗ trợ chuyển đổi liền mạch giữa chế độ \\"suy nghĩ\\" cho suy luận phức tạp, to\xe1n học v\xe0 c\xe1c nhiệm vụ m\xe3 với chế độ \\"kh\xf4ng suy nghĩ\\" cho hiệu suất đối thoại th\xf4ng thường. M\xf4 h\xecnh n\xe0y thể hiện khả năng suy luận mạnh mẽ, hỗ trợ đa ng\xf4n ngữ (hơn 100 ng\xf4n ngữ v\xe0 phương ngữ), tu\xe2n theo chỉ dẫn n\xe2ng cao v\xe0 khả năng gọi c\xf4ng cụ đại l\xfd. N\xf3 xử l\xfd cửa sổ ngữ cảnh 32K token một c\xe1ch tự nhi\xean v\xe0 c\xf3 thể mở rộng l\xean 131K token bằng c\xe1ch sử dụng mở rộng dựa tr\xean YaRN."},"qwen/qwen3-30b-a3b":{"description":"Qwen3 l\xe0 thế hệ mới nhất trong d\xf2ng m\xf4 h\xecnh ng\xf4n ngữ lớn Qwen, với kiến tr\xfac hỗn hợp chuy\xean gia (MoE) d\xe0y đặc, thể hiện xuất sắc trong suy luận, hỗ trợ đa ng\xf4n ngữ v\xe0 c\xe1c nhiệm vụ đại l\xfd n\xe2ng cao. Khả năng chuyển đổi liền mạch giữa chế độ suy nghĩ cho suy luận phức tạp v\xe0 chế độ kh\xf4ng suy nghĩ cho đối thoại hiệu quả đảm bảo hiệu suất đa chức năng v\xe0 chất lượng cao.\\n\\nQwen3 vượt trội hơn hẳn c\xe1c m\xf4 h\xecnh trước như QwQ v\xe0 Qwen2.5, cung cấp khả năng to\xe1n học, lập tr\xecnh, suy luận th\xf4ng thường, viết s\xe1ng tạo v\xe0 đối thoại tương t\xe1c xuất sắc. Biến thể Qwen3-30B-A3B chứa 30,5 tỷ tham số (3,3 tỷ tham số k\xedch hoạt), 48 lớp, 128 chuy\xean gia (mỗi nhiệm vụ k\xedch hoạt 8), v\xe0 hỗ trợ ngữ cảnh l\xean đến 131K token (sử dụng YaRN), thiết lập ti\xeau chuẩn mới cho c\xe1c m\xf4 h\xecnh m\xe3 nguồn mở."},"qwen/qwen3-30b-a3b:free":{"description":"Qwen3 l\xe0 thế hệ mới nhất trong d\xf2ng m\xf4 h\xecnh ng\xf4n ngữ lớn Qwen, với kiến tr\xfac hỗn hợp chuy\xean gia (MoE) d\xe0y đặc, thể hiện xuất sắc trong suy luận, hỗ trợ đa ng\xf4n ngữ v\xe0 c\xe1c nhiệm vụ đại l\xfd n\xe2ng cao. Khả năng chuyển đổi liền mạch giữa chế độ suy nghĩ cho suy luận phức tạp v\xe0 chế độ kh\xf4ng suy nghĩ cho đối thoại hiệu quả đảm bảo hiệu suất đa chức năng v\xe0 chất lượng cao.\\n\\nQwen3 vượt trội hơn hẳn c\xe1c m\xf4 h\xecnh trước như QwQ v\xe0 Qwen2.5, cung cấp khả năng to\xe1n học, lập tr\xecnh, suy luận th\xf4ng thường, viết s\xe1ng tạo v\xe0 đối thoại tương t\xe1c xuất sắc. Biến thể Qwen3-30B-A3B chứa 30,5 tỷ tham số (3,3 tỷ tham số k\xedch hoạt), 48 lớp, 128 chuy\xean gia (mỗi nhiệm vụ k\xedch hoạt 8), v\xe0 hỗ trợ ngữ cảnh l\xean đến 131K token (sử dụng YaRN), thiết lập ti\xeau chuẩn mới cho c\xe1c m\xf4 h\xecnh m\xe3 nguồn mở."},"qwen/qwen3-32b":{"description":"Qwen3-32B l\xe0 một m\xf4 h\xecnh ng\xf4n ngữ nguy\xean nh\xe2n d\xe0y đặc với 32,8 tỷ tham số trong d\xf2ng Qwen3, được tối ưu h\xf3a cho suy luận phức tạp v\xe0 đối thoại hiệu quả. N\xf3 hỗ trợ chuyển đổi liền mạch giữa chế độ \\"suy nghĩ\\" cho c\xe1c nhiệm vụ như to\xe1n học, lập tr\xecnh v\xe0 suy luận logic với chế độ \\"kh\xf4ng suy nghĩ\\" cho đối thoại nhanh hơn v\xe0 th\xf4ng thường. M\xf4 h\xecnh n\xe0y thể hiện hiệu suất mạnh mẽ trong việc tu\xe2n theo chỉ dẫn, sử dụng c\xf4ng cụ đại l\xfd, viết s\xe1ng tạo v\xe0 c\xe1c nhiệm vụ đa ng\xf4n ngữ tr\xean hơn 100 ng\xf4n ngữ v\xe0 phương ngữ. N\xf3 xử l\xfd ngữ cảnh 32K token một c\xe1ch tự nhi\xean v\xe0 c\xf3 thể mở rộng l\xean 131K token bằng c\xe1ch sử dụng mở rộng dựa tr\xean YaRN."},"qwen/qwen3-32b:free":{"description":"Qwen3-32B l\xe0 một m\xf4 h\xecnh ng\xf4n ngữ nguy\xean nh\xe2n d\xe0y đặc với 32,8 tỷ tham số trong d\xf2ng Qwen3, được tối ưu h\xf3a cho suy luận phức tạp v\xe0 đối thoại hiệu quả. N\xf3 hỗ trợ chuyển đổi liền mạch giữa chế độ \\"suy nghĩ\\" cho c\xe1c nhiệm vụ như to\xe1n học, lập tr\xecnh v\xe0 suy luận logic với chế độ \\"kh\xf4ng suy nghĩ\\" cho đối thoại nhanh hơn v\xe0 th\xf4ng thường. M\xf4 h\xecnh n\xe0y thể hiện hiệu suất mạnh mẽ trong việc tu\xe2n theo chỉ dẫn, sử dụng c\xf4ng cụ đại l\xfd, viết s\xe1ng tạo v\xe0 c\xe1c nhiệm vụ đa ng\xf4n ngữ tr\xean hơn 100 ng\xf4n ngữ v\xe0 phương ngữ. N\xf3 xử l\xfd ngữ cảnh 32K token một c\xe1ch tự nhi\xean v\xe0 c\xf3 thể mở rộng l\xean 131K token bằng c\xe1ch sử dụng mở rộng dựa tr\xean YaRN."},"qwen/qwen3-8b:free":{"description":"Qwen3-8B l\xe0 một m\xf4 h\xecnh ng\xf4n ngữ nguy\xean nh\xe2n d\xe0y đặc với 8,2 tỷ tham số trong d\xf2ng Qwen3, được thiết kế cho c\xe1c nhiệm vụ y\xeau cầu suy luận d\xe0y đặc v\xe0 đối thoại hiệu quả. N\xf3 hỗ trợ chuyển đổi liền mạch giữa chế độ \\"suy nghĩ\\" cho to\xe1n học, lập tr\xecnh v\xe0 suy luận logic với chế độ \\"kh\xf4ng suy nghĩ\\" cho đối thoại th\xf4ng thường. M\xf4 h\xecnh n\xe0y đ\xe3 được tinh chỉnh để sử dụng cho việc tu\xe2n theo chỉ dẫn, t\xedch hợp đại l\xfd, viết s\xe1ng tạo v\xe0 sử dụng đa ng\xf4n ngữ tr\xean hơn 100 ng\xf4n ngữ v\xe0 phương ngữ. N\xf3 hỗ trợ cửa sổ ngữ cảnh 32K token v\xe0 c\xf3 thể mở rộng l\xean 131K token th\xf4ng qua YaRN."},"qwen2":{"description":"Qwen2 l\xe0 m\xf4 h\xecnh ng\xf4n ngữ quy m\xf4 lớn thế hệ mới của Alibaba, hỗ trợ c\xe1c nhu cầu ứng dụng đa dạng với hiệu suất xuất sắc."},"qwen2.5":{"description":"Qwen2.5 l\xe0 thế hệ m\xf4 h\xecnh ng\xf4n ngữ quy m\xf4 lớn mới của Alibaba, hỗ trợ c\xe1c nhu cầu ứng dụng đa dạng với hiệu suất xuất sắc."},"qwen2.5-14b-instruct":{"description":"M\xf4 h\xecnh 14B quy m\xf4 mở nguồn của Qwen 2.5."},"qwen2.5-14b-instruct-1m":{"description":"M\xf4 h\xecnh quy m\xf4 72B được mở nguồn từ Qianwen 2.5."},"qwen2.5-32b-instruct":{"description":"M\xf4 h\xecnh 32B quy m\xf4 mở nguồn của Qwen 2.5."},"qwen2.5-72b-instruct":{"description":"M\xf4 h\xecnh 72B quy m\xf4 mở nguồn của Qwen 2.5."},"qwen2.5-7b-instruct":{"description":"Qwen2.5 7B Instruct, m\xf4 h\xecnh chỉ dẫn m\xe3 nguồn mở trưởng th\xe0nh, ph\xf9 hợp cho hội thoại v\xe0 tạo nội dung trong nhiều ngữ cảnh."},"qwen2.5-coder-1.5b-instruct":{"description":"Phi\xean bản m\xe3 nguồn mở của m\xf4 h\xecnh m\xe3 Qwen."},"qwen2.5-coder-14b-instruct":{"description":"Phi\xean bản m\xe3 nguồn mở của m\xf4 h\xecnh m\xe3 h\xf3a Tongyi Qianwen."},"qwen2.5-coder-32b-instruct":{"description":"Phi\xean bản m\xe3 nguồn mở của m\xf4 h\xecnh m\xe3 Qwen."},"qwen2.5-coder-7b-instruct":{"description":"Phi\xean bản m\xe3 nguồn mở của m\xf4 h\xecnh m\xe3 Qwen."},"qwen2.5-coder-instruct":{"description":"Qwen2.5-Coder l\xe0 m\xf4 h\xecnh ng\xf4n ngữ lớn mới nhất trong series Qwen, chuy\xean dụng cho lập tr\xecnh (trước đ\xe2y được gọi l\xe0 CodeQwen)."},"qwen2.5-instruct":{"description":"Qwen2.5 l\xe0 phi\xean bản mới nhất của m\xf4 h\xecnh ng\xf4n ngữ lớn Qwen. Đối với Qwen2.5, ch\xfang t\xf4i đ\xe3 ph\xe1t h\xe0nh nhiều m\xf4 h\xecnh ng\xf4n ngữ cơ sở v\xe0 m\xf4 h\xecnh ng\xf4n ngữ điều chỉnh theo lệnh, với phạm vi tham số từ 500 triệu đến 7,2 tỷ."},"qwen2.5-math-1.5b-instruct":{"description":"M\xf4 h\xecnh Qwen-Math c\xf3 khả năng giải to\xe1n mạnh mẽ."},"qwen2.5-math-72b-instruct":{"description":"M\xf4 h\xecnh Qwen-Math c\xf3 khả năng giải quyết b\xe0i to\xe1n to\xe1n học mạnh mẽ."},"qwen2.5-math-7b-instruct":{"description":"M\xf4 h\xecnh Qwen-Math c\xf3 khả năng giải quyết b\xe0i to\xe1n to\xe1n học mạnh mẽ."},"qwen2.5-omni-7b":{"description":"M\xf4 h\xecnh Qwen-Omni hỗ trợ đầu v\xe0o từ nhiều loại dữ liệu kh\xe1c nhau, bao gồm video, \xe2m thanh, h\xecnh ảnh v\xe0 văn bản, v\xe0 xuất ra \xe2m thanh v\xe0 văn bản."},"qwen2.5-vl-32b-instruct":{"description":"Qwen2.5 VL 32B Instruct, m\xf4 h\xecnh đa phương tiện m\xe3 nguồn mở, th\xedch hợp cho triển khai ri\xeang tư v\xe0 ứng dụng đa ngữ cảnh."},"qwen2.5-vl-72b-instruct":{"description":"N\xe2ng cao khả năng theo d\xf5i lệnh, to\xe1n học, giải quyết vấn đề, m\xe3 h\xf3a, n\xe2ng cao khả năng nhận diện mọi thứ, hỗ trợ định vị ch\xednh x\xe1c c\xe1c yếu tố thị gi\xe1c từ nhiều định dạng kh\xe1c nhau, hỗ trợ hiểu v\xe0 định vị thời gian sự kiện trong c\xe1c tệp video d\xe0i (tối đa 10 ph\xfat), c\xf3 khả năng hiểu thứ tự thời gian v\xe0 tốc độ, hỗ trợ điều khiển Agent tr\xean OS hoặc Mobile dựa tr\xean khả năng ph\xe2n t\xedch v\xe0 định vị, khả năng tr\xedch xuất th\xf4ng tin quan trọng v\xe0 xuất định dạng Json mạnh mẽ, phi\xean bản n\xe0y l\xe0 phi\xean bản 72B, phi\xean bản mạnh nhất trong d\xf2ng sản phẩm n\xe0y."},"qwen2.5-vl-7b-instruct":{"description":"Qwen2.5 VL 7B Instruct, m\xf4 h\xecnh đa phương tiện nhẹ, c\xe2n bằng giữa chi ph\xed triển khai v\xe0 khả năng nhận diện."},"qwen2.5-vl-instruct":{"description":"Qwen2.5-VL l\xe0 phi\xean bản mới nhất của m\xf4 h\xecnh ng\xf4n ngữ v\xe0 h\xecnh ảnh trong gia đ\xecnh m\xf4 h\xecnh Qwen."},"qwen2.5:0.5b":{"description":"Qwen2.5 l\xe0 thế hệ m\xf4 h\xecnh ng\xf4n ngữ quy m\xf4 lớn mới của Alibaba, hỗ trợ c\xe1c nhu cầu ứng dụng đa dạng với hiệu suất xuất sắc."},"qwen2.5:1.5b":{"description":"Qwen2.5 l\xe0 thế hệ m\xf4 h\xecnh ng\xf4n ngữ quy m\xf4 lớn mới của Alibaba, hỗ trợ c\xe1c nhu cầu ứng dụng đa dạng với hiệu suất xuất sắc."},"qwen2.5:72b":{"description":"Qwen2.5 l\xe0 thế hệ m\xf4 h\xecnh ng\xf4n ngữ quy m\xf4 lớn mới của Alibaba, hỗ trợ c\xe1c nhu cầu ứng dụng đa dạng với hiệu suất xuất sắc."},"qwen2:0.5b":{"description":"Qwen2 l\xe0 m\xf4 h\xecnh ng\xf4n ngữ quy m\xf4 lớn thế hệ mới của Alibaba, hỗ trợ c\xe1c nhu cầu ứng dụng đa dạng với hiệu suất xuất sắc."},"qwen2:1.5b":{"description":"Qwen2 l\xe0 m\xf4 h\xecnh ng\xf4n ngữ quy m\xf4 lớn thế hệ mới của Alibaba, hỗ trợ c\xe1c nhu cầu ứng dụng đa dạng với hiệu suất xuất sắc."},"qwen2:72b":{"description":"Qwen2 l\xe0 m\xf4 h\xecnh ng\xf4n ngữ quy m\xf4 lớn thế hệ mới của Alibaba, hỗ trợ c\xe1c nhu cầu ứng dụng đa dạng với hiệu suất xuất sắc."},"qwen3":{"description":"Qwen3 l\xe0 m\xf4 h\xecnh ng\xf4n ngữ quy m\xf4 lớn thế hệ mới của Alibaba, hỗ trợ nhu cầu ứng dụng đa dạng với hiệu suất xuất sắc."},"qwen3-0.6b":{"description":"Qwen3 0.6B, m\xf4 h\xecnh cấp nhập m\xf4n, ph\xf9 hợp cho suy luận đơn giản v\xe0 m\xf4i trường t\xe0i nguy\xean cực kỳ hạn chế."},"qwen3-1.7b":{"description":"Qwen3 1.7B, m\xf4 h\xecnh si\xeau nhẹ, dễ d\xe0ng triển khai tại bi\xean v\xe0 thiết bị đầu cuối."},"qwen3-14b":{"description":"Qwen3 14B, m\xf4 h\xecnh cỡ trung, ph\xf9 hợp cho hỏi đ\xe1p đa ng\xf4n ngữ v\xe0 tạo văn bản."},"qwen3-235b-a22b":{"description":"Qwen3 235B A22B, m\xf4 h\xecnh lớn đa năng, hướng đến nhiều nhiệm vụ phức tạp."},"qwen3-235b-a22b-instruct-2507":{"description":"Qwen3 235B A22B Instruct 2507, m\xf4 h\xecnh chỉ dẫn h\xe0ng đầu đa năng, ph\xf9 hợp cho nhiều nhiệm vụ tạo nội dung v\xe0 suy luận."},"qwen3-235b-a22b-thinking-2507":{"description":"Qwen3 235B A22B Thinking 2507, m\xf4 h\xecnh tư duy quy m\xf4 si\xeau lớn, th\xedch hợp cho suy luận độ kh\xf3 cao."},"qwen3-30b-a3b":{"description":"Qwen3 30B A3B, m\xf4 h\xecnh đa năng cỡ trung-lớn, c\xe2n bằng giữa chi ph\xed v\xe0 hiệu quả."},"qwen3-30b-a3b-instruct-2507":{"description":"Qwen3 30B A3B Instruct 2507, m\xf4 h\xecnh chỉ dẫn cỡ trung-lớn, ph\xf9 hợp cho tạo nội dung chất lượng cao v\xe0 hỏi đ\xe1p."},"qwen3-30b-a3b-thinking-2507":{"description":"Qwen3 30B A3B Thinking 2507, m\xf4 h\xecnh tư duy cỡ trung-lớn, c\xe2n bằng giữa độ ch\xednh x\xe1c v\xe0 chi ph\xed."},"qwen3-32b":{"description":"Qwen3 32B, ph\xf9 hợp cho c\xe1c nhiệm vụ đa năng y\xeau cầu khả năng hiểu s\xe2u hơn."},"qwen3-4b":{"description":"Qwen3 4B, ph\xf9 hợp cho ứng dụng vừa v\xe0 nhỏ v\xe0 c\xe1c t\xecnh huống suy luận cục bộ."},"qwen3-8b":{"description":"Qwen3 8B, m\xf4 h\xecnh nhẹ, triển khai linh hoạt, ph\xf9 hợp cho c\xe1c nghiệp vụ c\xf3 tần suất cao."},"qwen3-coder-30b-a3b-instruct":{"description":"Phi\xean bản m\xe3 nguồn mở của m\xf4 h\xecnh m\xe3 h\xf3a Tongyi Qianwen. M\xf4 h\xecnh qwen3-coder-30b-a3b-instruct mới nhất được ph\xe1t triển dựa tr\xean Qwen3, c\xf3 khả năng hoạt động như một T\xe1c nh\xe2n Lập tr\xecnh mạnh mẽ, th\xe0nh thạo trong việc gọi c\xf4ng cụ v\xe0 tương t\xe1c m\xf4i trường, hỗ trợ lập tr\xecnh tự động với năng lực m\xe3 h\xf3a xuất sắc v\xe0 khả năng tổng qu\xe1t cao."},"qwen3-coder-480b-a35b-instruct":{"description":"Qwen3 Coder 480B A35B Instruct, m\xf4 h\xecnh m\xe3 h\xf3a h\xe0ng đầu, hỗ trợ lập tr\xecnh đa ng\xf4n ngữ v\xe0 hiểu m\xe3 phức tạp."},"qwen3-coder-flash":{"description":"M\xf4 h\xecnh m\xe3 nguồn của Th\xf4ng Nghĩa Thi\xean Vấn. Bộ m\xf4 h\xecnh Qwen3-Coder mới nhất dựa tr\xean Qwen3 l\xe0 m\xf4 h\xecnh tạo m\xe3, c\xf3 khả năng Coding Agent mạnh mẽ, th\xe0nh thạo gọi c\xf4ng cụ v\xe0 tương t\xe1c m\xf4i trường, c\xf3 thể tự lập tr\xecnh, vừa xuất sắc về năng lực m\xe3 h\xf3a vừa c\xf3 khả năng tổng qu\xe1t."},"qwen3-coder-plus":{"description":"M\xf4 h\xecnh m\xe3 nguồn của Th\xf4ng Nghĩa Thi\xean Vấn. Bộ m\xf4 h\xecnh Qwen3-Coder mới nhất dựa tr\xean Qwen3 l\xe0 m\xf4 h\xecnh tạo m\xe3, c\xf3 khả năng Coding Agent mạnh mẽ, th\xe0nh thạo gọi c\xf4ng cụ v\xe0 tương t\xe1c m\xf4i trường, c\xf3 thể tự lập tr\xecnh, vừa xuất sắc về năng lực m\xe3 h\xf3a vừa c\xf3 khả năng tổng qu\xe1t."},"qwen3-coder:480b":{"description":"M\xf4 h\xecnh ngữ cảnh d\xe0i hiệu năng cao của Alibaba d\xe0nh cho c\xe1c t\xe1c vụ đại diện v\xe0 m\xe3 h\xf3a."},"qwen3-max":{"description":"D\xf2ng m\xf4 h\xecnh Max của Tongyi Qianwen 3, so với d\xf2ng 2.5 c\xf3 sự cải thiện lớn về khả năng chung, bao gồm hiểu văn bản song ngữ Trung-Anh, tu\xe2n thủ chỉ dẫn phức tạp, khả năng thực hiện c\xe1c t\xe1c vụ mở chủ quan, đa ng\xf4n ngữ v\xe0 gọi c\xf4ng cụ; giảm thiểu ảo tưởng kiến thức của m\xf4 h\xecnh. Phi\xean bản qwen3-max mới nhất đ\xe3 n\xe2ng cấp chuy\xean biệt về lập tr\xecnh t\xe1c nh\xe2n v\xe0 gọi c\xf4ng cụ so với phi\xean bản qwen3-max-preview. M\xf4 h\xecnh ch\xednh thức ph\xe1t h\xe0nh đạt mức SOTA trong lĩnh vực, ph\xf9 hợp với c\xe1c nhu cầu t\xe1c nh\xe2n phức tạp hơn."},"qwen3-max-preview":{"description":"M\xf4 h\xecnh mạnh nhất trong d\xf2ng Tongyi Qianwen, ph\xf9 hợp với c\xe1c t\xe1c vụ phức tạp v\xe0 nhiều bước. Phi\xean bản xem trước đ\xe3 hỗ trợ khả năng suy luận."},"qwen3-next-80b-a3b-instruct":{"description":"M\xf4 h\xecnh m\xe3 nguồn mở thế hệ mới kh\xf4ng c\xf3 chế độ suy nghĩ dựa tr\xean Qwen3, so với phi\xean bản trước (Th\xf4ng Nghĩa Thi\xean Vấn 3-235B-A22B-Instruct-2507) c\xf3 khả năng hiểu văn bản tiếng Trung tốt hơn, năng lực suy luận logic được cải thiện, v\xe0 hiệu suất trong c\xe1c nhiệm vụ tạo văn bản cũng tốt hơn."},"qwen3-next-80b-a3b-thinking":{"description":"Qwen3 Next 80B A3B Thinking, phi\xean bản m\xf4 h\xecnh tư duy h\xe0ng đầu cho c\xe1c nhiệm vụ phức tạp."},"qwen3-omni-flash":{"description":"M\xf4 h\xecnh Qwen-Omni c\xf3 thể tiếp nhận đầu v\xe0o kết hợp từ nhiều phương thức như văn bản, h\xecnh ảnh, \xe2m thanh v\xe0 video, v\xe0 tạo phản hồi dưới dạng văn bản hoặc giọng n\xf3i. M\xf4 h\xecnh cung cấp nhiều giọng n\xf3i nh\xe2n h\xf3a, hỗ trợ đầu ra bằng nhiều ng\xf4n ngữ v\xe0 phương ngữ, ph\xf9 hợp với c\xe1c ứng dụng như s\xe1ng t\xe1c văn bản, nhận diện h\xecnh ảnh v\xe0 trợ l\xfd giọng n\xf3i."},"qwen3-vl-235b-a22b-instruct":{"description":"Qwen3 VL 235B A22B Instruct, m\xf4 h\xecnh đa phương tiện h\xe0ng đầu, hướng đến c\xe1c t\xecnh huống y\xeau cầu cao về hiểu v\xe0 s\xe1ng tạo."},"qwen3-vl-235b-a22b-thinking":{"description":"Qwen3 VL 235B A22B Thinking, phi\xean bản tư duy h\xe0ng đầu, d\xf9ng cho suy luận v\xe0 lập kế hoạch đa phương tiện phức tạp."},"qwen3-vl-30b-a3b-instruct":{"description":"Qwen3 VL 30B A3B Instruct, m\xf4 h\xecnh đa phương tiện lớn, c\xe2n bằng giữa độ ch\xednh x\xe1c v\xe0 hiệu suất suy luận."},"qwen3-vl-30b-a3b-thinking":{"description":"Qwen3 VL 30B A3B Thinking, phi\xean bản tư duy s\xe2u cho c\xe1c nhiệm vụ đa phương tiện phức tạp."},"qwen3-vl-32b-instruct":{"description":"Qwen3 VL 32B Instruct, m\xf4 h\xecnh chỉ dẫn đa phương tiện, ph\xf9 hợp cho hỏi đ\xe1p v\xe0 s\xe1ng tạo h\xecnh ảnh-văn bản chất lượng cao."},"qwen3-vl-32b-thinking":{"description":"Qwen3 VL 32B Thinking, phi\xean bản tư duy s\xe2u đa phương tiện, tăng cường suy luận phức tạp v\xe0 ph\xe2n t\xedch chuỗi d\xe0i."},"qwen3-vl-8b-instruct":{"description":"Qwen3 VL 8B Instruct, m\xf4 h\xecnh đa phương tiện nhẹ, ph\xf9 hợp cho hỏi đ\xe1p thị gi\xe1c h\xe0ng ng\xe0y v\xe0 t\xedch hợp ứng dụng."},"qwen3-vl-8b-thinking":{"description":"Qwen3 VL 8B Thinking, m\xf4 h\xecnh chuỗi tư duy đa phương tiện, th\xedch hợp cho suy luận chi tiết về th\xf4ng tin h\xecnh ảnh."},"qwen3-vl-flash":{"description":"Qwen3 VL Flash: phi\xean bản suy luận tốc độ cao v\xe0 nhẹ, ph\xf9 hợp với c\xe1c t\xecnh huống y\xeau cầu độ trễ thấp hoặc xử l\xfd số lượng lớn y\xeau cầu."},"qwen3-vl-plus":{"description":"Tongyi Qianwen VL l\xe0 m\xf4 h\xecnh sinh văn bản c\xf3 khả năng hiểu thị gi\xe1c (h\xecnh ảnh), kh\xf4ng chỉ thực hiện OCR (nhận dạng chữ trong ảnh) m\xe0 c\xf2n c\xf3 thể t\xf3m tắt v\xe0 suy luận th\xeam, v\xed dụ như tr\xedch xuất thuộc t\xednh từ ảnh sản phẩm, giải b\xe0i tập dựa tr\xean h\xecnh ảnh minh họa."},"qwq":{"description":"QwQ l\xe0 một m\xf4 h\xecnh nghi\xean cứu thử nghiệm, tập trung v\xe0o việc n\xe2ng cao khả năng suy luận của AI."},"qwq-32b":{"description":"M\xf4 h\xecnh suy diễn QwQ được đ\xe0o tạo dựa tr\xean m\xf4 h\xecnh Qwen2.5-32B, đ\xe3 được cải thiện đ\xe1ng kể khả năng suy diễn của m\xf4 h\xecnh th\xf4ng qua học tăng cường. C\xe1c chỉ số cốt l\xf5i của m\xf4 h\xecnh như m\xe3 to\xe1n (AIME 24/25, LiveCodeBench) v\xe0 một số chỉ số chung (IFEval, LiveBench, v.v.) đạt đến mức độ của phi\xean bản đầy đủ DeepSeek-R1, tất cả c\xe1c chỉ số đều vượt trội so với DeepSeek-R1-Distill-Qwen-32B cũng dựa tr\xean Qwen2.5-32B."},"qwq-32b-preview":{"description":"M\xf4 h\xecnh QwQ l\xe0 một m\xf4 h\xecnh nghi\xean cứu thử nghiệm được ph\xe1t triển bởi đội ngũ Qwen, tập trung v\xe0o việc n\xe2ng cao khả năng suy luận của AI."},"qwq-plus":{"description":"M\xf4 h\xecnh suy luận QwQ dựa tr\xean m\xf4 h\xecnh Qwen2.5, đ\xe3 n\xe2ng cao đ\xe1ng kể khả năng suy luận th\xf4ng qua học tăng cường. C\xe1c chỉ số cốt l\xf5i về to\xe1n học, m\xe3 h\xf3a (AIME 24/25, LiveCodeBench) v\xe0 một số chỉ số chung (IFEval, LiveBench, v.v.) đạt mức tương đương phi\xean bản đầy đủ của DeepSeek-R1."},"qwq_32b":{"description":"M\xf4 h\xecnh suy luận c\xf3 quy m\xf4 trung b\xecnh trong d\xf2ng Qwen. So với c\xe1c m\xf4 h\xecnh tinh chỉnh hướng dẫn truyền thống, QwQ c\xf3 khả năng suy nghĩ v\xe0 suy luận, c\xf3 thể n\xe2ng cao hiệu suất đ\xe1ng kể trong c\xe1c nhiệm vụ hạ nguồn, đặc biệt l\xe0 trong việc giải quyết c\xe1c vấn đề kh\xf3 khăn."},"r1-1776":{"description":"R1-1776 l\xe0 một phi\xean bản của m\xf4 h\xecnh DeepSeek R1, đ\xe3 được huấn luyện lại, cung cấp th\xf4ng tin sự thật chưa được kiểm duyệt v\xe0 kh\xf4ng thi\xean lệch."},"solar-mini":{"description":"Solar Mini l\xe0 một LLM dạng nhỏ gọn, hiệu suất vượt trội hơn GPT-3.5, c\xf3 khả năng đa ng\xf4n ngữ mạnh mẽ, hỗ trợ tiếng Anh v\xe0 tiếng H\xe0n, cung cấp giải ph\xe1p hiệu quả v\xe0 nhỏ gọn."},"solar-mini-ja":{"description":"Solar Mini (Ja) mở rộng khả năng của Solar Mini, tập trung v\xe0o tiếng Nhật, đồng thời duy tr\xec hiệu quả v\xe0 hiệu suất xuất sắc trong việc sử dụng tiếng Anh v\xe0 tiếng H\xe0n."},"solar-pro":{"description":"Solar Pro l\xe0 một LLM th\xf4ng minh cao do Upstage ph\xe1t h\xe0nh, tập trung v\xe0o khả năng tu\xe2n theo hướng dẫn tr\xean một GPU, đạt điểm IFEval tr\xean 80. Hiện tại hỗ trợ tiếng Anh, phi\xean bản ch\xednh thức dự kiến ra mắt v\xe0o th\xe1ng 11 năm 2024, sẽ mở rộng hỗ trợ ng\xf4n ngữ v\xe0 độ d\xe0i ngữ cảnh."},"sonar":{"description":"Sản phẩm t\xecm kiếm nhẹ dựa tr\xean ngữ cảnh t\xecm kiếm, nhanh hơn v\xe0 rẻ hơn so với Sonar Pro."},"sonar-deep-research":{"description":"Nghi\xean cứu s\xe2u tiến h\xe0nh nghi\xean cứu chuy\xean gia to\xe0n diện v\xe0 tổng hợp th\xe0nh c\xe1c b\xe1o c\xe1o c\xf3 thể truy cập v\xe0 c\xf3 thể h\xe0nh động."},"sonar-pro":{"description":"Sản phẩm t\xecm kiếm n\xe2ng cao hỗ trợ ngữ cảnh t\xecm kiếm, cho ph\xe9p truy vấn v\xe0 theo d\xf5i n\xe2ng cao."},"sonar-reasoning":{"description":"Sản phẩm API mới được hỗ trợ bởi m\xf4 h\xecnh suy luận của DeepSeek."},"sonar-reasoning-pro":{"description":"Sản phẩm API mới được hỗ trợ bởi m\xf4 h\xecnh suy diễn DeepSeek."},"stable-diffusion-3-medium":{"description":"M\xf4 h\xecnh tạo h\xecnh ảnh từ văn bản mới nhất do Stability AI ph\xe1t h\xe0nh. Phi\xean bản n\xe0y kế thừa ưu điểm của thế hệ trước, cải tiến đ\xe1ng kể về chất lượng h\xecnh ảnh, hiểu văn bản v\xe0 đa dạng phong c\xe1ch, c\xf3 thể giải th\xedch ch\xednh x\xe1c c\xe1c gợi \xfd ng\xf4n ngữ tự nhi\xean phức tạp v\xe0 tạo ra h\xecnh ảnh ch\xednh x\xe1c, đa dạng hơn."},"stable-diffusion-3.5-large":{"description":"stable-diffusion-3.5-large l\xe0 m\xf4 h\xecnh tạo h\xecnh ảnh từ văn bản đa phương thức khuếch t\xe1n biến \xe1p (MMDiT) với 800 triệu tham số, c\xf3 chất lượng h\xecnh ảnh xuất sắc v\xe0 độ khớp gợi \xfd cao, hỗ trợ tạo h\xecnh ảnh độ ph\xe2n giải cao 1 triệu pixel, đồng thời vận h\xe0nh hiệu quả tr\xean phần cứng ti\xeau d\xf9ng phổ th\xf4ng."},"stable-diffusion-3.5-large-turbo":{"description":"stable-diffusion-3.5-large-turbo l\xe0 m\xf4 h\xecnh dựa tr\xean stable-diffusion-3.5-large, sử dụng kỹ thuật chưng cất khuếch t\xe1n đối kh\xe1ng (ADD), c\xf3 tốc độ nhanh hơn."},"stable-diffusion-v1.5":{"description":"stable-diffusion-v1.5 được khởi tạo từ trọng số checkpoint stable-diffusion-v1.2, được tinh chỉnh 595k bước ở độ ph\xe2n giải 512x512 tr\xean \\"laion-aesthetics v2 5+\\", giảm 10% điều kiện h\xf3a văn bản để cải thiện lấy mẫu hướng dẫn kh\xf4ng bộ ph\xe2n loại."},"stable-diffusion-xl":{"description":"stable-diffusion-xl c\xf3 cải tiến lớn so với v1.5 v\xe0 đạt hiệu quả tương đương m\xf4 h\xecnh SOTA m\xe3 nguồn mở hiện tại như midjourney. Cải tiến cụ thể bao gồm: unet backbone lớn hơn gấp 3 lần; th\xeam module tinh chỉnh để cải thiện chất lượng h\xecnh ảnh tạo ra; kỹ thuật huấn luyện hiệu quả hơn."},"stable-diffusion-xl-base-1.0":{"description":"M\xf4 h\xecnh tạo h\xecnh ảnh từ văn bản quy m\xf4 lớn do Stability AI ph\xe1t triển v\xe0 m\xe3 nguồn mở, c\xf3 khả năng tạo h\xecnh ảnh s\xe1ng tạo đứng đầu ng\xe0nh. C\xf3 khả năng hiểu chỉ dẫn xuất sắc, hỗ trợ định nghĩa prompt ngược để tạo nội dung ch\xednh x\xe1c."},"step-1-128k":{"description":"C\xe2n bằng hiệu suất v\xe0 chi ph\xed, ph\xf9 hợp cho c\xe1c t\xecnh huống chung."},"step-1-256k":{"description":"C\xf3 khả năng xử l\xfd ngữ cảnh si\xeau d\xe0i, đặc biệt ph\xf9 hợp cho ph\xe2n t\xedch t\xe0i liệu d\xe0i."},"step-1-32k":{"description":"Hỗ trợ đối thoại c\xf3 độ d\xe0i trung b\xecnh, ph\xf9 hợp cho nhiều t\xecnh huống ứng dụng."},"step-1-8k":{"description":"M\xf4 h\xecnh nhỏ, ph\xf9 hợp cho c\xe1c nhiệm vụ nhẹ."},"step-1-flash":{"description":"M\xf4 h\xecnh tốc độ cao, ph\xf9 hợp cho đối thoại thời gian thực."},"step-1.5v-mini":{"description":"M\xf4 h\xecnh n\xe0y c\xf3 khả năng hiểu video mạnh mẽ."},"step-1o-turbo-vision":{"description":"M\xf4 h\xecnh n\xe0y c\xf3 khả năng hiểu h\xecnh ảnh mạnh mẽ, vượt trội hơn 1o trong lĩnh vực to\xe1n học v\xe0 m\xe3. M\xf4 h\xecnh nhỏ hơn 1o v\xe0 c\xf3 tốc độ xuất ra nhanh hơn."},"step-1o-vision-32k":{"description":"M\xf4 h\xecnh n\xe0y c\xf3 khả năng hiểu h\xecnh ảnh mạnh mẽ. So với c\xe1c m\xf4 h\xecnh trong series step-1v, n\xf3 c\xf3 hiệu suất thị gi\xe1c vượt trội hơn."},"step-1v-32k":{"description":"Hỗ trợ đầu v\xe0o h\xecnh ảnh, tăng cường trải nghiệm tương t\xe1c đa m\xf4 h\xecnh."},"step-1v-8k":{"description":"M\xf4 h\xecnh thị gi\xe1c nhỏ, ph\xf9 hợp cho c\xe1c nhiệm vụ cơ bản về văn bản v\xe0 h\xecnh ảnh."},"step-1x-edit":{"description":"M\xf4 h\xecnh tập trung v\xe0o t\xe1c vụ chỉnh sửa h\xecnh ảnh, c\xf3 thể sửa đổi v\xe0 n\xe2ng cao h\xecnh ảnh dựa tr\xean h\xecnh ảnh v\xe0 m\xf4 tả văn bản do người d\xf9ng cung cấp. Hỗ trợ nhiều định dạng đầu v\xe0o, bao gồm m\xf4 tả văn bản v\xe0 h\xecnh ảnh mẫu. M\xf4 h\xecnh hiểu \xfd định người d\xf9ng v\xe0 tạo ra kết quả chỉnh sửa h\xecnh ảnh ph\xf9 hợp."},"step-1x-medium":{"description":"M\xf4 h\xecnh c\xf3 khả năng tạo h\xecnh ảnh mạnh mẽ, hỗ trợ đầu v\xe0o m\xf4 tả văn bản. Hỗ trợ tiếng Trung bản địa, c\xf3 thể hiểu v\xe0 xử l\xfd m\xf4 tả văn bản tiếng Trung tốt hơn, nắm bắt ch\xednh x\xe1c th\xf4ng tin ngữ nghĩa trong m\xf4 tả v\xe0 chuyển đổi th\xe0nh đặc trưng h\xecnh ảnh, từ đ\xf3 tạo h\xecnh ảnh ch\xednh x\xe1c hơn. M\xf4 h\xecnh c\xf3 thể tạo h\xecnh ảnh độ ph\xe2n giải cao, chất lượng tốt v\xe0 c\xf3 khả năng chuyển đổi phong c\xe1ch nhất định."},"step-2-16k":{"description":"Hỗ trợ tương t\xe1c ngữ cảnh quy m\xf4 lớn, ph\xf9 hợp cho c\xe1c t\xecnh huống đối thoại phức tạp."},"step-2-16k-exp":{"description":"Phi\xean bản thử nghiệm của m\xf4 h\xecnh step-2, bao gồm c\xe1c t\xednh năng mới nhất, đang được cập nhật li\xean tục. Kh\xf4ng khuyến nghị sử dụng trong m\xf4i trường sản xuất ch\xednh thức."},"step-2-mini":{"description":"M\xf4 h\xecnh lớn si\xeau tốc dựa tr\xean kiến tr\xfac Attention tự nghi\xean cứu thế hệ mới MFA, đạt được hiệu quả tương tự như step1 với chi ph\xed rất thấp, đồng thời duy tr\xec th\xf4ng lượng cao hơn v\xe0 độ trễ phản hồi nhanh hơn. C\xf3 khả năng xử l\xfd c\xe1c nhiệm vụ chung, đặc biệt c\xf3 năng lực trong lập tr\xecnh."},"step-2x-large":{"description":"M\xf4 h\xecnh tạo h\xecnh ảnh thế hệ mới của Step Star, tập trung v\xe0o t\xe1c vụ tạo h\xecnh ảnh, c\xf3 thể tạo ra h\xecnh ảnh chất lượng cao dựa tr\xean m\xf4 tả văn bản do người d\xf9ng cung cấp. M\xf4 h\xecnh mới tạo ra h\xecnh ảnh c\xf3 cảm gi\xe1c thực hơn, khả năng tạo chữ tiếng Trung v\xe0 tiếng Anh mạnh hơn."},"step-3":{"description":"M\xf4 h\xecnh n\xe0y c\xf3 khả năng nhận thức thị gi\xe1c mạnh mẽ v\xe0 suy luận phức tạp. C\xf3 thể ch\xednh x\xe1c ho\xe0n th\xe0nh việc hiểu c\xe1c kiến thức phức tạp li\xean ng\xe0nh, ph\xe2n t\xedch ch\xe9o giữa th\xf4ng tin to\xe1n học v\xe0 th\xf4ng tin thị gi\xe1c, cũng như xử l\xfd c\xe1c vấn đề ph\xe2n t\xedch h\xecnh ảnh trong đời sống h\xe0ng ng\xe0y."},"step-r1-v-mini":{"description":"M\xf4 h\xecnh n\xe0y l\xe0 một m\xf4 h\xecnh suy luận lớn với khả năng hiểu h\xecnh ảnh mạnh mẽ, c\xf3 thể xử l\xfd th\xf4ng tin h\xecnh ảnh v\xe0 văn bản, v\xe0 xuất ra nội dung văn bản sau khi suy nghĩ s\xe2u. M\xf4 h\xecnh n\xe0y thể hiện xuất sắc trong lĩnh vực suy luận h\xecnh ảnh, đồng thời c\xf3 khả năng to\xe1n học, m\xe3 v\xe0 suy luận văn bản h\xe0ng đầu. Độ d\xe0i ngữ cảnh l\xe0 100k."},"step3":{"description":"Step3 l\xe0 m\xf4 h\xecnh đa phương thức do Jiexue Xingchen ph\xe1t triển, c\xf3 khả năng hiểu h\xecnh ảnh mạnh mẽ."},"stepfun-ai/step3":{"description":"Step3 l\xe0 m\xf4 h\xecnh suy luận đa m\xf4 thức ti\xean tiến được ph\xe1t h\xe0nh bởi 阶跃星辰 (StepFun). M\xf4 h\xecnh n\xe0y được x\xe2y dựng tr\xean kiến tr\xfac Mixture-of-Experts (MoE) với 321B tham số tổng v\xe0 38B tham số k\xedch hoạt. Thiết kế đầu-cuối (end-to-end) nhằm tối thiểu h\xf3a chi ph\xed giải m\xe3, đồng thời cung cấp hiệu năng h\xe0ng đầu trong suy luận thị gi\xe1c-ng\xf4n ngữ. Th\xf4ng qua thiết kế phối hợp giữa Multi-Matrix Factorized Attention (MFA) v\xe0 Attention-FFN Decoupling (AFD), Step3 duy tr\xec hiệu suất vượt trội tr\xean cả bộ tăng tốc cao cấp v\xe0 c\xe1c thiết bị tăng tốc cấp thấp. Trong giai đoạn tiền huấn luyện, Step3 đ\xe3 xử l\xfd hơn 20T token văn bản v\xe0 4T token hỗn hợp ảnh-văn bản, bao phủ hơn mười ng\xf4n ngữ. M\xf4 h\xecnh n\xe0y đ\xe3 đạt vị thế dẫn đầu trong c\xe1c benchmark m\xe3 nguồn mở ở nhiều lĩnh vực, bao gồm to\xe1n học, m\xe3 (code) v\xe0 c\xe1c nhiệm vụ đa m\xf4 thức."},"taichu_llm":{"description":"M\xf4 h\xecnh ng\xf4n ngữ lớn Taichu c\xf3 khả năng hiểu ng\xf4n ngữ mạnh mẽ v\xe0 c\xe1c khả năng như s\xe1ng tạo văn bản, trả lời c\xe2u hỏi kiến thức, lập tr\xecnh m\xe3, t\xednh to\xe1n to\xe1n học, suy luận logic, ph\xe2n t\xedch cảm x\xfac, t\xf3m tắt văn bản. Đổi mới kết hợp giữa đ\xe0o tạo trước với dữ liệu phong ph\xfa từ nhiều nguồn, th\xf4ng qua việc li\xean tục cải tiến c\xf4ng nghệ thuật to\xe1n v\xe0 hấp thụ kiến thức mới từ dữ liệu văn bản khổng lồ, gi\xfap m\xf4 h\xecnh ng\xe0y c\xe0ng ho\xe0n thiện. Cung cấp th\xf4ng tin v\xe0 dịch vụ tiện lợi hơn cho người d\xf9ng c\xf9ng trải nghiệm th\xf4ng minh hơn."},"taichu_o1":{"description":"taichu_o1 l\xe0 m\xf4 h\xecnh suy luận lớn thế hệ mới, đạt được chuỗi suy nghĩ giống con người th\xf4ng qua tương t\xe1c đa phương tiện v\xe0 học tăng cường, hỗ trợ suy diễn quyết định phức tạp, đồng thời thể hiện con đường suy luận c\xf3 thể m\xf4 h\xecnh h\xf3a trong khi duy tr\xec đầu ra ch\xednh x\xe1c cao, ph\xf9 hợp cho ph\xe2n t\xedch chiến lược v\xe0 suy nghĩ s\xe2u."},"taichu_vl":{"description":"Kết hợp khả năng hiểu h\xecnh ảnh, chuyển giao kiến thức, suy luận logic, thể hiện xuất sắc trong lĩnh vực hỏi đ\xe1p h\xecnh ảnh v\xe0 văn bản."},"tencent/Hunyuan-A13B-Instruct":{"description":"Hunyuan-A13B-Instruct c\xf3 80 tỷ tham số, k\xedch hoạt 13 tỷ tham số để đạt hiệu năng tương đương c\xe1c m\xf4 h\xecnh lớn hơn, hỗ trợ suy luận kết hợp “tư duy nhanh/tư duy chậm”; khả năng hiểu văn bản d\xe0i ổn định; được x\xe1c nhận qua BFCL-v3 v\xe0 τ-Bench, năng lực Agent dẫn đầu; kết hợp GQA v\xe0 nhiều định dạng lượng tử h\xf3a, đạt hiệu quả suy luận cao."},"tencent/Hunyuan-MT-7B":{"description":"M\xf4 h\xecnh dịch Hunyuan (Hunyuan Translation Model) bao gồm một m\xf4 h\xecnh dịch Hunyuan-MT-7B v\xe0 một m\xf4 h\xecnh t\xedch hợp Hunyuan-MT-Chimera. Hunyuan-MT-7B l\xe0 một m\xf4 h\xecnh dịch nhẹ với 7 tỷ tham số, d\xf9ng để dịch văn bản nguồn sang ng\xf4n ngữ đ\xedch. M\xf4 h\xecnh hỗ trợ dịch qua lại giữa 33 ng\xf4n ngữ v\xe0 5 ng\xf4n ngữ d\xe2n tộc thiểu số Trung Quốc. Trong cuộc thi dịch m\xe1y quốc tế WMT25, Hunyuan-MT-7B đ\xe3 gi\xe0nh được 30 giải nhất trong số 31 hạng mục ng\xf4n ngữ tham gia, thể hiện năng lực dịch thuật xuất sắc. Đối với c\xe1c t\xecnh huống dịch thuật, Tencent Hunyuan đ\xe3 đề xuất một quy tr\xecnh huấn luyện ho\xe0n chỉnh từ tiền huấn luyện đến tinh chỉnh c\xf3 gi\xe1m s\xe1t, sau đ\xf3 l\xe0 tăng cường dịch thuật v\xe0 tăng cường t\xedch hợp, gi\xfap m\xf4 h\xecnh đạt hiệu suất h\xe0ng đầu trong c\xe1c m\xf4 h\xecnh c\xf9ng quy m\xf4. M\xf4 h\xecnh c\xf3 hiệu suất t\xednh to\xe1n cao, dễ triển khai v\xe0 ph\xf9 hợp với nhiều t\xecnh huống ứng dụng."},"text-embedding-3-large":{"description":"M\xf4 h\xecnh vector h\xf3a mạnh mẽ nhất, ph\xf9 hợp cho c\xe1c nhiệm vụ tiếng Anh v\xe0 kh\xf4ng phải tiếng Anh."},"text-embedding-3-small":{"description":"M\xf4 h\xecnh Embedding thế hệ mới hiệu quả v\xe0 tiết kiệm, ph\xf9 hợp cho t\xecm kiếm kiến thức, ứng dụng RAG v\xe0 c\xe1c t\xecnh huống kh\xe1c."},"thudm/glm-4-32b":{"description":"GLM-4-32B-0414 l\xe0 một m\xf4 h\xecnh ng\xf4n ngữ mở với trọng số 32B song ngữ (Trung-Anh), được tối ưu h\xf3a cho việc tạo m\xe3, gọi h\xe0m v\xe0 c\xe1c nhiệm vụ theo kiểu đại l\xfd. N\xf3 đ\xe3 được huấn luyện trước tr\xean 15T dữ liệu chất lượng cao v\xe0 dữ liệu suy luận lại, v\xe0 được ho\xe0n thiện th\xeam bằng c\xe1ch sử dụng sự ph\xf9 hợp với sở th\xedch của con người, lấy mẫu từ chối v\xe0 học tăng cường. M\xf4 h\xecnh n\xe0y thể hiện xuất sắc trong suy luận phức tạp, tạo ra sản phẩm v\xe0 c\xe1c nhiệm vụ đầu ra c\xf3 cấu tr\xfac, đạt được hiệu suất tương đương với GPT-4o v\xe0 DeepSeek-V3-0324 trong nhiều b\xe0i kiểm tra chuẩn."},"thudm/glm-4-32b:free":{"description":"GLM-4-32B-0414 l\xe0 một m\xf4 h\xecnh ng\xf4n ngữ mở với trọng số 32B song ngữ (Trung-Anh), được tối ưu h\xf3a cho việc tạo m\xe3, gọi h\xe0m v\xe0 c\xe1c nhiệm vụ theo kiểu đại l\xfd. N\xf3 đ\xe3 được huấn luyện trước tr\xean 15T dữ liệu chất lượng cao v\xe0 dữ liệu suy luận lại, v\xe0 được ho\xe0n thiện th\xeam bằng c\xe1ch sử dụng sự ph\xf9 hợp với sở th\xedch của con người, lấy mẫu từ chối v\xe0 học tăng cường. M\xf4 h\xecnh n\xe0y thể hiện xuất sắc trong suy luận phức tạp, tạo ra sản phẩm v\xe0 c\xe1c nhiệm vụ đầu ra c\xf3 cấu tr\xfac, đạt được hiệu suất tương đương với GPT-4o v\xe0 DeepSeek-V3-0324 trong nhiều b\xe0i kiểm tra chuẩn."},"thudm/glm-4-9b-chat":{"description":"Phi\xean bản m\xe3 nguồn mở của thế hệ m\xf4 h\xecnh tiền huấn luyện GLM-4 mới nhất được ph\xe1t h\xe0nh bởi Zhiyu AI."},"thudm/glm-z1-32b":{"description":"GLM-Z1-32B-0414 l\xe0 biến thể suy luận n\xe2ng cao của GLM-4-32B, được x\xe2y dựng cho việc giải quyết c\xe1c vấn đề s\xe2u về to\xe1n học, logic v\xe0 lập tr\xecnh. N\xf3 \xe1p dụng học tăng cường mở rộng (cụ thể cho nhiệm vụ v\xe0 dựa tr\xean sở th\xedch cặp chung) để cải thiện hiệu suất cho c\xe1c nhiệm vụ phức tạp nhiều bước. So với m\xf4 h\xecnh GLM-4-32B cơ bản, Z1 đ\xe3 n\xe2ng cao đ\xe1ng kể khả năng suy luận c\xf3 cấu tr\xfac v\xe0 trong c\xe1c lĩnh vực ch\xednh thức.\\n\\nM\xf4 h\xecnh n\xe0y hỗ trợ thực hiện c\xe1c bước \'suy nghĩ\' th\xf4ng qua kỹ thuật nhắc nhở v\xe0 cung cấp t\xednh li\xean kết cải thiện cho đầu ra định dạng d\xe0i. N\xf3 được tối ưu h\xf3a cho quy tr\xecnh l\xe0m việc của đại l\xfd v\xe0 hỗ trợ ngữ cảnh d\xe0i (th\xf4ng qua YaRN), gọi c\xf4ng cụ JSON v\xe0 cấu h\xecnh lấy mẫu chi tiết cho suy luận ổn định. Rất ph\xf9 hợp cho c\xe1c trường hợp cần suy nghĩ s\xe2u sắc, suy luận nhiều bước hoặc suy diễn ch\xednh thức."},"thudm/glm-z1-rumination-32b":{"description":"THUDM: GLM Z1 Rumination 32B l\xe0 m\xf4 h\xecnh suy luận s\xe2u với 32B tham số trong d\xf2ng GLM-4-Z1, được tối ưu h\xf3a cho c\xe1c nhiệm vụ phức tạp, mở cần suy nghĩ l\xe2u d\xe0i. N\xf3 được x\xe2y dựng tr\xean nền tảng glm-4-32b-0414, tăng cường th\xeam giai đoạn học tăng cường v\xe0 chiến lược căn chỉnh đa giai đoạn, giới thiệu khả năng \\"phản tư\\" nhằm m\xf4 phỏng qu\xe1 tr\xecnh xử l\xfd nhận thức mở rộng. Điều n\xe0y bao gồm suy luận lặp đi lặp lại, ph\xe2n t\xedch đa bước v\xe0 quy tr\xecnh l\xe0m việc tăng cường c\xf4ng cụ như t\xecm kiếm, truy xuất v\xe0 tổng hợp nhận thức tr\xedch dẫn.\\n\\nM\xf4 h\xecnh n\xe0y thể hiện xuất sắc trong viết nghi\xean cứu, ph\xe2n t\xedch so s\xe1nh v\xe0 c\xe2u hỏi phức tạp. N\xf3 hỗ trợ gọi h\xe0m cho c\xe1c nguy\xean ngữ t\xecm kiếm v\xe0 điều hướng (`search`, `click`, `open`, `finish`), cho ph\xe9p sử dụng trong quy tr\xecnh đại l\xfd. H\xe0nh vi phản tư được h\xecnh th\xe0nh bởi c\xe1c phần thưởng dựa tr\xean quy tắc v\xe0 cơ chế quyết định tr\xec ho\xe3n trong kiểm so\xe1t v\xf2ng lặp đa v\xf2ng, v\xe0 được chuẩn h\xf3a theo c\xe1c khung nghi\xean cứu s\xe2u như ngăn xếp căn chỉnh nội bộ của OpenAI. Biến thể n\xe0y ph\xf9 hợp cho c\xe1c t\xecnh huống cần độ s\xe2u hơn l\xe0 tốc độ."},"tngtech/deepseek-r1t-chimera:free":{"description":"DeepSeek-R1T-Chimera được tạo ra bằng c\xe1ch kết hợp DeepSeek-R1 v\xe0 DeepSeek-V3 (0324), kết hợp khả năng suy luận của R1 v\xe0 cải tiến hiệu quả token của V3. N\xf3 dựa tr\xean kiến tr\xfac DeepSeek-MoE Transformer v\xe0 được tối ưu h\xf3a cho c\xe1c nhiệm vụ tạo văn bản tổng qu\xe1t.\\n\\nM\xf4 h\xecnh n\xe0y kết hợp trọng số tiền huấn luyện của hai m\xf4 h\xecnh nguồn để c\xe2n bằng hiệu suất trong suy luận, hiệu quả v\xe0 c\xe1c nhiệm vụ tu\xe2n theo chỉ dẫn. N\xf3 được ph\xe1t h\xe0nh theo giấy ph\xe9p MIT, nhằm mục đ\xedch sử dụng cho nghi\xean cứu v\xe0 thương mại."},"togethercomputer/StripedHyena-Nous-7B":{"description":"StripedHyena Nous (7B) cung cấp khả năng t\xednh to\xe1n n\xe2ng cao th\xf4ng qua chiến lược v\xe0 kiến tr\xfac m\xf4 h\xecnh hiệu quả."},"tts-1":{"description":"M\xf4 h\xecnh chuyển văn bản th\xe0nh giọng n\xf3i mới nhất, tối ưu h\xf3a tốc độ cho c\xe1c t\xecnh huống thời gian thực."},"tts-1-hd":{"description":"M\xf4 h\xecnh chuyển văn bản th\xe0nh giọng n\xf3i mới nhất, tối ưu h\xf3a cho chất lượng."},"upstage/SOLAR-10.7B-Instruct-v1.0":{"description":"Upstage SOLAR Instruct v1 (11B) ph\xf9 hợp cho c\xe1c nhiệm vụ chỉ dẫn tinh vi, cung cấp khả năng xử l\xfd ng\xf4n ngữ xuất sắc."},"us.anthropic.claude-3-5-sonnet-20241022-v2:0":{"description":"Claude 3.5 Sonnet n\xe2ng cao ti\xeau chuẩn ng\xe0nh, hiệu suất vượt trội so với c\xe1c m\xf4 h\xecnh cạnh tranh v\xe0 Claude 3 Opus, thể hiện xuất sắc trong nhiều đ\xe1nh gi\xe1, đồng thời c\xf3 tốc độ v\xe0 chi ph\xed tương đương với c\xe1c m\xf4 h\xecnh tầm trung của ch\xfang t\xf4i."},"us.anthropic.claude-3-7-sonnet-20250219-v1:0":{"description":"Claude 3.7 sonnet l\xe0 m\xf4 h\xecnh thế hệ tiếp theo nhanh nhất của Anthropic. So với Claude 3 Haiku, Claude 3.7 Sonnet đ\xe3 cải thiện ở nhiều kỹ năng v\xe0 vượt qua m\xf4 h\xecnh lớn nhất thế hệ trước l\xe0 Claude 3 Opus trong nhiều b\xe0i kiểm tra tr\xed tuệ."},"us.anthropic.claude-haiku-4-5-20251001-v1:0":{"description":"Claude Haiku 4.5 l\xe0 m\xf4 h\xecnh Haiku nhanh nhất v\xe0 th\xf4ng minh nhất của Anthropic, với tốc độ như chớp v\xe0 khả năng tư duy mở rộng."},"us.anthropic.claude-sonnet-4-5-20250929-v1:0":{"description":"Claude Sonnet 4.5 l\xe0 m\xf4 h\xecnh th\xf4ng minh nhất của Anthropic cho đến nay."},"v0-1.0-md":{"description":"M\xf4 h\xecnh v0-1.0-md l\xe0 phi\xean bản cũ được cung cấp dịch vụ qua API v0"},"v0-1.5-lg":{"description":"M\xf4 h\xecnh v0-1.5-lg ph\xf9 hợp cho c\xe1c nhiệm vụ suy nghĩ hoặc l\xfd luận n\xe2ng cao"},"v0-1.5-md":{"description":"M\xf4 h\xecnh v0-1.5-md ph\xf9 hợp cho c\xe1c nhiệm vụ h\xe0ng ng\xe0y v\xe0 tạo giao diện người d\xf9ng (UI)"},"vercel/v0-1.0-md":{"description":"Truy cập m\xf4 h\xecnh ph\xeda sau v0 để tạo, sửa lỗi v\xe0 tối ưu h\xf3a ứng dụng Web hiện đại, với suy luận theo khung cụ thể v\xe0 kiến thức cập nhật."},"vercel/v0-1.5-md":{"description":"Truy cập m\xf4 h\xecnh ph\xeda sau v0 để tạo, sửa lỗi v\xe0 tối ưu h\xf3a ứng dụng Web hiện đại, với suy luận theo khung cụ thể v\xe0 kiến thức cập nhật."},"wan2.2-t2i-flash":{"description":"Phi\xean bản tốc độ cao Wanxiang 2.2, l\xe0 m\xf4 h\xecnh mới nhất hiện nay. N\xe2ng cấp to\xe0n diện về s\xe1ng tạo, ổn định v\xe0 cảm gi\xe1c thực, tốc độ tạo nhanh, hiệu quả chi ph\xed cao."},"wan2.2-t2i-plus":{"description":"Phi\xean bản chuy\xean nghiệp Wanxiang 2.2, l\xe0 m\xf4 h\xecnh mới nhất hiện nay. N\xe2ng cấp to\xe0n diện về s\xe1ng tạo, ổn định v\xe0 cảm gi\xe1c thực, tạo chi tiết phong ph\xfa."},"wanx-v1":{"description":"M\xf4 h\xecnh tạo h\xecnh ảnh từ văn bản cơ bản, tương ứng với m\xf4 h\xecnh chung 1.0 tr\xean trang ch\xednh thức Tongyi Wanxiang."},"wanx2.0-t2i-turbo":{"description":"Chuy\xean về ch\xe2n dung c\xf3 cảm gi\xe1c thực, tốc độ trung b\xecnh, chi ph\xed thấp. Tương ứng với m\xf4 h\xecnh tốc độ cao 2.0 tr\xean trang ch\xednh thức Tongyi Wanxiang."},"wanx2.1-t2i-plus":{"description":"Phi\xean bản n\xe2ng cấp to\xe0n diện, tạo h\xecnh ảnh chi tiết phong ph\xfa hơn, tốc độ hơi chậm. Tương ứng với m\xf4 h\xecnh chuy\xean nghiệp 2.1 tr\xean trang ch\xednh thức Tongyi Wanxiang."},"wanx2.1-t2i-turbo":{"description":"Phi\xean bản n\xe2ng cấp to\xe0n diện, tốc độ tạo nhanh, hiệu quả to\xe0n diện, chi ph\xed tổng hợp cao. Tương ứng với m\xf4 h\xecnh tốc độ cao 2.1 tr\xean trang ch\xednh thức Tongyi Wanxiang."},"whisper-1":{"description":"M\xf4 h\xecnh nhận dạng giọng n\xf3i đa năng, hỗ trợ nhận dạng giọng n\xf3i đa ng\xf4n ngữ, dịch giọng n\xf3i v\xe0 nhận diện ng\xf4n ngữ."},"wizardlm2":{"description":"WizardLM 2 l\xe0 m\xf4 h\xecnh ng\xf4n ngữ do Microsoft AI cung cấp, đặc biệt xuất sắc trong c\xe1c lĩnh vực đối thoại phức tạp, đa ng\xf4n ngữ, suy luận v\xe0 trợ l\xfd th\xf4ng minh."},"wizardlm2:8x22b":{"description":"WizardLM 2 l\xe0 m\xf4 h\xecnh ng\xf4n ngữ do Microsoft AI cung cấp, đặc biệt xuất sắc trong c\xe1c lĩnh vực đối thoại phức tạp, đa ng\xf4n ngữ, suy luận v\xe0 trợ l\xfd th\xf4ng minh."},"x-ai/grok-4-fast":{"description":"Ch\xfang t\xf4i rất vui mừng ra mắt Grok 4 Fast, bước tiến mới nhất của ch\xfang t\xf4i trong c\xe1c m\xf4 h\xecnh suy luận hiệu quả về chi ph\xed."},"x-ai/grok-code-fast-1":{"description":"Ch\xfang t\xf4i rất vui mừng giới thiệu grok-code-fast-1, một m\xf4 h\xecnh suy luận nhanh v\xe0 tiết kiệm chi ph\xed, nổi bật trong m\xe3 h\xf3a cho t\xe1c nh\xe2n."},"x1":{"description":"M\xf4 h\xecnh Spark X1 sẽ được n\xe2ng cấp th\xeam, tr\xean nền tảng dẫn đầu trong c\xe1c nhiệm vụ to\xe1n học trong nước, đạt được hiệu quả trong c\xe1c nhiệm vụ chung như suy luận, tạo văn bản, hiểu ng\xf4n ngữ tương đương với OpenAI o1 v\xe0 DeepSeek R1."},"xai/grok-2":{"description":"Grok 2 l\xe0 m\xf4 h\xecnh ng\xf4n ngữ ti\xean tiến với khả năng suy luận h\xe0ng đầu. N\xf3 c\xf3 năng lực vượt trội trong tr\xf2 chuyện, m\xe3 h\xf3a v\xe0 suy luận, đứng tr\xean Claude 3.5 Sonnet v\xe0 GPT-4-Turbo tr\xean bảng xếp hạng LMSYS."},"xai/grok-2-vision":{"description":"M\xf4 h\xecnh thị gi\xe1c Grok 2 thể hiện xuất sắc trong c\xe1c nhiệm vụ dựa tr\xean h\xecnh ảnh, cung cấp hiệu suất ti\xean tiến trong suy luận to\xe1n học dựa tr\xean h\xecnh ảnh (MathVista) v\xe0 hỏi đ\xe1p dựa tr\xean t\xe0i liệu (DocVQA). N\xf3 c\xf3 khả năng xử l\xfd đa dạng th\xf4ng tin h\xecnh ảnh, bao gồm t\xe0i liệu, biểu đồ, đồ thị, ảnh chụp m\xe0n h\xecnh v\xe0 ảnh chụp."},"xai/grok-3":{"description":"M\xf4 h\xecnh h\xe0ng đầu của xAI, xuất sắc trong c\xe1c trường hợp sử dụng doanh nghiệp như tr\xedch xuất dữ liệu, m\xe3 h\xf3a v\xe0 t\xf3m tắt văn bản. C\xf3 kiến thức chuy\xean s\xe2u trong c\xe1c lĩnh vực t\xe0i ch\xednh, chăm s\xf3c sức khỏe, ph\xe1p l\xfd v\xe0 khoa học."},"xai/grok-3-fast":{"description":"M\xf4 h\xecnh h\xe0ng đầu của xAI, xuất sắc trong c\xe1c trường hợp sử dụng doanh nghiệp như tr\xedch xuất dữ liệu, m\xe3 h\xf3a v\xe0 t\xf3m tắt văn bản. Biến thể m\xf4 h\xecnh nhanh phục vụ tr\xean cơ sở hạ tầng nhanh hơn, cung cấp thời gian phản hồi nhanh hơn nhiều so với ti\xeau chuẩn. Tốc độ tăng đi k\xe8m chi ph\xed token đầu ra cao hơn."},"xai/grok-3-mini":{"description":"M\xf4 h\xecnh nhẹ của xAI, suy nghĩ trước khi phản hồi. Rất ph\xf9 hợp cho c\xe1c nhiệm vụ đơn giản hoặc dựa tr\xean logic kh\xf4ng đ\xf2i hỏi kiến thức chuy\xean s\xe2u. C\xf3 thể truy cập đường đi suy nghĩ th\xf4."},"xai/grok-3-mini-fast":{"description":"M\xf4 h\xecnh nhẹ của xAI, suy nghĩ trước khi phản hồi. Rất ph\xf9 hợp cho c\xe1c nhiệm vụ đơn giản hoặc dựa tr\xean logic kh\xf4ng đ\xf2i hỏi kiến thức chuy\xean s\xe2u. C\xf3 thể truy cập đường đi suy nghĩ th\xf4. Biến thể m\xf4 h\xecnh nhanh phục vụ tr\xean cơ sở hạ tầng nhanh hơn, cung cấp thời gian phản hồi nhanh hơn nhiều so với ti\xeau chuẩn. Tốc độ tăng đi k\xe8m chi ph\xed token đầu ra cao hơn."},"xai/grok-4":{"description":"M\xf4 h\xecnh h\xe0ng đầu mới nhất v\xe0 tuyệt vời nhất của xAI, cung cấp hiệu suất v\xf4 song trong ng\xf4n ngữ tự nhi\xean, to\xe1n học v\xe0 suy luận — lựa chọn to\xe0n năng ho\xe0n hảo."},"yi-large":{"description":"M\xf4 h\xecnh với h\xe0ng trăm tỷ tham số mới, cung cấp khả năng hỏi đ\xe1p v\xe0 sinh văn bản mạnh mẽ."},"yi-large-fc":{"description":"Hỗ trợ v\xe0 tăng cường khả năng gọi c\xf4ng cụ tr\xean cơ sở m\xf4 h\xecnh yi-large, ph\xf9 hợp cho nhiều t\xecnh huống kinh doanh cần x\xe2y dựng agent hoặc workflow."},"yi-large-preview":{"description":"Phi\xean bản ban đầu, khuyến nghị sử dụng yi-large (phi\xean bản mới)."},"yi-large-rag":{"description":"Dịch vụ cao cấp dựa tr\xean m\xf4 h\xecnh yi-large mạnh mẽ, kết hợp c\xf4ng nghệ t\xecm kiếm v\xe0 sinh để cung cấp c\xe2u trả lời ch\xednh x\xe1c, dịch vụ t\xecm kiếm th\xf4ng tin to\xe0n mạng theo thời gian thực."},"yi-large-turbo":{"description":"Hiệu suất vượt trội với chi ph\xed hợp l\xfd. Tối ưu h\xf3a độ ch\xednh x\xe1c cao dựa tr\xean hiệu suất, tốc độ suy luận v\xe0 chi ph\xed."},"yi-lightning":{"description":"M\xf4 h\xecnh hiệu suất cao mới nhất, đảm bảo đầu ra chất lượng cao trong khi tốc độ suy luận được cải thiện đ\xe1ng kể."},"yi-lightning-lite":{"description":"Phi\xean bản nhẹ, được khuyến nghị sử dụng yi-lightning."},"yi-medium":{"description":"M\xf4 h\xecnh k\xedch thước trung b\xecnh được n\xe2ng cấp v\xe0 tinh chỉnh, khả năng c\xe2n bằng, chi ph\xed hiệu quả cao. Tối ưu h\xf3a s\xe2u khả năng tu\xe2n theo chỉ dẫn."},"yi-medium-200k":{"description":"Cửa sổ ngữ cảnh si\xeau d\xe0i 200K, cung cấp khả năng hiểu v\xe0 sinh văn bản s\xe2u cho c\xe1c văn bản d\xe0i."},"yi-spark":{"description":"M\xf4 h\xecnh nhỏ gọn v\xe0 nhanh ch\xf3ng. Cung cấp khả năng t\xednh to\xe1n to\xe1n học v\xe0 viết m\xe3 được tăng cường."},"yi-vision":{"description":"M\xf4 h\xecnh cho c\xe1c nhiệm vụ h\xecnh ảnh phức tạp, cung cấp khả năng hiểu v\xe0 ph\xe2n t\xedch h\xecnh ảnh hiệu suất cao."},"yi-vision-v2":{"description":"M\xf4 h\xecnh nhiệm vụ thị gi\xe1c phức tạp, cung cấp khả năng hiểu v\xe0 ph\xe2n t\xedch hiệu suất cao dựa tr\xean nhiều h\xecnh ảnh."},"z-ai/glm-4.6":{"description":"GLM-4.6, m\xf4 h\xecnh h\xe0ng đầu mới nhất của Zhipu AI, vượt trội ho\xe0n to\xe0n so với thế hệ trước về m\xe3 h\xf3a n\xe2ng cao, xử l\xfd văn bản d\xe0i, suy luận v\xe0 năng lực t\xe1c nh\xe2n."},"zai-org/GLM-4.5":{"description":"GLM-4.5 l\xe0 m\xf4 h\xecnh nền tảng d\xe0nh cho ứng dụng t\xe1c nh\xe2n th\xf4ng minh, sử dụng kiến tr\xfac chuy\xean gia hỗn hợp (Mixture-of-Experts). Được tối ưu s\xe2u trong c\xe1c lĩnh vực gọi c\xf4ng cụ, duyệt web, kỹ thuật phần mềm v\xe0 lập tr\xecnh front-end, hỗ trợ t\xedch hợp liền mạch v\xe0o c\xe1c t\xe1c nh\xe2n m\xe3 như Claude Code, Roo Code. GLM-4.5 sử dụng chế độ suy luận hỗn hợp, th\xedch ứng với nhiều kịch bản ứng dụng như suy luận phức tạp v\xe0 sử dụng h\xe0ng ng\xe0y."},"zai-org/GLM-4.5-Air":{"description":"GLM-4.5-Air l\xe0 m\xf4 h\xecnh nền tảng d\xe0nh cho ứng dụng t\xe1c nh\xe2n th\xf4ng minh, sử dụng kiến tr\xfac chuy\xean gia hỗn hợp (Mixture-of-Experts). Được tối ưu s\xe2u trong c\xe1c lĩnh vực gọi c\xf4ng cụ, duyệt web, kỹ thuật phần mềm v\xe0 lập tr\xecnh front-end, hỗ trợ t\xedch hợp liền mạch v\xe0o c\xe1c t\xe1c nh\xe2n m\xe3 như Claude Code, Roo Code. GLM-4.5 sử dụng chế độ suy luận hỗn hợp, th\xedch ứng với nhiều kịch bản ứng dụng như suy luận phức tạp v\xe0 sử dụng h\xe0ng ng\xe0y."},"zai-org/GLM-4.5V":{"description":"GLM-4.5V l\xe0 thế hệ m\xf4 h\xecnh ng\xf4n ngữ thị gi\xe1c (VLM) mới nhất được ph\xe1t h\xe0nh bởi Zhipu AI. M\xf4 h\xecnh n\xe0y được x\xe2y dựng tr\xean cơ sở m\xf4 h\xecnh văn bản chủ lực GLM-4.5-Air với tổng 106 tỷ tham số v\xe0 12 tỷ tham số k\xedch hoạt, sử dụng kiến tr\xfac chuy\xean gia hỗn hợp (Mixture of Experts - MoE), nhằm đạt hiệu năng xuất sắc với chi ph\xed suy luận thấp hơn. Về mặt kỹ thuật, GLM-4.5V tiếp nối hướng ph\xe1t triển của GLM-4.1V-Thinking v\xe0 giới thiệu c\xe1c đổi mới như m\xe3 h\xf3a vị tr\xed xoay ba chiều (3D-RoPE), đ\xe1ng kể n\xe2ng cao khả năng nhận thức v\xe0 suy luận về c\xe1c mối quan hệ trong kh\xf4ng gian 3D. Th\xf4ng qua tối ưu h\xf3a ở c\xe1c giai đoạn tiền huấn luyện, tinh chỉnh c\xf3 gi\xe1m s\xe1t v\xe0 học tăng cường, m\xf4 h\xecnh c\xf3 khả năng xử l\xfd nhiều dạng nội dung thị gi\xe1c như h\xecnh ảnh, video v\xe0 t\xe0i liệu d\xe0i, v\xe0 đ\xe3 đạt vị tr\xed h\xe0ng đầu trong số c\xe1c m\xf4 h\xecnh m\xe3 nguồn mở c\xf9ng cấp tr\xean 41 bộ đ\xe1nh gi\xe1 đa phương thức c\xf4ng khai. Ngo\xe0i ra, m\xf4 h\xecnh c\xf2n bổ sung c\xf4ng tắc “chế độ tư duy”, cho ph\xe9p người d\xf9ng linh hoạt lựa chọn giữa phản hồi nhanh v\xe0 suy luận s\xe2u để c\xe2n bằng hiệu quả v\xe0 chất lượng."},"zai-org/GLM-4.6":{"description":"So với GLM-4.5, GLM-4.6 mang đến nhiều cải tiến quan trọng. Cửa sổ ngữ cảnh được mở rộng từ 128K l\xean 200K token, gi\xfap m\xf4 h\xecnh xử l\xfd c\xe1c nhiệm vụ Agent phức tạp hơn. M\xf4 h\xecnh đạt điểm cao hơn trong c\xe1c b\xe0i kiểm tra chuẩn về m\xe3 v\xe0 thể hiện hiệu suất thực tế mạnh mẽ hơn trong c\xe1c ứng dụng như Claude Code, Cline, Roo Code v\xe0 Kilo Code, bao gồm cải tiến trong việc tạo giao diện frontend với hiệu ứng h\xecnh ảnh tinh tế. GLM-4.6 cải thiện r\xf5 rệt hiệu suất suy luận v\xe0 hỗ trợ sử dụng c\xf4ng cụ trong qu\xe1 tr\xecnh suy luận, mang lại năng lực tổng hợp mạnh mẽ hơn. M\xf4 h\xecnh thể hiện sức mạnh hơn trong việc sử dụng c\xf4ng cụ v\xe0 Agent dựa tr\xean t\xecm kiếm, đồng thời t\xedch hợp hiệu quả hơn v\xe0o khung Agent. Về mặt viết l\xe1ch, m\xf4 h\xecnh ph\xf9 hợp hơn với sở th\xedch về phong c\xe1ch v\xe0 khả năng đọc hiểu của con người, v\xe0 thể hiện tự nhi\xean hơn trong c\xe1c t\xecnh huống nhập vai."},"zai/glm-4.5":{"description":"D\xf2ng m\xf4 h\xecnh GLM-4.5 được thiết kế đặc biệt cho c\xe1c t\xe1c nh\xe2n th\xf4ng minh. M\xf4 h\xecnh h\xe0ng đầu GLM-4.5 t\xedch hợp 355 tỷ tham số tổng (32 tỷ tham số k\xedch hoạt), hợp nhất khả năng suy luận, m\xe3 h\xf3a v\xe0 đại l\xfd để giải quyết c\xe1c y\xeau cầu ứng dụng phức tạp. L\xe0 hệ thống suy luận hỗn hợp, n\xf3 cung cấp hai chế độ hoạt động."},"zai/glm-4.5-air":{"description":"GLM-4.5 v\xe0 GLM-4.5-Air l\xe0 c\xe1c m\xf4 h\xecnh h\xe0ng đầu mới nhất của ch\xfang t\xf4i, được thiết kế đặc biệt l\xe0m m\xf4 h\xecnh nền tảng cho c\xe1c ứng dụng đại l\xfd. Cả hai đều sử dụng kiến tr\xfac chuy\xean gia hỗn hợp (MoE). GLM-4.5 c\xf3 tổng số tham số 355 tỷ với 32 tỷ tham số k\xedch hoạt mỗi lần truyền tiến, trong khi GLM-4.5-Air c\xf3 thiết kế đơn giản hơn với tổng số tham số 106 tỷ v\xe0 12 tỷ tham số k\xedch hoạt."},"zai/glm-4.5v":{"description":"GLM-4.5V được x\xe2y dựng tr\xean m\xf4 h\xecnh nền tảng GLM-4.5-Air, kế thừa c\xf4ng nghệ đ\xe3 được x\xe1c minh của GLM-4.1V-Thinking, đồng thời mở rộng hiệu quả với kiến tr\xfac MoE 106 tỷ tham số mạnh mẽ."}}')}}]);