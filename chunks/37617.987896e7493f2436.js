"use strict";(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[37617],{37617:e=>{e.exports=JSON.parse('{"01-ai/yi-1.5-34b-chat":{"description":"Zero One Everything, en son a\xe7ık kaynak ince ayar modelidir, 34 milyar parametreye sahiptir, ince ayar \xe7eşitli diyalog senaryolarını destekler, y\xfcksek kaliteli eğitim verileri ile insan tercihleri ile hizalanmıştır."},"01-ai/yi-1.5-9b-chat":{"description":"Zero One Everything, en son a\xe7ık kaynak ince ayar modelidir, 9 milyar parametreye sahiptir, ince ayar \xe7eşitli diyalog senaryolarını destekler, y\xfcksek kaliteli eğitim verileri ile insan tercihleri ile hizalanmıştır."},"360/deepseek-r1":{"description":"[360 Dağıtım Versiyonu] DeepSeek-R1, son eğitim aşamasında geniş \xe7apta pekiştirme \xf6ğrenimi teknikleri kullanarak, \xe7ok az etiketli veri ile modelin \xe7ıkarım yeteneğini b\xfcy\xfck \xf6l\xe7\xfcde artırmıştır. Matematik, kod, doğal dil \xe7ıkarımı gibi g\xf6revlerde, OpenAI o1 resmi s\xfcr\xfcm\xfc ile benzer performans sergilemektedir."},"360gpt-pro":{"description":"360GPT Pro, 360 AI model serisinin \xf6nemli bir \xfcyesi olarak, \xe7eşitli doğal dil uygulama senaryolarını karşılamak i\xe7in etkili metin işleme yeteneği sunar, uzun metin anlama ve \xe7oklu diyalog gibi işlevleri destekler."},"360gpt-pro-trans":{"description":"\xc7eviri i\xe7in \xf6zel olarak tasarlanmış model, derinlemesine ince ayar yapılmış ve \xe7eviri sonu\xe7ları lider konumdadır."},"360gpt-turbo":{"description":"360GPT Turbo, g\xfc\xe7l\xfc hesaplama ve diyalog yetenekleri sunar, m\xfckemmel anlam anlama ve oluşturma verimliliğine sahiptir, işletmeler ve geliştiriciler i\xe7in ideal bir akıllı asistan \xe7\xf6z\xfcm\xfcd\xfcr."},"360gpt-turbo-responsibility-8k":{"description":"360GPT Turbo Responsibility 8K, anlam g\xfcvenliği ve sorumluluk odaklılığı vurgular, i\xe7erik g\xfcvenliği konusunda y\xfcksek gereksinimlere sahip uygulama senaryoları i\xe7in tasarlanmıştır, kullanıcı deneyiminin doğruluğunu ve sağlamlığını garanti eder."},"360gpt2-o1":{"description":"360gpt2-o1, d\xfcş\xfcnce zincirini ağa\xe7 arama ile inşa eder ve yansıtma mekanizmasını entegre eder, pekiştirme \xf6ğrenimi ile eğitilir, model kendini yansıtma ve hata d\xfczeltme yeteneğine sahiptir."},"360gpt2-pro":{"description":"360GPT2 Pro, 360 şirketi tarafından sunulan y\xfcksek d\xfczeyde doğal dil işleme modelidir, m\xfckemmel metin oluşturma ve anlama yeteneğine sahiptir, \xf6zellikle oluşturma ve yaratma alanında olağan\xfcst\xfc performans g\xf6sterir, karmaşık dil d\xf6n\xfcş\xfcmleri ve rol canlandırma g\xf6revlerini işleyebilir."},"360zhinao2-o1":{"description":"360zhinao2-o1, d\xfcş\xfcnce zincirini oluşturmak i\xe7in ağa\xe7 araması kullanır ve yansıtma mekanizmasını entegre eder, pekiştirme \xf6ğrenimi ile eğitilir, model kendini yansıtma ve hata d\xfczeltme yeteneğine sahiptir."},"4.0Ultra":{"description":"Spark4.0 Ultra, Xinghuo b\xfcy\xfck model serisinin en g\xfc\xe7l\xfc versiyonudur, \xe7evrimi\xe7i arama bağlantısını y\xfckseltirken, metin i\xe7eriğini anlama ve \xf6zetleme yeteneğini artırır. Ofis verimliliğini artırmak ve taleplere doğru yanıt vermek i\xe7in kapsamlı bir \xe7\xf6z\xfcm sunar, sekt\xf6rdeki akıllı \xfcr\xfcnlerin \xf6nc\xfcs\xfcd\xfcr."},"AnimeSharp":{"description":"AnimeSharp (diğer adıyla “4x‑AnimeSharp”), Kim2091 tarafından ESRGAN mimarisi temel alınarak geliştirilen a\xe7ık kaynaklı bir s\xfcper \xe7\xf6z\xfcn\xfcrl\xfck modelidir ve anime tarzı g\xf6r\xfcnt\xfclerin b\xfcy\xfct\xfclmesi ve keskinleştirilmesine odaklanır. Şubat 2022\'de “4x-TextSharpV1” olarak yeniden adlandırılmıştır; başlangı\xe7ta metin g\xf6r\xfcnt\xfcleri i\xe7in de uygundu ancak performansı anime i\xe7eriği i\xe7in \xf6nemli \xf6l\xe7\xfcde optimize edilmiştir."},"Baichuan2-Turbo":{"description":"Arama artırma teknolojisi kullanarak b\xfcy\xfck model ile alan bilgisi ve t\xfcm ağ bilgisi arasında kapsamlı bir bağlantı sağlar. PDF, Word gibi \xe7eşitli belge y\xfcklemelerini ve URL girişini destekler, bilgi edinimi zamanında ve kapsamlıdır, \xe7ıktı sonu\xe7ları doğru ve profesyoneldir."},"Baichuan3-Turbo":{"description":"Kurumsal y\xfcksek frekanslı senaryolar i\xe7in optimize edilmiş, etkisi b\xfcy\xfck \xf6l\xe7\xfcde artırılmış ve y\xfcksek maliyet etkinliği sunmaktadır. Baichuan2 modeline kıyasla, i\xe7erik \xfcretimi %20, bilgi sorgulama %17, rol oynama yeteneği %40 oranında artmıştır. Genel performansı GPT3.5\'ten daha iyidir."},"Baichuan3-Turbo-128k":{"description":"128K ultra uzun bağlam penceresine sahip, kurumsal y\xfcksek frekanslı senaryolar i\xe7in optimize edilmiş, etkisi b\xfcy\xfck \xf6l\xe7\xfcde artırılmış ve y\xfcksek maliyet etkinliği sunmaktadır. Baichuan2 modeline kıyasla, i\xe7erik \xfcretimi %20, bilgi sorgulama %17, rol oynama yeteneği %40 oranında artmıştır. Genel performansı GPT3.5\'ten daha iyidir."},"Baichuan4":{"description":"Model yetenekleri \xfclke i\xe7inde birinci sırada, bilgi ansiklopedisi, uzun metinler, yaratıcı \xfcretim gibi \xc7ince g\xf6revlerde yurtdışındaki \xf6nde gelen modelleri geride bırakmaktadır. Ayrıca, sekt\xf6r lideri \xe7ok modlu yeteneklere sahiptir ve bir\xe7ok yetkili değerlendirme kriterinde m\xfckemmel performans g\xf6stermektedir."},"Baichuan4-Air":{"description":"Model yetenekleri \xfclke i\xe7inde birinci, bilgi ansiklopedisi, uzun metinler, yaratıcı \xfcretim gibi \xc7ince g\xf6revlerde uluslararası ana akım modelleri aşmaktadır. Ayrıca, sekt\xf6rde lider \xe7ok modlu yeteneklere sahip olup, bir\xe7ok yetkili değerlendirme \xf6l\xe7\xfct\xfcnde m\xfckemmel performans sergilemektedir."},"Baichuan4-Turbo":{"description":"Model yetenekleri \xfclke i\xe7inde birinci, bilgi ansiklopedisi, uzun metinler, yaratıcı \xfcretim gibi \xc7ince g\xf6revlerde uluslararası ana akım modelleri aşmaktadır. Ayrıca, sekt\xf6rde lider \xe7ok modlu yeteneklere sahip olup, bir\xe7ok yetkili değerlendirme \xf6l\xe7\xfct\xfcnde m\xfckemmel performans sergilemektedir."},"ByteDance-Seed/Seed-OSS-36B-Instruct":{"description":"Seed-OSS, ByteDance Seed ekibi tarafından geliştirilen, g\xfc\xe7l\xfc uzun bağlam işleme, akıl y\xfcr\xfctme, ajan (agent) ve genel yetenekler i\xe7in tasarlanmış bir dizi a\xe7ık kaynaklı b\xfcy\xfck dil modelidir. Bu serideki Seed-OSS-36B-Instruct, 36 milyar parametreye sahip bir talimat ince ayar modelidir ve doğal olarak \xe7ok uzun bağlam uzunluğunu destekleyerek, b\xfcy\xfck belgeleri veya karmaşık kod tabanlarını tek seferde işleyebilmesini sağlar. Model, akıl y\xfcr\xfctme, kod \xfcretimi ve ara\xe7 kullanımı gibi ajan g\xf6revlerinde \xf6zel olarak optimize edilmiştir ve dengeli, \xfcst\xfcn genel yetenekler sunar. Modelin \xf6nemli bir \xf6zelliği olan “D\xfcş\xfcnme B\xfct\xe7esi” fonksiyonu, kullanıcıların ihtiya\xe7larına g\xf6re akıl y\xfcr\xfctme uzunluğunu esnek şekilde ayarlamasına olanak tanır ve b\xf6ylece ger\xe7ek uygulamalarda akıl y\xfcr\xfctme verimliliğini artırır."},"DeepSeek-R1":{"description":"En gelişmiş verimli LLM, akıl y\xfcr\xfctme, matematik ve programlama konularında uzmandır."},"DeepSeek-R1-Distill-Llama-70B":{"description":"DeepSeek R1 - DeepSeek setindeki daha b\xfcy\xfck ve daha akıllı model - Llama 70B mimarisine damıtılmıştır. Kıyaslamalar ve insan değerlendirmelerine dayanarak, bu model orijinal Llama 70B\'den daha akıllıdır, \xf6zellikle matematik ve ger\xe7eklik doğruluğu gerektiren g\xf6revlerde m\xfckemmel performans g\xf6stermektedir."},"DeepSeek-R1-Distill-Qwen-1.5B":{"description":"Qwen2.5-Math-1.5B temel alınarak oluşturulmuş DeepSeek-R1 damıtma modeli, pekiştirme \xf6ğrenimi ve soğuk başlatma verileri ile \xe7ıkarım performansını optimize eder, a\xe7ık kaynak model \xe7oklu g\xf6rev standartlarını yeniler."},"DeepSeek-R1-Distill-Qwen-14B":{"description":"Qwen2.5-14B temel alınarak oluşturulmuş DeepSeek-R1 damıtma modeli, pekiştirme \xf6ğrenimi ve soğuk başlatma verileri ile \xe7ıkarım performansını optimize eder, a\xe7ık kaynak model \xe7oklu g\xf6rev standartlarını yeniler."},"DeepSeek-R1-Distill-Qwen-32B":{"description":"DeepSeek-R1 serisi, pekiştirme \xf6ğrenimi ve soğuk başlatma verileri ile \xe7ıkarım performansını optimize eder, a\xe7ık kaynak model \xe7oklu g\xf6rev standartlarını yeniler, OpenAI-o1-mini seviyesini aşar."},"DeepSeek-R1-Distill-Qwen-7B":{"description":"Qwen2.5-Math-7B temel alınarak oluşturulmuş DeepSeek-R1 damıtma modeli, pekiştirme \xf6ğrenimi ve soğuk başlatma verileri ile \xe7ıkarım performansını optimize eder, a\xe7ık kaynak model \xe7oklu g\xf6rev standartlarını yeniler."},"DeepSeek-V3":{"description":"DeepSeek-V3, Derin Arayış şirketi tarafından geliştirilen bir MoE modelidir. DeepSeek-V3, bir\xe7ok değerlendirmede Qwen2.5-72B ve Llama-3.1-405B gibi diğer a\xe7ık kaynak modelleri geride bırakmış ve performans a\xe7ısından d\xfcnya \xe7apında en iyi kapalı kaynak model olan GPT-4o ve Claude-3.5-Sonnet ile eşit seviyededir."},"DeepSeek-V3-1":{"description":"DeepSeek V3.1: Karmaşık \xe7ıkarım ve bağlantılı d\xfcş\xfcnme yeteneklerini geliştiren, derinlemesine analiz gerektiren g\xf6revler i\xe7in uygun bir sonraki nesil \xe7ıkarım modeli."},"DeepSeek-V3-Fast":{"description":"Model sağlayıcısı: sophnet platformu. DeepSeek V3 Fast, DeepSeek V3 0324 s\xfcr\xfcm\xfcn\xfcn y\xfcksek TPS hızlı versiyonudur, tam performanslı ve kuantize edilmemiştir, kodlama ve matematik yetenekleri daha g\xfc\xe7l\xfcd\xfcr, yanıt s\xfcresi daha hızlıdır!"},"DeepSeek-V3.1":{"description":"DeepSeek-V3.1-D\xfcş\xfcnme modu dışı; DeepSeek-V3.1, DeepSeek tarafından yeni sunulan hibrit akıl y\xfcr\xfctme modelidir ve d\xfcş\xfcnme ile d\xfcş\xfcnmeme olmak \xfczere iki akıl y\xfcr\xfctme modunu destekler. DeepSeek-R1-0528 modeline kıyasla d\xfcş\xfcnme verimliliği daha y\xfcksektir. Sonrası eğitim optimizasyonları sayesinde, ajan ara\xe7 kullanımı ve akıllı ajan g\xf6revlerinde performans \xf6nemli \xf6l\xe7\xfcde artmıştır."},"DeepSeek-V3.1-Fast":{"description":"DeepSeek V3.1 Fast, DeepSeek V3.1 s\xfcr\xfcm\xfcn\xfcn y\xfcksek TPS hızlı versiyonudur. Hibrit d\xfcş\xfcnme modu: Sohbet şablonunu değiştirerek, tek bir model hem d\xfcş\xfcnme hem de d\xfcş\xfcnmeme modlarını destekleyebilir. Daha akıllı ara\xe7 \xe7ağrısı: Sonrası eğitim optimizasyonları sayesinde model, ara\xe7 kullanımı ve ajan g\xf6revlerindeki performansını belirgin şekilde artırmıştır."},"DeepSeek-V3.1-Think":{"description":"DeepSeek-V3.1-D\xfcş\xfcnme modu; DeepSeek-V3.1, DeepSeek tarafından yeni sunulan hibrit akıl y\xfcr\xfctme modelidir ve d\xfcş\xfcnme ile d\xfcş\xfcnmeme olmak \xfczere iki akıl y\xfcr\xfctme modunu destekler. DeepSeek-R1-0528 modeline kıyasla d\xfcş\xfcnme verimliliği daha y\xfcksektir. Sonrası eğitim optimizasyonları sayesinde, ajan ara\xe7 kullanımı ve akıllı ajan g\xf6revlerinde performans \xf6nemli \xf6l\xe7\xfcde artmıştır."},"DeepSeek-V3.2-Exp":{"description":"DeepSeek V3.2, DeepSeek\'in en yeni genel modeli olup, hibrit \xe7ıkarım mimarisini destekler ve daha g\xfc\xe7l\xfc Agent yeteneklerine sahiptir."},"DeepSeek-V3.2-Exp-Think":{"description":"DeepSeek V3.2 D\xfcş\xfcnme Modu. Nihai cevabı vermeden \xf6nce, model doğruluğu artırmak i\xe7in bir d\xfcş\xfcnce zinciri \xe7ıktısı \xfcretir."},"Doubao-lite-128k":{"description":"Doubao-lite, son derece hızlı yanıt s\xfcresi ve daha iyi fiyat-performans oranı ile m\xfcşterilere farklı senaryolar i\xe7in daha esnek se\xe7enekler sunar. 128k bağlam penceresi ile \xe7ıkarım ve ince ayar desteği sağlar."},"Doubao-lite-32k":{"description":"Doubao-lite, son derece hızlı yanıt s\xfcresi ve daha iyi fiyat-performans oranı ile m\xfcşterilere farklı senaryolar i\xe7in daha esnek se\xe7enekler sunar. 32k bağlam penceresi ile \xe7ıkarım ve ince ayar desteği sağlar."},"Doubao-lite-4k":{"description":"Doubao-lite, son derece hızlı yanıt s\xfcresi ve daha iyi fiyat-performans oranı ile m\xfcşterilere farklı senaryolar i\xe7in daha esnek se\xe7enekler sunar. 4k bağlam penceresi ile \xe7ıkarım ve ince ayar desteği sağlar."},"Doubao-pro-128k":{"description":"En etkili ana model olup, karmaşık g\xf6revlerin işlenmesi i\xe7in uygundur. Referans soru-cevap, \xf6zet \xe7ıkarma, yaratıcı yazım, metin sınıflandırma, rol yapma gibi senaryolarda m\xfckemmel performans g\xf6sterir. 128k bağlam penceresi ile \xe7ıkarım ve ince ayar desteği sağlar."},"Doubao-pro-32k":{"description":"En etkili ana model olup, karmaşık g\xf6revlerin işlenmesi i\xe7in uygundur. Referans soru-cevap, \xf6zet \xe7ıkarma, yaratıcı yazım, metin sınıflandırma, rol yapma gibi senaryolarda m\xfckemmel performans g\xf6sterir. 32k bağlam penceresi ile \xe7ıkarım ve ince ayar desteği sağlar."},"Doubao-pro-4k":{"description":"En etkili ana model olup, karmaşık g\xf6revlerin işlenmesi i\xe7in uygundur. Referans soru-cevap, \xf6zet \xe7ıkarma, yaratıcı yazım, metin sınıflandırma, rol yapma gibi senaryolarda m\xfckemmel performans g\xf6sterir. 4k bağlam penceresi ile \xe7ıkarım ve ince ayar desteği sağlar."},"DreamO":{"description":"DreamO, ByteDance ve Pekin \xdcniversitesi iş birliğiyle geliştirilen a\xe7ık kaynaklı, \xe7ok g\xf6revli g\xf6r\xfcnt\xfc \xfcretim modelidir. Birleşik mimari sayesinde kullanıcı tarafından belirtilen kimlik, konu, stil, arka plan gibi \xe7oklu koşullara g\xf6re y\xfcksek tutarlılıkta ve \xf6zelleştirilmiş g\xf6r\xfcnt\xfcler oluşturabilir."},"ERNIE-3.5-128K":{"description":"Baidu\'nun kendi geliştirdiği, b\xfcy\xfck \xf6l\xe7ekli bir dil modeli olan ERNIE-3.5, geniş bir \xc7in ve İngilizce veri k\xfcmesini kapsar. G\xfc\xe7l\xfc genel yeteneklere sahip olup, \xe7oğu diyalog, soru-cevap, yaratıcı i\xe7erik \xfcretimi ve eklenti uygulama senaryolarını karşılayabilir; ayrıca, Baidu arama eklentisi ile otomatik entegrasyonu destekleyerek, soru-cevap bilgilerinin g\xfcncelliğini sağlar."},"ERNIE-3.5-8K":{"description":"Baidu\'nun kendi geliştirdiği, b\xfcy\xfck \xf6l\xe7ekli bir dil modeli olan ERNIE-3.5, geniş bir \xc7in ve İngilizce veri k\xfcmesini kapsar. G\xfc\xe7l\xfc genel yeteneklere sahip olup, \xe7oğu diyalog, soru-cevap, yaratıcı i\xe7erik \xfcretimi ve eklenti uygulama senaryolarını karşılayabilir; ayrıca, Baidu arama eklentisi ile otomatik entegrasyonu destekleyerek, soru-cevap bilgilerinin g\xfcncelliğini sağlar."},"ERNIE-3.5-8K-Preview":{"description":"Baidu\'nun kendi geliştirdiği, b\xfcy\xfck \xf6l\xe7ekli bir dil modeli olan ERNIE-3.5, geniş bir \xc7in ve İngilizce veri k\xfcmesini kapsar. G\xfc\xe7l\xfc genel yeteneklere sahip olup, \xe7oğu diyalog, soru-cevap, yaratıcı i\xe7erik \xfcretimi ve eklenti uygulama senaryolarını karşılayabilir; ayrıca, Baidu arama eklentisi ile otomatik entegrasyonu destekleyerek, soru-cevap bilgilerinin g\xfcncelliğini sağlar."},"ERNIE-4.0-8K-Latest":{"description":"Baidu\'nun kendi geliştirdiği amiral gemisi ultra b\xfcy\xfck \xf6l\xe7ekli dil modeli, ERNIE 3.5\'e kıyasla model yeteneklerinde kapsamlı bir y\xfckseltme ger\xe7ekleştirmiştir, \xe7eşitli alanlardaki karmaşık g\xf6rev senaryolarında geniş bir şekilde uygulanabilir; Baidu arama eklentisi ile otomatik entegrasyonu destekler, yanıt bilgilerini g\xfcncel tutar."},"ERNIE-4.0-8K-Preview":{"description":"Baidu\'nun kendi geliştirdiği amiral gemisi ultra b\xfcy\xfck \xf6l\xe7ekli dil modeli, ERNIE 3.5\'e kıyasla model yeteneklerinde kapsamlı bir y\xfckseltme ger\xe7ekleştirmiştir, \xe7eşitli alanlardaki karmaşık g\xf6rev senaryolarında geniş bir şekilde uygulanabilir; Baidu arama eklentisi ile otomatik entegrasyonu destekler, yanıt bilgilerini g\xfcncel tutar."},"ERNIE-4.0-Turbo-8K-Latest":{"description":"Baidu tarafından geliştirilen, geniş \xf6l\xe7ekli b\xfcy\xfck dil modeli, genel performansı m\xfckemmeldir ve her alanda karmaşık g\xf6rev sahneleri i\xe7in geniş bir şekilde kullanılabilir; Baidu arama eklentisi ile otomatik entegrasyonu destekler, yanıt bilgi g\xfcncellemelerinin zamanlamasını g\xfcvence altına alır. ERNIE 4.0\'a kıyasla, performans olarak daha \xfcst\xfcnd\xfcr."},"ERNIE-4.0-Turbo-8K-Preview":{"description":"Baidu\'nun kendi geliştirdiği amiral gemisi ultra b\xfcy\xfck \xf6l\xe7ekli dil modeli, genel performansı m\xfckemmel olup, \xe7eşitli alanlardaki karmaşık g\xf6rev senaryolarında geniş bir şekilde uygulanabilir; Baidu arama eklentisi ile otomatik entegrasyonu destekler, yanıt bilgilerini g\xfcncel tutar. ERNIE 4.0\'a kıyasla performans a\xe7ısından daha \xfcst\xfcnd\xfcr."},"ERNIE-Character-8K":{"description":"Baidu\'nun kendi geliştirdiği dikey senaryo b\xfcy\xfck dil modeli, oyun NPC\'leri, m\xfcşteri hizmetleri diyalogları, diyalog karakter rol\xfc gibi uygulama senaryoları i\xe7in uygundur, karakter tarzı daha belirgin ve tutarlıdır, talimatları takip etme yeteneği daha g\xfc\xe7l\xfcd\xfcr ve \xe7ıkarım performansı daha iyidir."},"ERNIE-Lite-Pro-128K":{"description":"Baidu\'nun kendi geliştirdiği hafif b\xfcy\xfck dil modeli, m\xfckemmel model performansı ve \xe7ıkarım yeteneklerini dengeler, ERNIE Lite\'dan daha iyi sonu\xe7lar verir, d\xfcş\xfck hesaplama g\xfcc\xfcne sahip AI hızlandırıcı kartları i\xe7in uygundur."},"ERNIE-Speed-128K":{"description":"Baidu\'nun 2024 yılında piyasaya s\xfcrd\xfcğ\xfc kendi geliştirdiği y\xfcksek performanslı b\xfcy\xfck dil modeli, genel yetenekleri m\xfckemmel olup, belirli senaryo sorunlarını daha iyi işlemek i\xe7in temel model olarak ince ayar yapmak i\xe7in uygundur ve m\xfckemmel \xe7ıkarım performansına sahiptir."},"ERNIE-Speed-Pro-128K":{"description":"Baidu\'nun 2024 yılında piyasaya s\xfcrd\xfcğ\xfc kendi geliştirdiği y\xfcksek performanslı b\xfcy\xfck dil modeli, genel yetenekleri m\xfckemmel olup, ERNIE Speed\'den daha iyi sonu\xe7lar verir, belirli senaryo sorunlarını daha iyi işlemek i\xe7in temel model olarak ince ayar yapmak i\xe7in uygundur ve m\xfckemmel \xe7ıkarım performansına sahiptir."},"FLUX-1.1-pro":{"description":"FLUX.1.1 Pro"},"FLUX.1-Kontext-dev":{"description":"FLUX.1-Kontext-dev, Black Forest Labs tarafından geliştirilen, Rectified Flow Transformer mimarisine dayanan \xe7ok modlu g\xf6r\xfcnt\xfc oluşturma ve d\xfczenleme modelidir. 12 milyar parametreye sahip olup, verilen bağlam koşullarında g\xf6r\xfcnt\xfc oluşturma, yeniden yapılandırma, iyileştirme ve d\xfczenleme işlemlerine odaklanır. Model, dif\xfczyon modellerinin kontroll\xfc \xfcretim avantajlarını ve Transformer\'ın bağlam modelleme yeteneklerini birleştirerek y\xfcksek kaliteli g\xf6r\xfcnt\xfc \xe7ıktısı sağlar ve g\xf6r\xfcnt\xfc onarımı, tamamlama, g\xf6rsel sahne yeniden yapılandırma gibi g\xf6revlerde geniş uygulama alanına sahiptir."},"FLUX.1-Kontext-pro":{"description":"FLUX.1 Kontext [pro]"},"FLUX.1-dev":{"description":"FLUX.1-dev, Black Forest Labs tarafından geliştirilen a\xe7ık kaynaklı \xe7ok modlu dil modelidir (Multimodal Language Model, MLLM). G\xf6r\xfcnt\xfc ve metin anlama ile \xfcretim yeteneklerini birleştirerek g\xf6rsel ve metin g\xf6revleri i\xe7in optimize edilmiştir. Mistral-7B gibi gelişmiş b\xfcy\xfck dil modelleri temel alınarak, \xf6zenle tasarlanmış g\xf6rsel kodlayıcı ve \xe7ok aşamalı talimat ince ayarı ile g\xf6rsel-metinsel işbirliği ve karmaşık g\xf6rev \xe7ıkarımı sağlar."},"Gryphe/MythoMax-L2-13b":{"description":"MythoMax-L2 (13B), \xe7ok alanlı uygulamalar ve karmaşık g\xf6revler i\xe7in uygun yenilik\xe7i bir modeldir."},"HelloMeme":{"description":"HelloMeme, sağladığınız resim veya hareketlere dayanarak otomatik olarak meme, GIF veya kısa video oluşturabilen bir yapay zeka aracıdır. Hi\xe7bir \xe7izim veya programlama bilgisi gerektirmez; sadece referans resim hazırlamanız yeterlidir, b\xf6ylece size g\xfczel, eğlenceli ve tutarlı tarzda i\xe7erikler oluşturur."},"HiDream-I1-Full":{"description":"HiDream-E1-Full, ZhiXiang Future (HiDream.ai) tarafından geliştirilen a\xe7ık kaynaklı \xe7ok modlu g\xf6r\xfcnt\xfc d\xfczenleme b\xfcy\xfck modelidir. Gelişmiş Diffusion Transformer mimarisi ve g\xfc\xe7l\xfc dil anlama yeteneği (g\xf6m\xfcl\xfc LLaMA 3.1-8B-Instruct) ile doğal dil komutlarıyla g\xf6r\xfcnt\xfc oluşturma, stil transferi, yerel d\xfczenleme ve i\xe7erik yeniden \xe7izim desteği sunar; \xfcst\xfcn g\xf6rsel-metinsel anlama ve y\xfcr\xfctme kabiliyetine sahiptir."},"HunyuanDiT-v1.2-Diffusers-Distilled":{"description":"hunyuandit-v1.2-distilled, damıtma optimizasyonu ile hafifletilmiş, hızlı y\xfcksek kaliteli g\xf6r\xfcnt\xfc \xfcretebilen bir metinden g\xf6r\xfcnt\xfcye modeldir. \xd6zellikle d\xfcş\xfck kaynaklı ortamlar ve ger\xe7ek zamanlı \xfcretim g\xf6revleri i\xe7in uygundur."},"InstantCharacter":{"description":"InstantCharacter, Tencent AI ekibi tarafından 2025 yılında yayınlanan, ince ayar gerektirmeyen (tuning-free) kişiselleştirilmiş karakter oluşturma modelidir. Y\xfcksek doğrulukta ve sahneler arası tutarlı karakter \xfcretmeyi hedefler. Sadece bir referans g\xf6r\xfcnt\xfcye dayanarak karakter modellemesi yapabilir ve bu karakteri farklı stiller, hareketler ve arka planlara esnek şekilde taşıyabilir."},"InternVL2-8B":{"description":"InternVL2-8B, g\xfc\xe7l\xfc bir g\xf6rsel dil modelidir. G\xf6r\xfcnt\xfc ve metinlerin \xe7ok modlu işlenmesini destekler, g\xf6r\xfcnt\xfc i\xe7eriğini hassas bir şekilde tanıyabilir ve ilgili a\xe7ıklamalar veya yanıtlar \xfcretebilir."},"InternVL2.5-26B":{"description":"InternVL2.5-26B, g\xfc\xe7l\xfc bir g\xf6rsel dil modelidir. G\xf6r\xfcnt\xfc ve metinlerin \xe7ok modlu işlenmesini destekler, g\xf6r\xfcnt\xfc i\xe7eriğini hassas bir şekilde tanıyabilir ve ilgili a\xe7ıklamalar veya yanıtlar \xfcretebilir."},"Kolors":{"description":"Kolors, Kuaishou Kolors ekibi tarafından geliştirilen metinden g\xf6r\xfcnt\xfcye modeldir. Milyarlarca parametre ile eğitilmiş olup, g\xf6rsel kalite, \xc7ince anlamsal anlama ve metin işleme konularında belirgin avantajlara sahiptir."},"Kwai-Kolors/Kolors":{"description":"Kolors, Kuaishou Kolors ekibi tarafından geliştirilen, latent dif\xfczyon tabanlı b\xfcy\xfck \xf6l\xe7ekli metinden g\xf6r\xfcnt\xfcye \xfcretim modelidir. Milyarlarca metin-g\xf6r\xfcnt\xfc \xe7iftinden eğitilerek g\xf6rsel kalite, karmaşık anlamsal doğruluk ve \xc7ince-İngilizce karakter işleme alanlarında \xfcst\xfcn performans g\xf6sterir. Hem \xc7ince hem İngilizce girişleri destekler ve \xf6zellikle \xc7ince i\xe7erik anlama ve \xfcretiminde başarılıdır."},"Kwaipilot/KAT-Dev":{"description":"KAT-Dev (32B), yazılım m\xfchendisliği g\xf6revleri i\xe7in \xf6zel olarak tasarlanmış a\xe7ık kaynaklı bir 32B parametreli modeldir. SWE-Bench Verified kıyaslamasında %62,4 başarı oranı elde etmiş ve farklı boyutlardaki t\xfcm a\xe7ık kaynak modeller arasında beşinci sırada yer almıştır. Model; ara eğitim, denetimli ince ayar (SFT) ve pekiştirmeli \xf6ğrenme (RL) dahil olmak \xfczere \xe7ok aşamalı bir s\xfcre\xe7le optimize edilmiştir. Kod tamamlama, hata d\xfczeltme, kod incelemesi gibi karmaşık programlama g\xf6revlerinde g\xfc\xe7l\xfc destek sunmak \xfczere tasarlanmıştır."},"Llama-3.2-11B-Vision-Instruct":{"description":"Y\xfcksek \xe7\xf6z\xfcn\xfcrl\xfckl\xfc g\xf6r\xfcnt\xfclerde m\xfckemmel g\xf6r\xfcnt\xfc akıl y\xfcr\xfctme yeteneği, g\xf6rsel anlama uygulamaları i\xe7in uygundur."},"Llama-3.2-90B-Vision-Instruct\\t":{"description":"G\xf6rsel anlama ajan uygulamaları i\xe7in gelişmiş g\xf6r\xfcnt\xfc akıl y\xfcr\xfctme yeteneği."},"Meta-Llama-3-3-70B-Instruct":{"description":"Llama 3.3 70B: Diyalog ve \xfcretim g\xf6revleri i\xe7in uygun, y\xfcksek genel ama\xe7lı Transformer modeli."},"Meta-Llama-3.1-405B-Instruct":{"description":"Llama 3.1 talimat ayarlı metin modeli, \xe7ok dilli diyalog kullanım durumları i\xe7in optimize edilmiştir ve bir\xe7ok mevcut a\xe7ık kaynak ve kapalı sohbet modelinde yaygın end\xfcstri kıyaslamalarında m\xfckemmel performans g\xf6stermektedir."},"Meta-Llama-3.1-70B-Instruct":{"description":"Llama 3.1 talimat ayarlı metin modeli, \xe7ok dilli diyalog kullanım durumları i\xe7in optimize edilmiştir ve bir\xe7ok mevcut a\xe7ık kaynak ve kapalı sohbet modelinde yaygın end\xfcstri kıyaslamalarında m\xfckemmel performans g\xf6stermektedir."},"Meta-Llama-3.1-8B-Instruct":{"description":"Llama 3.1 talimat ayarlı metin modeli, \xe7ok dilli diyalog kullanım durumları i\xe7in optimize edilmiştir ve bir\xe7ok mevcut a\xe7ık kaynak ve kapalı sohbet modelinde yaygın end\xfcstri kıyaslamalarında m\xfckemmel performans g\xf6stermektedir."},"Meta-Llama-3.2-1B-Instruct":{"description":"Gelişmiş, en son teknolojiye sahip k\xfc\xe7\xfck dil modeli, dil anlama, m\xfckemmel akıl y\xfcr\xfctme yeteneği ve metin oluşturma yeteneğine sahiptir."},"Meta-Llama-3.2-3B-Instruct":{"description":"Gelişmiş, en son teknolojiye sahip k\xfc\xe7\xfck dil modeli, dil anlama, m\xfckemmel akıl y\xfcr\xfctme yeteneği ve metin oluşturma yeteneğine sahiptir."},"Meta-Llama-3.3-70B-Instruct":{"description":"Llama 3.3, Llama serisinin en gelişmiş \xe7ok dilli a\xe7ık kaynak b\xfcy\xfck dil modelidir ve 405B modelinin performansını \xe7ok d\xfcş\xfck maliyetle deneyimlemenizi sağlar. Transformer yapısına dayanmaktadır ve yararlılığını ve g\xfcvenliğini artırmak i\xe7in denetimli ince ayar (SFT) ve insan geri bildirimi ile g\xfc\xe7lendirilmiş \xf6ğrenme (RLHF) kullanılmıştır. Talimat ayarlı versiyonu \xe7ok dilli diyaloglar i\xe7in optimize edilmiştir ve bir\xe7ok end\xfcstri kıyaslamasında bir\xe7ok a\xe7ık kaynak ve kapalı sohbet modelinden daha iyi performans g\xf6stermektedir. Bilgi kesim tarihi 2023 yılı Aralık ayıdır."},"Meta-Llama-4-Maverick-17B-128E-Instruct-FP8":{"description":"Llama 4 Maverick: Mixture-of-Experts tabanlı b\xfcy\xfck \xf6l\xe7ekli model, \xe7ıkarımda \xfcst\xfcn performans i\xe7in verimli uzman aktivasyon stratejisi sunar."},"MiniMax-M1":{"description":"Tamamen yeni, kendi geliştirdiğimiz \xe7ıkarım modeli. D\xfcnya lideri: 80K d\xfcş\xfcnce zinciri x 1M girdi, performansı yurtdışındaki en iyi modellerle kıyaslanabilir d\xfczeyde."},"MiniMax-M2":{"description":"Verimli kodlama ve Agent iş akışları i\xe7in \xf6zel olarak tasarlandı."},"MiniMax-Text-01":{"description":"MiniMax-01 serisi modellerinde cesur yenilikler yaptık: ilk kez b\xfcy\xfck \xf6l\xe7ekli lineer dikkat mekanizmasını ger\xe7ekleştirdik, geleneksel Transformer mimarisi artık tek se\xe7enek değil. Bu modelin parametre sayısı 456 milyara kadar \xe7ıkmakta, tek bir aktivasyonda 45.9 milyar. Modelin genel performansı, yurtdışındaki en iyi modellerle karşılaştırılabilirken, d\xfcnya genelinde 4 milyon token uzunluğundaki bağlamı verimli bir şekilde işleyebilir, bu da GPT-4o\'nun 32 katı, Claude-3.5-Sonnet\'in 20 katıdır."},"MiniMaxAI/MiniMax-M1-80k":{"description":"MiniMax-M1, a\xe7ık kaynak ağırlıklı b\xfcy\xfck \xf6l\xe7ekli karma dikkat \xe7ıkarım modeli olup, 456 milyar parametreye sahiptir ve her Token yaklaşık 45.9 milyar parametreyi aktive eder. Model, doğal olarak 1 milyon Token uzunluğunda bağlamı destekler ve şimşek dikkat mekanizması sayesinde 100 bin Token \xfcretim g\xf6revlerinde DeepSeek R1\'e kıyasla %75 daha az kayan nokta işlemi kullanır. Ayrıca, MiniMax-M1 MoE (karışık uzman) mimarisini, CISPO algoritması ve karma dikkat tasarımı ile verimli pekiştirmeli \xf6ğrenme eğitimiyle birleştirerek uzun giriş \xe7ıkarımı ve ger\xe7ek yazılım m\xfchendisliği senaryolarında sekt\xf6r lideri performans sunar."},"MiniMaxAI/MiniMax-M2":{"description":"MiniMax-M2, yapay zek\xe2 ajanları i\xe7in verimliliği yeniden tanımlıyor. 230 milyar toplam parametreye ve 10 milyar etkin parametreye sahip olan bu kompakt, hızlı ve ekonomik MoE (Uzman Karışımı) modeli, kodlama ve yapay zek\xe2 g\xf6revlerinde \xfcst\xfcn performans sunmak \xfczere tasarlanmıştır ve aynı zamanda g\xfc\xe7l\xfc bir genel zek\xe2 kapasitesini korur. Sadece 10 milyar etkin parametreyle, MiniMax-M2 b\xfcy\xfck \xf6l\xe7ekli modellerle karşılaştırılabilir bir performans sunarak y\xfcksek verimlilik gerektiren uygulamalar i\xe7in ideal bir tercih haline gelir."},"Moonshot-Kimi-K2-Instruct":{"description":"Toplam 1 trilyon parametre, 32 milyar aktif parametreye sahip. D\xfcş\xfcnme modeli olmayanlar arasında, g\xfcncel bilgi, matematik ve kodlama alanlarında en \xfcst d\xfczeyde performans g\xf6sterir ve genel ajan g\xf6revlerinde daha yetkindir. Ajan g\xf6revleri i\xe7in optimize edilmiştir; sadece soruları yanıtlamakla kalmaz, aynı zamanda eylem de ger\xe7ekleştirebilir. Doğa\xe7lama, genel sohbet ve ajan deneyimleri i\xe7in en uygunudur; uzun d\xfcş\xfcnme gerektirmeyen refleks seviyesinde bir modeldir."},"NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO":{"description":"Nous Hermes 2 - Mixtral 8x7B-DPO (46.7B), karmaşık hesaplamalar i\xe7in y\xfcksek hassasiyetli bir talimat modelidir."},"OmniConsistency":{"description":"OmniConsistency, b\xfcy\xfck \xf6l\xe7ekli Dif\xfczyon Transformerlar (DiTs) ve eşleştirilmiş stilize veri kullanarak g\xf6r\xfcnt\xfcden g\xf6r\xfcnt\xfcye (Image-to-Image) g\xf6revlerinde stil tutarlılığı ve genelleme yeteneğini artırır, stil bozulmasını \xf6nler."},"Phi-3-medium-128k-instruct":{"description":"Aynı Phi-3-medium modeli, ancak RAG veya az sayıda \xf6rnek isteme i\xe7in daha b\xfcy\xfck bir bağlam boyutuna sahiptir."},"Phi-3-medium-4k-instruct":{"description":"14B parametreli bir model, Phi-3-mini\'den daha iyi kalite sunar, y\xfcksek kaliteli, akıl y\xfcr\xfctme yoğun veriye odaklanır."},"Phi-3-mini-128k-instruct":{"description":"Aynı Phi-3-mini modeli, ancak RAG veya az sayıda \xf6rnek isteme i\xe7in daha b\xfcy\xfck bir bağlam boyutuna sahiptir."},"Phi-3-mini-4k-instruct":{"description":"Phi-3 ailesinin en k\xfc\xe7\xfck \xfcyesi. Hem kalite hem de d\xfcş\xfck gecikme i\xe7in optimize edilmiştir."},"Phi-3-small-128k-instruct":{"description":"Aynı Phi-3-small modeli, ancak RAG veya az sayıda \xf6rnek isteme i\xe7in daha b\xfcy\xfck bir bağlam boyutuna sahiptir."},"Phi-3-small-8k-instruct":{"description":"7B parametreli bir model, Phi-3-mini\'den daha iyi kalite sunar, y\xfcksek kaliteli, akıl y\xfcr\xfctme yoğun veriye odaklanır."},"Phi-3.5-mini-instruct":{"description":"Phi-3-mini modelinin g\xfcncellenmiş versiyonu."},"Phi-3.5-vision-instrust":{"description":"Phi-3-g\xf6rsel modelinin g\xfcncellenmiş versiyonu."},"Pro/Qwen/Qwen2-7B-Instruct":{"description":"Qwen2-7B-Instruct, Qwen2 serisindeki talimat ince ayar b\xfcy\xfck dil modelidir ve parametre \xf6l\xe7eği 7B\'dir. Bu model, Transformer mimarisi temelinde, SwiGLU aktivasyon fonksiyonu, dikkat QKV \xf6nyargısı ve grup sorgu dikkati gibi teknikler kullanmaktadır. B\xfcy\xfck \xf6l\xe7ekli girişleri işleyebilme yeteneğine sahiptir. Bu model, dil anlama, \xfcretim, \xe7ok dilli yetenek, kodlama, matematik ve akıl y\xfcr\xfctme gibi bir\xe7ok standart testte m\xfckemmel performans sergilemekte ve \xe7oğu a\xe7ık kaynak modelini geride bırakmakta, bazı g\xf6revlerde \xf6zel modellere karşı rekabet edebilir. Qwen2-7B-Instruct, bir\xe7ok değerlendirmede Qwen1.5-7B-Chat\'ten daha iyi performans g\xf6stermekte ve belirgin bir performans artışı sergilemektedir."},"Pro/Qwen/Qwen2.5-7B-Instruct":{"description":"Qwen2.5-7B-Instruct, Alibaba Cloud tarafından yayınlanan en son b\xfcy\xfck dil modeli serilerinden biridir. Bu 7B modeli, kodlama ve matematik gibi alanlarda \xf6nemli \xf6l\xe7\xfcde geliştirilmiş yeteneklere sahiptir. Model ayrıca, \xc7ince, İngilizce gibi 29\'dan fazla dili kapsayan \xe7ok dilli destek sunmaktadır. Model, talimat takibi, yapılandırılmış verileri anlama ve yapılandırılmış \xe7ıktı (\xf6zellikle JSON) \xfcretme konularında \xf6nemli iyileştirmeler g\xf6stermektedir."},"Pro/Qwen/Qwen2.5-Coder-7B-Instruct":{"description":"Qwen2.5-Coder-7B-Instruct, Alibaba Cloud tarafından yayınlanan kod odaklı b\xfcy\xfck dil modeli serisinin en son versiyonudur. Bu model, Qwen2.5 temelinde, 5.5 trilyon token ile eğitilerek kod \xfcretimi, akıl y\xfcr\xfctme ve d\xfczeltme yeteneklerini \xf6nemli \xf6l\xe7\xfcde artırmıştır. Hem kodlama yeteneklerini geliştirmiş hem de matematik ve genel yetenek avantajlarını korumuştur. Model, kod akıllı ajanları gibi pratik uygulamalar i\xe7in daha kapsamlı bir temel sunmaktadır."},"Pro/Qwen/Qwen2.5-VL-7B-Instruct":{"description":"Qwen2.5-VL, Qwen serisinin yeni \xfcyesidir ve g\xfc\xe7l\xfc g\xf6rsel anlama yeteneğine sahiptir. G\xf6rsellerdeki metinleri, grafikleri ve d\xfczenleri analiz edebilir, uzun videoları anlayabilir ve olayları yakalayabilir. Akıl y\xfcr\xfctme yapabilir, ara\xe7ları kullanabilir, \xe7oklu format nesne konumlandırmayı destekler ve yapılandırılmış \xe7ıktılar \xfcretebilir. Video anlama i\xe7in dinamik \xe7\xf6z\xfcn\xfcrl\xfck ve kare hızı eğitimini optimize etmiş ve g\xf6rsel kodlayıcı verimliliğini artırmıştır."},"Pro/THUDM/GLM-4.1V-9B-Thinking":{"description":"GLM-4.1V-9B-Thinking, Zhipu AI ve Tsinghua \xdcniversitesi KEG Laboratuvarı tarafından ortaklaşa yayınlanan a\xe7ık kaynaklı bir g\xf6rsel dil modeli (VLM) olup, karmaşık \xe7ok modlu bilişsel g\xf6revleri işlemek i\xe7in tasarlanmıştır. Bu model, GLM-4-9B-0414 temel modeli \xfczerine kurulmuş olup, \\"D\xfcş\xfcnce Zinciri\\" (Chain-of-Thought) akıl y\xfcr\xfctme mekanizmasını ve pekiştirmeli \xf6ğrenme stratejisini benimseyerek, modlar arası akıl y\xfcr\xfctme yeteneği ve kararlılığını \xf6nemli \xf6l\xe7\xfcde artırmıştır."},"Pro/THUDM/glm-4-9b-chat":{"description":"GLM-4-9B-Chat, Zhipu AI tarafından sunulan GLM-4 serisi \xf6nceden eğitilmiş modellerin a\xe7ık kaynak versiyonudur. Bu model, anlam, matematik, akıl y\xfcr\xfctme, kod ve bilgi gibi bir\xe7ok alanda m\xfckemmel performans sergilemektedir. \xc7oklu diyalogları desteklemenin yanı sıra, GLM-4-9B-Chat, web tarayıcı, kod y\xfcr\xfctme, \xf6zelleştirilmiş ara\xe7 \xe7ağrısı (Function Call) ve uzun metin akıl y\xfcr\xfctme gibi gelişmiş \xf6zelliklere de sahiptir. Model, \xc7ince, İngilizce, Japonca, Korece ve Almanca gibi 26 dili desteklemektedir. GLM-4-9B-Chat, AlignBench-v2, MT-Bench, MMLU ve C-Eval gibi bir\xe7ok standart testte m\xfckemmel performans sergilemiştir. Bu model, maksimum 128K bağlam uzunluğunu desteklemekte olup, akademik araştırmalar ve ticari uygulamalar i\xe7in uygundur."},"Pro/deepseek-ai/DeepSeek-R1":{"description":"DeepSeek-R1, modeldeki tekrarlılık ve okunabilirlik sorunlarını \xe7\xf6zen bir g\xfc\xe7lendirilmiş \xf6ğrenme (RL) destekli \xe7ıkarım modelidir. RL\'den \xf6nce, DeepSeek-R1 soğuk başlangı\xe7 verileri tanıtarak \xe7ıkarım performansını daha da optimize etmiştir. Matematik, kod ve \xe7ıkarım g\xf6revlerinde OpenAI-o1 ile benzer performans g\xf6stermektedir ve \xf6zenle tasarlanmış eğitim y\xf6ntemleri ile genel etkisini artırmıştır."},"Pro/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B":{"description":"DeepSeek-R1-Distill-Qwen-7B, Qwen2.5-Math-7B modelinden bilgi damıtma y\xf6ntemiyle elde edilmiş bir modeldir. Bu model, DeepSeek-R1 tarafından oluşturulan 800 bin se\xe7kin \xf6rnekle ince ayar yapılarak geliştirilmiş olup, \xfcst\xfcn akıl y\xfcr\xfctme yeteneği sergilemektedir. \xc7eşitli kıyaslama testlerinde başarılı performans g\xf6steren model, MATH-500\'de %92,8 doğruluk, AIME 2024\'te %55,5 ge\xe7me oranı ve CodeForces\'ta 1189 puan alarak, 7B \xf6l\xe7eğindeki bir model i\xe7in g\xfc\xe7l\xfc matematik ve programlama yeteneklerini ortaya koymuştur."},"Pro/deepseek-ai/DeepSeek-V3":{"description":"DeepSeek-V3, 6710 milyar parametreye sahip bir karma uzman (MoE) dil modelidir ve \xe7ok başlı potansiyel dikkat (MLA) ve DeepSeekMoE mimarisini kullanarak, yardımcı kayıplar olmadan y\xfck dengeleme stratejileri ile \xe7ıkarım ve eğitim verimliliğini optimize etmektedir. 14.8 trilyon y\xfcksek kaliteli token \xfczerinde \xf6nceden eğitilmiş ve denetimli ince ayar ve g\xfc\xe7lendirilmiş \xf6ğrenme ile, DeepSeek-V3 performans a\xe7ısından diğer a\xe7ık kaynak modelleri geride bırakmakta ve lider kapalı kaynak modellere yaklaşmaktadır."},"Pro/deepseek-ai/DeepSeek-V3.1-Terminus":{"description":"DeepSeek-V3.1-Terminus, DeepSeek tarafından yayınlanan V3.1 modelinin g\xfcncellenmiş versiyonudur ve hibrit ajan b\xfcy\xfck dil modeli olarak konumlandırılmıştır. Bu g\xfcncelleme, modelin mevcut yeteneklerini koruyarak kullanıcı geri bildirimlerine dayalı sorunları d\xfczeltmeye ve kararlılığı artırmaya odaklanmıştır. Dil tutarlılığını \xf6nemli \xf6l\xe7\xfcde iyileştirmiş, \xc7ince ve İngilizce karışımı ile anormal karakterlerin g\xf6r\xfcn\xfcm\xfcn\xfc azaltmıştır. Model, farklı g\xf6revler i\xe7in sohbet şablonları aracılığıyla esnek ge\xe7iş yapılabilen “D\xfcş\xfcnme Modu” ve “D\xfcş\xfcnmeme Modu”nu entegre etmiştir. \xd6nemli bir iyileştirme olarak, V3.1-Terminus, kod ajanı (Code Agent) ve arama ajanı (Search Agent) performansını artırarak ara\xe7 \xe7ağrıları ve \xe7ok adımlı karmaşık g\xf6revlerin y\xfcr\xfct\xfclmesinde daha g\xfcvenilir hale getirmiştir."},"Pro/deepseek-ai/DeepSeek-V3.2-Exp":{"description":"DeepSeek-V3.2-Exp, DeepSeek tarafından yayınlanan deneysel V3.2 s\xfcr\xfcm\xfcd\xfcr ve yeni nesil mimariye ge\xe7işte bir ara keşif niteliğindedir. Bu s\xfcr\xfcm, V3.1-Terminus temelinde geliştirilmiş olup, uzun bağlamlı eğitim ve \xe7ıkarım verimliliğini artırmak amacıyla DeepSeek Seyrek Dikkat (DeepSeek Sparse Attention, DSA) mekanizmasını entegre eder. Ara\xe7 kullanımı, uzun belge anlama ve \xe7ok adımlı akıl y\xfcr\xfctme gibi alanlarda \xf6zel optimizasyonlar yapılmıştır. V3.2-Exp, araştırma ile \xfcr\xfcnleştirme arasında bir k\xf6pr\xfc g\xf6revi g\xf6r\xfcr ve y\xfcksek bağlam b\xfct\xe7esi gerektiren senaryolarda daha verimli \xe7ıkarım arayan kullanıcılar i\xe7in uygundur."},"Pro/moonshotai/Kimi-K2-Instruct-0905":{"description":"Kimi K2-Instruct-0905, Kimi K2\'nin en yeni ve en g\xfc\xe7l\xfc versiyonudur. Bu, toplamda 1 trilyon parametreye ve 32 milyar aktif parametreye sahip, \xfcst d\xfczey bir Hibrit Uzman (MoE) dil modelidir. Modelin başlıca \xf6zellikleri şunlardır: geliştirilmiş ajan kodlama zekası, a\xe7ık benchmark testlerinde ve ger\xe7ek d\xfcnya ajan kodlama g\xf6revlerinde belirgin performans artışı; \xf6n u\xe7 kodlama deneyiminde iyileştirmeler, \xf6n u\xe7 programlamada estetik ve işlevsellik a\xe7ısından ilerlemeler."},"QwQ-32B-Preview":{"description":"QwQ-32B-Preview, karmaşık diyalog oluşturma ve bağlam anlama g\xf6revlerini etkili bir şekilde işleyebilen yenilik\xe7i bir doğal dil işleme modelidir."},"Qwen/QVQ-72B-Preview":{"description":"QVQ-72B-Preview, Qwen ekibi tarafından geliştirilen ve g\xf6rsel \xe7ıkarım yeteneklerine odaklanan bir araştırma modelidir. Karmaşık sahne anlayışı ve g\xf6rsel ile ilgili matematiksel sorunları \xe7\xf6zme konusundaki benzersiz avantajları ile dikkat \xe7ekmektedir."},"Qwen/QwQ-32B":{"description":"QwQ, Qwen serisinin \xe7ıkarım modelidir. Geleneksel talimat ayarlama modellerine kıyasla, QwQ d\xfcş\xfcnme ve \xe7ıkarım yeteneğine sahiptir ve \xf6zellikle zor problemleri \xe7\xf6zme konusunda \xf6nemli \xf6l\xe7\xfcde artırılmış performans sergileyebilir. QwQ-32B, orta \xf6l\xe7ekli bir \xe7ıkarım modelidir ve en son \xe7ıkarım modelleri (\xf6rneğin, DeepSeek-R1, o1-mini) ile karşılaştırıldığında rekabet\xe7i bir performans elde edebilir. Bu model, RoPE, SwiGLU, RMSNorm ve Attention QKV bias gibi teknikleri kullanmakta olup, 64 katmanlı bir ağ yapısına ve 40 Q dikkat başlığına (GQA mimarisinde KV 8\'dir) sahiptir."},"Qwen/QwQ-32B-Preview":{"description":"QwQ-32B-Preview, Qwen\'in en son deneysel araştırma modelidir ve AI akıl y\xfcr\xfctme yeteneklerini artırmaya odaklanmaktadır. Dil karışımı, \xf6zyinelemeli akıl y\xfcr\xfctme gibi karmaşık mekanizmaları keşfederek, g\xfc\xe7l\xfc akıl y\xfcr\xfctme analizi, matematik ve programlama yetenekleri gibi ana avantajlar sunmaktadır. Bununla birlikte, dil ge\xe7iş sorunları, akıl y\xfcr\xfctme d\xf6ng\xfcleri, g\xfcvenlik endişeleri ve diğer yetenek farklılıkları gibi zorluklar da bulunmaktadır."},"Qwen/Qwen-Image":{"description":"Qwen-Image, Alibaba Tongyi Qianwen ekibi tarafından geliştirilen bir g\xf6rsel \xfcretim temel modelidir ve 20 milyar parametreye sahiptir. Bu model, karmaşık metin işleme ve hassas g\xf6rsel d\xfczenleme konularında \xf6nemli ilerlemeler kaydetmiştir; \xf6zellikle y\xfcksek doğrulukta \xc7ince ve İngilizce metin i\xe7eren g\xf6rseller \xfcretme konusunda uzmandır. Qwen-Image, \xe7ok satırlı d\xfczenler ve paragraf d\xfczeyindeki metinleri işleyebilmenin yanı sıra, g\xf6rsel \xfcretim sırasında tutarlı bir mizanpaj ve bağlamsal uyum sağlayabilir. \xdcst\xfcn metin işleme yeteneklerinin \xf6tesinde, model ger\xe7ek\xe7i fotoğraflardan anime estetiğine kadar geniş bir sanatsal tarz yelpazesini destekler ve \xe7eşitli yaratıcı ihtiya\xe7lara esnek şekilde uyum sağlar. Ayrıca, stil transferi, nesne ekleme/\xe7ıkarma, detay iyileştirme, metin d\xfczenleme ve insan pozu kontrol\xfc gibi gelişmiş işlemleri destekleyen g\xfc\xe7l\xfc bir g\xf6rsel d\xfczenleme ve anlama yeteneğine sahiptir. Qwen-Image, dil, d\xfczen ve g\xf6rseli bir araya getiren kapsamlı bir akıllı g\xf6rsel yaratım ve işleme temel modeli olmayı hedeflemektedir."},"Qwen/Qwen-Image-Edit-2509":{"description":"Qwen-Image-Edit-2509, Alibaba Tongyi Qianwen ekibi tarafından geliştirilen Qwen-Image modelinin en son g\xf6rsel d\xfczenleme versiyonudur. 20 milyar parametreli Qwen-Image modeli temel alınarak derinlemesine eğitilmiş olan bu model, \xf6zg\xfcn metin işleme yeteneklerini g\xf6rsel d\xfczenleme alanına başarıyla taşımış ve g\xf6rsellerdeki metinlerin hassas şekilde d\xfczenlenmesini m\xfcmk\xfcn kılmıştır. Qwen-Image-Edit, yenilik\xe7i bir mimari kullanarak giriş g\xf6rselini hem g\xf6rsel anlamsal kontrol i\xe7in Qwen2.5-VL’ye hem de g\xf6rsel g\xf6r\xfcn\xfcm kontrol\xfc i\xe7in VAE Encoder’a iletir; b\xf6ylece hem anlamsal hem de g\xf6rsel d\xfczenleme yeteneklerini bir arada sunar. Bu, yalnızca \xf6ğe ekleme, silme veya değiştirme gibi yerel g\xf6r\xfcn\xfcm d\xfczenlemelerini değil, aynı zamanda IP yaratımı ve stil transferi gibi anlamsal tutarlılık gerektiren ileri d\xfczey g\xf6rsel anlamsal d\xfczenlemeleri de desteklediği anlamına gelir. Model, bir\xe7ok a\xe7ık kaynaklı kıyaslama testinde en \xfcst d\xfczey (SOTA) performans sergileyerek g\xfc\xe7l\xfc bir g\xf6rsel d\xfczenleme temel modeli haline gelmiştir."},"Qwen/Qwen2-72B-Instruct":{"description":"Qwen2, \xe7ok \xe7eşitli talimat t\xfcrlerini destekleyen gelişmiş bir genel dil modelidir."},"Qwen/Qwen2-7B-Instruct":{"description":"Qwen2-72B-Instruct, Qwen2 serisindeki talimat ince ayar b\xfcy\xfck dil modelidir ve parametre \xf6l\xe7eği 72B\'dir. Bu model, Transformer mimarisi temelinde, SwiGLU aktivasyon fonksiyonu, dikkat QKV \xf6nyargısı ve grup sorgu dikkati gibi teknikler kullanmaktadır. B\xfcy\xfck \xf6l\xe7ekli girişleri işleyebilme yeteneğine sahiptir. Bu model, dil anlama, \xfcretim, \xe7ok dilli yetenek, kodlama, matematik ve akıl y\xfcr\xfctme gibi bir\xe7ok standart testte m\xfckemmel performans sergilemekte ve \xe7oğu a\xe7ık kaynak modelini geride bırakmakta, bazı g\xf6revlerde \xf6zel modellere karşı rekabet edebilir."},"Qwen/Qwen2-VL-72B-Instruct":{"description":"Qwen2-VL, Qwen-VL modelinin en son yineleme versiyonudur ve g\xf6rsel anlama kıyaslama testlerinde en gelişmiş performansı sergilemiştir."},"Qwen/Qwen2.5-14B-Instruct":{"description":"Qwen2.5, talimat tabanlı g\xf6revlerin işlenmesini optimize etmek i\xe7in tasarlanmış yeni bir b\xfcy\xfck dil modeli serisidir."},"Qwen/Qwen2.5-32B-Instruct":{"description":"Qwen2.5, talimat tabanlı g\xf6revlerin işlenmesini optimize etmek i\xe7in tasarlanmış yeni bir b\xfcy\xfck dil modeli serisidir."},"Qwen/Qwen2.5-72B-Instruct":{"description":"Alibaba Cloud Tongyi Qianwen ekibi tarafından geliştirilen b\xfcy\xfck bir dil modeli"},"Qwen/Qwen2.5-72B-Instruct-128K":{"description":"Qwen2.5, daha g\xfc\xe7l\xfc anlama ve \xfcretim yeteneği ile yeni bir b\xfcy\xfck dil modeli serisidir."},"Qwen/Qwen2.5-72B-Instruct-Turbo":{"description":"Qwen2.5, komut tabanlı g\xf6revlerin işlenmesini optimize etmek i\xe7in tasarlanmış yeni bir b\xfcy\xfck dil modeli serisidir."},"Qwen/Qwen2.5-7B-Instruct":{"description":"Qwen2.5, talimat tabanlı g\xf6revlerin işlenmesini optimize etmek i\xe7in tasarlanmış yeni bir b\xfcy\xfck dil modeli serisidir."},"Qwen/Qwen2.5-7B-Instruct-Turbo":{"description":"Qwen2.5, komut tabanlı g\xf6revlerin işlenmesini optimize etmek i\xe7in tasarlanmış yeni bir b\xfcy\xfck dil modeli serisidir."},"Qwen/Qwen2.5-Coder-32B-Instruct":{"description":"Qwen2.5-Coder, kod yazımına odaklanmaktadır."},"Qwen/Qwen2.5-Coder-7B-Instruct":{"description":"Qwen2.5-Coder-7B-Instruct, Alibaba Cloud tarafından yayınlanan kod odaklı b\xfcy\xfck dil modeli serisinin en son versiyonudur. Bu model, Qwen2.5 temelinde, 5.5 trilyon token ile eğitilerek kod \xfcretimi, akıl y\xfcr\xfctme ve d\xfczeltme yeteneklerini \xf6nemli \xf6l\xe7\xfcde artırmıştır. Hem kodlama yeteneklerini geliştirmiş hem de matematik ve genel yetenek avantajlarını korumuştur. Model, kod akıllı ajanları gibi pratik uygulamalar i\xe7in daha kapsamlı bir temel sunmaktadır."},"Qwen/Qwen2.5-VL-32B-Instruct":{"description":"Qwen2.5-VL-32B-Instruct, Tongyi Qianwen ekibi tarafından geliştirilen \xe7ok modelli bir b\xfcy\xfck modeldir ve Qwen2.5-VL serisinin bir par\xe7asıdır. Bu model yalnızca yaygın nesneleri tanımakla kalmaz, aynı zamanda g\xf6r\xfcnt\xfclerdeki metinleri, tabloları, simgeleri, grafikleri ve d\xfczenleri analiz edebilir. G\xf6rsel bir akıllı ajan olarak \xe7alışabilir, ara\xe7ları dinamik olarak y\xf6netebilir ve bilgisayar ile telefon kullanma yeteneğine sahiptir. Ayrıca, bu model g\xf6r\xfcnt\xfclerdeki nesneleri hassas bir şekilde konumlandırabilir ve fatura, tablo gibi belgeler i\xe7in yapılandırılmış \xe7ıktılar \xfcretebilir. \xd6nceki model Qwen2-VL\'ye kıyasla, bu s\xfcr\xfcm matematik ve problem \xe7\xf6zme yeteneklerinde pekiştirmeli \xf6ğrenme ile daha da geliştirilmiştir ve yanıt tarzı insan tercihlerine daha uygun hale getirilmiştir."},"Qwen/Qwen2.5-VL-72B-Instruct":{"description":"Qwen2.5-VL, Qwen2.5 serisindeki g\xf6rsel-dil modelidir. Bu model bir\xe7ok alanda \xf6nemli gelişmeler sunmaktadır: Gelişmiş g\xf6rsel anlama yeteneğiyle yaygın nesneleri tanıyabilir, metinleri, grafikleri ve d\xfczenleri analiz edebilir; g\xf6rsel bir ajan olarak akıl y\xfcr\xfctebilir ve ara\xe7 kullanımını dinamik olarak y\xf6nlendirebilir; 1 saati aşan uzun videoları anlayabilir ve \xf6nemli olayları yakalayabilir; g\xf6r\xfcnt\xfclerdeki nesneleri sınırlayıcı kutular veya noktalar oluşturarak hassas bir şekilde konumlandırabilir; yapılandırılmış \xe7ıktılar \xfcretebilir, \xf6zellikle fatura, tablo gibi taranmış veriler i\xe7in uygundur."},"Qwen/Qwen3-14B":{"description":"Qwen3, akıl y\xfcr\xfctme, genel, Ajan ve \xe7ok dilli gibi bir\xe7ok temel yetenekte \xf6nemli \xf6l\xe7\xfcde geliştirilmiş yeni nesil Tongyi Qianwen b\xfcy\xfck modelidir ve d\xfcş\xfcnme modu ge\xe7işini destekler."},"Qwen/Qwen3-235B-A22B":{"description":"Qwen3, akıl y\xfcr\xfctme, genel, Ajan ve \xe7ok dilli gibi bir\xe7ok temel yetenekte \xf6nemli \xf6l\xe7\xfcde geliştirilmiş yeni nesil Tongyi Qianwen b\xfcy\xfck modelidir ve d\xfcş\xfcnme modu ge\xe7işini destekler."},"Qwen/Qwen3-235B-A22B-Instruct-2507":{"description":"Qwen3 serisinden, Alibaba Cloud Tongyi Qianwen ekibi tarafından geliştirilen amiral gemisi hibrit uzman (MoE) b\xfcy\xfck dil modelidir. Toplam 235 milyar parametreye, her \xe7ıkarımda 22 milyar aktif parametreye sahiptir. Qwen3-235B-A22B\'nin d\xfcş\xfcnme modu olmayan g\xfcncellenmiş versiyonudur; talimat uyumu, mantıksal \xe7ıkarım, metin anlama, matematik, bilim, programlama ve ara\xe7 kullanımı gibi genel yeteneklerde \xf6nemli iyileştirmeler sunar. Ayrıca \xe7ok dilli uzun kuyruk bilgisi kapsamını artırır ve kullanıcıların \xf6znel ve a\xe7ık u\xe7lu g\xf6rev tercihlerine daha iyi uyum sağlayarak daha faydalı ve kaliteli metinler \xfcretir."},"Qwen/Qwen3-235B-A22B-Thinking-2507":{"description":"Alibaba Tongyi Qianwen ekibi tarafından geliştirilen Qwen3 serisinden b\xfcy\xfck dil modelidir ve karmaşık y\xfcksek zorlukta \xe7ıkarım g\xf6revlerine odaklanır. MoE mimarisi temel alınmış olup toplam 235 milyar parametreye sahiptir; her token işlenirken yaklaşık 22 milyar parametre aktif olur, b\xf6ylece g\xfc\xe7l\xfc performansla birlikte hesaplama verimliliği sağlanır. \xd6zel bir \\"d\xfcş\xfcnme\\" modeli olarak, mantıksal \xe7ıkarım, matematik, bilim, programlama ve akademik kıyaslama testlerinde insan uzmanlığı gerektiren g\xf6revlerde \xfcst\xfcn performans g\xf6sterir ve a\xe7ık kaynak d\xfcş\xfcnme modelleri arasında en \xfcst seviyededir. Ayrıca talimat uyumu, ara\xe7 kullanımı ve metin \xfcretimi gibi genel yetenekleri geliştirir ve 256K uzun bağlam anlama desteği ile derin \xe7ıkarım ve uzun belge işleme senaryoları i\xe7in idealdir."},"Qwen/Qwen3-30B-A3B":{"description":"Qwen3, akıl y\xfcr\xfctme, genel, Ajan ve \xe7ok dilli gibi bir\xe7ok temel yetenekte \xf6nemli \xf6l\xe7\xfcde geliştirilmiş yeni nesil Tongyi Qianwen b\xfcy\xfck modelidir ve d\xfcş\xfcnme modu ge\xe7işini destekler."},"Qwen/Qwen3-30B-A3B-Instruct-2507":{"description":"Qwen3-30B-A3B-Instruct-2507, Qwen3-30B-A3B\'nin d\xfcş\xfcnme modu olmayan g\xfcncellenmiş bir versiyonudur. Bu, toplam 30,5 milyar parametre ve 3,3 milyar aktif parametreye sahip bir Hibrit Uzman (MoE) modelidir. Model, talimat takibi, mantıksal akıl y\xfcr\xfctme, metin anlama, matematik, bilim, kodlama ve ara\xe7 kullanımı gibi genel yeteneklerde \xf6nemli geliştirmeler i\xe7ermektedir. Ayrıca, \xe7ok dilli uzun kuyruk bilgi kapsamı a\xe7ısından kayda değer ilerlemeler kaydetmiş ve kullanıcıların \xf6znel ve a\xe7ık u\xe7lu g\xf6revlerdeki tercihlerine daha iyi uyum sağlayarak daha faydalı yanıtlar ve daha y\xfcksek kaliteli metinler \xfcretebilmektedir. Buna ek olarak, modelin uzun metin anlama kapasitesi 256K\'ya kadar artırılmıştır. Bu model yalnızca d\xfcş\xfcnme modu dışındadır ve \xe7ıktılarında `<think></think>` etiketleri oluşturmaz."},"Qwen/Qwen3-30B-A3B-Thinking-2507":{"description":"Qwen3-30B-A3B-Thinking-2507, Alibaba\'nın Tongyi Qianwen ekibi tarafından yayımlanan Qwen3 serisinin en yeni d\xfcş\xfcnme modelidir. Toplam 30,5 milyar parametreye ve 3,3 milyar aktif parametreye sahip bir melez uzman (MoE) modeli olarak karmaşık g\xf6revleri ele alma yeteneğini artırmaya odaklanır. Bu model mantıksal akıl y\xfcr\xfctme, matematik, bilim, programlama ve insan uzmanlığı gerektiren akademik kıyaslama testlerinde belirgin performans artışları g\xf6stermektedir. Aynı zamanda talimatlara uyum, ara\xe7 kullanımı, metin \xfcretimi ve insan tercihlerine hizalanma gibi genel yeteneklerde de \xf6nemli \xf6l\xe7\xfcde geliştirilmiştir. Model yerel olarak 256K uzun bağlam anlama yeteneğini destekler ve 1 milyona kadar token\'a genişletilebilir. Bu s\xfcr\xfcm, ayrıntılı adım adım akıl y\xfcr\xfctmeyle y\xfcksek derecede karmaşık g\xf6revleri \xe7\xf6zmeyi ama\xe7layan \\"d\xfcş\xfcnme modu\\" i\xe7in \xf6zel olarak tasarlanmıştır; ajan yetenekleri de \xf6ne \xe7ıkmaktadır."},"Qwen/Qwen3-32B":{"description":"Qwen3, akıl y\xfcr\xfctme, genel, Ajan ve \xe7ok dilli gibi bir\xe7ok temel yetenekte \xf6nemli \xf6l\xe7\xfcde geliştirilmiş yeni nesil Tongyi Qianwen b\xfcy\xfck modelidir ve d\xfcş\xfcnme modu ge\xe7işini destekler."},"Qwen/Qwen3-8B":{"description":"Qwen3, akıl y\xfcr\xfctme, genel, Ajan ve \xe7ok dilli gibi bir\xe7ok temel yetenekte \xf6nemli \xf6l\xe7\xfcde geliştirilmiş yeni nesil Tongyi Qianwen b\xfcy\xfck modelidir ve d\xfcş\xfcnme modu ge\xe7işini destekler."},"Qwen/Qwen3-Coder-30B-A3B-Instruct":{"description":"Qwen3-Coder-30B-A3B-Instruct, Alibaba\'nın Tongyi Qianwen ekibi tarafından geliştirilen Qwen3 serisindeki bir kod modelidir. Optimize edilmiş ve sadeleştirilmiş bir model olarak, y\xfcksek performans ve verimliliği korurken \xf6zellikle kod işleme yeteneklerini artırmaya odaklanır. Bu model, ajan programlama (Agentic Coding), otomatik tarayıcı işlemleri ve ara\xe7 \xe7ağırma gibi karmaşık g\xf6revlerde a\xe7ık kaynak modeller i\xe7inde belirgin bir performans avantajı g\xf6sterir. Yerel olarak 256K token uzunluğunda bağlamı destekler ve 1M token\'a kadar genişletilebilir; bu sayede kod tabanı d\xfczeyinde anlama ve işleme kapasitesi artar. Ayrıca model, Qwen Code ve CLINE gibi platformlara g\xfc\xe7l\xfc ajan kodlama desteği sağlar ve \xf6zel bir fonksiyon \xe7ağırma formatı i\xe7in tasarlanmıştır."},"Qwen/Qwen3-Coder-480B-A35B-Instruct":{"description":"Qwen3-Coder-480B-A35B-Instruct, Alibaba tarafından yayımlanan ve şimdiye kadar en gelişmiş ajan (Agentic) yeteneklerine sahip kod modelidir. Bu model, toplam 480 milyar parametre ve 35 milyar aktifleşen parametreye sahip bir Mixture-of-Experts (MoE, karışık uzman) modelidir ve verimlilik ile performans arasında bir denge sağlar. Model, yerel olarak 256K (yaklaşık 260.000) token bağlam uzunluğunu destekler ve YaRN gibi dışa genelleme y\xf6ntemleriyle 1.000.000 token seviyesine kadar genişletilebilerek b\xfcy\xfck \xf6l\xe7ekli kod tabanları ve karmaşık programlama g\xf6revleriyle başa \xe7ıkabilir. Qwen3-Coder, ajan tabanlı kodlama iş akışları i\xe7in tasarlanmış olup yalnızca kod \xfcretmez; aynı zamanda geliştirme ara\xe7ları ve ortamlarla bağımsız şekilde etkileşime girerek karmaşık programlama problemlerini \xe7\xf6zer. Bir\xe7ok kodlama ve ajan g\xf6revindeki kıyaslama testlerinde bu model, a\xe7ık kaynak modeller arasında en \xfcst d\xfczey performansı g\xf6stermiş ve performansı Claude Sonnet 4 gibi \xf6nde gelen modellerle kıyaslanabilir d\xfczeydedir."},"Qwen/Qwen3-Next-80B-A3B-Instruct":{"description":"Qwen3-Next-80B-A3B-Instruct, Alibaba Tongyi Qianwen ekibi tarafından yayınlanan yeni nesil temel modeldir. Tamamen yeni Qwen3-Next mimarisi \xfczerine kurulmuş olup, en \xfcst d\xfczey eğitim ve \xe7ıkarım verimliliğini hedeflemektedir. Model, yenilik\xe7i hibrit dikkat mekanizması (Gated DeltaNet ve Gated Attention), y\xfcksek seyrekli hibrit uzman (MoE) yapısı ve \xe7eşitli eğitim stabilitesi optimizasyonları kullanmaktadır. 80 milyar toplam parametreye sahip seyrek bir model olarak, \xe7ıkarım sırasında yalnızca yaklaşık 3 milyar parametreyi aktive ederek hesaplama maliyetlerini \xf6nemli \xf6l\xe7\xfcde d\xfcş\xfcr\xfcr ve 32K token’dan uzun bağlam g\xf6revlerinde \xe7ıkarım verimliliği Qwen3-32B modeline kıyasla 10 kat daha fazladır. Bu model, genel g\xf6revler i\xe7in tasarlanmış talimat ince ayarlı bir versiyondur ve D\xfcş\xfcnme (Thinking) modunu desteklemez. Performans a\xe7ısından, Tongyi Qianwen’in amiral gemisi modeli Qwen3-235B ile bazı kıyaslama testlerinde eşdeğer performans sergiler ve \xf6zellikle uzun bağlam g\xf6revlerinde belirgin avantajlar g\xf6sterir."},"Qwen/Qwen3-Next-80B-A3B-Thinking":{"description":"Qwen3-Next-80B-A3B-Thinking, Alibaba Tongyi Qianwen ekibi tarafından karmaşık \xe7ıkarım g\xf6revleri i\xe7in tasarlanmış yeni nesil temel modeldir. Yenilik\xe7i Qwen3-Next mimarisi \xfczerine kurulmuş olup, hibrit dikkat mekanizması (Gated DeltaNet ve Gated Attention) ve y\xfcksek seyrekli hibrit uzman (MoE) yapısını birleştirerek en \xfcst d\xfczey eğitim ve \xe7ıkarım verimliliğini hedefler. 80 milyar toplam parametreye sahip seyrek bir model olarak, \xe7ıkarım sırasında yalnızca yaklaşık 3 milyar parametreyi aktive ederek hesaplama maliyetlerini \xf6nemli \xf6l\xe7\xfcde d\xfcş\xfcr\xfcr ve 32K token’dan uzun bağlam g\xf6revlerinde \xe7ıkarım verimliliği Qwen3-32B modeline kıyasla 10 kat daha fazladır. Bu “Thinking” versiyonu, matematiksel ispatlar, kod sentezi, mantıksal analiz ve planlama gibi zorlu \xe7ok adımlı g\xf6revler i\xe7in optimize edilmiştir ve \xe7ıkarım s\xfcrecini varsayılan olarak yapılandırılmış “d\xfcş\xfcnce zinciri” bi\xe7iminde sunar. Performans a\xe7ısından, yalnızca daha maliyetli modeller olan Qwen3-32B-Thinking’i değil, aynı zamanda Gemini-2.5-Flash-Thinking’i de bir\xe7ok kıyaslama testinde geride bırakır."},"Qwen/Qwen3-Omni-30B-A3B-Captioner":{"description":"Qwen3-Omni-30B-A3B-Captioner, Alibaba Tongyi Qianwen ekibinin Qwen3 serisinden bir g\xf6rsel-dil modeli (VLM)\'dir. Y\xfcksek kaliteli, ayrıntılı ve doğru g\xf6rsel a\xe7ıklamalar \xfcretmek i\xe7in \xf6zel olarak tasarlanmıştır. 30 milyar toplam parametreye sahip karma uzman (MoE) mimarisi \xfczerine kuruludur ve g\xf6rsel i\xe7eriği derinlemesine anlayarak bunu doğal ve akıcı metin a\xe7ıklamalarına d\xf6n\xfcşt\xfcrebilir. G\xf6rsel detay yakalama, sahne anlama, nesne tanıma ve ilişki \xe7ıkarımı gibi alanlarda \xfcst\xfcn performans g\xf6sterir. \xd6zellikle hassas g\xf6rsel anlama ve a\xe7ıklama \xfcretimi gerektiren uygulamalar i\xe7in uygundur."},"Qwen/Qwen3-Omni-30B-A3B-Instruct":{"description":"Qwen3-Omni-30B-A3B-Instruct, Alibaba Tongyi Qianwen ekibinin en yeni Qwen3 serisinin bir \xfcyesidir. 30 milyar toplam parametre ve 3 milyar aktif parametreye sahip karma uzman (MoE) mimarisiyle, g\xfc\xe7l\xfc performansını korurken \xe7ıkarım maliyetini etkin şekilde d\xfcş\xfcr\xfcr. Y\xfcksek kaliteli, \xe7ok kaynaklı ve \xe7ok dilli verilerle eğitilmiştir; g\xfc\xe7l\xfc genel yeteneklere sahiptir ve metin, g\xf6rsel, ses ve video dahil olmak \xfczere t\xfcm modlarda girdi işleyebilir. Modlar arası i\xe7erik anlama ve \xfcretme yeteneğine sahiptir."},"Qwen/Qwen3-Omni-30B-A3B-Thinking":{"description":"Qwen3-Omni-30B-A3B-Thinking, Qwen3-Omni \xe7ok modlu modelinin \xe7ekirdek \\"d\xfcş\xfcnen\\" (Thinker) bileşenidir. Metin, ses, g\xf6rsel ve video dahil olmak \xfczere \xe7ok modlu girdileri işlemek ve karmaşık d\xfcş\xfcnce zinciri \xe7ıkarımı ger\xe7ekleştirmek \xfczere tasarlanmıştır. \xc7ıkarımın beyni olarak, t\xfcm girdileri ortak bir temsili alana d\xf6n\xfcşt\xfcrerek modlar arası derin anlama ve karmaşık \xe7ıkarım yetenekleri sağlar. Karma uzman (MoE) mimarisi \xfczerine kuruludur, 30 milyar toplam parametre ve 3 milyar aktif parametreye sahiptir; g\xfc\xe7l\xfc \xe7ıkarım yeteneğini korurken hesaplama verimliliğini optimize eder."},"Qwen/Qwen3-VL-235B-A22B-Instruct":{"description":"Qwen3-VL-235B-A22B-Instruct, Qwen3-VL serisinin b\xfcy\xfck \xf6l\xe7ekli talimatla ince ayarlanmış modelidir. Karışık uzman (MoE) mimarisi \xfczerine kuruludur ve \xfcst\xfcn \xe7ok modlu anlama ve \xfcretim yeteneklerine sahiptir. Doğal olarak 256K bağlamı destekler ve y\xfcksek eşzamanlı \xfcretim d\xfczeyinde \xe7ok modlu hizmetler i\xe7in uygundur."},"Qwen/Qwen3-VL-235B-A22B-Thinking":{"description":"Qwen3-VL-235B-A22B-Thinking, Qwen3-VL serisinin amiral gemisi d\xfcş\xfcnme s\xfcr\xfcm\xfcd\xfcr. Karmaşık \xe7ok modlu akıl y\xfcr\xfctme, uzun bağlamlı \xe7ıkarım ve yapay zeka etkileşimleri i\xe7in \xf6zel olarak optimize edilmiştir. Derin d\xfcş\xfcnme ve g\xf6rsel akıl y\xfcr\xfctme gerektiren kurumsal d\xfczeydeki senaryolar i\xe7in uygundur."},"Qwen/Qwen3-VL-30B-A3B-Instruct":{"description":"Qwen3-VL-30B-A3B-Instruct, Qwen3-VL serisinin talimatla ince ayarlanmış s\xfcr\xfcm\xfcd\xfcr. G\xfc\xe7l\xfc g\xf6rsel-dil anlama ve \xfcretim yeteneklerine sahiptir, doğal olarak 256K bağlam uzunluğunu destekler ve \xe7ok modlu diyaloglar ile g\xf6rsel koşullu \xfcretim g\xf6revleri i\xe7in uygundur."},"Qwen/Qwen3-VL-30B-A3B-Thinking":{"description":"Qwen3-VL-30B-A3B-Thinking, Qwen3-VL serisinin akıl y\xfcr\xfctme yetenekleri geliştirilmiş (Thinking) s\xfcr\xfcm\xfcd\xfcr. \xc7ok modlu akıl y\xfcr\xfctme, g\xf6rselden koda d\xf6n\xfcş\xfcm ve karmaşık g\xf6rsel anlama g\xf6revlerinde optimize edilmiştir. 256K bağlam desteği sunar ve daha g\xfc\xe7l\xfc zincirleme d\xfcş\xfcnme yeteneğine sahiptir."},"Qwen/Qwen3-VL-32B-Instruct":{"description":"Qwen3-VL-32B-Instruct, Alibaba Tongyi Qianwen ekibi tarafından geliştirilen bir g\xf6rsel-dil modelidir ve bir\xe7ok g\xf6rsel-dil kıyaslamasında SOTA (state-of-the-art) performans elde etmiştir. Milyon piksel seviyesinde y\xfcksek \xe7\xf6z\xfcn\xfcrl\xfckl\xfc g\xf6rsel girdileri destekler ve g\xfc\xe7l\xfc genel g\xf6rsel anlama, \xe7ok dilli OCR, ince ayrıntılı g\xf6rsel konumlandırma ve g\xf6rsel diyalog yeteneklerine sahiptir. Qwen3 serisinin bir g\xf6rsel-dil modeli olarak, karmaşık \xe7ok modlu g\xf6revleri işleyebilir; ara\xe7 \xe7ağırma ve \xf6n ek tamamlama gibi gelişmiş işlevleri destekler."},"Qwen/Qwen3-VL-32B-Thinking":{"description":"Qwen3-VL-32B-Thinking, Alibaba Tongyi Qianwen ekibi tarafından geliştirilen g\xf6rsel-dil modelleri arasında, karmaşık g\xf6rsel \xe7ıkarım g\xf6revleri i\xe7in \xf6zel olarak optimize edilmiş bir versiyondur. Dahili \\"d\xfcş\xfcnme modu\\" sayesinde, soruları yanıtlamadan \xf6nce ayrıntılı ara \xe7ıkarım adımları \xfcretebilir; bu da \xe7ok adımlı mantık, planlama ve karmaşık \xe7ıkarım gerektiren g\xf6revlerde performansını \xf6nemli \xf6l\xe7\xfcde artırır. Milyon piksel seviyesinde y\xfcksek \xe7\xf6z\xfcn\xfcrl\xfckl\xfc g\xf6rsel girdileri destekler; g\xfc\xe7l\xfc genel g\xf6rsel anlama, \xe7ok dilli OCR, ince ayrıntılı g\xf6rsel konumlandırma ve g\xf6rsel diyalog yeteneklerine sahiptir. Ayrıca ara\xe7 \xe7ağırma ve \xf6n ek tamamlama gibi işlevleri destekler."},"Qwen/Qwen3-VL-8B-Instruct":{"description":"Qwen3-VL-8B-Instruct, Qwen3 serisinin bir g\xf6rsel-dil modelidir. Qwen3-8B-Instruct temel alınarak geliştirilmiş ve b\xfcy\xfck miktarda g\xf6rsel-metin verisiyle eğitilmiştir. Genel g\xf6rsel anlama, g\xf6rsel odaklı diyaloglar ve g\xf6rsellerde \xe7ok dilli metin tanıma konularında uzmandır. G\xf6rsel soru-cevap, g\xf6rsel betimleme, \xe7ok modlu komut takibi ve ara\xe7 \xe7ağırma gibi senaryolarda kullanılabilir."},"Qwen/Qwen3-VL-8B-Thinking":{"description":"Qwen3-VL-8B-Thinking, Qwen3 serisinin g\xf6rsel d\xfcş\xfcnme versiyonudur ve karmaşık \xe7ok adımlı akıl y\xfcr\xfctme g\xf6revleri i\xe7in optimize edilmiştir. Varsayılan olarak, yanıt vermeden \xf6nce adım adım d\xfcş\xfcnme zinciri (thinking chain) oluşturarak akıl y\xfcr\xfctme doğruluğunu artırır. Derinlemesine akıl y\xfcr\xfctme gerektiren g\xf6rsel soru-cevap, g\xf6rsel i\xe7erik inceleme ve ayrıntılı analiz sunma gibi senaryolar i\xe7in uygundur."},"Qwen2-72B-Instruct":{"description":"Qwen2, Qwen modelinin en yeni serisidir ve 128k bağlamı destekler. Mevcut en iyi a\xe7ık kaynak modellerle karşılaştırıldığında, Qwen2-72B doğal dil anlama, bilgi, kod, matematik ve \xe7ok dilli yetenekler a\xe7ısından mevcut lider modelleri \xf6nemli \xf6l\xe7\xfcde aşmaktadır."},"Qwen2-7B-Instruct":{"description":"Qwen2, Qwen modelinin en yeni serisidir ve eşit \xf6l\xe7ekli en iyi a\xe7ık kaynak modelleri hatta daha b\xfcy\xfck \xf6l\xe7ekli modelleri aşabilmektedir. Qwen2 7B, bir\xe7ok değerlendirmede belirgin bir avantaj elde etmiş, \xf6zellikle kod ve \xc7ince anlama konusunda."},"Qwen2-VL-72B":{"description":"Qwen2-VL-72B, g\xf6r\xfcnt\xfc ve metin i\xe7in \xe7ok modlu işleme desteği sunan g\xfc\xe7l\xfc bir g\xf6rsel dil modelidir, g\xf6r\xfcnt\xfc i\xe7eriğini hassas bir şekilde tanıyabilir ve ilgili a\xe7ıklamalar veya yanıtlar \xfcretebilir."},"Qwen2.5-14B-Instruct":{"description":"Qwen2.5-14B-Instruct, 14 milyar parametreye sahip b\xfcy\xfck bir dil modelidir. Performansı m\xfckemmel olup, \xc7ince ve \xe7ok dilli senaryoları optimize eder, akıllı soru-cevap, i\xe7erik \xfcretimi gibi uygulamaları destekler."},"Qwen2.5-32B-Instruct":{"description":"Qwen2.5-32B-Instruct, 32 milyar parametreye sahip b\xfcy\xfck bir dil modelidir. Performans dengeli olup, \xc7ince ve \xe7ok dilli senaryoları optimize eder, akıllı soru-cevap, i\xe7erik \xfcretimi gibi uygulamaları destekler."},"Qwen2.5-72B-Instruct":{"description":"Qwen2.5-72B-Instruct, 16k bağlamı destekler ve 8K\'dan uzun metinler \xfcretebilir. Fonksiyon \xe7ağrısı ile dış sistemlerle sorunsuz etkileşim sağlar, esneklik ve \xf6l\xe7eklenebilirliği b\xfcy\xfck \xf6l\xe7\xfcde artırır. Modelin bilgisi belirgin şekilde artmış ve kodlama ile matematik yetenekleri b\xfcy\xfck \xf6l\xe7\xfcde geliştirilmiştir, 29\'dan fazla dil desteği sunmaktadır."},"Qwen2.5-7B-Instruct":{"description":"Qwen2.5-7B-Instruct, 7 milyar parametreye sahip b\xfcy\xfck bir dil modelidir. Fonksiyon \xe7ağrısı ile dış sistemlerle sorunsuz etkileşim destekler, esneklik ve \xf6l\xe7eklenebilirliği b\xfcy\xfck \xf6l\xe7\xfcde artırır. \xc7ince ve \xe7ok dilli senaryoları optimize eder, akıllı soru-cevap, i\xe7erik \xfcretimi gibi uygulamaları destekler."},"Qwen2.5-Coder-14B-Instruct":{"description":"Qwen2.5-Coder-14B-Instruct, b\xfcy\xfck \xf6l\xe7ekli \xf6nceden eğitilmiş bir programlama talimat modelidir, g\xfc\xe7l\xfc kod anlama ve \xfcretme yeteneğine sahiptir, \xe7eşitli programlama g\xf6revlerini verimli bir şekilde işleyebilir, \xf6zellikle akıllı kod yazma, otomatik betik oluşturma ve programlama sorunlarına yanıt verme i\xe7in uygundur."},"Qwen2.5-Coder-32B-Instruct":{"description":"Qwen2.5-Coder-32B-Instruct, kod \xfcretimi, kod anlama ve verimli geliştirme senaryoları i\xe7in tasarlanmış b\xfcy\xfck bir dil modelidir. Sekt\xf6rdeki en ileri 32B parametre \xf6l\xe7eğini kullanarak \xe7eşitli programlama ihtiya\xe7larını karşılayabilir."},"Qwen3-235B":{"description":"Qwen3-235B-A22B, MoE (Hibrit Uzman Modeli) modelidir ve \\"Hibrit Akıl Y\xfcr\xfctme Modu\\"nu tanıtmaktadır. Kullanıcıların \\"d\xfcş\xfcnme modu\\" ile \\"d\xfcş\xfcnme modu dışı\\" arasında kesintisiz ge\xe7iş yapmasını destekler, 119 dil ve leh\xe7ede anlama ve akıl y\xfcr\xfctme yeteneğine sahiptir ve g\xfc\xe7l\xfc ara\xe7 \xe7ağırma kapasitesine sahiptir. Kapsamlı yetenekler, kodlama ve matematik, \xe7ok dilli yetenekler, bilgi ve akıl y\xfcr\xfctme gibi \xe7eşitli kıyaslama testlerinde, DeepSeek R1, OpenAI o1, o3-mini, Grok 3 ve Google Gemini 2.5 Pro gibi piyasadaki \xf6nde gelen b\xfcy\xfck modellerle rekabet edebilmektedir."},"Qwen3-235B-A22B-Instruct-2507-FP8":{"description":"Qwen3 235B A22B Instruct 2507: Gelişmiş \xe7ıkarım ve diyalog talimatları i\xe7in optimize edilmiş model, b\xfcy\xfck \xf6l\xe7ekli parametrelerde \xe7ıkarım verimliliğini koruyan karma uzman mimarisi."},"Qwen3-32B":{"description":"Qwen3-32B, Yoğun Model (Dense Model) olup \\"Hibrit Akıl Y\xfcr\xfctme Modu\\"nu tanıtmaktadır. Kullanıcıların \\"d\xfcş\xfcnme modu\\" ile \\"d\xfcş\xfcnme modu dışı\\" arasında kesintisiz ge\xe7iş yapmasını destekler. Model mimarisi iyileştirmeleri, artırılmış eğitim verisi ve daha etkili eğitim y\xf6ntemleri sayesinde genel performansı Qwen2.5-72B ile karşılaştırılabilir d\xfczeydedir."},"SenseChat":{"description":"Temel s\xfcr\xfcm model (V4), 4K bağlam uzunluğu ile genel yetenekleri g\xfc\xe7l\xfcd\xfcr."},"SenseChat-128K":{"description":"Temel s\xfcr\xfcm model (V4), 128K bağlam uzunluğu ile uzun metin anlama ve \xfcretme g\xf6revlerinde m\xfckemmel performans sergilemektedir."},"SenseChat-32K":{"description":"Temel s\xfcr\xfcm model (V4), 32K bağlam uzunluğu ile \xe7eşitli senaryolarda esnek bir şekilde uygulanabilir."},"SenseChat-5":{"description":"En son s\xfcr\xfcm model (V5.5), 128K bağlam uzunluğu, matematiksel akıl y\xfcr\xfctme, İngilizce diyalog, talimat takibi ve uzun metin anlama gibi alanlarda \xf6nemli gelişmeler g\xf6stermektedir ve GPT-4o ile karşılaştırılabilir."},"SenseChat-5-1202":{"description":"V5.5 tabanlı en son s\xfcr\xfcm olup, \xf6nceki s\xfcr\xfcme kıyasla \xc7ince ve İngilizce temel yetenekler, sohbet, fen bilimleri bilgisi, sosyal bilimler bilgisi, yazım, matematiksel mantık ve kelime sayısı kontrol\xfc gibi bir\xe7ok alanda belirgin gelişmeler sunar."},"SenseChat-5-Cantonese":{"description":"32K bağlam uzunluğu ile, Kantonca diyalog anlama konusunda GPT-4\'\xfc aşmakta, bilgi, akıl y\xfcr\xfctme, matematik ve kod yazma gibi bir\xe7ok alanda GPT-4 Turbo ile rekabet edebilmektedir."},"SenseChat-5-beta":{"description":"Bazı performansları SenseCat-5-1202\'den daha iyidir."},"SenseChat-Character":{"description":"Standart s\xfcr\xfcm model, 8K bağlam uzunluğu ile y\xfcksek yanıt hızı sunmaktadır."},"SenseChat-Character-Pro":{"description":"Gelişmiş s\xfcr\xfcm model, 32K bağlam uzunluğu ile yetenekleri tamamen geliştirilmiş, \xc7ince/İngilizce diyalogları desteklemektedir."},"SenseChat-Turbo":{"description":"Hızlı soru-cevap ve model ince ayar senaryoları i\xe7in uygundur."},"SenseChat-Turbo-1202":{"description":"En son hafif versiyon modelidir, tam modelin %90\'ından fazla yetenek sunar ve \xe7ıkarım maliyetini \xf6nemli \xf6l\xe7\xfcde azaltır."},"SenseChat-Vision":{"description":"En son versiyon modeli (V5.5), \xe7oklu g\xf6rsel girişi destekler, modelin temel yetenek optimizasyonunu tamamen ger\xe7ekleştirir; nesne \xf6zellik tanıma, mekansal ilişkiler, hareket olayları tanıma, sahne anlama, duygu tanıma, mantıksal bilgi \xe7ıkarımı ve metin anlama \xfcretimi gibi alanlarda \xf6nemli gelişmeler sağlamıştır."},"SenseNova-V6-5-Pro":{"description":"\xc7ok modlu, dil ve akıl y\xfcr\xfctme verilerinin kapsamlı g\xfcncellenmesi ve eğitim stratejilerinin optimize edilmesiyle, yeni model \xe7ok modlu akıl y\xfcr\xfctme ve genel talimat takibi yeteneklerinde \xf6nemli gelişmeler sağlamıştır. 128k\'ya kadar bağlam penceresini destekler ve OCR ile k\xfclt\xfcrel turizm IP tanıma gibi \xf6zel g\xf6revlerde \xfcst\xfcn performans g\xf6sterir."},"SenseNova-V6-5-Turbo":{"description":"\xc7ok modlu, dil ve akıl y\xfcr\xfctme verilerinin kapsamlı g\xfcncellenmesi ve eğitim stratejilerinin optimize edilmesiyle, yeni model \xe7ok modlu akıl y\xfcr\xfctme ve genel talimat takibi yeteneklerinde \xf6nemli gelişmeler sağlamıştır. 128k\'ya kadar bağlam penceresini destekler ve OCR ile k\xfclt\xfcrel turizm IP tanıma gibi \xf6zel g\xf6revlerde \xfcst\xfcn performans g\xf6sterir."},"SenseNova-V6-Pro":{"description":"G\xf6r\xfcnt\xfc, metin ve video yeteneklerinin yerel birliğini sağlar, geleneksel \xe7ok modlu ayrım sınırlamalarını aşar, OpenCompass ve SuperCLUE değerlendirmelerinde \xe7ift şampiyonluk kazanmıştır."},"SenseNova-V6-Reasoner":{"description":"G\xf6rsel ve dil derin akıl y\xfcr\xfctmesini bir araya getirerek, yavaş d\xfcş\xfcnme ve derin akıl y\xfcr\xfctmeyi ger\xe7ekleştirir, tam bir d\xfcş\xfcnce zinciri s\xfcrecini sunar."},"SenseNova-V6-Turbo":{"description":"G\xf6r\xfcnt\xfc, metin ve video yeteneklerinin yerel birliğini sağlar, geleneksel \xe7ok modlu ayrım sınırlamalarını aşar, \xe7oklu temel yetenekler, dil temel yetenekleri gibi ana boyutlarda kapsamlı bir şekilde \xf6nde gelir, hem edebi hem de mantıksal olarak dengelidir ve bir\xe7ok değerlendirmede ulusal ve uluslararası birinci lig seviyesinde yer almıştır."},"Skylark2-lite-8k":{"description":"Skylark\'in (Bulut Şarkıcısı) ikinci nesil modeli, Skylark2-lite modeli y\xfcksek yanıt hızı ile donatılmıştır; ger\xe7ek zamanlı talep gereksinimleri y\xfcksek, maliyet duyarlı ve model hassasiyetine daha az ihtiya\xe7 duyulan senaryolar i\xe7in uygundur; bağlam pencere uzunluğu 8k\'dır."},"Skylark2-pro-32k":{"description":"Skylark\'in (Bulut Şarkıcısı) ikinci nesil modeli, Skylark2-pro s\xfcr\xfcm\xfcyle y\xfcksek model hassasiyetine sahiptir; profesyonel alan metin \xfcretimi, roman yazımı, y\xfcksek kaliteli \xe7eviri gibi daha karmaşık metin \xfcretim sahneleri i\xe7in uygundur ve bağlam pencere uzunluğu 32k\'dır."},"Skylark2-pro-4k":{"description":"Skylark\'in (Bulut Şarkıcısı) ikinci nesil modeli, Skylark2-pro modeli y\xfcksek model hassasiyetine sahiptir; profesyonel alan metin \xfcretimi, roman yazımı, y\xfcksek kaliteli \xe7eviri gibi daha karmaşık metin \xfcretim sahneleri i\xe7in uygundur ve bağlam pencere uzunluğu 4k\'dır."},"Skylark2-pro-character-4k":{"description":"Skylark\'in (Bulut Şarkıcısı) ikinci nesil modeli, Skylark2-pro-character modeli, m\xfckemmel rol yapma ve sohbet yeteneklerine sahiptir; kullanıcıdan gelen istem taleplerine g\xf6re farklı roller \xfcstlenme kabiliyeti ile sohbet edebilir. Rol stili belirgindir ve diyalog i\xe7eriği doğal ve akıcıdır. Chatbot, sanal asistan ve \xe7evrimi\xe7i m\xfcşteri hizmetleri gibi senaryolar i\xe7in uygundur ve y\xfcksek yanıt hızı vardır."},"Skylark2-pro-turbo-8k":{"description":"Skylark\'in (Bulut Şarkıcısı) ikinci nesil modeli, Skylark2-pro-turbo-8k ile daha hızlı \xe7ıkarım ger\xe7ekleştirir, maliyeti d\xfcş\xfckt\xfcr ve bağlam pencere uzunluğu 8k\'dır."},"THUDM/GLM-4-32B-0414":{"description":"GLM-4-32B-0414, GLM serisinin yeni nesil a\xe7ık kaynak modelidir ve 32 milyar parametreye sahiptir. Bu model, OpenAI\'nin GPT serisi ve DeepSeek\'in V3/R1 serisi ile karşılaştırılabilir performans sunar."},"THUDM/GLM-4-9B-0414":{"description":"GLM-4-9B-0414, GLM serisinin k\xfc\xe7\xfck modelidir ve 9 milyar parametreye sahiptir. Bu model, GLM-4-32B serisinin teknik \xf6zelliklerini devralır, ancak daha hafif bir dağıtım se\xe7eneği sunar. Boyutu daha k\xfc\xe7\xfck olmasına rağmen, GLM-4-9B-0414, kod oluşturma, web tasarımı, SVG grafik oluşturma ve arama tabanlı yazım gibi g\xf6revlerde m\xfckemmel yetenekler sergiler."},"THUDM/GLM-4.1V-9B-Thinking":{"description":"GLM-4.1V-9B-Thinking, Zhipu AI ve Tsinghua \xdcniversitesi KEG Laboratuvarı tarafından ortaklaşa yayınlanan a\xe7ık kaynaklı bir g\xf6rsel dil modeli (VLM) olup, karmaşık \xe7ok modlu bilişsel g\xf6revleri işlemek i\xe7in tasarlanmıştır. Bu model, GLM-4-9B-0414 temel modeli \xfczerine kurulmuş olup, \\"D\xfcş\xfcnce Zinciri\\" (Chain-of-Thought) akıl y\xfcr\xfctme mekanizmasını ve pekiştirmeli \xf6ğrenme stratejisini benimseyerek, modlar arası akıl y\xfcr\xfctme yeteneği ve kararlılığını \xf6nemli \xf6l\xe7\xfcde artırmıştır."},"THUDM/GLM-Z1-32B-0414":{"description":"GLM-Z1-32B-0414, derin d\xfcş\xfcnme yeteneğine sahip bir \xe7ıkarım modelidir. Bu model, GLM-4-32B-0414 temel alınarak soğuk başlatma ve genişletilmiş pekiştirme \xf6ğrenimi ile geliştirilmiştir ve matematik, kod ve mantık g\xf6revlerinde daha fazla eğitim almıştır. Temel model ile karşılaştırıldığında, GLM-Z1-32B-0414, matematik yeteneklerini ve karmaşık g\xf6revleri \xe7\xf6zme yeteneğini \xf6nemli \xf6l\xe7\xfcde artırmıştır."},"THUDM/GLM-Z1-9B-0414":{"description":"GLM-Z1-9B-0414, GLM serisinin k\xfc\xe7\xfck modelidir, yalnızca 9 milyar parametreye sahiptir, ancak a\xe7ık kaynak geleneğini s\xfcrd\xfcr\xfcrken etkileyici yetenekler sergiler. Boyutu daha k\xfc\xe7\xfck olmasına rağmen, bu model matematik \xe7ıkarımı ve genel g\xf6revlerde m\xfckemmel performans g\xf6sterir, genel performansı eşit boyuttaki a\xe7ık kaynak modeller arasında lider konumdadır."},"THUDM/GLM-Z1-Rumination-32B-0414":{"description":"GLM-Z1-Rumination-32B-0414, derin d\xfcş\xfcnme yeteneğine sahip bir derin \xe7ıkarım modelidir (OpenAI\'nin Derin Araştırması ile karşılaştırılabilir). Tipik derin d\xfcş\xfcnme modellerinin aksine, d\xfcş\xfcnme modeli daha uzun s\xfcreli derin d\xfcş\xfcnme ile daha a\xe7ık ve karmaşık sorunları \xe7\xf6zmektedir."},"THUDM/glm-4-9b-chat":{"description":"GLM-4 9B a\xe7ık kaynak versiyonu, diyalog uygulamaları i\xe7in optimize edilmiş bir diyalog deneyimi sunar."},"Tongyi-Zhiwen/QwenLong-L1-32B":{"description":"QwenLong-L1-32B, uzun bağlamlı b\xfcy\xfck \xf6l\xe7ekli akıl y\xfcr\xfctme modeli (LRM) olup, pekiştirmeli \xf6ğrenme ile eğitilen ilk modeldir ve uzun metin akıl y\xfcr\xfctme g\xf6revlerine optimize edilmiştir. Model, kademeli bağlam genişletme pekiştirmeli \xf6ğrenme \xe7er\xe7evesiyle kısa bağlamdan uzun bağlama stabil ge\xe7iş sağlar. Yedi uzun bağlamlı belge soru-cevap kıyaslama testinde, QwenLong-L1-32B OpenAI-o3-mini ve Qwen3-235B-A22B gibi amiral gemisi modelleri geride bırakmış ve Claude-3.7-Sonnet-Thinking ile karşılaştırılabilir performans g\xf6stermiştir. Model \xf6zellikle matematiksel akıl y\xfcr\xfctme, mantıksal akıl y\xfcr\xfctme ve \xe7ok adımlı akıl y\xfcr\xfctme gibi karmaşık g\xf6revlerde uzmandır."},"Yi-34B-Chat":{"description":"Yi-1.5-34B, orijinal model serisinin m\xfckemmel genel dil yeteneklerini korurken, 500 milyar y\xfcksek kaliteli token ile artımlı eğitim sayesinde matematiksel mantık ve kodlama yeteneklerini b\xfcy\xfck \xf6l\xe7\xfcde artırmıştır."},"abab5.5-chat":{"description":"\xdcretkenlik senaryoları i\xe7in tasarlanmış, karmaşık g\xf6rev işleme ve verimli metin \xfcretimini destekler, profesyonel alan uygulamaları i\xe7in uygundur."},"abab5.5s-chat":{"description":"\xc7in karakter diyalog senaryoları i\xe7in tasarlanmış, y\xfcksek kaliteli \xc7in diyalog \xfcretim yeteneği sunar ve \xe7eşitli uygulama senaryoları i\xe7in uygundur."},"abab6.5g-chat":{"description":"\xc7ok dilli karakter diyalogları i\xe7in tasarlanmış, İngilizce ve diğer bir\xe7ok dilde y\xfcksek kaliteli diyalog \xfcretimini destekler."},"abab6.5s-chat":{"description":"Metin \xfcretimi, diyalog sistemleri gibi geniş doğal dil işleme g\xf6revleri i\xe7in uygundur."},"abab6.5t-chat":{"description":"\xc7in karakter diyalog senaryoları i\xe7in optimize edilmiş, akıcı ve \xc7in ifade alışkanlıklarına uygun diyalog \xfcretim yeteneği sunar."},"accounts/fireworks/models/deepseek-r1":{"description":"DeepSeek-R1, g\xfc\xe7lendirilmiş \xf6ğrenme ve soğuk başlangı\xe7 verileri ile optimize edilmiş, m\xfckemmel akıl y\xfcr\xfctme, matematik ve programlama performansına sahip en son teknoloji b\xfcy\xfck bir dil modelidir."},"accounts/fireworks/models/deepseek-v3":{"description":"Deepseek tarafından sunulan g\xfc\xe7l\xfc Mixture-of-Experts (MoE) dil modeli, toplamda 671B parametreye sahiptir ve her bir etiket i\xe7in 37B parametre etkinleştirilmektedir."},"accounts/fireworks/models/llama-v3-70b-instruct":{"description":"Llama 3 70B talimat modeli, \xe7ok dilli diyalog ve doğal dil anlama i\xe7in optimize edilmiştir, \xe7oğu rakip modelden daha iyi performans g\xf6sterir."},"accounts/fireworks/models/llama-v3-8b-instruct":{"description":"Llama 3 8B talimat modeli, diyalog ve \xe7ok dilli g\xf6revler i\xe7in optimize edilmiştir, m\xfckemmel ve etkili performans sunar."},"accounts/fireworks/models/llama-v3-8b-instruct-hf":{"description":"Llama 3 8B talimat modeli (HF versiyonu), resmi uygulama sonu\xe7larıyla uyumlu olup y\xfcksek tutarlılık ve platformlar arası uyumluluk sunar."},"accounts/fireworks/models/llama-v3p1-405b-instruct":{"description":"Llama 3.1 405B talimat modeli, devasa parametreler ile karmaşık g\xf6revler ve y\xfcksek y\xfck senaryolarında talimat takibi i\xe7in uygundur."},"accounts/fireworks/models/llama-v3p1-70b-instruct":{"description":"Llama 3.1 70B talimat modeli, m\xfckemmel doğal dil anlama ve \xfcretim yetenekleri sunar, diyalog ve analiz g\xf6revleri i\xe7in idealdir."},"accounts/fireworks/models/llama-v3p1-8b-instruct":{"description":"Llama 3.1 8B talimat modeli, \xe7ok dilli diyaloglar i\xe7in optimize edilmiştir ve yaygın end\xfcstri standartlarını aşmaktadır."},"accounts/fireworks/models/llama-v3p2-11b-vision-instruct":{"description":"Meta\'nın 11B parametreli komut ayarlı g\xf6r\xfcnt\xfc akıl y\xfcr\xfctme modelidir. Bu model, g\xf6rsel tanıma, g\xf6r\xfcnt\xfc akıl y\xfcr\xfctme, g\xf6r\xfcnt\xfc betimleme ve g\xf6r\xfcnt\xfc hakkında genel sorulara yanıt verme \xfczerine optimize edilmiştir. Bu model, grafikler ve resimler gibi g\xf6rsel verileri anlayabilir ve g\xf6r\xfcnt\xfc detaylarını metin olarak betimleyerek g\xf6rsel ile dil arasındaki boşluğu kapatır."},"accounts/fireworks/models/llama-v3p2-3b-instruct":{"description":"Llama 3.2 3B komut modeli, Meta tarafından sunulan hafif \xe7ok dilli bir modeldir. Bu model, verimliliği artırmak amacıyla daha b\xfcy\xfck modellere g\xf6re gecikme ve maliyet a\xe7ısından \xf6nemli iyileştirmeler sunar. Bu modelin \xf6rnek kullanım alanları arasında sorgulama, \xf6neri yeniden yazma ve yazma desteği bulunmaktadır."},"accounts/fireworks/models/llama-v3p2-90b-vision-instruct":{"description":"Meta\'nın 90B parametreli komut ayarlı g\xf6r\xfcnt\xfc akıl y\xfcr\xfctme modelidir. Bu model, g\xf6rsel tanıma, g\xf6r\xfcnt\xfc akıl y\xfcr\xfctme, g\xf6r\xfcnt\xfc betimleme ve g\xf6r\xfcnt\xfc hakkında genel sorulara yanıt verme \xfczerine optimize edilmiştir. Bu model, grafikler ve resimler gibi g\xf6rsel verileri anlayabilir ve g\xf6r\xfcnt\xfc detaylarını metin olarak betimleyerek g\xf6rsel ile dil arasındaki boşluğu kapatır."},"accounts/fireworks/models/llama-v3p3-70b-instruct":{"description":"Llama 3.3 70B Instruct, Llama 3.1 70B\'nin Aralık g\xfcncellemesi olan bir modeldir. Bu model, Llama 3.1 70B (2024 Temmuz\'da piyasaya s\xfcr\xfcld\xfc) temel alınarak geliştirilmiş olup, ara\xe7 \xe7ağrıları, \xe7ok dilli metin desteği, matematik ve programlama yeteneklerini artırmıştır. Model, akıl y\xfcr\xfctme, matematik ve talimat takibi alanlarında sekt\xf6rdeki en y\xfcksek standartlara ulaşmış olup, 3.1 405B ile benzer performans sunarken hız ve maliyet a\xe7ısından \xf6nemli avantajlar sağlamaktadır."},"accounts/fireworks/models/mistral-small-24b-instruct-2501":{"description":"24B parametreli model, daha b\xfcy\xfck modellerle karşılaştırılabilir en son teknoloji yeteneklerine sahiptir."},"accounts/fireworks/models/mixtral-8x22b-instruct":{"description":"Mixtral MoE 8x22B talimat modeli, b\xfcy\xfck \xf6l\xe7ekli parametreler ve \xe7ok uzmanlı mimarisi ile karmaşık g\xf6revlerin etkili işlenmesini destekler."},"accounts/fireworks/models/mixtral-8x7b-instruct":{"description":"Mixtral MoE 8x7B talimat modeli, \xe7ok uzmanlı mimarisi ile etkili talimat takibi ve y\xfcr\xfctme sunar."},"accounts/fireworks/models/mythomax-l2-13b":{"description":"MythoMax L2 13B modeli, yenilik\xe7i birleşim teknolojileri ile hikaye anlatımı ve rol yapma konularında uzmandır."},"accounts/fireworks/models/phi-3-vision-128k-instruct":{"description":"Phi 3 Vision talimat modeli, karmaşık g\xf6rsel ve metin bilgilerini işleyebilen hafif \xe7ok modlu bir modeldir ve g\xfc\xe7l\xfc akıl y\xfcr\xfctme yeteneklerine sahiptir."},"accounts/fireworks/models/qwen-qwq-32b-preview":{"description":"QwQ modeli, Qwen ekibi tarafından geliştirilen deneysel bir araştırma modelidir ve AI akıl y\xfcr\xfctme yeteneklerini artırmaya odaklanmaktadır."},"accounts/fireworks/models/qwen2-vl-72b-instruct":{"description":"Qwen-VL modelinin 72B versiyonu, Alibaba\'nın en son iterasyonunun bir \xfcr\xfcn\xfcd\xfcr ve son bir yılın yeniliklerini temsil etmektedir."},"accounts/fireworks/models/qwen2p5-72b-instruct":{"description":"Qwen2.5, Alibaba Cloud Qwen ekibi tarafından geliştirilen yalnızca kodlayıcı i\xe7eren bir dizi dil modelidir. Bu modeller, 0.5B, 1.5B, 3B, 7B, 14B, 32B ve 72B gibi farklı boyutları sunar ve temel (base) ve komut (instruct) versiyonlarına sahiptir."},"accounts/fireworks/models/qwen2p5-coder-32b-instruct":{"description":"Qwen2.5 Coder 32B Instruct, Alibaba Cloud tarafından yayınlanan kod odaklı b\xfcy\xfck dil modeli serisinin en son versiyonudur. Bu model, Qwen2.5 temelinde, 5.5 trilyon token ile eğitilerek kod \xfcretimi, akıl y\xfcr\xfctme ve d\xfczeltme yeteneklerini \xf6nemli \xf6l\xe7\xfcde artırmıştır. Hem kodlama yeteneklerini geliştirmiş hem de matematik ve genel yetenek avantajlarını korumuştur. Model, kod akıllı ajanları gibi pratik uygulamalar i\xe7in daha kapsamlı bir temel sunmaktadır."},"accounts/yi-01-ai/models/yi-large":{"description":"Yi-Large modeli, m\xfckemmel \xe7ok dilli işleme yetenekleri sunar ve her t\xfcrl\xfc dil \xfcretimi ve anlama g\xf6revleri i\xe7in uygundur."},"ai21-jamba-1.5-large":{"description":"398B parametreli (94B aktif) \xe7ok dilli bir model, 256K uzun bağlam penceresi, fonksiyon \xe7ağrısı, yapılandırılmış \xe7ıktı ve temellendirilmiş \xfcretim sunar."},"ai21-jamba-1.5-mini":{"description":"52B parametreli (12B aktif) \xe7ok dilli bir model, 256K uzun bağlam penceresi, fonksiyon \xe7ağrısı, yapılandırılmış \xe7ıktı ve temellendirilmiş \xfcretim sunar."},"ai21-labs/AI21-Jamba-1.5-Large":{"description":"398 milyar parametreli (94 milyar aktif) \xe7ok dilli model, 256K uzun bağlam penceresi, fonksiyon \xe7ağrısı, yapılandırılmış \xe7ıktı ve ger\xe7eklere dayalı \xfcretim sunar."},"ai21-labs/AI21-Jamba-1.5-Mini":{"description":"52 milyar parametreli (12 milyar aktif) \xe7ok dilli model, 256K uzun bağlam penceresi, fonksiyon \xe7ağrısı, yapılandırılmış \xe7ıktı ve ger\xe7eklere dayalı \xfcretim sunar."},"alibaba/qwen-3-14b":{"description":"Qwen3, Qwen serisinin en yeni nesil b\xfcy\xfck dil modeli olup, kapsamlı bir yoğun ve karma uzman (MoE) model seti sunar. Geniş \xe7aplı eğitimlere dayanarak, Qwen3 \xe7ıkarım, talimat takibi, ajan yetenekleri ve \xe7ok dilli destek alanlarında \xe7ığır a\xe7an ilerlemeler sağlar."},"alibaba/qwen-3-235b":{"description":"Qwen3, Qwen serisinin en yeni nesil b\xfcy\xfck dil modeli olup, kapsamlı bir yoğun ve karma uzman (MoE) model seti sunar. Geniş \xe7aplı eğitimlere dayanarak, Qwen3 \xe7ıkarım, talimat takibi, ajan yetenekleri ve \xe7ok dilli destek alanlarında \xe7ığır a\xe7an ilerlemeler sağlar."},"alibaba/qwen-3-30b":{"description":"Qwen3, Qwen serisinin en yeni nesil b\xfcy\xfck dil modeli olup, kapsamlı bir yoğun ve karma uzman (MoE) model seti sunar. Geniş \xe7aplı eğitimlere dayanarak, Qwen3 \xe7ıkarım, talimat takibi, ajan yetenekleri ve \xe7ok dilli destek alanlarında \xe7ığır a\xe7an ilerlemeler sağlar."},"alibaba/qwen-3-32b":{"description":"Qwen3, Qwen serisinin en yeni nesil b\xfcy\xfck dil modeli olup, kapsamlı bir yoğun ve karma uzman (MoE) model seti sunar. Geniş \xe7aplı eğitimlere dayanarak, Qwen3 \xe7ıkarım, talimat takibi, ajan yetenekleri ve \xe7ok dilli destek alanlarında \xe7ığır a\xe7an ilerlemeler sağlar."},"alibaba/qwen3-coder":{"description":"Qwen3-Coder-480B-A35B-Instruct, Qwen serisinin en yetenekli kodlama modeli olup, ajan kodlama, ajan tarayıcı kullanımı ve diğer temel kodlama g\xf6revlerinde belirgin performans sergiler ve Claude Sonnet ile karşılaştırılabilir sonu\xe7lar elde eder."},"amazon/nova-lite":{"description":"\xc7ok d\xfcş\xfck maliyetli \xe7ok modlu bir model olup, g\xf6r\xfcnt\xfc, video ve metin girişlerini \xe7ok hızlı işler."},"amazon/nova-micro":{"description":"Sadece metin modeli olup, \xe7ok d\xfcş\xfck maliyetle en d\xfcş\xfck gecikmeli yanıtları sunar."},"amazon/nova-pro":{"description":"Y\xfcksek yetenekli \xe7ok modlu model olup, doğruluk, hız ve maliyetin en iyi kombinasyonunu sunar ve geniş g\xf6rev yelpazesi i\xe7in uygundur."},"amazon/titan-embed-text-v2":{"description":"Amazon Titan Text Embeddings V2, hafif, verimli \xe7ok dilli g\xf6mme modeli olup, 1024, 512 ve 256 boyutlarını destekler."},"anthropic.claude-3-5-sonnet-20240620-v1:0":{"description":"Claude 3.5 Sonnet, end\xfcstri standartlarını y\xfckselterek, rakip modelleri ve Claude 3 Opus\'u geride bırakarak geniş bir değerlendirmede m\xfckemmel performans sergilerken, orta seviye modellerimizin hızı ve maliyeti ile birlikte gelir."},"anthropic.claude-3-5-sonnet-20241022-v2:0":{"description":"Claude 3.5 Sonnet, sekt\xf6r standartlarını y\xfckselterek, rakip modelleri ve Claude 3 Opus\'u geride bırakarak, geniş bir değerlendirme yelpazesinde m\xfckemmel performans sergilemekte, orta seviye modellerimizin hız ve maliyet avantajlarını sunmaktadır."},"anthropic.claude-3-haiku-20240307-v1:0":{"description":"Claude 3 Haiku, Anthropic\'in en hızlı ve en kompakt modelidir, neredeyse anında yanıt hızı sunar. Basit sorgular ve taleplere hızlı bir şekilde yanıt verebilir. M\xfcşteriler, insan etkileşimini taklit eden kesintisiz bir AI deneyimi oluşturabileceklerdir. Claude 3 Haiku, g\xf6r\xfcnt\xfcleri işleyebilir ve metin \xe7ıktısı d\xf6nd\xfcrebilir, 200K bağlam penceresine sahiptir."},"anthropic.claude-3-opus-20240229-v1:0":{"description":"Claude 3 Opus, Anthropic\'in en g\xfc\xe7l\xfc AI modelidir, son derece karmaşık g\xf6revlerde en ileri d\xfczey performansa sahiptir. A\xe7ık u\xe7lu istemleri ve daha \xf6nce g\xf6r\xfclmemiş senaryoları işleyebilir, m\xfckemmel akıcılık ve insan benzeri anlama yeteneğine sahiptir. Claude 3 Opus, \xfcretken AI olasılıklarının \xf6nc\xfcs\xfcd\xfcr. Claude 3 Opus, g\xf6r\xfcnt\xfcleri işleyebilir ve metin \xe7ıktısı d\xf6nd\xfcrebilir, 200K bağlam penceresine sahiptir."},"anthropic.claude-3-sonnet-20240229-v1:0":{"description":"Anthropic\'in Claude 3 Sonnet, zeka ve hız arasında ideal bir denge sağlar - \xf6zellikle kurumsal iş y\xfckleri i\xe7in uygundur. Rakiplerine g\xf6re daha d\xfcş\xfck bir fiyatla maksimum fayda sunar ve \xf6l\xe7eklenebilir AI dağıtımları i\xe7in g\xfcvenilir, dayanıklı bir ana makine olarak tasarlanmıştır. Claude 3 Sonnet, g\xf6r\xfcnt\xfcleri işleyebilir ve metin \xe7ıktısı d\xf6nd\xfcrebilir, 200K bağlam penceresine sahiptir."},"anthropic.claude-instant-v1":{"description":"G\xfcnl\xfck diyaloglar, metin analizi, \xf6zetleme ve belge soru-cevap gibi bir dizi g\xf6revi işleyebilen hızlı, ekonomik ve hala olduk\xe7a yetenekli bir modeldir."},"anthropic.claude-v2":{"description":"Anthropic, karmaşık diyaloglardan yaratıcı i\xe7erik \xfcretimine ve ayrıntılı talimat takibine kadar geniş bir g\xf6rev yelpazesinde y\xfcksek yetenek sergileyen bir modeldir."},"anthropic.claude-v2:1":{"description":"Claude 2\'nin g\xfcncellenmiş versiyonu, iki kat daha b\xfcy\xfck bir bağlam penceresine sahiptir ve uzun belgeler ve RAG bağlamındaki g\xfcvenilirlik, yanılsama oranı ve kanıta dayalı doğrulukta iyileştirmeler sunar."},"anthropic/claude-3-haiku":{"description":"Claude 3 Haiku, Anthropic\'in şimdiye kadarki en hızlı modeli olup, genellikle uzun istemler i\xe7eren kurumsal iş y\xfckleri i\xe7in tasarlanmıştır. Haiku, \xe7eyrek dosyaları, s\xf6zleşmeler veya hukuk davaları gibi b\xfcy\xfck belge yığınlarını hızlıca analiz edebilir ve maliyeti performans seviyesindeki diğer modellere g\xf6re yarı yarıya d\xfcş\xfckt\xfcr."},"anthropic/claude-3-opus":{"description":"Claude 3 Opus, Anthropic\'in en zeki modeli olup, y\xfcksek karmaşıklıktaki g\xf6revlerde piyasa lideri performans sunar. A\xe7ık u\xe7lu istemleri ve daha \xf6nce g\xf6r\xfclmemiş senaryoları \xfcst\xfcn akıcılık ve insan benzeri anlayışla y\xf6netebilir."},"anthropic/claude-3.5-haiku":{"description":"Claude 3.5 Haiku, en hızlı modelimizin bir sonraki neslidir. Claude 3 Haiku ile benzer hızda olup, her beceri setinde geliştirilmiş ve bir\xe7ok zeka kıyaslamasında \xf6nceki nesil en b\xfcy\xfck modelimiz Claude 3 Opus\'u geride bırakmıştır."},"anthropic/claude-3.5-sonnet":{"description":"Claude 3.5 Sonnet, zeka ve hız arasında ideal dengeyi sağlar—\xf6zellikle kurumsal iş y\xfckleri i\xe7in. Benzer \xfcr\xfcnlere kıyasla daha d\xfcş\xfck maliyetle g\xfc\xe7l\xfc performans sunar ve b\xfcy\xfck \xf6l\xe7ekli yapay zeka dağıtımlarında y\xfcksek dayanıklılık i\xe7in tasarlanmıştır."},"anthropic/claude-3.7-sonnet":{"description":"Claude 3.7 Sonnet, ilk karma \xe7ıkarım modeli olup, Anthropic\'in şimdiye kadarki en zeki modelidir. Kodlama, i\xe7erik oluşturma, veri analizi ve planlama g\xf6revlerinde en ileri performansı sunar ve selefi Claude 3.5 Sonnet\'in yazılım m\xfchendisliği ve bilgisayar kullanımı yetenekleri \xfczerine inşa edilmiştir."},"anthropic/claude-opus-4":{"description":"Claude Opus 4, Anthropic\'in şimdiye kadarki en g\xfc\xe7l\xfc modeli ve d\xfcnyanın en iyi kodlama modeli olup, SWE-bench (%72.5) ve Terminal-bench (%43.2) testlerinde liderdir. Uzun s\xfcreli, binlerce adımlı g\xf6revlerde s\xfcrekli performans sağlar ve saatlerce kesintisiz \xe7alışabilir—AI ajanlarının yeteneklerini \xf6nemli \xf6l\xe7\xfcde genişletir."},"anthropic/claude-opus-4.1":{"description":"Claude Opus 4.1, Opus 4\'\xfcn tak-\xe7alıştır alternatifi olup, ger\xe7ek kodlama ve ajan g\xf6revlerinde \xfcst\xfcn performans ve doğruluk sunar. Opus 4.1, en ileri kodlama performansını SWE-bench Verified\'de %74.5\'e y\xfckseltir ve karmaşık \xe7ok adımlı problemleri daha y\xfcksek titizlik ve detay odaklılıkla ele alır."},"anthropic/claude-sonnet-4":{"description":"Claude Sonnet 4, Sonnet 3.7\'nin sekt\xf6r lideri yetenekleri \xfczerine \xf6nemli geliştirmeler yapmış olup, kodlama alanında m\xfckemmel performans sergiler ve SWE-bench\'te en ileri %72.7 skoruna ulaşır. Model, performans ve verimlilik arasında denge sağlar, hem dahili hem de harici kullanım durumları i\xe7in uygundur ve geliştirilmiş kontrol edilebilirlik ile uygulama \xfczerinde daha fazla hakimiyet sunar."},"anthropic/claude-sonnet-4.5":{"description":"Claude Sonnet 4.5, Anthropic\'in şimdiye kadarki en akıllı modelidir."},"ascend-tribe/pangu-pro-moe":{"description":"Pangu-Pro-MoE 72B-A16B, 72 milyar parametreli ve 16 milyar parametre aktive eden seyrek b\xfcy\xfck bir dil modelidir. Bu model, grup tabanlı uzman karışımı (MoGE) mimarisine dayanır; uzman se\xe7im aşamasında uzmanları gruplar halinde d\xfczenler ve her grupta token başına eşit sayıda uzmanı aktive ederek uzman y\xfck dengesini sağlar. Bu sayede Ascend platformunda modelin dağıtım verimliliği \xf6nemli \xf6l\xe7\xfcde artırılmıştır."},"aya":{"description":"Aya 23, Cohere tarafından sunulan \xe7ok dilli bir modeldir, 23 dili destekler ve \xe7ok dilli uygulamalar i\xe7in kolaylık sağlar."},"aya:35b":{"description":"Aya 23, Cohere tarafından sunulan \xe7ok dilli bir modeldir, 23 dili destekler ve \xe7ok dilli uygulamalar i\xe7in kolaylık sağlar."},"azure-DeepSeek-R1-0528":{"description":"Microsoft tarafından dağıtılmıştır; DeepSeek R1 modeli k\xfc\xe7\xfck bir s\xfcr\xfcm g\xfcncellemesi almıştır, mevcut s\xfcr\xfcm DeepSeek-R1-0528\'dir. En son g\xfcncellemede, DeepSeek R1 hesaplama kaynaklarını artırarak ve eğitim sonrası algoritma optimizasyon mekanizmasını tanıtarak \xe7ıkarım derinliği ve tahmin yeteneğini \xf6nemli \xf6l\xe7\xfcde geliştirmiştir. Bu model matematik, programlama ve genel mantık gibi \xe7eşitli kıyaslama testlerinde \xfcst\xfcn performans g\xf6stermiştir ve genel performansı O3 ve Gemini 2.5 Pro gibi \xf6nde gelen modellerle yakındır."},"baichuan-m2-32b":{"description":"Baichuan M2 32B, Baichuan Intelligence tarafından geliştirilen bir karma uzman modelidir ve g\xfc\xe7l\xfc akıl y\xfcr\xfctme yeteneklerine sahiptir."},"baichuan/baichuan2-13b-chat":{"description":"Baichuan-13B, Baichuan Zhi Neng tarafından geliştirilen 130 milyar parametreye sahip a\xe7ık kaynaklı ticari bir b\xfcy\xfck dil modelidir ve yetkili \xc7ince ve İngilizce benchmark\'larda aynı boyuttaki en iyi sonu\xe7ları elde etmiştir."},"baidu/ERNIE-4.5-300B-A47B":{"description":"ERNIE-4.5-300B-A47B, Baidu tarafından geliştirilen, karma uzman (MoE) mimarisine dayanan b\xfcy\xfck bir dil modelidir. Modelin toplam parametre sayısı 300 milyar olup, \xe7ıkarım sırasında her token i\xe7in yalnızca 47 milyar parametre aktive edilir; b\xf6ylece g\xfc\xe7l\xfc performans ile hesaplama verimliliği dengelenir. ERNIE 4.5 serisinin temel modellerinden biri olarak, metin anlama, \xfcretme, akıl y\xfcr\xfctme ve programlama gibi g\xf6revlerde \xfcst\xfcn yetenekler sergiler. Model, metin ve g\xf6rsel modların ortak eğitimiyle \xe7ok modlu heterojen MoE \xf6n eğitim y\xf6ntemi kullanarak genel yeteneklerini artırmış, \xf6zellikle talimat takibi ve d\xfcnya bilgisi hafızasında etkileyici sonu\xe7lar elde etmiştir."},"c4ai-aya-expanse-32b":{"description":"Aya Expanse, talimat ayarlama, veri arbitrajı, tercih eğitimi ve model birleştirme yenilikleri ile tek dilli modellerin performansını zorlamak i\xe7in tasarlanmış y\xfcksek performanslı bir 32B \xe7ok dilli modeldir. 23 dili desteklemektedir."},"c4ai-aya-expanse-8b":{"description":"Aya Expanse, talimat ayarlama, veri arbitrajı, tercih eğitimi ve model birleştirme yenilikleri ile tek dilli modellerin performansını zorlamak i\xe7in tasarlanmış y\xfcksek performanslı bir 8B \xe7ok dilli modeldir. 23 dili desteklemektedir."},"c4ai-aya-vision-32b":{"description":"Aya Vision, dil, metin ve g\xf6r\xfcnt\xfc yeteneklerinin birden fazla anahtar \xf6l\xe7\xfct\xfcnde m\xfckemmel performans sergileyen en son teknoloji \xe7ok modlu bir modeldir. 23 dili desteklemektedir. Bu 32 milyar parametreli versiyon, en son teknoloji \xe7ok dilli performansa odaklanmaktadır."},"c4ai-aya-vision-8b":{"description":"Aya Vision, dil, metin ve g\xf6r\xfcnt\xfc yeteneklerinin birden fazla anahtar \xf6l\xe7\xfct\xfcnde m\xfckemmel performans sergileyen en son teknoloji \xe7ok modlu bir modeldir. Bu 8 milyar parametreli versiyon, d\xfcş\xfck gecikme ve en iyi performansa odaklanmaktadır."},"charglm-3":{"description":"CharGLM-3, rol yapma ve duygusal destek i\xe7in tasarlanmış, ultra uzun \xe7ok turlu bellek ve kişiselleştirilmiş diyalog desteği sunan bir modeldir, geniş bir uygulama yelpazesine sahiptir."},"charglm-4":{"description":"CharGLM-4, rol yapma ve duygusal destek i\xe7in tasarlanmıştır, uzun s\xfcreli \xe7oklu hafıza ve kişiselleştirilmiş diyalogları destekler, geniş bir uygulama yelpazesine sahiptir."},"chatgpt-4o-latest":{"description":"ChatGPT-4o, g\xfcncel versiyonunu korumak i\xe7in ger\xe7ek zamanlı olarak g\xfcncellenen dinamik bir modeldir. G\xfc\xe7l\xfc dil anlama ve \xfcretme yeteneklerini birleştirir, m\xfcşteri hizmetleri, eğitim ve teknik destek gibi geniş \xf6l\xe7ekli uygulama senaryoları i\xe7in uygundur."},"claude-2.0":{"description":"Claude 2, işletmelere kritik yeteneklerin ilerlemesini sunar, sekt\xf6rdeki en iyi 200K token bağlamı, model yanılsamalarının \xf6nemli \xf6l\xe7\xfcde azaltılması, sistem ipu\xe7ları ve yeni bir test \xf6zelliği: ara\xe7 \xe7ağrısı i\xe7erir."},"claude-2.1":{"description":"Claude 2, işletmelere kritik yeteneklerin ilerlemesini sunar, sekt\xf6rdeki en iyi 200K token bağlamı, model yanılsamalarının \xf6nemli \xf6l\xe7\xfcde azaltılması, sistem ipu\xe7ları ve yeni bir test \xf6zelliği: ara\xe7 \xe7ağrısı i\xe7erir."},"claude-3-5-haiku-20241022":{"description":"Claude 3.5 Haiku, Anthropic\'in en hızlı bir sonraki nesil modelidir. Claude 3 Haiku ile karşılaştırıldığında, Claude 3.5 Haiku, t\xfcm becerilerde gelişim g\xf6stermiştir ve bir\xe7ok zeka standart testinde bir \xf6nceki neslin en b\xfcy\xfck modeli olan Claude 3 Opus\'u geride bırakmıştır."},"claude-3-5-haiku-latest":{"description":"Claude 3.5 Haiku hızlı yanıtlar sunar ve hafif g\xf6revler i\xe7in uygundur."},"claude-3-7-sonnet-20250219":{"description":"Claude 3.7 Sonnet, end\xfcstri standartlarını y\xfckselterek, rakip modelleri ve Claude 3 Opus\'u geride bırakarak, geniş bir değerlendirme yelpazesinde m\xfckemmel performans sergilemekte, orta seviye modellerimizin hız ve maliyet avantajlarını sunmaktadır."},"claude-3-7-sonnet-latest":{"description":"Claude 3.7 Sonnet, Anthropic\'in en yeni ve en g\xfc\xe7l\xfc modeli olup, y\xfcksek karmaşıklıktaki g\xf6revleri işler. Performans, zeka, akıcılık ve anlama yeteneğinde \xfcst\xfcnl\xfck g\xf6sterir."},"claude-3-haiku-20240307":{"description":"Claude 3 Haiku, Anthropic\'in en hızlı ve en kompakt modelidir, neredeyse anlık yanıtlar sağlamak i\xe7in tasarlanmıştır. Hızlı ve doğru y\xf6nlendirme performansına sahiptir."},"claude-3-opus-20240229":{"description":"Claude 3 Opus, Anthropic\'in y\xfcksek karmaşıklıkta g\xf6revleri işlemek i\xe7in en g\xfc\xe7l\xfc modelidir. Performans, zeka, akıcılık ve anlama a\xe7ısından m\xfckemmel bir şekilde \xf6ne \xe7ıkar."},"claude-3-sonnet-20240229":{"description":"Claude 3 Sonnet, akıllı ve hızlı bir denge sunarak kurumsal iş y\xfckleri i\xe7in idealdir. Daha d\xfcş\xfck bir fiyatla maksimum fayda sağlar, g\xfcvenilir ve b\xfcy\xfck \xf6l\xe7ekli dağıtım i\xe7in uygundur."},"claude-haiku-4-5-20251001":{"description":"Claude Haiku 4.5, Anthropic\'in en hızlı ve en akıllı Haiku modeli olup, yıldırım hızında \xe7alışır ve gelişmiş d\xfcş\xfcnme yeteneklerine sahiptir."},"claude-opus-4-1-20250805":{"description":"Claude Opus 4.1, Anthropic\'in en karmaşık g\xf6revleri işlemek i\xe7in geliştirdiği en g\xfc\xe7l\xfc modelidir. Performans, zeka, akıcılık ve anlama yeteneği a\xe7ısından olağan\xfcst\xfc bir performans sergiler."},"claude-opus-4-1-20250805-thinking":{"description":"Claude Opus 4.1 d\xfcş\xfcnme modeli, akıl y\xfcr\xfctme s\xfcrecini g\xf6sterebilen gelişmiş bir versiyondur."},"claude-opus-4-20250514":{"description":"Claude Opus 4, Anthropic\'in son derece karmaşık g\xf6revleri işlemek i\xe7in geliştirdiği en g\xfc\xe7l\xfc modeldir. Performans, zeka, akıcılık ve anlama a\xe7ısından m\xfckemmel bir şekilde \xf6ne \xe7ıkmaktadır."},"claude-sonnet-4-20250514":{"description":"Claude Sonnet 4, neredeyse anında yanıtlar veya uzatılmış adım adım d\xfcş\xfcnme s\xfcre\xe7leri \xfcretebilir; kullanıcılar bu s\xfcre\xe7leri net bir şekilde g\xf6rebilir."},"claude-sonnet-4-20250514-thinking":{"description":"Claude Sonnet 4 d\xfcş\xfcnme modeli, neredeyse anında yanıtlar veya uzatılmış adım adım d\xfcş\xfcnme s\xfcre\xe7leri \xfcretebilir; kullanıcılar bu s\xfcre\xe7leri net bir şekilde g\xf6rebilir."},"claude-sonnet-4-5-20250929":{"description":"Claude Sonnet 4.5, Anthropic\'in şimdiye kadarki en akıllı modelidir."},"codegeex-4":{"description":"CodeGeeX-4, \xe7eşitli programlama dillerinde akıllı soru-cevap ve kod tamamlama desteği sunan g\xfc\xe7l\xfc bir AI programlama asistanıdır, geliştirme verimliliğini artırır."},"codegeex4-all-9b":{"description":"CodeGeeX4-ALL-9B, \xe7ok dilli kod \xfcretim modeli olup, kod tamamlama ve \xfcretimi, kod yorumlayıcı, web arama, fonksiyon \xe7ağrısı, depo d\xfczeyinde kod soru-cevap gibi kapsamlı işlevleri destekler ve yazılım geliştirme i\xe7in \xe7eşitli senaryoları kapsar. 10B\'den az parametreye sahip en iyi kod \xfcretim modelidir."},"codegemma":{"description":"CodeGemma, farklı programlama g\xf6revleri i\xe7in \xf6zel olarak tasarlanmış hafif bir dil modelidir, hızlı iterasyon ve entegrasyonu destekler."},"codegemma:2b":{"description":"CodeGemma, farklı programlama g\xf6revleri i\xe7in \xf6zel olarak tasarlanmış hafif bir dil modelidir, hızlı iterasyon ve entegrasyonu destekler."},"codellama":{"description":"Code Llama, kod \xfcretimi ve tartışmalarına odaklanan bir LLM\'dir, geniş programlama dili desteği ile geliştirici ortamları i\xe7in uygundur."},"codellama/CodeLlama-34b-Instruct-hf":{"description":"Code Llama, kod \xfcretimi ve tartışmalarına odaklanan bir LLM\'dir ve geniş bir programlama dili desteği sunarak geliştirici ortamları i\xe7in uygundur."},"codellama:13b":{"description":"Code Llama, kod \xfcretimi ve tartışmalarına odaklanan bir LLM\'dir, geniş programlama dili desteği ile geliştirici ortamları i\xe7in uygundur."},"codellama:34b":{"description":"Code Llama, kod \xfcretimi ve tartışmalarına odaklanan bir LLM\'dir, geniş programlama dili desteği ile geliştirici ortamları i\xe7in uygundur."},"codellama:70b":{"description":"Code Llama, kod \xfcretimi ve tartışmalarına odaklanan bir LLM\'dir, geniş programlama dili desteği ile geliştirici ortamları i\xe7in uygundur."},"codeqwen":{"description":"CodeQwen1.5, b\xfcy\xfck miktarda kod verisi ile eğitilmiş b\xfcy\xfck bir dil modelidir, karmaşık programlama g\xf6revlerini \xe7\xf6zmek i\xe7in \xf6zel olarak tasarlanmıştır."},"codestral":{"description":"Codestral, Mistral AI\'nın ilk kod modelidir, kod \xfcretim g\xf6revlerine m\xfckemmel destek sunar."},"codestral-latest":{"description":"Codestral, kod \xfcretimine odaklanan son teknoloji bir \xfcretim modelidir, ara doldurma ve kod tamamlama g\xf6revlerini optimize etmiştir."},"codex-mini-latest":{"description":"codex-mini-latest, Codex CLI i\xe7in \xf6zel olarak ince ayarlanmış o4-mini versiyonudur. API \xfczerinden doğrudan kullanım i\xe7in, gpt-4.1\'den başlamanızı \xf6neririz."},"cogview-4":{"description":"CogView-4, Zhipu\'nun \xc7ince karakter \xfcretimini destekleyen ilk a\xe7ık kaynaklı metinden g\xf6rsele modelidir. Anlam anlayışı, g\xf6r\xfcnt\xfc \xfcretim kalitesi ve \xc7ince-İngilizce metin \xfcretme yeteneklerinde kapsamlı iyileştirmeler sunar. Her uzunlukta \xc7ince ve İngilizce \xe7ift dilli girişi destekler ve verilen aralıkta herhangi bir \xe7\xf6z\xfcn\xfcrl\xfckte g\xf6r\xfcnt\xfc oluşturabilir."},"cohere-command-r":{"description":"Command R, \xfcretim \xf6l\xe7eğinde AI sağlamak i\xe7in RAG ve Ara\xe7 Kullanımına y\xf6nelik \xf6l\xe7eklenebilir bir \xfcretken modeldir."},"cohere-command-r-plus":{"description":"Command R+, kurumsal d\xfczeyde iş y\xfcklerini ele almak i\xe7in tasarlanmış en son RAG optimize edilmiş bir modeldir."},"cohere/Cohere-command-r":{"description":"Command R, RAG ve ara\xe7 kullanımı i\xe7in \xf6l\xe7eklenebilir bir \xfcretim modeli olup, işletmelerin \xfcretim seviyesinde yapay zeka uygulamalarını ger\xe7ekleştirmesine olanak tanır."},"cohere/Cohere-command-r-plus":{"description":"Command R+, işletme d\xfczeyindeki iş y\xfckleri i\xe7in tasarlanmış, en gelişmiş RAG optimize modelidir."},"cohere/command-a":{"description":"Command A, Cohere\'in şimdiye kadarki en g\xfc\xe7l\xfc modeli olup, ara\xe7 kullanımı, ajanlık, arama destekli \xfcretim (RAG) ve \xe7ok dilli kullanım durumlarında \xfcst\xfcn performans g\xf6sterir. Command A\'nın bağlam uzunluğu 256K\'dır, sadece iki GPU ile \xe7alışabilir ve Command R+ 08-2024\'e kıyasla işlem hacminde %150 artış sağlar."},"cohere/command-r":{"description":"Command R, diyalog etkileşimleri ve uzun bağlam g\xf6revleri i\xe7in optimize edilmiş b\xfcy\xfck bir dil modelidir. \\"\xd6l\xe7eklenebilir\\" model kategorisinde konumlanır ve y\xfcksek performans ile g\xfc\xe7l\xfc doğruluk arasında denge kurarak şirketlerin kavram kanıtını aşarak \xfcretime ge\xe7mesini sağlar."},"cohere/command-r-plus":{"description":"Command R+, Cohere\'in en yeni b\xfcy\xfck dil modeli olup, diyalog etkileşimleri ve uzun bağlam g\xf6revleri i\xe7in optimize edilmiştir. Performansta olağan\xfcst\xfc olmayı hedefler ve şirketlerin kavram kanıtını aşarak \xfcretime ge\xe7mesini sağlar."},"cohere/embed-v4.0":{"description":"Metin, g\xf6r\xfcnt\xfc veya karma i\xe7eriklerin sınıflandırılması veya g\xf6mme haline d\xf6n\xfcşt\xfcr\xfclmesine olanak tanıyan model."},"comfyui/flux-dev":{"description":"FLUX.1 Dev - Y\xfcksek kaliteli metinden g\xf6rsele model, 10-50 adımda \xfcretim, sanatsal \xe7alışmalar ve yaratıcı i\xe7erikler i\xe7in uygundur"},"comfyui/flux-kontext-dev":{"description":"FLUX.1 Kontext-dev - G\xf6rsel d\xfczenleme modeli, metin komutlarına dayalı mevcut g\xf6rselleri d\xfczenlemeyi destekler, b\xf6lgesel d\xfczenleme ve stil transferi m\xfcmk\xfcnd\xfcr"},"comfyui/flux-krea-dev":{"description":"FLUX.1 Krea-dev - Geliştirilmiş g\xfcvenliğe sahip metinden g\xf6rsele modeli, Krea iş birliğiyle geliştirilmiştir, yerleşik g\xfcvenlik filtresi i\xe7erir"},"comfyui/flux-schnell":{"description":"FLUX.1 Schnell - Ultra hızlı metinden g\xf6rsele modeli, yalnızca 1-4 adımda y\xfcksek kaliteli g\xf6rseller \xfcretir, ger\xe7ek zamanlı uygulamalar ve hızlı prototipleme i\xe7in idealdir"},"comfyui/stable-diffusion-15":{"description":"Stable Diffusion 1.5 metinden g\xf6rsele modeli, klasik 512x512 \xe7\xf6z\xfcn\xfcrl\xfckte metinden g\xf6rsele \xfcretim sağlar, hızlı prototipleme ve yaratıcı denemeler i\xe7in uygundur"},"comfyui/stable-diffusion-35":{"description":"Stable Diffusion 3.5 yeni nesil metinden g\xf6rsele modeli, Large ve Medium olmak \xfczere iki s\xfcr\xfcm\xfc destekler, harici CLIP kodlayıcı dosyası gerektirir, \xfcst\xfcn g\xf6rsel kalite ve istem uyumu sunar"},"comfyui/stable-diffusion-35-inclclip":{"description":"Stable Diffusion 3.5 yerleşik CLIP/T5 kodlayıcılı s\xfcr\xfcm, harici kodlayıcı dosyasına ihtiya\xe7 duymaz, sd3.5_medium_incl_clips gibi modeller i\xe7in uygundur, daha az kaynak kullanır"},"comfyui/stable-diffusion-custom":{"description":"\xd6zelleştirilmiş SD metinden g\xf6rsele modeli, model dosya adı custom_sd_lobe.safetensors olmalıdır, varsa VAE dosyası custom_sd_vae_lobe.safetensors olarak adlandırılmalıdır, model dosyaları Comfy\'nin gereksinimlerine g\xf6re ilgili klas\xf6re yerleştirilmelidir"},"comfyui/stable-diffusion-custom-refiner":{"description":"\xd6zelleştirilmiş SDXL g\xf6rselden g\xf6rsele modeli, model dosya adı custom_sd_lobe.safetensors olmalıdır, varsa VAE dosyası custom_sd_vae_lobe.safetensors olarak adlandırılmalıdır, model dosyaları Comfy\'nin gereksinimlerine g\xf6re ilgili klas\xf6re yerleştirilmelidir"},"comfyui/stable-diffusion-refiner":{"description":"SDXL g\xf6rselden g\xf6rsele modeli, giriş g\xf6rseline dayalı y\xfcksek kaliteli d\xf6n\xfcş\xfcm sağlar, stil transferi, g\xf6rsel onarımı ve yaratıcı d\xf6n\xfcş\xfcmleri destekler"},"comfyui/stable-diffusion-xl":{"description":"SDXL metinden g\xf6rsele modeli, 1024x1024 y\xfcksek \xe7\xf6z\xfcn\xfcrl\xfckte metinden g\xf6rsele \xfcretimi destekler, daha iyi g\xf6rsel kalite ve detay sunar"},"command":{"description":"Dil g\xf6revlerinde y\xfcksek kalite ve g\xfcvenilirlik sunan, talimatları izleyen bir diyalog modelidir ve temel \xfcretim modelimize g\xf6re daha uzun bir bağlam uzunluğuna sahiptir."},"command-a-03-2025":{"description":"Command A, şimdiye kadar geliştirdiğimiz en g\xfc\xe7l\xfc modeldir ve ara\xe7 kullanımı, ajan, bilgi artırımlı \xfcretim (RAG) ve \xe7ok dilli uygulama senaryolarında m\xfckemmel performans sergilemektedir. Command A, 256K bağlam uzunluğuna sahiptir, yalnızca iki GPU ile \xe7alıştırılabilir ve Command R+ 08-2024\'e kıyasla %150 daha y\xfcksek bir verimlilik sunar."},"command-light":{"description":"Neredeyse aynı g\xfc\xe7te, ancak daha hızlı olan daha k\xfc\xe7\xfck ve daha hızlı bir Command versiyonudur."},"command-light-nightly":{"description":"Ana s\xfcr\xfcm g\xfcncellemeleri arasındaki s\xfcreyi kısaltmak i\xe7in Command modelinin her gece s\xfcr\xfcm\xfcn\xfc sunuyoruz. command-light serisi i\xe7in bu s\xfcr\xfcm command-light-nightly olarak adlandırılmaktadır. L\xfctfen dikkat edin, command-light-nightly en g\xfcncel, en deneysel ve (muhtemelen) kararsız s\xfcr\xfcmd\xfcr. Her gece s\xfcr\xfcm\xfc d\xfczenli olarak g\xfcncellenir ve \xf6nceden bildirilmez, bu nedenle \xfcretim ortamında kullanılması \xf6nerilmez."},"command-nightly":{"description":"Ana s\xfcr\xfcm g\xfcncellemeleri arasındaki s\xfcreyi kısaltmak i\xe7in Command modelinin her gece s\xfcr\xfcm\xfcn\xfc sunuyoruz. Command serisi i\xe7in bu s\xfcr\xfcm command-cightly olarak adlandırılmaktadır. L\xfctfen dikkat edin, command-nightly en g\xfcncel, en deneysel ve (muhtemelen) kararsız s\xfcr\xfcmd\xfcr. Her gece s\xfcr\xfcm\xfc d\xfczenli olarak g\xfcncellenir ve \xf6nceden bildirilmez, bu nedenle \xfcretim ortamında kullanılması \xf6nerilmez."},"command-r":{"description":"Command R, diyalog ve uzun bağlam g\xf6revleri i\xe7in optimize edilmiş bir LLM\'dir, dinamik etkileşim ve bilgi y\xf6netimi i\xe7in \xf6zellikle uygundur."},"command-r-03-2024":{"description":"Command R, dil g\xf6revlerinde daha y\xfcksek kalite ve g\xfcvenilirlik sunan, talimatları izleyen bir diyalog modelidir ve \xf6nceki modellere g\xf6re daha uzun bir bağlam uzunluğuna sahiptir. Kod \xfcretimi, bilgi artırımlı \xfcretim (RAG), ara\xe7 kullanımı ve ajan gibi karmaşık iş akışları i\xe7in kullanılabilir."},"command-r-08-2024":{"description":"command-r-08-2024, Command R modelinin g\xfcncellenmiş versiyonudur ve 2024 yılının Ağustos ayında piyasaya s\xfcr\xfclm\xfcşt\xfcr."},"command-r-plus":{"description":"Command R+, ger\xe7ek işletme senaryoları ve karmaşık uygulamalar i\xe7in tasarlanmış y\xfcksek performanslı bir b\xfcy\xfck dil modelidir."},"command-r-plus-04-2024":{"description":"Command R+, dil g\xf6revlerinde daha y\xfcksek kalite ve g\xfcvenilirlik sunan, talimatları izleyen bir diyalog modelidir ve \xf6nceki modellere g\xf6re daha uzun bir bağlam uzunluğuna sahiptir. Karmaşık RAG iş akışları ve \xe7ok adımlı ara\xe7 kullanımı i\xe7in en uygunudur."},"command-r-plus-08-2024":{"description":"Command R+ talimatları takip eden bir diyalog modelidir, dil g\xf6revlerinde daha y\xfcksek kalite, daha g\xfcvenilirlik sunar ve \xf6nceki modellere g\xf6re daha uzun bağlam uzunluğuna sahiptir. Karmaşık RAG iş akışları ve \xe7ok adımlı ara\xe7 kullanımı i\xe7in en uygunudur."},"command-r7b-12-2024":{"description":"command-r7b-12-2024, 2024 yılının Aralık ayında piyasaya s\xfcr\xfclen k\xfc\xe7\xfck ve verimli bir g\xfcncellenmiş versiyondur. RAG, ara\xe7 kullanımı, ajan gibi karmaşık akıl y\xfcr\xfctme ve \xe7ok adımlı işlemler gerektiren g\xf6revlerde m\xfckemmel performans sergilemektedir."},"computer-use-preview":{"description":"computer-use-preview modeli, \\"Bilgisayar Kullanım Ara\xe7ları\\" i\xe7in \xf6zel olarak tasarlanmış ve bilgisayarla ilgili g\xf6revleri anlama ve yerine getirme konusunda eğitilmiş \xf6zel bir modeldir."},"dall-e-2":{"description":"İkinci nesil DALL\xb7E modeli, daha ger\xe7ek\xe7i ve doğru g\xf6r\xfcnt\xfc \xfcretimi destekler, \xe7\xf6z\xfcn\xfcrl\xfcğ\xfc birinci neslin 4 katıdır."},"dall-e-3":{"description":"En son DALL\xb7E modeli, Kasım 2023\'te piyasaya s\xfcr\xfcld\xfc. Daha ger\xe7ek\xe7i ve doğru g\xf6r\xfcnt\xfc \xfcretimi destekler, daha g\xfc\xe7l\xfc detay ifade yeteneğine sahiptir."},"databricks/dbrx-instruct":{"description":"DBRX Instruct, y\xfcksek g\xfcvenilirlikte talimat işleme yetenekleri sunar ve \xe7ok \xe7eşitli end\xfcstri uygulamalarını destekler."},"deepseek-ai/DeepSeek-OCR":{"description":"DeepSeek-OCR, DeepSeek AI tarafından geliştirilen bir g\xf6rsel-dil modelidir ve optik karakter tanıma (OCR) ile \\"bağlam optik sıkıştırma\\"ya odaklanır. G\xf6rsellerden bağlamsal bilgiyi sıkıştırma sınırlarını keşfetmeyi ama\xe7lar; belgeleri verimli şekilde işleyerek Markdown gibi yapılandırılmış metin formatlarına d\xf6n\xfcşt\xfcrebilir. G\xf6rsellerdeki metin i\xe7eriğini doğru şekilde tanıyabilir; \xf6zellikle belge dijitalleştirme, metin \xe7ıkarımı ve yapılandırılmış işleme gibi uygulamalar i\xe7in uygundur."},"deepseek-ai/DeepSeek-R1":{"description":"DeepSeek-R1, tekrarlayan \xf6ğrenme (RL) destekli bir \xe7ıkarım modelidir ve modeldeki tekrarlama ve okunabilirlik sorunlarını \xe7\xf6zmektedir. RL\'den \xf6nce, DeepSeek-R1 soğuk başlangı\xe7 verilerini tanıtarak \xe7ıkarım performansını daha da optimize etmiştir. Matematik, kod ve \xe7ıkarım g\xf6revlerinde OpenAI-o1 ile benzer bir performans sergilemekte ve \xf6zenle tasarlanmış eğitim y\xf6ntemleri ile genel etkisini artırmaktadır."},"deepseek-ai/DeepSeek-R1-0528":{"description":"DeepSeek R1, artırılmış hesaplama kaynakları ve son eğitim s\xfcrecinde algoritma optimizasyon mekanizmalarının entegrasyonu sayesinde \xe7ıkarım ve akıl y\xfcr\xfctme derinliğini \xf6nemli \xf6l\xe7\xfcde artırmıştır. Model, matematik, programlama ve genel mantık alanlarında \xe7eşitli kıyaslama testlerinde \xfcst\xfcn performans g\xf6stermektedir. Genel performansı, O3 ve Gemini 2.5 Pro gibi lider modellerle yakındır."},"deepseek-ai/DeepSeek-R1-0528-Qwen3-8B":{"description":"DeepSeek-R1-0528-Qwen3-8B, DeepSeek-R1-0528 modelinden d\xfcş\xfcnce zinciri distilasyonu yoluyla Qwen3 8B Base modeline elde edilen bir modeldir. A\xe7ık kaynak modeller arasında en ileri (SOTA) performansa sahiptir, AIME 2024 testinde Qwen3 8B\'yi %10 aşmış ve Qwen3-235B-thinking performans seviyesine ulaşmıştır. Model matematiksel akıl y\xfcr\xfctme, programlama ve genel mantık gibi \xe7eşitli kıyaslama testlerinde \xfcst\xfcn performans g\xf6sterir; mimarisi Qwen3-8B ile aynıdır ancak DeepSeek-R1-0528\'in tokenizer konfig\xfcrasyonunu paylaşır."},"deepseek-ai/DeepSeek-R1-Distill-Llama-70B":{"description":"DeepSeek-R1 damıtma modeli, pekiştirme \xf6ğrenimi ve soğuk başlatma verileri ile \xe7ıkarım performansını optimize eder, a\xe7ık kaynak model \xe7oklu g\xf6rev standartlarını yeniler."},"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B":{"description":"DeepSeek-R1 damıtma modeli, pekiştirme \xf6ğrenimi ve soğuk başlatma verileri ile \xe7ıkarım performansını optimize eder, a\xe7ık kaynak model \xe7oklu g\xf6rev standartlarını yeniler."},"deepseek-ai/DeepSeek-R1-Distill-Qwen-14B":{"description":"DeepSeek-R1 damıtma modeli, pekiştirme \xf6ğrenimi ve soğuk başlatma verileri ile \xe7ıkarım performansını optimize eder, a\xe7ık kaynak model \xe7oklu g\xf6rev standartlarını yeniler."},"deepseek-ai/DeepSeek-R1-Distill-Qwen-32B":{"description":"DeepSeek-R1-Distill-Qwen-32B, Qwen2.5-32B temel alınarak bilgi damıtma ile elde edilen bir modeldir. Bu model, DeepSeek-R1 tarafından \xfcretilen 800.000 se\xe7kin \xf6rnek ile ince ayar yapılmış, matematik, programlama ve \xe7ıkarım gibi bir\xe7ok alanda olağan\xfcst\xfc performans sergilemektedir. AIME 2024, MATH-500, GPQA Diamond gibi bir\xe7ok referans testinde m\xfckemmel sonu\xe7lar elde etmiş, MATH-500\'de %94.3 doğruluk oranına ulaşarak g\xfc\xe7l\xfc matematik \xe7ıkarım yeteneğini g\xf6stermiştir."},"deepseek-ai/DeepSeek-R1-Distill-Qwen-7B":{"description":"DeepSeek-R1-Distill-Qwen-7B, Qwen2.5-Math-7B temel alınarak bilgi damıtma ile elde edilen bir modeldir. Bu model, DeepSeek-R1 tarafından \xfcretilen 800.000 se\xe7kin \xf6rnek ile ince ayar yapılmış, m\xfckemmel \xe7ıkarım yeteneği sergilemektedir. Bir\xe7ok referans testinde \xf6ne \xe7ıkmış, MATH-500\'de %92.8 doğruluk oranına, AIME 2024\'te %55.5 ge\xe7iş oranına ulaşmış, CodeForces\'ta 1189 puan alarak 7B \xf6l\xe7eğindeki model olarak g\xfc\xe7l\xfc matematik ve programlama yeteneğini g\xf6stermiştir."},"deepseek-ai/DeepSeek-V2.5":{"description":"DeepSeek V2.5, \xf6nceki s\xfcr\xfcmlerin m\xfckemmel \xf6zelliklerini bir araya getirir, genel ve kodlama yeteneklerini artırır."},"deepseek-ai/DeepSeek-V3":{"description":"DeepSeek-V3, 6710 milyar parametreye sahip bir karma uzman (MoE) dil modelidir. \xc7ok başlı potansiyel dikkat (MLA) ve DeepSeekMoE mimarisini kullanarak, yardımcı kayıplar olmadan y\xfck dengeleme stratejisi ile \xe7ıkarım ve eğitim verimliliğini optimize etmektedir. 14.8 trilyon y\xfcksek kaliteli token \xfczerinde \xf6nceden eğitilmiş ve denetimli ince ayar ile tekrarlayan \xf6ğrenme ger\xe7ekleştirilmiştir; DeepSeek-V3, performans a\xe7ısından diğer a\xe7ık kaynaklı modelleri geride bırakmakta ve lider kapalı kaynaklı modellere yaklaşmaktadır."},"deepseek-ai/DeepSeek-V3.1":{"description":"DeepSeek V3.1 modeli, hem d\xfcş\xfcnme hem de d\xfcş\xfcnme dışı modları destekleyen hibrit akıl y\xfcr\xfctme mimarisine sahip bir modeldir."},"deepseek-ai/DeepSeek-V3.1-Terminus":{"description":"DeepSeek-V3.1-Terminus, DeepSeek tarafından yayınlanan V3.1 modelinin g\xfcncellenmiş versiyonudur ve hibrit ajan b\xfcy\xfck dil modeli olarak konumlandırılmıştır. Bu g\xfcncelleme, modelin mevcut yeteneklerini koruyarak kullanıcı geri bildirimlerine dayalı sorunları d\xfczeltmeye ve kararlılığı artırmaya odaklanmıştır. Dil tutarlılığını \xf6nemli \xf6l\xe7\xfcde iyileştirmiş, \xc7ince ve İngilizce karışımı ile anormal karakterlerin g\xf6r\xfcn\xfcm\xfcn\xfc azaltmıştır. Model, farklı g\xf6revler i\xe7in sohbet şablonları aracılığıyla esnek ge\xe7iş yapılabilen “D\xfcş\xfcnme Modu” ve “D\xfcş\xfcnmeme Modu”nu entegre etmiştir. \xd6nemli bir iyileştirme olarak, V3.1-Terminus, kod ajanı (Code Agent) ve arama ajanı (Search Agent) performansını artırarak ara\xe7 \xe7ağrıları ve \xe7ok adımlı karmaşık g\xf6revlerin y\xfcr\xfct\xfclmesinde daha g\xfcvenilir hale getirmiştir."},"deepseek-ai/DeepSeek-V3.2-Exp":{"description":"DeepSeek-V3.2-Exp, DeepSeek tarafından yayınlanan deneysel V3.2 s\xfcr\xfcm\xfcd\xfcr ve yeni nesil mimariye ge\xe7işte bir ara keşif niteliğindedir. Bu s\xfcr\xfcm, V3.1-Terminus temelinde geliştirilmiş olup, uzun bağlamlı eğitim ve \xe7ıkarım verimliliğini artırmak amacıyla DeepSeek Seyrek Dikkat (DeepSeek Sparse Attention, DSA) mekanizmasını entegre eder. Ara\xe7 kullanımı, uzun belge anlama ve \xe7ok adımlı akıl y\xfcr\xfctme gibi alanlarda \xf6zel optimizasyonlar yapılmıştır. V3.2-Exp, araştırma ile \xfcr\xfcnleştirme arasında bir k\xf6pr\xfc g\xf6revi g\xf6r\xfcr ve y\xfcksek bağlam b\xfct\xe7esi gerektiren senaryolarda daha verimli \xe7ıkarım arayan kullanıcılar i\xe7in uygundur."},"deepseek-ai/deepseek-llm-67b-chat":{"description":"DeepSeek 67B, y\xfcksek karmaşıklıkta diyaloglar i\xe7in eğitilmiş gelişmiş bir modeldir."},"deepseek-ai/deepseek-r1":{"description":"En son teknolojiye sahip verimli LLM, akıl y\xfcr\xfctme, matematik ve programlama konularında uzmandır."},"deepseek-ai/deepseek-v3.1":{"description":"DeepSeek V3.1: Karmaşık \xe7ıkarım ve bağlantılı d\xfcş\xfcnme yeteneklerini geliştiren yeni nesil \xe7ıkarım modeli, derinlemesine analiz gerektiren g\xf6revler i\xe7in uygundur."},"deepseek-ai/deepseek-v3.1-terminus":{"description":"DeepSeek V3.1: Yeni nesil akıl y\xfcr\xfctme modeli, karmaşık mantıksal \xe7ıkarımlar ve zincirleme d\xfcş\xfcnme yeteneklerini geliştirir, derinlemesine analiz gerektiren g\xf6revler i\xe7in idealdir."},"deepseek-ai/deepseek-vl2":{"description":"DeepSeek-VL2, DeepSeekMoE-27B tabanlı bir karma uzman (MoE) g\xf6rsel dil modelidir. Seyrek etkinleştirilen MoE mimarisini kullanarak yalnızca 4.5B parametreyi etkinleştirerek olağan\xfcst\xfc performans sergilemektedir. Bu model, g\xf6rsel soru yanıtlama, optik karakter tanıma, belge/tablolar/grafikler anlama ve g\xf6rsel konumlandırma gibi bir\xe7ok g\xf6revde m\xfckemmel sonu\xe7lar elde etmektedir."},"deepseek-chat":{"description":"Genel ve kod yeteneklerini birleştiren yeni bir a\xe7ık kaynak modeli, yalnızca mevcut Chat modelinin genel diyalog yeteneklerini ve Coder modelinin g\xfc\xe7l\xfc kod işleme yeteneklerini korumakla kalmaz, aynı zamanda insan tercihleri ile daha iyi hizalanmıştır. Ayrıca, DeepSeek-V2.5 yazım g\xf6revleri, talimat takibi gibi bir\xe7ok alanda b\xfcy\xfck iyileştirmeler sağlamıştır."},"deepseek-coder-33B-instruct":{"description":"DeepSeek Coder 33B, 20 trilyon veri ile eğitilmiş bir kod dili modelidir. Bunun %87\'si kod, %13\'\xfc ise \xc7ince ve İngilizce dillerindendir. Model, 16K pencere boyutu ve boşluk doldurma g\xf6revini tanıtarak proje d\xfczeyinde kod tamamlama ve par\xe7a doldurma işlevi sunmaktadır."},"deepseek-coder-v2":{"description":"DeepSeek Coder V2, a\xe7ık kaynaklı bir karışık uzman kod modelidir, kod g\xf6revlerinde m\xfckemmel performans sergiler ve GPT4-Turbo ile karşılaştırılabilir."},"deepseek-coder-v2:236b":{"description":"DeepSeek Coder V2, a\xe7ık kaynaklı bir karışık uzman kod modelidir, kod g\xf6revlerinde m\xfckemmel performans sergiler ve GPT4-Turbo ile karşılaştırılabilir."},"deepseek-r1":{"description":"DeepSeek-R1, tekrarlayan \xf6ğrenme (RL) destekli bir \xe7ıkarım modelidir ve modeldeki tekrarlama ve okunabilirlik sorunlarını \xe7\xf6zmektedir. RL\'den \xf6nce, DeepSeek-R1 soğuk başlangı\xe7 verilerini tanıtarak \xe7ıkarım performansını daha da optimize etmiştir. Matematik, kod ve \xe7ıkarım g\xf6revlerinde OpenAI-o1 ile benzer bir performans sergilemekte ve \xf6zenle tasarlanmış eğitim y\xf6ntemleri ile genel etkisini artırmaktadır."},"deepseek-r1-0528":{"description":"685 milyar parametreli tam s\xfcr\xfcm model, 28 Mayıs 2025\'te yayınlandı. DeepSeek-R1, son eğitim aşamasında pek az etiketli veriyle g\xfc\xe7lendirilmiş \xf6ğrenme tekniklerini geniş \xe7apta kullanarak modelin \xe7ıkarım yeteneğini b\xfcy\xfck \xf6l\xe7\xfcde artırdı. Matematik, kodlama, doğal dil \xe7ıkarımı gibi g\xf6revlerde y\xfcksek performans ve g\xfc\xe7l\xfc yetenekler sergiler."},"deepseek-r1-250528":{"description":"DeepSeek R1 250528, tam \xf6zellikli DeepSeek-R1 \xe7ıkarım modeli, zorlu matematik ve mantık g\xf6revleri i\xe7in uygundur."},"deepseek-r1-70b-fast-online":{"description":"DeepSeek R1 70B hızlı versiyonu, ger\xe7ek zamanlı \xe7evrimi\xe7i arama desteği ile, model performansını korurken daha hızlı yanıt s\xfcreleri sunar."},"deepseek-r1-70b-online":{"description":"DeepSeek R1 70B standart versiyonu, ger\xe7ek zamanlı \xe7evrimi\xe7i arama desteği ile, en g\xfcncel bilgilere ihtiya\xe7 duyan diyalog ve metin işleme g\xf6revleri i\xe7in uygundur."},"deepseek-r1-distill-llama":{"description":"deepseek-r1-distill-llama, DeepSeek-R1\'den Llama tabanlı damıtılarak elde edilmiş bir modeldir."},"deepseek-r1-distill-llama-70b":{"description":"DeepSeek R1 Distill Llama 70B, genel ama\xe7lı R1 \xe7ıkarım yeteneğini Llama ekosistemiyle birleştiren distilasyon modeli."},"deepseek-r1-distill-llama-8b":{"description":"DeepSeek-R1-Distill-Llama-8B, Llama-3.1-8B tabanlı bir distilasyon b\xfcy\xfck dil modelidir ve DeepSeek R1 \xe7ıktılarıyla eğitilmiştir."},"deepseek-r1-distill-qianfan-70b":{"description":"DeepSeek R1 Distill Qianfan 70B, Qianfan-70B tabanlı R1 distilasyon modeli, y\xfcksek maliyet-performans oranına sahiptir."},"deepseek-r1-distill-qianfan-8b":{"description":"DeepSeek R1 Distill Qianfan 8B, Qianfan-8B tabanlı R1 distilasyon modeli, orta ve k\xfc\xe7\xfck \xf6l\xe7ekli uygulamalar i\xe7in uygundur."},"deepseek-r1-distill-qianfan-llama-70b":{"description":"DeepSeek R1 Distill Qianfan Llama 70B, Llama-70B tabanlı R1 distilasyon modelidir."},"deepseek-r1-distill-qwen":{"description":"deepseek-r1-distill-qwen, Qwen temel alınarak DeepSeek-R1\'den damıtılmış bir modeldir."},"deepseek-r1-distill-qwen-1.5b":{"description":"DeepSeek R1 Distill Qwen 1.5B, son derece hafif R1 distilasyon modeli, d\xfcş\xfck kaynaklı ortamlar i\xe7in uygundur."},"deepseek-r1-distill-qwen-14b":{"description":"DeepSeek R1 Distill Qwen 14B, orta \xf6l\xe7ekli R1 distilasyon modeli, \xe7oklu senaryo dağıtımı i\xe7in uygundur."},"deepseek-r1-distill-qwen-32b":{"description":"DeepSeek R1 Distill Qwen 32B, Qwen-32B tabanlı R1 distilasyon modeli, performans ve maliyet arasında denge sağlar."},"deepseek-r1-distill-qwen-7b":{"description":"DeepSeek R1 Distill Qwen 7B, hafif R1 distilasyon modeli, u\xe7 nokta ve kurumsal \xf6zel ortamlar i\xe7in uygundur."},"deepseek-r1-fast-online":{"description":"DeepSeek R1 tam hızlı versiyonu, ger\xe7ek zamanlı \xe7evrimi\xe7i arama desteği ile, 671B parametrenin g\xfc\xe7l\xfc yetenekleri ile daha hızlı yanıt s\xfcrelerini birleştirir."},"deepseek-r1-online":{"description":"DeepSeek R1 tam s\xfcr\xfcm\xfc, 671B parametreye sahip olup, ger\xe7ek zamanlı \xe7evrimi\xe7i arama desteği ile daha g\xfc\xe7l\xfc anlama ve \xfcretim yeteneklerine sahiptir."},"deepseek-reasoner":{"description":"DeepSeek V3.2 D\xfcş\xfcnme Modu. Nihai cevabı vermeden \xf6nce, model doğruluğu artırmak i\xe7in bir d\xfcş\xfcnce zinciri \xe7ıktısı \xfcretir."},"deepseek-v2":{"description":"DeepSeek V2, ekonomik ve verimli işleme ihtiya\xe7ları i\xe7in uygun, etkili bir Mixture-of-Experts dil modelidir."},"deepseek-v2:236b":{"description":"DeepSeek V2 236B, DeepSeek\'in tasarım kodu modelidir, g\xfc\xe7l\xfc kod \xfcretim yetenekleri sunar."},"deepseek-v3":{"description":"DeepSeek-V3, Hangzhou DeepSeek Yapay Zeka Temel Teknoloji Araştırma Şirketi tarafından geliştirilen MoE modelidir, bir\xe7ok değerlendirme sonucunda \xf6ne \xe7ıkmakta ve ana akım listelerde a\xe7ık kaynak modeller arasında birinci sırada yer almaktadır. V3, V2.5 modeline g\xf6re \xfcretim hızında 3 kat artış sağlamış, kullanıcılara daha hızlı ve akıcı bir deneyim sunmuştur."},"deepseek-v3-0324":{"description":"DeepSeek-V3-0324, 671B parametreye sahip bir MoE modelidir ve programlama ile teknik yetenekler, bağlam anlama ve uzun metin işleme gibi alanlarda belirgin avantajlar sunar."},"deepseek-v3.1":{"description":"DeepSeek-V3.1, DeepSeek\'in tamamen yeni hibrit \xe7ıkarım modeli olup, d\xfcş\xfcnme ve d\xfcş\xfcnmeme olmak \xfczere iki \xe7ıkarım modunu destekler ve DeepSeek-R1-0528\'e kıyasla d\xfcş\xfcnme verimliliği daha y\xfcksektir. Post-Training optimizasyonu sayesinde, Agent ara\xe7 kullanımı ve akıllı g\xf6rev performansı \xf6nemli \xf6l\xe7\xfcde artırılmıştır. 128k bağlam penceresini destekler ve \xe7ıktı uzunluğu maksimum 64k token\'a kadar \xe7ıkabilir."},"deepseek-v3.1-terminus":{"description":"DeepSeek-V3.1-Terminus, DeepSeek tarafından geliştirilen ve u\xe7 cihazlar i\xe7in optimize edilmiş b\xfcy\xfck dil modeli s\xfcr\xfcm\xfcd\xfcr."},"deepseek-v3.1-think-250821":{"description":"DeepSeek V3.1 Think 250821, Terminus s\xfcr\xfcm\xfcne karşılık gelen derin d\xfcş\xfcnme modeli, y\xfcksek performanslı \xe7ıkarım senaryoları i\xe7in uygundur."},"deepseek-v3.1:671b":{"description":"DeepSeek V3.1: Karmaşık \xe7ıkarım ve bağlantılı d\xfcş\xfcnme yeteneklerini geliştiren yeni nesil \xe7ıkarım modeli, derinlemesine analiz gerektiren g\xf6revler i\xe7in uygundur."},"deepseek-v3.2-exp":{"description":"deepseek-v3.2-exp seyrek dikkat mekanizması getirir, uzun metinlerin işlenmesinde eğitim ve \xe7ıkarım verimliliğini artırmayı ama\xe7lar, fiyatı deepseek-v3.1\'den daha d\xfcş\xfckt\xfcr."},"deepseek-v3.2-think":{"description":"DeepSeek V3.2 Think, tam \xf6zellikli derin d\xfcş\xfcnme modeli, uzun zincirli \xe7ıkarım yeteneklerini g\xfc\xe7lendirir."},"deepseek-vl2":{"description":"DeepSeek VL2, \xe7ok modlu model, g\xf6rsel ve metin anlayışı ile ayrıntılı g\xf6rsel soru-cevap desteği sunar."},"deepseek-vl2-small":{"description":"DeepSeek VL2 Small, hafif \xe7ok modlu s\xfcr\xfcm, kaynak kısıtlı ve y\xfcksek eşzamanlılık gerektiren senaryolar i\xe7in uygundur."},"deepseek/deepseek-chat-v3-0324":{"description":"DeepSeek V3, 685B parametreye sahip bir uzman karışık modeldir ve DeepSeek ekibinin amiral gemisi sohbet modeli serisinin en son iterasyonudur.\\n\\n\xc7eşitli g\xf6revlerde m\xfckemmel performans sergileyen [DeepSeek V3](/deepseek/deepseek-chat-v3) modelini devralmıştır."},"deepseek/deepseek-chat-v3-0324:free":{"description":"DeepSeek V3, 685B parametreye sahip bir uzman karışık modeldir ve DeepSeek ekibinin amiral gemisi sohbet modeli serisinin en son iterasyonudur.\\n\\n\xc7eşitli g\xf6revlerde m\xfckemmel performans sergileyen [DeepSeek V3](/deepseek/deepseek-chat-v3) modelini devralmıştır."},"deepseek/deepseek-chat-v3.1":{"description":"DeepSeek-V3.1, 128K uzun bağlam ve verimli mod ge\xe7işini destekleyen b\xfcy\xfck hibrit \xe7ıkarım modelidir; ara\xe7 \xe7ağrıları, kod \xfcretimi ve karmaşık \xe7ıkarım g\xf6revlerinde \xfcst\xfcn performans ve hız sağlar."},"deepseek/deepseek-r1":{"description":"DeepSeek R1 modeli k\xfc\xe7\xfck bir s\xfcr\xfcm g\xfcncellemesi aldı, mevcut s\xfcr\xfcm DeepSeek-R1-0528\'dir. Son g\xfcncellemede, DeepSeek R1 artırılmış hesaplama kaynakları ve eğitim sonrası algoritma optimizasyon mekanizmaları kullanarak \xe7ıkarım derinliği ve yeteneğini \xf6nemli \xf6l\xe7\xfcde artırdı. Model, matematik, programlama ve genel mantık gibi bir\xe7ok kıyaslama testinde \xfcst\xfcn performans g\xf6sterir ve genel performansı artık O3 ve Gemini 2.5 Pro gibi lider modellerle yakındır."},"deepseek/deepseek-r1-0528":{"description":"DeepSeek-R1, \xe7ok az etiketli veri ile modelin akıl y\xfcr\xfctme yeteneğini b\xfcy\xfck \xf6l\xe7\xfcde artırır. Nihai yanıtı vermeden \xf6nce, model doğruluğu artırmak i\xe7in bir d\xfcş\xfcnce zinciri \xe7ıktısı \xfcretir."},"deepseek/deepseek-r1-0528:free":{"description":"DeepSeek-R1, \xe7ok az etiketli veri ile modelin akıl y\xfcr\xfctme yeteneğini b\xfcy\xfck \xf6l\xe7\xfcde artırır. Nihai yanıtı vermeden \xf6nce, model doğruluğu artırmak i\xe7in bir d\xfcş\xfcnce zinciri \xe7ıktısı \xfcretir."},"deepseek/deepseek-r1-distill-llama-70b":{"description":"DeepSeek R1 Distill Llama 70B, Llama3.3 70B tabanlı b\xfcy\xfck bir dil modelidir. Bu model, DeepSeek R1 tarafından sağlanan ince ayarlarla, \xf6nc\xfc b\xfcy\xfck modellerle kıyaslanabilir rekabet\xe7i bir performans elde etmiştir."},"deepseek/deepseek-r1-distill-llama-8b":{"description":"DeepSeek R1 Distill Llama 8B, Llama-3.1-8B-Instruct tabanlı bir damıtılmış b\xfcy\xfck dil modelidir ve DeepSeek R1\'in \xe7ıktısını kullanarak eğitilmiştir."},"deepseek/deepseek-r1-distill-qwen-14b":{"description":"DeepSeek R1 Distill Qwen 14B, Qwen 2.5 14B tabanlı bir damıtılmış b\xfcy\xfck dil modelidir ve DeepSeek R1\'in \xe7ıktısını kullanarak eğitilmiştir. Bu model, bir\xe7ok benchmark testinde OpenAI\'nin o1-mini\'sini ge\xe7erek yoğun modellerin (dense models) en son teknik liderlik başarılarını elde etmiştir. İşte bazı benchmark test sonu\xe7ları:\\nAIME 2024 pass@1: 69.7\\nMATH-500 pass@1: 93.9\\nCodeForces Rating: 1481\\nBu model, DeepSeek R1\'in \xe7ıktısından ince ayar yaparak daha b\xfcy\xfck \xf6l\xe7ekli \xf6nc\xfc modellerle karşılaştırılabilir bir performans sergilemiştir."},"deepseek/deepseek-r1-distill-qwen-32b":{"description":"DeepSeek R1 Distill Qwen 32B, Qwen 2.5 32B tabanlı bir damıtılmış b\xfcy\xfck dil modelidir ve DeepSeek R1\'in \xe7ıktısını kullanarak eğitilmiştir. Bu model, bir\xe7ok benchmark testinde OpenAI\'nin o1-mini\'sini ge\xe7erek yoğun modellerin (dense models) en son teknik liderlik başarılarını elde etmiştir. İşte bazı benchmark test sonu\xe7ları:\\nAIME 2024 pass@1: 72.6\\nMATH-500 pass@1: 94.3\\nCodeForces Rating: 1691\\nBu model, DeepSeek R1\'in \xe7ıktısından ince ayar yaparak daha b\xfcy\xfck \xf6l\xe7ekli \xf6nc\xfc modellerle karşılaştırılabilir bir performans sergilemiştir."},"deepseek/deepseek-r1/community":{"description":"DeepSeek R1, DeepSeek ekibinin yayınladığı en son a\xe7ık kaynak modelidir ve \xf6zellikle matematik, programlama ve akıl y\xfcr\xfctme g\xf6revlerinde OpenAI\'nin o1 modeli ile karşılaştırılabilir bir \xe7ıkarım performansına sahiptir."},"deepseek/deepseek-r1:free":{"description":"DeepSeek-R1, yalnızca \xe7ok az etiketli veri ile modelin akıl y\xfcr\xfctme yeteneğini b\xfcy\xfck \xf6l\xe7\xfcde artırır. Model, nihai yanıtı vermeden \xf6nce bir d\xfcş\xfcnce zinciri i\xe7eriği sunarak nihai yanıtın doğruluğunu artırır."},"deepseek/deepseek-v3":{"description":"Gelişmiş \xe7ıkarım yeteneklerine sahip hızlı, genel ama\xe7lı b\xfcy\xfck dil modeli."},"deepseek/deepseek-v3.1-base":{"description":"DeepSeek V3.1 Base, DeepSeek V3 modelinin geliştirilmiş bir versiyonudur."},"deepseek/deepseek-v3/community":{"description":"DeepSeek-V3, \xe7ıkarım hızında \xf6nceki modellere g\xf6re \xf6nemli bir atılım ger\xe7ekleştirmiştir. A\xe7ık kaynak modeller arasında birinci sırada yer almakta ve d\xfcnya \xe7apındaki en gelişmiş kapalı kaynak modellerle rekabet edebilmektedir. DeepSeek-V3, DeepSeek-V2\'de kapsamlı bir şekilde doğrulanan \xe7ok başlı potansiyel dikkat (MLA) ve DeepSeekMoE mimarilerini kullanmaktadır. Ayrıca, DeepSeek-V3, y\xfck dengeleme i\xe7in yardımcı kayıpsız bir strateji geliştirmiştir ve daha g\xfc\xe7l\xfc bir performans elde etmek i\xe7in \xe7ok etiketli tahmin eğitim hedefleri belirlemiştir."},"deepseek_r1":{"description":"DeepSeek-R1, pekiştirme \xf6ğrenimi (RL) ile y\xf6nlendirilen bir \xe7ıkarım modelidir, modeldeki tekrarlama ve okunabilirlik sorunlarını \xe7\xf6zmektedir. RL\'den \xf6nce, DeepSeek-R1, soğuk başlatma verilerini tanıtarak \xe7ıkarım performansını daha da optimize etmiştir. Matematik, kod ve \xe7ıkarım g\xf6revlerinde OpenAI-o1 ile benzer performans sergilemekte ve \xf6zenle tasarlanmış eğitim y\xf6ntemleri ile genel etkisini artırmaktadır."},"deepseek_r1_distill_llama_70b":{"description":"DeepSeek-R1-Distill-Llama-70B, Llama-3.3-70B-Instruct temel alınarak damıtma eğitimi ile elde edilen bir modeldir. Bu model, DeepSeek-R1 serisinin bir par\xe7asıdır ve DeepSeek-R1 tarafından \xfcretilen \xf6rnekler kullanılarak ince ayar yapılmış, matematik, programlama ve \xe7ıkarım gibi bir\xe7ok alanda m\xfckemmel performans sergilemektedir."},"deepseek_r1_distill_qwen_14b":{"description":"DeepSeek-R1-Distill-Qwen-14B, Qwen2.5-14B temel alınarak bilgi damıtma ile elde edilen bir modeldir. Bu model, DeepSeek-R1 tarafından \xfcretilen 800.000 se\xe7kin \xf6rnek ile ince ayar yapılmış ve m\xfckemmel \xe7ıkarım yetenekleri sergilemektedir."},"deepseek_r1_distill_qwen_32b":{"description":"DeepSeek-R1-Distill-Qwen-32B, Qwen2.5-32B temel alınarak bilgi damıtma ile elde edilen bir modeldir. Bu model, DeepSeek-R1 tarafından \xfcretilen 800.000 se\xe7kin \xf6rnek ile ince ayar yapılmış ve matematik, programlama ve \xe7ıkarım gibi bir\xe7ok alanda olağan\xfcst\xfc performans sergilemektedir."},"doubao-1.5-lite-32k":{"description":"Doubao-1.5-lite, tamamen yeni nesil hafif modeldir, olağan\xfcst\xfc yanıt hızı ile etkisi ve gecikmesi d\xfcnya standartlarında bir seviyeye ulaşmıştır."},"doubao-1.5-pro-256k":{"description":"Doubao-1.5-pro-256k, Doubao-1.5-Pro\'nun kapsamlı bir y\xfckseltmesi olup, genel performans %10 oranında b\xfcy\xfck bir artış g\xf6stermektedir. 256k bağlam penceresi ile akıl y\xfcr\xfctmeyi destekler, \xe7ıktı uzunluğu maksimum 12k token\'a kadar desteklenmektedir. Daha y\xfcksek performans, daha b\xfcy\xfck pencere, y\xfcksek maliyet etkinliği ile daha geniş uygulama alanlarına uygundur."},"doubao-1.5-pro-32k":{"description":"Doubao-1.5-pro, tamamen yeni nesil ana model, performansı tamamen y\xfckseltilmiş olup, bilgi, kod, akıl y\xfcr\xfctme gibi alanlarda m\xfckemmel bir performans sergilemektedir."},"doubao-1.5-thinking-pro":{"description":"Doubao-1.5, tamamen yeni bir derin d\xfcş\xfcnme modeli, matematik, programlama, bilimsel akıl y\xfcr\xfctme gibi uzmanlık alanlarında ve yaratıcı yazım gibi genel g\xf6revlerde olağan\xfcst\xfc performans sergilemektedir. AIME 2024, Codeforces, GPQA gibi bir\xe7ok saygın \xf6l\xe7ekte sekt\xf6r\xfcn en \xfcst seviyelerine ulaşmakta veya bunlara yakın bir performans g\xf6stermektedir. 128k bağlam penceresi ve 16k \xe7ıktı desteği sunmaktadır."},"doubao-1.5-thinking-pro-m":{"description":"Doubao-1.5 yeni derin d\xfcş\xfcnme modeli (m versiyonu yerel \xe7ok modlu derin \xe7ıkarım yeteneği ile birlikte gelir), matematik, programlama, bilimsel \xe7ıkarım gibi uzmanlık alanlarında ve yaratıcı yazım gibi genel g\xf6revlerde \xfcst\xfcn performans g\xf6sterir. AIME 2024, Codeforces, GPQA gibi bir\xe7ok otoriter kıyaslamada sekt\xf6r\xfcn ilk sıralarına ulaşmıştır veya yaklaşmıştır. 128k bağlam penceresi ve 16k \xe7ıktı desteği sağlar."},"doubao-1.5-thinking-vision-pro":{"description":"Yeni g\xf6rsel derin d\xfcş\xfcnme modeli, daha g\xfc\xe7l\xfc genel \xe7ok modlu anlama ve \xe7ıkarım yeteneklerine sahiptir ve 59 a\xe7ık değerlendirme kıyaslamasından 37\'sinde SOTA (en iyi) performans g\xf6stermiştir."},"doubao-1.5-ui-tars":{"description":"Doubao-1.5-UI-TARS, grafik kullanıcı aray\xfcz\xfc (GUI) etkileşimine \xf6zg\xfc yerel bir Agent modelidir. Algılama, \xe7ıkarım ve eylem gibi insan benzeri yeteneklerle GUI ile kesintisiz etkileşim sağlar."},"doubao-1.5-vision-lite":{"description":"Doubao-1.5-vision-lite, yeni g\xfcncellenmiş \xe7ok modlu b\xfcy\xfck modeldir, herhangi bir \xe7\xf6z\xfcn\xfcrl\xfck ve aşırı en-boy oranı g\xf6r\xfcnt\xfc tanıma desteği sunar, g\xf6rsel \xe7ıkarım, belge tanıma, detay bilgisi anlama ve talimat takibi yeteneklerini artırır. 128k bağlam penceresi destekler, \xe7ıktı uzunluğu maksimum 16k token destekler."},"doubao-1.5-vision-pro":{"description":"Doubao-1.5-vision-pro, tamamen yenilenmiş \xe7ok modlu b\xfcy\xfck modeldir. Herhangi bir \xe7\xf6z\xfcn\xfcrl\xfckte ve aşırı en-boy oranlarındaki g\xf6r\xfcnt\xfcleri tanıyabilir, g\xf6rsel \xe7ıkarımı, belge tanımayı, detaylı bilgi anlayışını ve komutlara uyumu artırır."},"doubao-1.5-vision-pro-32k":{"description":"Doubao-1.5-vision-pro, tamamen yenilenmiş \xe7ok modlu b\xfcy\xfck modeldir. Herhangi bir \xe7\xf6z\xfcn\xfcrl\xfckte ve aşırı en-boy oranlarındaki g\xf6r\xfcnt\xfcleri tanıyabilir, g\xf6rsel \xe7ıkarımı, belge tanımayı, detaylı bilgi anlayışını ve komutlara uyumu artırır."},"doubao-lite-128k":{"description":"Son derece hızlı yanıt s\xfcresi ve daha iyi fiyat-performans oranı ile m\xfcşterilere farklı senaryolar i\xe7in daha esnek se\xe7enekler sunar. 128k bağlam penceresi ile \xe7ıkarım ve ince ayar desteği sağlar."},"doubao-lite-32k":{"description":"Son derece hızlı yanıt s\xfcresi ve daha iyi fiyat-performans oranı ile m\xfcşterilere farklı senaryolar i\xe7in daha esnek se\xe7enekler sunar. 32k bağlam penceresi ile \xe7ıkarım ve ince ayar desteği sağlar."},"doubao-lite-4k":{"description":"Son derece hızlı yanıt s\xfcresi ve daha iyi fiyat-performans oranı ile m\xfcşterilere farklı senaryolar i\xe7in daha esnek se\xe7enekler sunar. 4k bağlam penceresi ile \xe7ıkarım ve ince ayar desteği sağlar."},"doubao-pro-256k":{"description":"En etkili ana model olup, karmaşık g\xf6revlerin işlenmesi i\xe7in uygundur. Referans soru-cevap, \xf6zet \xe7ıkarma, yaratıcı yazım, metin sınıflandırma, rol yapma gibi senaryolarda m\xfckemmel performans g\xf6sterir. 256k bağlam penceresi ile \xe7ıkarım ve ince ayar desteği sağlar."},"doubao-pro-32k":{"description":"En etkili ana model olup, karmaşık g\xf6revlerin işlenmesi i\xe7in uygundur. Referans soru-cevap, \xf6zet \xe7ıkarma, yaratıcı yazım, metin sınıflandırma, rol yapma gibi senaryolarda m\xfckemmel performans g\xf6sterir. 32k bağlam penceresi ile \xe7ıkarım ve ince ayar desteği sağlar."},"doubao-seed-1.6":{"description":"Doubao-Seed-1.6, auto/thinking/non-thinking olmak \xfczere \xfc\xe7 d\xfcş\xfcnme modunu destekleyen tamamen yeni \xe7ok modlu derin d\xfcş\xfcnme modelidir. Non-thinking modunda, model performansı Doubao-1.5-pro/250115\'e kıyasla b\xfcy\xfck \xf6l\xe7\xfcde artmıştır. 256k bağlam penceresini destekler ve \xe7ıktı uzunluğu maksimum 16k token olabilir."},"doubao-seed-1.6-flash":{"description":"Doubao-Seed-1.6-flash, TPOT sadece 10ms olan son derece hızlı \xe7ok modlu derin d\xfcş\xfcnme modelidir; hem metin hem de g\xf6rsel anlayışı destekler, metin anlama yeteneği \xf6nceki lite neslini aşar, g\xf6rsel anlama ise rakiplerin pro serisi modelleriyle eşdeğerdir. 256k bağlam penceresini destekler ve \xe7ıktı uzunluğu maksimum 16k token olabilir."},"doubao-seed-1.6-lite":{"description":"Doubao-Seed-1.6-lite, yeni nesil \xe7ok modlu derin d\xfcş\xfcnme modelidir. Ayarlanabilir d\xfcş\xfcnme d\xfczeylerini (reasoning effort) destekler: Minimal, D\xfcş\xfck, Orta ve Y\xfcksek. Y\xfcksek fiyat-performans oranı sunar ve yaygın g\xf6revler i\xe7in en iyi tercihtir. 256k\'ya kadar bağlam penceresini destekler."},"doubao-seed-1.6-thinking":{"description":"Doubao-Seed-1.6-thinking modeli d\xfcş\xfcnme yeteneğinde b\xfcy\xfck gelişme g\xf6stermiştir, Doubao-1.5-thinking-pro ile karşılaştırıldığında Kodlama, Matematik ve mantıksal akıl y\xfcr\xfctme gibi temel yeteneklerde daha da iyileşmiştir, g\xf6rsel anlayışı destekler. 256k bağlam penceresini destekler ve \xe7ıktı uzunluğu maksimum 16k token olabilir."},"doubao-seed-1.6-vision":{"description":"Doubao-Seed-1.6-vision g\xf6rsel derin d\xfcş\xfcnme modeli, eğitim, g\xf6r\xfcnt\xfc denetimi, denetim ve g\xfcvenlik ile AI arama ve soru-cevap gibi senaryolarda daha g\xfc\xe7l\xfc genel \xe7ok modlu anlama ve akıl y\xfcr\xfctme yetenekleri sergiler. 256k bağlam penceresini destekler ve \xe7ıktı uzunluğu maksimum 64k token olabilir."},"doubao-seededit-3-0-i2i-250628":{"description":"Doubao resim oluşturma modeli, ByteDance Seed ekibi tarafından geliştirilmiştir; metin ve resim girişini destekler, y\xfcksek kontrol ve kaliteli resim oluşturma deneyimi sunar. Metin komutlarıyla g\xf6r\xfcnt\xfc d\xfczenlemeyi destekler ve oluşturulan g\xf6r\xfcnt\xfclerin kenar uzunluğu 512 ile 1536 piksel arasındadır."},"doubao-seedream-3-0-t2i-250415":{"description":"Seedream 3.0 resim oluşturma modeli, ByteDance Seed ekibi tarafından geliştirilmiştir; metin ve resim girişini destekler, y\xfcksek kontrol ve kaliteli resim oluşturma deneyimi sunar. Metin istemlerine dayalı olarak resim oluşturur."},"doubao-seedream-4-0-250828":{"description":"Seedream 4.0 resim oluşturma modeli, ByteDance Seed ekibi tarafından geliştirilmiştir; metin ve resim girişini destekler, y\xfcksek kontrol ve kaliteli resim oluşturma deneyimi sunar. Metin istemlerine dayalı olarak resim oluşturur."},"doubao-vision-lite-32k":{"description":"Doubao-vision modeli, Doubao tarafından geliştirilen \xe7ok modlu b\xfcy\xfck bir modeldir. G\xfc\xe7l\xfc g\xf6r\xfcnt\xfc anlama ve \xe7ıkarım yeteneklerine ve hassas komut anlama becerisine sahiptir. Model, g\xf6r\xfcnt\xfc metin bilgisi \xe7ıkarımı ve g\xf6r\xfcnt\xfc tabanlı \xe7ıkarım g\xf6revlerinde g\xfc\xe7l\xfc performans sergiler ve daha karmaşık, geniş kapsamlı g\xf6rsel soru-cevap g\xf6revlerinde kullanılabilir."},"doubao-vision-pro-32k":{"description":"Doubao-vision modeli, Doubao tarafından geliştirilen \xe7ok modlu b\xfcy\xfck bir modeldir. G\xfc\xe7l\xfc g\xf6r\xfcnt\xfc anlama ve \xe7ıkarım yeteneklerine ve hassas komut anlama becerisine sahiptir. Model, g\xf6r\xfcnt\xfc metin bilgisi \xe7ıkarımı ve g\xf6r\xfcnt\xfc tabanlı \xe7ıkarım g\xf6revlerinde g\xfc\xe7l\xfc performans sergiler ve daha karmaşık, geniş kapsamlı g\xf6rsel soru-cevap g\xf6revlerinde kullanılabilir."},"emohaa":{"description":"Emohaa, duygusal sorunları anlamalarına yardımcı olmak i\xe7in profesyonel danışmanlık yeteneklerine sahip bir psikolojik modeldir."},"ernie-4.5-0.3b":{"description":"ERNIE 4.5 0.3B, a\xe7ık kaynaklı hafif model, yerel ve \xf6zelleştirilmiş dağıtım \xe7\xf6z\xfcmleri i\xe7in uygundur."},"ernie-4.5-21b-a3b":{"description":"ERNIE 4.5 21B A3B, b\xfcy\xfck parametreli a\xe7ık kaynak modeli, anlama ve \xfcretim g\xf6revlerinde \xfcst\xfcn performans sunar."},"ernie-4.5-300b-a47b":{"description":"ERNIE 4.5 300B A47B, Baidu Wenxin tarafından geliştirilen son derece b\xfcy\xfck \xf6l\xe7ekli karma uzman modelidir ve \xfcst\xfcn akıl y\xfcr\xfctme yeteneklerine sahiptir."},"ernie-4.5-8k-preview":{"description":"ERNIE 4.5 8K Preview, 8K bağlam \xf6nizleme modeli, Wenxin 4.5 yeteneklerini deneyimlemek ve test etmek i\xe7in kullanılır."},"ernie-4.5-turbo-128k":{"description":"ERNIE 4.5 Turbo 128K, y\xfcksek performanslı genel model, arama destekli ve ara\xe7 \xe7ağrılı g\xf6revleri destekler, soru-cevap, kodlama ve akıllı ajanlar gibi \xe7eşitli iş senaryolarına uygundur."},"ernie-4.5-turbo-128k-preview":{"description":"ERNIE 4.5 Turbo 128K Preview, resmi s\xfcr\xfcmle aynı yetenek deneyimini sunar, entegrasyon ve kademeli testler i\xe7in uygundur."},"ernie-4.5-turbo-32k":{"description":"ERNIE 4.5 Turbo 32K, orta-uzun bağlam s\xfcr\xfcm\xfc, soru-cevap, bilgi tabanı arama ve \xe7ok turlu diyalog gibi senaryolar i\xe7in uygundur."},"ernie-4.5-turbo-latest":{"description":"ERNIE 4.5 Turbo En Son S\xfcr\xfcm, kapsamlı performans optimizasyonu ile \xfcretim ortamında genel ama\xe7lı ana model olarak uygundur."},"ernie-4.5-turbo-vl":{"description":"ERNIE 4.5 Turbo VL, olgun \xe7ok modlu model, \xfcretim ortamında g\xf6rsel-metin anlama ve tanıma g\xf6revleri i\xe7in uygundur."},"ernie-4.5-turbo-vl-32k":{"description":"ERNIE 4.5 Turbo VL 32K, orta-uzun metin \xe7ok modlu s\xfcr\xfcm, uzun belgeler ve g\xf6rsellerin birlikte anlaşılması i\xe7in uygundur."},"ernie-4.5-turbo-vl-32k-preview":{"description":"ERNIE 4.5 Turbo VL 32K Preview, \xe7ok modlu 32K \xf6nizleme s\xfcr\xfcm\xfc, uzun bağlamlı g\xf6rsel yeteneklerin değerlendirilmesini kolaylaştırır."},"ernie-4.5-turbo-vl-latest":{"description":"ERNIE 4.5 Turbo VL En Son S\xfcr\xfcm, en yeni \xe7ok modlu s\xfcr\xfcm, daha iyi g\xf6rsel-metin anlama ve \xe7ıkarım performansı sunar."},"ernie-4.5-turbo-vl-preview":{"description":"ERNIE 4.5 Turbo VL Preview, \xe7ok modlu \xf6nizleme modeli, g\xf6rsel-metin anlama ve \xfcretimi destekler, g\xf6rsel soru-cevap ve i\xe7erik anlama deneyimi i\xe7in uygundur."},"ernie-4.5-vl-28b-a3b":{"description":"ERNIE 4.5 VL 28B A3B, \xe7ok modlu a\xe7ık kaynak modeli, g\xf6rsel-metin anlama ve \xe7ıkarım g\xf6revlerini destekler."},"ernie-5.0-thinking-preview":{"description":"Wenxin 5.0 Thinking \xd6nizleme S\xfcr\xfcm\xfc, yerel tam modlu amiral gemisi modeli, metin, g\xf6rsel, ses ve video i\xe7in birleşik modelleme desteği sunar, karmaşık soru-cevap, yaratım ve akıllı ajan senaryoları i\xe7in uygundur."},"ernie-char-8k":{"description":"ERNIE Character 8K, karakter kişiliği diyalog modeli, IP karakter oluşturma ve uzun vadeli sohbet i\xe7in uygundur."},"ernie-char-fiction-8k":{"description":"ERNIE Character Fiction 8K, roman ve hikaye yaratımı i\xe7in kişilik modeli, uzun metinli hikaye \xfcretimi i\xe7in uygundur."},"ernie-char-fiction-8k-preview":{"description":"ERNIE Character Fiction 8K Preview, karakter ve hikaye yaratımı modeli \xf6nizleme s\xfcr\xfcm\xfc, işlev deneyimi ve test i\xe7in kullanılır."},"ernie-irag-edit":{"description":"ERNIE iRAG Edit, g\xf6rsel silme, yeniden \xe7izim ve varyant \xfcretimini destekleyen g\xf6rsel d\xfczenleme modeli."},"ernie-lite-8k":{"description":"ERNIE Lite 8K, hafif genel model, maliyet duyarlı g\xfcnl\xfck soru-cevap ve i\xe7erik \xfcretimi senaryoları i\xe7in uygundur."},"ernie-lite-pro-128k":{"description":"ERNIE Lite Pro 128K, hafif ve y\xfcksek performanslı model, gecikme ve maliyet hassas iş senaryoları i\xe7in uygundur."},"ernie-novel-8k":{"description":"ERNIE Novel 8K, uzun roman ve IP hikaye yaratımı modeli, \xe7ok karakterli ve \xe7ok katmanlı anlatımda uzmandır."},"ernie-speed-128k":{"description":"ERNIE Speed 128K, giriş-\xe7ıkış \xfccreti olmayan b\xfcy\xfck model, uzun metin anlama ve b\xfcy\xfck \xf6l\xe7ekli deneme senaryoları i\xe7in uygundur."},"ernie-speed-8k":{"description":"ERNIE Speed 8K, \xfccretsiz ve hızlı model, g\xfcnl\xfck diyalog ve hafif metin g\xf6revleri i\xe7in uygundur."},"ernie-speed-pro-128k":{"description":"ERNIE Speed Pro 128K, y\xfcksek eşzamanlılık ve y\xfcksek maliyet-performans oranına sahip model, b\xfcy\xfck \xf6l\xe7ekli \xe7evrimi\xe7i hizmetler ve kurumsal uygulamalar i\xe7in uygundur."},"ernie-tiny-8k":{"description":"ERNIE Tiny 8K, son derece hafif model, basit soru-cevap, sınıflandırma gibi d\xfcş\xfck maliyetli \xe7ıkarım senaryoları i\xe7in uygundur."},"ernie-x1-turbo-32k":{"description":"ERNIE X1 Turbo 32K, y\xfcksek hızlı d\xfcş\xfcnme modeli, 32K uzun bağlam desteği ile karmaşık \xe7ıkarım ve \xe7ok turlu diyaloglar i\xe7in uygundur."},"ernie-x1.1-preview":{"description":"ERNIE X1.1 Preview, ERNIE X1.1 d\xfcş\xfcnme modeli \xf6nizleme s\xfcr\xfcm\xfc, yetenek doğrulama ve test i\xe7in uygundur."},"fal-ai/bytedance/seedream/v4":{"description":"Seedream 4.0 resim oluşturma modeli, ByteDance Seed ekibi tarafından geliştirilmiştir; metin ve resim girişini destekler, y\xfcksek kontrol ve kaliteli resim oluşturma deneyimi sunar. Metin istemlerine dayalı olarak resim oluşturur."},"fal-ai/flux-kontext/dev":{"description":"G\xf6r\xfcnt\xfc d\xfczenleme g\xf6revlerine odaklanan FLUX.1 modeli, metin ve resim girişini destekler."},"fal-ai/flux-pro/kontext":{"description":"FLUX.1 Kontext [pro], metin ve referans g\xf6r\xfcnt\xfcleri giriş olarak işleyebilir; hedefe y\xf6nelik yerel d\xfczenlemeler ve karmaşık genel sahne d\xf6n\xfcş\xfcmlerini sorunsuzca ger\xe7ekleştirir."},"fal-ai/flux/krea":{"description":"Flux Krea [dev], estetik tercihlere sahip bir g\xf6r\xfcnt\xfc oluşturma modelidir ve daha ger\xe7ek\xe7i, doğal g\xf6r\xfcnt\xfcler \xfcretmeyi hedefler."},"fal-ai/flux/schnell":{"description":"FLUX.1 [schnell], 12 milyar parametreye sahip bir g\xf6r\xfcnt\xfc oluşturma modelidir ve hızlı y\xfcksek kaliteli g\xf6r\xfcnt\xfc \xfcretimine odaklanır."},"fal-ai/hunyuan-image/v3":{"description":"G\xfc\xe7l\xfc bir yerel \xe7ok modlu g\xf6r\xfcnt\xfc oluşturma modeli"},"fal-ai/imagen4/preview":{"description":"Google tarafından sunulan y\xfcksek kaliteli g\xf6r\xfcnt\xfc oluşturma modeli."},"fal-ai/nano-banana":{"description":"Nano Banana, Google\'ın en yeni, en hızlı ve en verimli yerel \xe7ok modlu modelidir; diyalog yoluyla g\xf6r\xfcnt\xfc oluşturma ve d\xfczenleme imkanı sunar."},"fal-ai/qwen-image":{"description":"Qwen ekibinin g\xfc\xe7l\xfc ham g\xf6r\xfcnt\xfc modeli, etkileyici \xc7ince metin oluşturma yeteneği ve \xe7eşitli g\xf6rsel stil se\xe7enekleri sunar."},"fal-ai/qwen-image-edit":{"description":"Qwen ekibi tarafından geliştirilen profesyonel g\xf6r\xfcnt\xfc d\xfczenleme modeli; anlamsal ve g\xf6r\xfcn\xfcm d\xfczenlemeyi destekler, \xc7ince ve İngilizce metinleri hassas şekilde d\xfczenleyebilir, stil d\xf6n\xfcş\xfcm\xfc, nesne d\xf6nd\xfcrme gibi y\xfcksek kaliteli d\xfczenlemeler yapabilir."},"flux-1-schnell":{"description":"Black Forest Labs tarafından geliştirilen 12 milyar parametreli metinden g\xf6r\xfcnt\xfcye modeldir. Latent adversarial diffusion distillation teknolojisi kullanır ve 1 ila 4 adımda y\xfcksek kaliteli g\xf6r\xfcnt\xfcler oluşturabilir. Performansı kapalı kaynak alternatiflerle karşılaştırılabilir ve Apache-2.0 lisansı altında kişisel, akademik ve ticari kullanıma uygundur."},"flux-dev":{"description":"FLUX.1 [dev], ticari olmayan uygulamalar i\xe7in a\xe7ık kaynaklı ağırlık ve rafine modeldir. FLUX.1 [dev], FLUX profesyonel s\xfcr\xfcm\xfcne yakın g\xf6r\xfcnt\xfc kalitesi ve talimat uyumu sağlarken daha y\xfcksek \xe7alışma verimliliğine sahiptir. Aynı boyuttaki standart modellere kıyasla kaynak kullanımı a\xe7ısından daha etkilidir."},"flux-kontext-max":{"description":"En gelişmiş bağlamsal g\xf6rsel oluşturma ve d\xfczenleme — metin ve g\xf6rselleri birleştirerek hassas ve tutarlı sonu\xe7lar sunar."},"flux-kontext-pro":{"description":"Metin ve g\xf6r\xfcnt\xfcleri birleştirerek hassas ve tutarlı sonu\xe7lar elde etmek i\xe7in en gelişmiş bağlamsal g\xf6r\xfcnt\xfc oluşturma ve d\xfczenleme."},"flux-merged":{"description":"FLUX.1-merged modeli, geliştirme aşamasında \\"DEV\\" tarafından keşfedilen derin \xf6zellikler ile \\"Schnell\\" in y\xfcksek hızlı y\xfcr\xfctme avantajlarını birleştirir. Bu sayede model performans sınırlarını artırır ve uygulama alanlarını genişletir."},"flux-pro":{"description":"En \xfcst d\xfczey ticari yapay zeka g\xf6r\xfcnt\xfc oluşturma modeli — eşsiz g\xf6r\xfcnt\xfc kalitesi ve \xe7ok \xe7eşitli \xe7ıktı yetenekleri."},"flux-pro-1.1":{"description":"Geliştirilmiş profesyonel d\xfczeyde yapay zeka g\xf6r\xfcnt\xfc oluşturma modeli — \xfcst\xfcn g\xf6r\xfcnt\xfc kalitesi ve verilen promptlara/komutlara hassas uyum sağlama yeteneği sunar."},"flux-pro-1.1-ultra":{"description":"Ultra y\xfcksek \xe7\xf6z\xfcn\xfcrl\xfckl\xfc yapay zeka ile g\xf6r\xfcnt\xfc \xfcretimi — 4 megapiksel \xe7ıktı desteği; 10 saniye i\xe7inde ultra net g\xf6rseller oluşturur."},"flux-schnell":{"description":"FLUX.1 [schnell], şu anda a\xe7ık kaynaklı en gelişmiş az adımlı modeldir; benzer rakiplerini aşmakla kalmaz, Midjourney v6.0 ve DALL\xb7E 3 (HD) gibi g\xfc\xe7l\xfc damıtılmamış modellerden bile \xfcst\xfcnd\xfcr. Model, \xf6n eğitim aşamasındaki t\xfcm \xe7ıktı \xe7eşitliliğini koruyacak şekilde \xf6zel olarak ince ayar yapılmıştır. Piyasadaki en gelişmiş modellere kıyasla g\xf6rsel kalite, talimat uyumu, boyut/oran değişiklikleri, yazı tipi işleme ve \xe7ıktı \xe7eşitliliği gibi alanlarda belirgin iyileştirmeler sunar ve kullanıcılara daha zengin ve \xe7eşitli yaratıcı g\xf6r\xfcnt\xfc \xfcretim deneyimi sağlar."},"flux.1-schnell":{"description":"FLUX.1-schnell, y\xfcksek performanslı g\xf6rsel \xfcretim modeli, \xe7ok \xe7eşitli tarzlarda hızlı g\xf6rsel \xfcretimi destekler."},"gemini-1.0-pro-001":{"description":"Gemini 1.0 Pro 001 (Tuning), kararlı ve ayarlanabilir bir performans sunar, karmaşık g\xf6rev \xe7\xf6z\xfcmleri i\xe7in ideal bir se\xe7imdir."},"gemini-1.0-pro-002":{"description":"Gemini 1.0 Pro 002 (Tuning), m\xfckemmel \xe7ok modlu destek sunar ve karmaşık g\xf6revlerin etkili bir şekilde \xe7\xf6z\xfclmesine odaklanır."},"gemini-1.0-pro-latest":{"description":"Gemini 1.0 Pro, Google\'ın y\xfcksek performanslı AI modelidir ve geniş g\xf6rev genişletmeleri i\xe7in tasarlanmıştır."},"gemini-1.5-flash-001":{"description":"Gemini 1.5 Flash 001, geniş uygulama alanları i\xe7in destekleyen verimli bir \xe7ok modlu modeldir."},"gemini-1.5-flash-002":{"description":"Gemini 1.5 Flash 002, geniş uygulama yelpazesini destekleyen verimli bir \xe7ok modlu modeldir."},"gemini-1.5-flash-8b":{"description":"Gemini 1.5 Flash 8B, geniş uygulama yelpazesini destekleyen verimli bir \xe7ok modlu modeldir."},"gemini-1.5-flash-8b-exp-0924":{"description":"Gemini 1.5 Flash 8B 0924, metin ve \xe7ok modlu kullanım durumlarında \xf6nemli performans artışları sunan en son deneysel modeldir."},"gemini-1.5-flash-8b-latest":{"description":"Gemini 1.5 Flash 8B, geniş uygulama desteğiyle \xe7oklu modaliteyi destekleyen y\xfcksek verimli bir modeldir."},"gemini-1.5-flash-exp-0827":{"description":"Gemini 1.5 Flash 0827, optimize edilmiş \xe7ok modlu işleme yetenekleri sunarak \xe7eşitli karmaşık g\xf6rev sahnelerine uygundur."},"gemini-1.5-flash-latest":{"description":"Gemini 1.5 Flash, Google\'ın en son \xe7ok modlu AI modelidir, hızlı işleme yeteneğine sahiptir ve metin, g\xf6r\xfcnt\xfc ve video girişi destekler, \xe7eşitli g\xf6revlerin verimli bir şekilde genişletilmesine olanak tanır."},"gemini-1.5-pro-001":{"description":"Gemini 1.5 Pro 001, geniş karmaşık g\xf6revleri destekleyen \xf6l\xe7eklenebilir bir \xe7ok modlu AI \xe7\xf6z\xfcm\xfcd\xfcr."},"gemini-1.5-pro-002":{"description":"Gemini 1.5 Pro 002, daha y\xfcksek kaliteli \xe7ıktılar sunan en son \xfcretim hazır modeldir; \xf6zellikle matematik, uzun bağlam ve g\xf6rsel g\xf6revlerde \xf6nemli iyileştirmeler sağlamaktadır."},"gemini-1.5-pro-exp-0801":{"description":"Gemini 1.5 Pro 0801, olağan\xfcst\xfc \xe7ok modlu işleme yetenekleri sunarak uygulama geliştirmeye daha fazla esneklik getirir."},"gemini-1.5-pro-exp-0827":{"description":"Gemini 1.5 Pro 0827, en son optimize edilmiş teknolojilerle birleştirilmiş daha verimli \xe7ok modlu veri işleme yeteneği sunar."},"gemini-1.5-pro-latest":{"description":"Gemini 1.5 Pro, 2 milyon token\'a kadar destekler, orta \xf6l\xe7ekli \xe7ok modlu modeller i\xe7in ideal bir se\xe7imdir ve karmaşık g\xf6revler i\xe7in \xe7ok y\xf6nl\xfc destek sunar."},"gemini-2.0-flash":{"description":"Gemini 2.0 Flash, m\xfckemmel hız, yerel ara\xe7 kullanımı, \xe7ok modlu \xfcretim ve 1M token bağlam penceresi dahil olmak \xfczere bir sonraki nesil \xf6zellikler ve iyileştirmeler sunar."},"gemini-2.0-flash-001":{"description":"Gemini 2.0 Flash, m\xfckemmel hız, yerel ara\xe7 kullanımı, \xe7ok modlu \xfcretim ve 1M token bağlam penceresi dahil olmak \xfczere bir sonraki nesil \xf6zellikler ve iyileştirmeler sunar."},"gemini-2.0-flash-exp":{"description":"Gemini 2.0 Flash modeli varyantı, maliyet etkinliği ve d\xfcş\xfck gecikme gibi hedefler i\xe7in optimize edilmiştir."},"gemini-2.0-flash-exp-image-generation":{"description":"Gemini 2.0 Flash deneysel modeli, g\xf6r\xfcnt\xfc oluşturmayı destekler"},"gemini-2.0-flash-lite":{"description":"Gemini 2.0 Flash model varyantı, maliyet etkinliği ve d\xfcş\xfck gecikme gibi hedefler i\xe7in optimize edilmiştir."},"gemini-2.0-flash-lite-001":{"description":"Gemini 2.0 Flash model varyantı, maliyet etkinliği ve d\xfcş\xfck gecikme gibi hedefler i\xe7in optimize edilmiştir."},"gemini-2.5-flash":{"description":"Gemini 2.5 Flash, Google\'ın en y\xfcksek maliyet-performans modelidir ve kapsamlı \xf6zellikler sunar."},"gemini-2.5-flash-image":{"description":"Nano Banana, Google\'ın en yeni, en hızlı ve en verimli yerel \xe7ok modlu modelidir; diyalog yoluyla g\xf6r\xfcnt\xfc oluşturmanıza ve d\xfczenlemenize olanak tanır."},"gemini-2.5-flash-image-preview":{"description":"Nano Banana, Google\'ın en yeni, en hızlı ve en verimli yerel \xe7ok modlu modelidir; diyalog yoluyla g\xf6r\xfcnt\xfc oluşturmanıza ve d\xfczenlemenize olanak tanır."},"gemini-2.5-flash-image-preview:image":{"description":"Nano Banana, Google\'ın en yeni, en hızlı ve en verimli yerel \xe7ok modlu modelidir; diyalog yoluyla g\xf6r\xfcnt\xfc oluşturmanıza ve d\xfczenlemenize olanak tanır."},"gemini-2.5-flash-image:image":{"description":"Nano Banana, Google\'ın en yeni, en hızlı ve en verimli yerel \xe7ok modlu modelidir; diyalog yoluyla g\xf6r\xfcnt\xfc oluşturmanıza ve d\xfczenlemenize olanak tanır."},"gemini-2.5-flash-lite":{"description":"Gemini 2.5 Flash-Lite, Google\'ın en k\xfc\xe7\xfck ve en uygun maliyetli modeli olup, geniş \xe7aplı kullanım i\xe7in tasarlanmıştır."},"gemini-2.5-flash-lite-preview-06-17":{"description":"Gemini 2.5 Flash-Lite \xd6nizlemesi, Google\'ın en k\xfc\xe7\xfck ve en y\xfcksek maliyet-performans modelidir ve b\xfcy\xfck \xf6l\xe7ekli kullanım i\xe7in tasarlanmıştır."},"gemini-2.5-flash-lite-preview-09-2025":{"description":"Gemini 2.5 Flash-Lite\'ın \xf6nizleme s\xfcr\xfcm\xfc (25 Eyl\xfcl 2025)"},"gemini-2.5-flash-preview-04-17":{"description":"Gemini 2.5 Flash \xd6nizleme, Google\'ın en iyi fiyat-performans oranına sahip modelidir ve kapsamlı \xf6zellikler sunar."},"gemini-2.5-flash-preview-09-2025":{"description":"Gemini 2.5 Flash\'ın \xf6nizleme s\xfcr\xfcm\xfc (25 Eyl\xfcl 2025)"},"gemini-2.5-pro":{"description":"Gemini 2.5 Pro, Google\'ın en gelişmiş d\xfcş\xfcnce modelidir; kodlama, matematik ve STEM alanlarındaki karmaşık problemleri \xe7ıkarım yapabilir ve uzun bağlam kullanarak b\xfcy\xfck veri setleri, kod tabanları ve belgeleri analiz edebilir."},"gemini-2.5-pro-preview-03-25":{"description":"Gemini 2.5 Pro \xd6nizleme, Google\'ın en gelişmiş d\xfcş\xfcnce modeli olup, kod, matematik ve STEM alanlarındaki karmaşık sorunları akıl y\xfcr\xfctme yeteneğine sahiptir. Uzun bağlamları analiz ederek b\xfcy\xfck veri setleri, kod havuzları ve belgeler \xfczerinde \xe7alışabilir."},"gemini-2.5-pro-preview-05-06":{"description":"Gemini 2.5 Pro \xd6nizleme, Google\'ın en gelişmiş d\xfcş\xfcnce modelidir ve kod, matematik ve STEM alanlarındaki karmaşık sorunları akıl y\xfcr\xfctme yeteneğine sahiptir. Uzun bağlamları analiz ederek b\xfcy\xfck veri setleri, kod havuzları ve belgeler \xfczerinde \xe7alışabilir."},"gemini-2.5-pro-preview-06-05":{"description":"Gemini 2.5 Pro \xd6nizlemesi, Google\'ın en gelişmiş d\xfcş\xfcnce modelidir; kodlama, matematik ve STEM alanlarındaki karmaşık problemleri \xe7\xf6zebilir ve uzun bağlam kullanarak b\xfcy\xfck veri setleri, kod k\xfct\xfcphaneleri ve belgeleri analiz edebilir."},"gemini-3-pro-preview":{"description":"Gemini 3 Pro, Google\'ın en akıllı modeli olup, en son teknoloji \xe7ıkarım ve \xe7ok modlu anlama yeteneklerinin yanı sıra g\xfc\xe7l\xfc aracı ve bağlam kodlama \xf6zelliklerine sahiptir."},"gemini-flash-latest":{"description":"Gemini Flash\'ın en son s\xfcr\xfcm\xfc"},"gemini-flash-lite-latest":{"description":"Gemini Flash-Lite\'ın en son s\xfcr\xfcm\xfc"},"gemini-pro-latest":{"description":"Gemini Pro\'nun en son s\xfcr\xfcm\xfc"},"gemma-7b-it":{"description":"Gemma 7B, orta \xf6l\xe7ekli g\xf6rev işleme i\xe7in uygundur ve maliyet etkinliği sunar."},"gemma2":{"description":"Gemma 2, Google tarafından sunulan verimli bir modeldir, k\xfc\xe7\xfck uygulamalardan karmaşık veri işleme senaryolarına kadar \xe7eşitli uygulama alanlarını kapsar."},"gemma2-9b-it":{"description":"Gemma 2 9B, belirli g\xf6revler ve ara\xe7 entegrasyonu i\xe7in optimize edilmiş bir modeldir."},"gemma2:27b":{"description":"Gemma 2, Google tarafından sunulan verimli bir modeldir, k\xfc\xe7\xfck uygulamalardan karmaşık veri işleme senaryolarına kadar \xe7eşitli uygulama alanlarını kapsar."},"gemma2:2b":{"description":"Gemma 2, Google tarafından sunulan verimli bir modeldir, k\xfc\xe7\xfck uygulamalardan karmaşık veri işleme senaryolarına kadar \xe7eşitli uygulama alanlarını kapsar."},"generalv3":{"description":"Spark Pro, profesyonel alanlar i\xe7in optimize edilmiş y\xfcksek performanslı b\xfcy\xfck dil modelidir, matematik, programlama, sağlık, eğitim gibi bir\xe7ok alana odaklanır ve \xe7evrimi\xe7i arama ile yerleşik hava durumu, tarih gibi eklentileri destekler. Optimize edilmiş modeli, karmaşık bilgi sorgulama, dil anlama ve y\xfcksek d\xfczeyde metin oluşturma konularında m\xfckemmel performans ve y\xfcksek verimlilik sergiler, profesyonel uygulama senaryoları i\xe7in ideal bir se\xe7imdir."},"generalv3.5":{"description":"Spark3.5 Max, en kapsamlı \xf6zelliklere sahip versiyondur, \xe7evrimi\xe7i arama ve bir\xe7ok yerleşik eklentiyi destekler. Kapsamlı optimize edilmiş temel yetenekleri ve sistem rol ayarları ile fonksiyon \xe7ağırma \xf6zellikleri, \xe7eşitli karmaşık uygulama senaryolarında son derece m\xfckemmel ve olağan\xfcst\xfc performans sergiler."},"glm-4":{"description":"GLM-4, Ocak 2024\'te piyasaya s\xfcr\xfclen eski amiral gemisi versiyonudur, şu anda daha g\xfc\xe7l\xfc GLM-4-0520 ile değiştirilmiştir."},"glm-4-0520":{"description":"GLM-4-0520, son derece karmaşık ve \xe7eşitli g\xf6revler i\xe7in tasarlanmış en yeni model versiyonudur, olağan\xfcst\xfc performans sergiler."},"glm-4-32b-0414":{"description":"GLM-4 32B 0414, GLM serisi genel b\xfcy\xfck model s\xfcr\xfcm\xfc, \xe7ok g\xf6revli metin \xfcretimi ve anlama desteği sunar."},"glm-4-9b-chat":{"description":"GLM-4-9B-Chat, anlamsal anlama, matematik, akıl y\xfcr\xfctme, kodlama ve bilgi alanlarında y\xfcksek performans sergiler. Web tarama, kod y\xfcr\xfctme, \xf6zel ara\xe7 \xe7ağırma ve uzun metin akıl y\xfcr\xfctme gibi \xf6zellikleri destekler. Japonca, Korece ve Almanca dahil olmak \xfczere 26 dili destekler."},"glm-4-air":{"description":"GLM-4-Air, maliyet etkin bir versiyondur, GLM-4\'e yakın performans sunar ve hızlı hız ve uygun fiyat sağlar."},"glm-4-air-250414":{"description":"GLM-4-Air, maliyet a\xe7ısından y\xfcksek verimlilik sunan bir versiyondur, GLM-4\'e yakın performans sunar, hızlı hız ve uygun fiyat sağlar."},"glm-4-airx":{"description":"GLM-4-AirX, GLM-4-Air\'ın verimli bir versiyonunu sunar, \xe7ıkarım hızı 2.6 katına kadar \xe7ıkabilir."},"glm-4-alltools":{"description":"GLM-4-AllTools, karmaşık talimat planlaması ve ara\xe7 \xe7ağrıları gibi \xe7ok işlevli g\xf6revleri desteklemek i\xe7in optimize edilmiş bir akıllı modeldir. İnternet tarayıcıları, kod a\xe7ıklamaları ve metin \xfcretimi gibi \xe7oklu g\xf6revleri yerine getirmek i\xe7in uygundur."},"glm-4-flash":{"description":"GLM-4-Flash, basit g\xf6revleri işlemek i\xe7in ideal bir se\xe7imdir, en hızlı ve en uygun fiyatlıdır."},"glm-4-flash-250414":{"description":"GLM-4-Flash, basit g\xf6revler i\xe7in ideal bir se\xe7imdir, en hızlı ve \xfccretsizdir."},"glm-4-flashx":{"description":"GLM-4-FlashX, Flash\'ın geliştirilmiş bir versiyonudur ve ultra hızlı \xe7ıkarım hızı sunar."},"glm-4-long":{"description":"GLM-4-Long, ultra uzun metin girişlerini destekler, bellek tabanlı g\xf6revler ve b\xfcy\xfck \xf6l\xe7ekli belge işleme i\xe7in uygundur."},"glm-4-plus":{"description":"GLM-4-Plus, g\xfc\xe7l\xfc uzun metin işleme ve karmaşık g\xf6revler i\xe7in yeteneklere sahip y\xfcksek akıllı bir amiral gemisidir, performansı tamamen artırılmıştır."},"glm-4.1v-thinking-flash":{"description":"GLM-4.1V-Thinking serisi modeller, bilinen 10 milyar parametre seviyesindeki VLM modelleri arasında en g\xfc\xe7l\xfc g\xf6rsel modellerdir. Aynı seviyedeki SOTA g\xf6rsel dil g\xf6revlerini birleştirir; video anlama, g\xf6rsel soru-cevap, akademik problem \xe7\xf6zme, OCR metin tanıma, belge ve grafik yorumlama, GUI ajanı, \xf6n u\xe7 web kodlama, grounding gibi bir\xe7ok g\xf6revde 8 kat daha b\xfcy\xfck parametreli Qwen2.5-VL-72B modelini bile aşan performans g\xf6sterir. \xd6nde gelen pekiştirmeli \xf6ğrenme teknikleri sayesinde, d\xfcş\xfcnce zinciri akıl y\xfcr\xfctme yoluyla cevapların doğruluğu ve zenginliği artırılmıştır; nihai sonu\xe7lar ve a\xe7ıklanabilirlik a\xe7ısından geleneksel d\xfcş\xfcnce zinciri olmayan modellerin \xe7ok \xf6tesindedir."},"glm-4.1v-thinking-flashx":{"description":"GLM-4.1V-Thinking serisi modeller, bilinen 10 milyar parametre seviyesindeki VLM modelleri arasında en g\xfc\xe7l\xfc g\xf6rsel modellerdir. Aynı seviyedeki SOTA g\xf6rsel dil g\xf6revlerini birleştirir; video anlama, g\xf6rsel soru-cevap, akademik problem \xe7\xf6zme, OCR metin tanıma, belge ve grafik yorumlama, GUI ajanı, \xf6n u\xe7 web kodlama, grounding gibi bir\xe7ok g\xf6revde 8 kat daha b\xfcy\xfck parametreli Qwen2.5-VL-72B modelini bile aşan performans g\xf6sterir. \xd6nde gelen pekiştirmeli \xf6ğrenme teknikleri sayesinde, d\xfcş\xfcnce zinciri akıl y\xfcr\xfctme yoluyla cevapların doğruluğu ve zenginliği artırılmıştır; nihai sonu\xe7lar ve a\xe7ıklanabilirlik a\xe7ısından geleneksel d\xfcş\xfcnce zinciri olmayan modellerin \xe7ok \xf6tesindedir."},"glm-4.5":{"description":"Zhipu\'nun amiral gemisi modeli, d\xfcş\xfcnme modu ge\xe7işini destekler, kapsamlı yetenekleri a\xe7ık kaynak modellerin SOTA seviyesine ulaşır, bağlam uzunluğu 128K\'ya kadar \xe7ıkabilir."},"glm-4.5-air":{"description":"GLM-4.5\'in hafif versiyonu olup performans ve maliyet etkinliğini dengeler; hibrit d\xfcş\xfcnme modeli olarak esnek ge\xe7iş sağlar."},"glm-4.5-airx":{"description":"GLM-4.5-Air\'in ultra hızlı versiyonu olup daha hızlı yanıt s\xfcresi sunar ve b\xfcy\xfck \xf6l\xe7ekli y\xfcksek hız gereksinimleri i\xe7in tasarlanmıştır."},"glm-4.5-flash":{"description":"GLM-4.5\'in \xfccretsiz versiyonu olup \xe7ıkarım, kodlama ve ajan g\xf6revlerinde \xfcst\xfcn performans g\xf6sterir."},"glm-4.5-x":{"description":"GLM-4.5\'in ultra hızlı versiyonu olup g\xfc\xe7l\xfc performansla birlikte saniyede 100 token \xfcretim hızına ulaşır."},"glm-4.5v":{"description":"Zhipu\'nun MOE mimarisine dayanan yeni nesil g\xf6rsel akıl y\xfcr\xfctme modeli; 106B toplam parametreye ve 12B aktif parametreye sahip olup \xe7eşitli kıyaslama testlerinde aynı seviyedeki a\xe7ık kaynaklı \xe7ok modlu modeller arasında d\xfcnya \xe7apında SOTA\'ya ulaşır; g\xf6r\xfcnt\xfc, video, belge anlama ve GUI g\xf6revleri gibi yaygın g\xf6revleri kapsar."},"glm-4.6":{"description":"Zhipu\'nun en yeni amiral gemisi modeli GLM-4.6 (355B), gelişmiş kodlama, uzun metin işleme, \xe7ıkarım ve ajan yeteneklerinde \xf6nceki nesli tamamen aşar, \xf6zellikle programlama yeteneklerinde Claude Sonnet 4 ile hizalanarak \xfclkenin en iyi Kodlama modeli olur."},"glm-4v":{"description":"GLM-4V, g\xfc\xe7l\xfc g\xf6r\xfcnt\xfc anlama ve akıl y\xfcr\xfctme yetenekleri sunar, \xe7eşitli g\xf6rsel g\xf6revleri destekler."},"glm-4v-flash":{"description":"GLM-4V-Flash, hızlı g\xf6rsel analiz veya toplu g\xf6rsel işleme gibi sahnelerde, tek bir g\xf6r\xfcnt\xfc anlayışına odaklanarak etkili bir performans sunar."},"glm-4v-plus":{"description":"GLM-4V-Plus, video i\xe7eriği ve \xe7oklu g\xf6r\xfcnt\xfcleri anlama yeteneğine sahiptir, \xe7ok modlu g\xf6revler i\xe7in uygundur."},"glm-4v-plus-0111":{"description":"GLM-4V-Plus, video i\xe7eriği ve \xe7oklu g\xf6r\xfcnt\xfcleri anlama yeteneğine sahiptir, \xe7ok modlu g\xf6revler i\xe7in uygundur."},"glm-z1-air":{"description":"\xc7ıkarım modeli: G\xfc\xe7l\xfc \xe7ıkarım yeteneklerine sahiptir, derin \xe7ıkarım gerektiren g\xf6revler i\xe7in uygundur."},"glm-z1-airx":{"description":"Hızlı \xe7ıkarım: S\xfcper hızlı \xe7ıkarım hızı ve g\xfc\xe7l\xfc \xe7ıkarım etkisi sunar."},"glm-z1-flash":{"description":"GLM-Z1 serisi, karmaşık \xe7ıkarım yeteneklerine sahiptir ve mantıksal \xe7ıkarım, matematik, programlama gibi alanlarda \xfcst\xfcn performans g\xf6sterir."},"glm-z1-flashx":{"description":"Y\xfcksek hız ve d\xfcş\xfck maliyet: Flash geliştirilmiş versiyon, ultra hızlı \xe7ıkarım hızı ve daha hızlı eşzamanlılık garantisi sunar."},"glm-zero-preview":{"description":"GLM-Zero-Preview, karmaşık akıl y\xfcr\xfctme yeteneklerine sahip olup, mantıksal akıl y\xfcr\xfctme, matematik, programlama gibi alanlarda m\xfckemmel performans sergilemektedir."},"google/gemini-2.0-flash":{"description":"Gemini 2.0 Flash, \xfcst\xfcn hız, yerleşik ara\xe7 kullanımı, \xe7ok modlu \xfcretim ve 1 milyon token bağlam penceresi dahil olmak \xfczere yeni nesil \xf6zellikler ve geliştirmeler sunar."},"google/gemini-2.0-flash-001":{"description":"Gemini 2.0 Flash, m\xfckemmel hız, yerel ara\xe7 kullanımı, \xe7ok modlu \xfcretim ve 1M token bağlam penceresi dahil olmak \xfczere bir sonraki nesil \xf6zellikler ve iyileştirmeler sunar."},"google/gemini-2.0-flash-exp:free":{"description":"Gemini 2.0 Flash Deneysel, Google\'ın en yeni deneysel \xe7ok modlu AI modelidir ve \xf6nceki s\xfcr\xfcmlere g\xf6re belirli bir kalite artışı sağlamaktadır, \xf6zellikle d\xfcnya bilgisi, kod ve uzun bağlam i\xe7in."},"google/gemini-2.0-flash-lite":{"description":"Gemini 2.0 Flash Lite, \xfcst\xfcn hız, yerleşik ara\xe7 kullanımı, \xe7ok modlu \xfcretim ve 1 milyon token bağlam penceresi dahil olmak \xfczere yeni nesil \xf6zellikler ve geliştirmeler sunar."},"google/gemini-2.5-flash":{"description":"Gemini 2.5 Flash, kapsamlı yetenekler sunan d\xfcş\xfcnme modelidir. Fiyat ve performans arasında denge kurmayı ama\xe7lar, \xe7ok modlu ve 1 milyon token bağlam penceresini destekler."},"google/gemini-2.5-flash-image-preview":{"description":"Gemini 2.5 Flash deneysel modeli, g\xf6r\xfcnt\xfc oluşturmayı destekler."},"google/gemini-2.5-flash-lite":{"description":"Gemini 2.5 Flash-Lite, dengeli, d\xfcş\xfck gecikmeli bir model olup, yapılandırılabilir d\xfcş\xfcnme b\xfct\xe7esi ve ara\xe7 bağlantısı (\xf6rneğin Google Arama temelli ve kod y\xfcr\xfctme) sunar. \xc7ok modlu girişi destekler ve 1 milyon token bağlam penceresi sağlar."},"google/gemini-2.5-flash-preview":{"description":"Gemini 2.5 Flash, Google\'ın en gelişmiş ana modelidir ve ileri d\xfczey akıl y\xfcr\xfctme, kodlama, matematik ve bilimsel g\xf6revler i\xe7in tasarlanmıştır. Daha y\xfcksek doğruluk ve ayrıntılı bağlam işleme ile yanıtlar sunabilen yerleşik \'d\xfcş\xfcnme\' yeteneğine sahiptir.\\n\\nNot: Bu modelin iki varyantı vardır: d\xfcş\xfcnme ve d\xfcş\xfcnmeme. \xc7ıktı fiyatlandırması, d\xfcş\xfcnme yeteneğinin etkin olup olmamasına g\xf6re \xf6nemli \xf6l\xe7\xfcde farklılık g\xf6sterir. Standart varyantı (\':thinking\' eki olmadan) se\xe7erseniz, model a\xe7ık\xe7a d\xfcş\xfcnme tokenleri \xfcretmekten ka\xe7ınacaktır.\\n\\nD\xfcş\xfcnme yeteneğinden yararlanmak ve d\xfcş\xfcnme tokenleri almak i\xe7in, \':thinking\' varyantını se\xe7melisiniz; bu, daha y\xfcksek d\xfcş\xfcnme \xe7ıktı fiyatlandırması ile sonu\xe7lanacaktır.\\n\\nAyrıca, Gemini 2.5 Flash, belgede belirtildiği gibi \'akıl y\xfcr\xfctme maksimum token sayısı\' parametresi ile yapılandırılabilir (https://openrouter.ai/docs/use-cases/reasoning-tokens#max-tokens-for-reasoning)."},"google/gemini-2.5-flash-preview:thinking":{"description":"Gemini 2.5 Flash, Google\'ın en gelişmiş ana modelidir ve ileri d\xfczey akıl y\xfcr\xfctme, kodlama, matematik ve bilimsel g\xf6revler i\xe7in tasarlanmıştır. Daha y\xfcksek doğruluk ve ayrıntılı bağlam işleme ile yanıtlar sunabilen yerleşik \'d\xfcş\xfcnme\' yeteneğine sahiptir.\\n\\nNot: Bu modelin iki varyantı vardır: d\xfcş\xfcnme ve d\xfcş\xfcnmeme. \xc7ıktı fiyatlandırması, d\xfcş\xfcnme yeteneğinin etkin olup olmamasına g\xf6re \xf6nemli \xf6l\xe7\xfcde farklılık g\xf6sterir. Standart varyantı (\':thinking\' eki olmadan) se\xe7erseniz, model a\xe7ık\xe7a d\xfcş\xfcnme tokenleri \xfcretmekten ka\xe7ınacaktır.\\n\\nD\xfcş\xfcnme yeteneğinden yararlanmak ve d\xfcş\xfcnme tokenleri almak i\xe7in, \':thinking\' varyantını se\xe7melisiniz; bu, daha y\xfcksek d\xfcş\xfcnme \xe7ıktı fiyatlandırması ile sonu\xe7lanacaktır.\\n\\nAyrıca, Gemini 2.5 Flash, belgede belirtildiği gibi \'akıl y\xfcr\xfctme maksimum token sayısı\' parametresi ile yapılandırılabilir (https://openrouter.ai/docs/use-cases/reasoning-tokens#max-tokens-for-reasoning)."},"google/gemini-2.5-pro":{"description":"Gemini 2.5 Pro, karmaşık problemleri \xe7\xf6zebilen en gelişmiş \xe7ıkarım Gemini modelimizdir. 2 milyon token bağlam penceresine sahiptir ve metin, g\xf6r\xfcnt\xfc, ses, video ve PDF belgeleri dahil \xe7ok modlu girişleri destekler."},"google/gemini-2.5-pro-preview":{"description":"Gemini 2.5 Pro \xd6nizlemesi, Google\'ın en gelişmiş d\xfcş\xfcnce modeli olup, kodlama, matematik ve STEM alanlarındaki karmaşık sorunları \xe7\xf6zme yeteneğine sahiptir ve uzun bağlam kullanarak b\xfcy\xfck veri setleri, kod tabanları ve belgeleri analiz edebilir."},"google/gemini-embedding-001":{"description":"İngilizce, \xe7ok dilli ve kod g\xf6revlerinde \xfcst\xfcn performans sunan en gelişmiş g\xf6mme modeli."},"google/gemini-flash-1.5":{"description":"Gemini 1.5 Flash, optimize edilmiş \xe7ok modlu işleme yetenekleri sunar ve \xe7eşitli karmaşık g\xf6rev senaryolarına uygundur."},"google/gemini-pro-1.5":{"description":"Gemini 1.5 Pro, en son optimize edilmiş teknolojileri birleştirerek daha verimli \xe7ok modlu veri işleme yetenekleri sunar."},"google/gemma-2-27b":{"description":"Gemma 2, Google tarafından sunulan verimli bir modeldir, k\xfc\xe7\xfck uygulamalardan karmaşık veri işleme senaryolarına kadar \xe7eşitli uygulama alanlarını kapsar."},"google/gemma-2-27b-it":{"description":"Gemma 2, hafiflik ve verimlilik tasarım felsefesini s\xfcrd\xfcrmektedir."},"google/gemma-2-2b-it":{"description":"Google\'ın hafif talimat ayarlama modeli"},"google/gemma-2-9b":{"description":"Gemma 2, Google tarafından sunulan verimli bir modeldir, k\xfc\xe7\xfck uygulamalardan karmaşık veri işleme senaryolarına kadar \xe7eşitli uygulama alanlarını kapsar."},"google/gemma-2-9b-it":{"description":"Gemma 2, Google\'ın hafif a\xe7ık kaynak metin modeli serisidir."},"google/gemma-2-9b-it:free":{"description":"Gemma 2, Google\'ın hafif a\xe7ık kaynak metin modeli serisidir."},"google/gemma-2b-it":{"description":"Gemma Instruct (2B), temel talimat işleme yetenekleri sunar ve hafif uygulamalar i\xe7in uygundur."},"google/gemma-3-12b-it":{"description":"Gemma 3 12B, Google tarafından geliştirilen a\xe7ık kaynaklı bir dil modelidir ve verimlilik ile performansta yeni standartlar belirlemiştir."},"google/gemma-3-27b-it":{"description":"Gemma 3 27B, Google\'ın verimlilik ve performans a\xe7ısından yeni standartlar belirleyen a\xe7ık kaynaklı bir dil modelidir."},"google/text-embedding-005":{"description":"Kod ve İngilizce dil g\xf6revleri i\xe7in optimize edilmiş İngilizce odaklı metin g\xf6mme modeli."},"google/text-multilingual-embedding-002":{"description":"\xc7oklu dil g\xf6revleri i\xe7in optimize edilmiş \xe7ok dilli metin g\xf6mme modeli, bir\xe7ok dili destekler."},"gpt-3.5-turbo":{"description":"GPT 3.5 Turbo, \xe7eşitli metin \xfcretimi ve anlama g\xf6revleri i\xe7in uygundur, şu anda gpt-3.5-turbo-0125\'e işaret ediyor."},"gpt-3.5-turbo-0125":{"description":"GPT 3.5 Turbo, \xe7eşitli metin \xfcretimi ve anlama g\xf6revleri i\xe7in uygundur, şu anda gpt-3.5-turbo-0125\'e işaret ediyor."},"gpt-3.5-turbo-1106":{"description":"GPT 3.5 Turbo, \xe7eşitli metin \xfcretimi ve anlama g\xf6revleri i\xe7in uygundur, şu anda gpt-3.5-turbo-0125\'e işaret ediyor."},"gpt-3.5-turbo-instruct":{"description":"GPT 3.5 Turbo, \xe7eşitli metin \xfcretimi ve anlama g\xf6revleri i\xe7in uygundur, şu anda gpt-3.5-turbo-0125\'e işaret ediyor."},"gpt-35-turbo":{"description":"GPT 3.5 Turbo, OpenAI tarafından sağlanan verimli bir modeldir ve sohbet ve metin \xfcretim g\xf6revleri i\xe7in uygundur, paralel fonksiyon \xe7ağrılarını destekler."},"gpt-35-turbo-16k":{"description":"GPT 3.5 Turbo 16k, karmaşık g\xf6revler i\xe7in uygun y\xfcksek kapasiteli bir metin \xfcretim modelidir."},"gpt-4":{"description":"GPT-4, daha b\xfcy\xfck bir bağlam penceresi sunarak daha uzun metin girişlerini işleyebilir, geniş bilgi entegrasyonu ve veri analizi gerektiren senaryolar i\xe7in uygundur."},"gpt-4-0125-preview":{"description":"En son GPT-4 Turbo modeli g\xf6rsel işlevselliğe sahiptir. Artık g\xf6rsel talepler JSON formatı ve fonksiyon \xe7ağrıları ile işlenebilir. GPT-4 Turbo, \xe7ok modlu g\xf6revler i\xe7in maliyet etkin bir destek sunan geliştirilmiş bir versiyondur. Doğruluk ve verimlilik arasında bir denge sağlar, ger\xe7ek zamanlı etkileşim gerektiren uygulama senaryoları i\xe7in uygundur."},"gpt-4-0613":{"description":"GPT-4, daha b\xfcy\xfck bir bağlam penceresi sunarak daha uzun metin girişlerini işleyebilir, geniş bilgi entegrasyonu ve veri analizi gerektiren senaryolar i\xe7in uygundur."},"gpt-4-1106-preview":{"description":"En son GPT-4 Turbo modeli g\xf6rsel işlevselliğe sahiptir. Artık g\xf6rsel talepler JSON formatı ve fonksiyon \xe7ağrıları ile işlenebilir. GPT-4 Turbo, \xe7ok modlu g\xf6revler i\xe7in maliyet etkin bir destek sunan geliştirilmiş bir versiyondur. Doğruluk ve verimlilik arasında bir denge sağlar, ger\xe7ek zamanlı etkileşim gerektiren uygulama senaryoları i\xe7in uygundur."},"gpt-4-32k":{"description":"GPT-4, daha b\xfcy\xfck bir bağlam penceresi sunarak daha uzun metin girişlerini işleyebilir, geniş bilgi entegrasyonu ve veri analizi gerektiren senaryolar i\xe7in uygundur."},"gpt-4-32k-0613":{"description":"GPT-4, daha b\xfcy\xfck bir bağlam penceresi sunarak daha uzun metin girişlerini işleyebilir, geniş bilgi entegrasyonu ve veri analizi gerektiren senaryolar i\xe7in uygundur."},"gpt-4-turbo":{"description":"En son GPT-4 Turbo modeli g\xf6rsel işlevselliğe sahiptir. Artık g\xf6rsel talepler JSON formatı ve fonksiyon \xe7ağrıları ile işlenebilir. GPT-4 Turbo, \xe7ok modlu g\xf6revler i\xe7in maliyet etkin bir destek sunan geliştirilmiş bir versiyondur. Doğruluk ve verimlilik arasında bir denge sağlar, ger\xe7ek zamanlı etkileşim gerektiren uygulama senaryoları i\xe7in uygundur."},"gpt-4-turbo-2024-04-09":{"description":"En son GPT-4 Turbo modeli g\xf6rsel işlevselliğe sahiptir. Artık g\xf6rsel talepler JSON formatı ve fonksiyon \xe7ağrıları ile işlenebilir. GPT-4 Turbo, \xe7ok modlu g\xf6revler i\xe7in maliyet etkin bir destek sunan geliştirilmiş bir versiyondur. Doğruluk ve verimlilik arasında bir denge sağlar, ger\xe7ek zamanlı etkileşim gerektiren uygulama senaryoları i\xe7in uygundur."},"gpt-4-turbo-preview":{"description":"En son GPT-4 Turbo modeli g\xf6rsel işlevselliğe sahiptir. Artık g\xf6rsel talepler JSON formatı ve fonksiyon \xe7ağrıları ile işlenebilir. GPT-4 Turbo, \xe7ok modlu g\xf6revler i\xe7in maliyet etkin bir destek sunan geliştirilmiş bir versiyondur. Doğruluk ve verimlilik arasında bir denge sağlar, ger\xe7ek zamanlı etkileşim gerektiren uygulama senaryoları i\xe7in uygundur."},"gpt-4-vision-preview":{"description":"En son GPT-4 Turbo modeli g\xf6rsel işlevselliğe sahiptir. Artık g\xf6rsel talepler JSON formatı ve fonksiyon \xe7ağrıları ile işlenebilir. GPT-4 Turbo, \xe7ok modlu g\xf6revler i\xe7in maliyet etkin bir destek sunan geliştirilmiş bir versiyondur. Doğruluk ve verimlilik arasında bir denge sağlar, ger\xe7ek zamanlı etkileşim gerektiren uygulama senaryoları i\xe7in uygundur."},"gpt-4.1":{"description":"GPT-4.1, karmaşık g\xf6revler i\xe7in kullandığımız amiral gemisi modelidir. Farklı alanlarda sorunları \xe7\xf6zmek i\xe7in son derece uygundur."},"gpt-4.1-mini":{"description":"GPT-4.1 mini, zeka, hız ve maliyet arasında bir denge sunarak bir\xe7ok kullanım durumu i\xe7in \xe7ekici bir model haline getirir."},"gpt-4.1-nano":{"description":"GPT-4.1 mini, zeka, hız ve maliyet arasında bir denge sunarak bir\xe7ok kullanım durumu i\xe7in \xe7ekici bir model haline getirir."},"gpt-4.5-preview":{"description":"GPT-4.5-preview, kapsamlı d\xfcnya bilgisine ve kullanıcı niyetlerini daha iyi anlama yeteneğine sahip en yeni genel ama\xe7lı modeldir; yaratıcı g\xf6revler ve ajan planlaması konusunda uzmandır. Modelin bilgi kesiti Ekim 2023\'t\xfcr."},"gpt-4o":{"description":"ChatGPT-4o, g\xfcncel versiyonunu korumak i\xe7in ger\xe7ek zamanlı olarak g\xfcncellenen dinamik bir modeldir. G\xfc\xe7l\xfc dil anlama ve \xfcretme yeteneklerini birleştirir, m\xfcşteri hizmetleri, eğitim ve teknik destek gibi geniş \xf6l\xe7ekli uygulama senaryoları i\xe7in uygundur."},"gpt-4o-2024-05-13":{"description":"ChatGPT-4o, g\xfcncel versiyonunu korumak i\xe7in ger\xe7ek zamanlı olarak g\xfcncellenen dinamik bir modeldir. G\xfc\xe7l\xfc dil anlama ve \xfcretme yeteneklerini birleştirir, m\xfcşteri hizmetleri, eğitim ve teknik destek gibi geniş \xf6l\xe7ekli uygulama senaryoları i\xe7in uygundur."},"gpt-4o-2024-08-06":{"description":"ChatGPT-4o, g\xfcncel versiyonunu korumak i\xe7in ger\xe7ek zamanlı olarak g\xfcncellenen dinamik bir modeldir. G\xfc\xe7l\xfc dil anlama ve \xfcretme yeteneklerini birleştirir, m\xfcşteri hizmetleri, eğitim ve teknik destek gibi geniş \xf6l\xe7ekli uygulama senaryoları i\xe7in uygundur."},"gpt-4o-2024-11-20":{"description":"ChatGPT-4o, g\xfcncel en son s\xfcr\xfcm\xfc korumak i\xe7in ger\xe7ek zamanlı olarak g\xfcncellenen dinamik bir modeldir. M\xfcşteri hizmetleri, eğitim ve teknik destek gibi b\xfcy\xfck \xf6l\xe7ekli uygulama senaryoları i\xe7in g\xfc\xe7l\xfc dil anlama ve \xfcretme yeteneklerini bir araya getirir."},"gpt-4o-audio-preview":{"description":"Ses giriş ve \xe7ıkışını destekleyen GPT-4o Ses \xd6nizleme modeli"},"gpt-4o-mini":{"description":"GPT-4o mini, OpenAI\'nin GPT-4 Omni\'den sonra tanıttığı en yeni modeldir. G\xf6rsel ve metin girişi destekler ve metin \xe7ıktısı verir. En gelişmiş k\xfc\xe7\xfck model olarak, diğer son zamanlardaki \xf6nc\xfc modellere g\xf6re \xe7ok daha ucuzdur ve GPT-3.5 Turbo\'dan %60\'tan fazla daha ucuzdur. En son teknolojiyi korurken, \xf6nemli bir maliyet etkinliği sunar. GPT-4o mini, MMLU testinde %82 puan almış olup, şu anda sohbet tercihleri a\xe7ısından GPT-4\'\xfcn \xfczerinde yer almaktadır."},"gpt-4o-mini-audio-preview":{"description":"GPT-4o mini Ses modeli, sesli giriş ve \xe7ıkışı destekler."},"gpt-4o-mini-realtime-preview":{"description":"GPT-4o-mini ger\xe7ek zamanlı versiyonu, ses ve metin i\xe7in ger\xe7ek zamanlı giriş ve \xe7ıkış desteği sunar."},"gpt-4o-mini-search-preview":{"description":"GPT-4o mini arama \xf6nizleme s\xfcr\xfcm\xfc, web arama sorgularını anlama ve y\xfcr\xfctme i\xe7in \xf6zel olarak eğitilmiş bir modeldir ve Chat Completions API kullanır. Jeton \xfccretlerinin yanı sıra, web arama sorguları her ara\xe7 \xe7ağrısı başına \xfccretlendirilir."},"gpt-4o-mini-transcribe":{"description":"GPT-4o Mini Transcribe, GPT-4o kullanarak sesleri metne d\xf6n\xfcşt\xfcren bir konuşma tanıma modelidir. Orijinal Whisper modeline kıyasla kelime hata oranını d\xfcş\xfcr\xfcr ve dil tanıma ile doğruluğu artırır. Daha doğru transkripsiyonlar i\xe7in kullanın."},"gpt-4o-mini-tts":{"description":"GPT-4o mini TTS, GPT-4o mini\'ye dayalı bir metin-ses modeldir ve y\xfcksek kaliteli ses \xfcretimi, d\xfcş\xfck maliyetli oluşturma sunar."},"gpt-4o-realtime-preview":{"description":"GPT-4o ger\xe7ek zamanlı versiyonu, ses ve metin i\xe7in ger\xe7ek zamanlı giriş ve \xe7ıkış desteği sunar."},"gpt-4o-realtime-preview-2024-10-01":{"description":"GPT-4o ger\xe7ek zamanlı versiyonu, ses ve metin i\xe7in ger\xe7ek zamanlı giriş ve \xe7ıkış desteği sunar."},"gpt-4o-realtime-preview-2025-06-03":{"description":"GPT-4o ger\xe7ek zamanlı s\xfcr\xfcm\xfc, ses ve metin giriş-\xe7ıkışını ger\xe7ek zamanlı destekler."},"gpt-4o-search-preview":{"description":"GPT-4o arama \xf6nizleme s\xfcr\xfcm\xfc, web arama sorgularını anlama ve y\xfcr\xfctme i\xe7in \xf6zel olarak eğitilmiş bir modeldir ve Chat Completions API kullanır. Jeton \xfccretlerinin yanı sıra, web arama sorguları her ara\xe7 \xe7ağrısı başına \xfccretlendirilir."},"gpt-4o-transcribe":{"description":"GPT-4o Transcribe, GPT-4o kullanarak sesleri metne d\xf6n\xfcşt\xfcren bir konuşma tanıma modelidir. Orijinal Whisper modeline kıyasla kelime hata oranını d\xfcş\xfcr\xfcr ve dil tanıma ile doğruluğu artırır. Daha doğru transkripsiyonlar i\xe7in kullanın."},"gpt-5":{"description":"\xc7apraz alan kodlama ve temsil g\xf6revleri i\xe7in en iyi model. GPT-5, doğruluk, hız, akıl y\xfcr\xfctme, bağlam tanıma, yapısal d\xfcş\xfcnme ve problem \xe7\xf6zmede b\xfcy\xfck ilerleme kaydetti."},"gpt-5-chat":{"description":"GPT-5 Chat, diyalog senaryoları i\xe7in optimize edilmiş bir \xf6nizleme s\xfcr\xfcm\xfcd\xfcr. Metin ve g\xf6rsel girişi destekler, yalnızca metin \xe7ıktısı verir; sohbet robotları ve diyalog tabanlı yapay zeka uygulamaları i\xe7in uygundur."},"gpt-5-chat-latest":{"description":"ChatGPT\'de kullanılan GPT-5 modeli. G\xfc\xe7l\xfc dil anlama ve \xfcretme yeteneklerini birleştirerek diyalog tabanlı etkileşim uygulamaları i\xe7in uygundur."},"gpt-5-codex":{"description":"GPT-5 Codex, Codex veya benzeri ortamlardaki ajan kodlama g\xf6revleri i\xe7in optimize edilmiş GPT-5 versiyonudur."},"gpt-5-mini":{"description":"Daha hızlı ve ekonomik GPT-5 versiyonu, belirgin tanımlı g\xf6revler i\xe7in uygundur. Y\xfcksek kaliteli \xe7ıktıyı korurken daha hızlı yanıt sağlar."},"gpt-5-nano":{"description":"En hızlı ve en ekonomik GPT-5 versiyonu. Hızlı yanıt gerektiren ve maliyet duyarlı uygulamalar i\xe7in idealdir."},"gpt-5-pro":{"description":"GPT-5 pro, daha derin d\xfcş\xfcnme i\xe7in daha fazla hesaplama g\xfcc\xfc kullanır ve s\xfcrekli olarak daha iyi yanıtlar sunar."},"gpt-5.1":{"description":"GPT-5.1 — Kodlama ve ajan g\xf6revleri i\xe7in optimize edilmiş amiral gemisi modelidir; yapılandırılabilir akıl y\xfcr\xfctme g\xfcc\xfc ve daha uzun bağlam desteği sunar."},"gpt-5.1-chat-latest":{"description":"GPT-5.1 Chat: Sohbet senaryoları i\xe7in uygun, ChatGPT’ye \xf6zel GPT-5.1 varyantı."},"gpt-5.1-codex":{"description":"GPT-5.1 Codex: Ajan tabanlı kodlama g\xf6revleri i\xe7in optimize edilmiş GPT-5.1 s\xfcr\xfcm\xfcd\xfcr; daha karmaşık kod/ajan iş akışları i\xe7in Responses API ile kullanılabilir."},"gpt-5.1-codex-mini":{"description":"GPT-5.1 Codex mini: Daha k\xfc\xe7\xfck boyutlu ve daha d\xfcş\xfck maliyetli Codex varyantı; ajan tabanlı kodlama g\xf6revleri i\xe7in optimize edilmiştir."},"gpt-audio":{"description":"GPT Audio, ses giriş ve \xe7ıkışına y\xf6nelik genel sohbet modelidir ve Chat Completions API’de ses I/O kullanımını destekler."},"gpt-image-1":{"description":"ChatGPT\'nin yerel \xe7ok modlu g\xf6r\xfcnt\xfc oluşturma modeli"},"gpt-image-1-mini":{"description":"Daha d\xfcş\xfck maliyetli bir GPT Image 1 s\xfcr\xfcm\xfcd\xfcr, metin ve g\xf6rsel girdilerini doğal olarak destekler ve g\xf6rsel \xe7ıktılar \xfcretebilir."},"gpt-oss-120b":{"description":"Bu modelin kullanımı i\xe7in başvuru gereklidir. GPT-OSS-120B, OpenAI tarafından geliştirilen a\xe7ık kaynaklı b\xfcy\xfck \xf6l\xe7ekli bir dil modelidir ve g\xfc\xe7l\xfc metin \xfcretme yeteneklerine sahiptir."},"gpt-oss-20b":{"description":"Bu modelin kullanımı i\xe7in başvuru gereklidir. GPT-OSS-20B, OpenAI tarafından geliştirilen a\xe7ık kaynaklı orta \xf6l\xe7ekli bir dil modelidir ve verimli metin \xfcretme yeteneklerine sahiptir."},"gpt-oss:120b":{"description":"GPT-OSS 120B, OpenAI tarafından yayımlanan b\xfcy\xfck \xf6l\xe7ekli a\xe7ık kaynak dil modelidir ve MXFP4 kuantizasyon teknolojisini kullanır. Amiral gemisi model olarak \xe7oklu GPU veya y\xfcksek performanslı iş istasyonu ortamlarında \xe7alıştırılması gerekmektedir. Karmaşık \xe7ıkarım, kod \xfcretimi ve \xe7ok dilli işleme konularında \xfcst\xfcn performans sunar ve gelişmiş fonksiyon \xe7ağrıları ile ara\xe7 entegrasyonunu destekler."},"gpt-oss:20b":{"description":"GPT-OSS 20B, OpenAI tarafından yayınlanan a\xe7ık kaynaklı b\xfcy\xfck dil modelidir. MXFP4 kuantizasyon teknolojisi kullanır ve \xfcst d\xfczey t\xfcketici sınıfı GPU’lar veya Apple Silicon Mac \xfczerinde \xe7alışmaya uygundur. Model, diyalog \xfcretimi, kod yazımı ve \xe7ıkarım g\xf6revlerinde \xfcst\xfcn performans sergiler, fonksiyon \xe7ağrısı ve ara\xe7 kullanımını destekler."},"gpt-realtime":{"description":"Metin ve sesin ger\xe7ek zamanlı giriş ve \xe7ıkışını destekleyen genel ama\xe7lı ger\xe7ek zamanlı model, ayrıca g\xf6r\xfcnt\xfc girişini de destekler."},"grok-2-image-1212":{"description":"En yeni g\xf6r\xfcnt\xfc oluşturma modelimiz, metin istemlerine dayanarak canlı ve ger\xe7ek\xe7i g\xf6r\xfcnt\xfcler oluşturabilir. Pazarlama, sosyal medya ve eğlence gibi alanlarda g\xf6r\xfcnt\xfc \xfcretiminde m\xfckemmel performans sergiler."},"grok-2-vision-1212":{"description":"Bu model, doğruluk, talimat takibi ve \xe7ok dilli yetenekler a\xe7ısından geliştirilmiştir."},"grok-3":{"description":"Amiral gemisi model olup, veri \xe7ıkarımı, programlama ve metin \xf6zetleme gibi kurumsal uygulamalarda uzmandır; finans, sağlık, hukuk ve bilim alanlarında derin bilgiye sahiptir."},"grok-3-mini":{"description":"Hafif model olup, konuşma \xf6ncesi d\xfcş\xfcn\xfcr. Hızlı ve akıllı \xe7alışır, derin alan bilgisi gerektirmeyen mantıksal g\xf6revler i\xe7in uygundur ve orijinal d\xfcş\xfcnce izlerini elde edebilir."},"grok-4":{"description":"En yeni ve en g\xfc\xe7l\xfc amiral gemisi modelimiz, doğal dil işleme, matematiksel hesaplama ve akıl y\xfcr\xfctme alanlarında \xfcst\xfcn performans sergiliyor — m\xfckemmel bir \xe7ok y\xf6nl\xfc oyuncu."},"grok-4-0709":{"description":"xAI\'nin Grok 4 modeli, g\xfc\xe7l\xfc akıl y\xfcr\xfctme yeteneklerine sahiptir."},"grok-4-1-fast-non-reasoning":{"description":"Y\xfcksek performanslı aracı ara\xe7 \xe7ağrıları i\xe7in \xf6zel olarak optimize edilmiş, son teknoloji \xe7ok modlu model."},"grok-4-1-fast-reasoning":{"description":"Y\xfcksek performanslı aracı ara\xe7 \xe7ağrıları i\xe7in \xf6zel olarak optimize edilmiş, son teknoloji \xe7ok modlu model."},"grok-4-fast-non-reasoning":{"description":"Maliyet-etkin \xe7ıkarım modellerinde en son gelişmemiz olan Grok 4 Fast’i sunmaktan mutluluk duyuyoruz."},"grok-4-fast-reasoning":{"description":"Maliyet-etkin \xe7ıkarım modellerinde en son gelişmemiz olan Grok 4 Fast’i sunmaktan mutluluk duyuyoruz."},"grok-code-fast-1":{"description":"Hızlı ve ekonomik bir \xe7ıkarım modeli olan grok-code-fast-1\'i sunmaktan mutluluk duyuyoruz; ajan kodlamasında m\xfckemmel performans sergiler."},"groq/compound":{"description":"Compound, GroqCloud’da desteklenen birden fazla a\xe7ık erişimli model tarafından desteklenen birleşik bir yapay zeka sistemidir ve kullanıcı sorgularını yanıtlamak i\xe7in ara\xe7ları akıllıca ve se\xe7ici şekilde kullanabilir."},"groq/compound-mini":{"description":"Compound-mini, GroqCloud’da desteklenen a\xe7ık erişimli modeller tarafından desteklenen birleşik bir yapay zeka sistemidir ve kullanıcı sorgularını yanıtlamak i\xe7in ara\xe7ları akıllıca ve se\xe7ici şekilde kullanabilir."},"gryphe/mythomax-l2-13b":{"description":"MythoMax l2 13B, birden fazla \xfcst d\xfczey modelin birleşimiyle yaratıcı ve zeka odaklı bir dil modelidir."},"hunyuan-a13b":{"description":"Hunyuan\'ın ilk karma akıl y\xfcr\xfctme modeli olan hunyuan-standard-256K\'nın y\xfckseltilmiş versiyonu, toplam 80 milyar parametre ve 13 milyar parametre aktive eder. Varsayılan olarak yavaş d\xfcş\xfcnme modundadır ve parametre veya komut yoluyla hızlı ve yavaş d\xfcş\xfcnme modları arasında ge\xe7işi destekler; hızlı/yavaş d\xfcş\xfcnme ge\xe7işi i\xe7in sorguya / no_think eklenir. Genel yetenekler \xf6nceki nesle g\xf6re kapsamlı şekilde geliştirilmiş olup, \xf6zellikle matematik, bilim, uzun metin anlama ve ajan yeteneklerinde belirgin artışlar vardır."},"hunyuan-code":{"description":"Hunyuan\'ın en son kod oluşturma modeli, 200B y\xfcksek kaliteli kod verisi ile artırılmış temel model ile altı ay boyunca y\xfcksek kaliteli SFT verisi eğitimi almıştır. Bağlam penceresi uzunluğu 8K\'ya \xe7ıkarılmıştır ve beş b\xfcy\xfck dil i\xe7in kod oluşturma otomatik değerlendirme g\xf6stergelerinde \xf6n sıralardadır; beş b\xfcy\xfck dilde 10 kriterin her y\xf6n\xfcyle y\xfcksek kaliteli değerlendirmelerde performansı birinci sıradadır."},"hunyuan-functioncall":{"description":"Hunyuan\'ın en son MOE mimarisi FunctionCall modeli, y\xfcksek kaliteli FunctionCall verisi ile eğitilmiş olup, bağlam penceresi 32K\'ya ulaşmıştır ve bir\xe7ok boyutta değerlendirme g\xf6stergelerinde lider konumdadır."},"hunyuan-large":{"description":"Hunyuan-large modelinin toplam parametre sayısı yaklaşık 389B, etkin parametre sayısı yaklaşık 52B\'dir; bu, mevcut end\xfcstrideki en b\xfcy\xfck parametre \xf6l\xe7eğine sahip ve en iyi performansı g\xf6steren Transformer mimarisinin a\xe7ık kaynaklı MoE modelidir."},"hunyuan-large-longcontext":{"description":"Uzun metin g\xf6revlerini, \xf6rneğin belge \xf6zeti ve belge sorgulama gibi, işleme konusunda uzmandır; aynı zamanda genel metin oluşturma g\xf6revlerini de yerine getirme yeteneğine sahiptir. Uzun metinlerin analizi ve oluşturulmasında m\xfckemmel bir performans sergiler, karmaşık ve ayrıntılı uzun metin i\xe7erik işleme ihtiya\xe7larına etkili bir şekilde yanıt verebilir."},"hunyuan-large-vision":{"description":"Bu model, g\xf6rsel ve metin anlama senaryoları i\xe7in uygundur. Hunyuan Large tabanlı g\xf6rsel-dil b\xfcy\xfck modelidir, herhangi bir \xe7\xf6z\xfcn\xfcrl\xfckte \xe7oklu resim ve metin girişini destekler, metin \xfcretir, g\xf6rsel-metinsel anlama g\xf6revlerine odaklanır ve \xe7ok dilli g\xf6rsel-metinsel anlama yeteneğinde belirgin gelişme sağlar."},"hunyuan-lite":{"description":"MOE yapısına y\xfckseltilmiş, bağlam penceresi 256k, NLP, kod, matematik, end\xfcstri gibi bir\xe7ok değerlendirme setinde bir\xe7ok a\xe7ık kaynak modelden \xf6nde."},"hunyuan-lite-vision":{"description":"Hunyuan\'ın en son 7B \xe7ok modlu modeli, bağlam penceresi 32K, \xc7ince ve İngilizce senaryolarında \xe7ok modlu diyalog, g\xf6r\xfcnt\xfc nesne tanıma, belge tablo anlama, \xe7ok modlu matematik vb. destekler; bir\xe7ok boyutta değerlendirme kriterleri 7B rakip modellerden \xfcst\xfcnd\xfcr."},"hunyuan-pro":{"description":"Trilyon seviyesinde parametre \xf6l\xe7eğine sahip MOE-32K uzun metin modeli. \xc7eşitli benchmarklarda kesin bir liderlik seviyesine ulaşarak, karmaşık talimatlar ve akıl y\xfcr\xfctme yetenekleri ile karmaşık matematik yetenekleri sunar, functioncall desteği ile \xe7ok dilli \xe7eviri, finans, hukuk ve sağlık gibi alanlarda \xf6nemli optimizasyonlar sağlar."},"hunyuan-role":{"description":"Hunyuan\'ın en son rol yapma modeli, Hunyuan resmi ince ayar eğitimi ile geliştirilmiş rol yapma modelidir. Hunyuan modeli ile rol yapma senaryosu veri seti birleştirilerek artırılmıştır ve rol yapma senaryolarında daha iyi temel performans sunmaktadır."},"hunyuan-standard":{"description":"Daha iyi bir y\xf6nlendirme stratejisi kullanarak, y\xfck dengeleme ve uzman yakınsaması sorunlarını hafifletir. Uzun metinlerde, iğne arama g\xf6stergesi %99.9\'a ulaşmaktadır. MOE-32K, uzun metin girişlerini işleme yeteneği ile etki ve fiyat dengesini sağlarken, maliyet a\xe7ısından daha y\xfcksek bir değer sunar."},"hunyuan-standard-256K":{"description":"Daha iyi bir y\xf6nlendirme stratejisi kullanarak, y\xfck dengeleme ve uzman yakınsaması sorunlarını hafifletir. Uzun metinlerde, iğne arama g\xf6stergesi %99.9\'a ulaşmaktadır. MOE-256K, uzunluk ve etki a\xe7ısından daha fazla bir sı\xe7rama yaparak, girdi uzunluğunu b\xfcy\xfck \xf6l\xe7\xfcde genişletir."},"hunyuan-standard-vision":{"description":"Hunyuan\'ın en son \xe7ok modlu modeli, \xe7ok dilli yanıtları destekler, \xc7ince ve İngilizce yetenekleri dengelidir."},"hunyuan-t1-20250321":{"description":"Modelin hem fen hem de sosyal bilimler alanındaki yeteneklerini kapsamlı bir şekilde inşa eder, uzun metin bilgilerini yakalama yeteneği y\xfcksektir. Her t\xfcrl\xfc zorluktaki matematik/ mantık \xe7ıkarımı/ bilim/ kod gibi bilimsel sorunları \xe7\xf6zme yeteneğini destekler."},"hunyuan-t1-20250403":{"description":"Proje d\xfczeyinde kod \xfcretme yeteneğini artırır; metin oluşturma ve yazma kalitesini y\xfckseltir; metin anlama, \xe7ok turlu konu takibi, toB komut uyumu ve kelime-anlama yeteneklerini geliştirir; karmaşık geleneksel ve basitleştirilmiş \xc7ince ile İngilizce karışık \xe7ıktı sorunlarını optimize eder."},"hunyuan-t1-20250529":{"description":"Metin oluşturma ve kompozisyon yazımını optimize eder; kod \xf6n y\xfcz\xfc, matematik, mantıksal \xe7ıkarım gibi fen bilimleri yeteneklerini geliştirir ve talimatlara uyum yeteneğini artırır."},"hunyuan-t1-20250711":{"description":"Zorlu matematik, mantık ve kodlama yeteneklerinde b\xfcy\xfck iyileştirmeler sağlar, model \xe7ıktı kararlılığını optimize eder ve uzun metin işleme kapasitesini artırır."},"hunyuan-t1-latest":{"description":"Ana modelin yavaş d\xfcş\xfcnme modelinin y\xfcksek zorlukta matematik, karmaşık akıl y\xfcr\xfctme, zor kodlama, talimat uyumu ve metin oluşturma kalitesi gibi yeteneklerinde b\xfcy\xfck gelişmeler sağlar."},"hunyuan-t1-vision-20250619":{"description":"Hunyuan\'ın en yeni t1-vision \xe7ok modlu anlama derin d\xfcş\xfcnme modeli, \xe7ok modlu doğal d\xfcş\xfcnce zincirini destekler ve \xf6nceki nesil varsayılan modele kıyasla kapsamlı iyileştirmeler sunar."},"hunyuan-t1-vision-20250916":{"description":"Hunyuan\'ın en son s\xfcr\xfcm\xfc t1-vision, g\xf6rsel derin d\xfcş\xfcnme modeli olarak \xf6nceki versiyona kıyasla genel g\xf6rsel-s\xf6zel soru-cevap, g\xf6rsel konumlandırma, OCR, grafik yorumlama, soru \xe7\xf6zme ve g\xf6rsel yaratıcılık gibi g\xf6revlerde kapsamlı iyileştirmeler sunar. İngilizce ve az konuşulan dillerdeki performansı da belirgin şekilde geliştirilmiştir."},"hunyuan-turbo":{"description":"Hunyuan\'ın yeni nesil b\xfcy\xfck dil modelinin \xf6nizleme s\xfcr\xfcm\xfc, tamamen yeni bir karma uzman modeli (MoE) yapısı kullanır ve hunyuan-pro\'ya kıyasla daha hızlı \xe7ıkarım verimliliği ve daha g\xfc\xe7l\xfc performans sunar."},"hunyuan-turbo-20241223":{"description":"Bu s\xfcr\xfcmde yapılan optimizasyonlar: veri talimatı \xf6l\xe7eklendirme, modelin genel genelleme yeteneğini b\xfcy\xfck \xf6l\xe7\xfcde artırma; matematik, kodlama, mantıksal akıl y\xfcr\xfctme yeteneklerini b\xfcy\xfck \xf6l\xe7\xfcde artırma; metin anlama ve kelime anlama ile ilgili yetenekleri optimize etme; metin oluşturma i\xe7erik \xfcretim kalitesini optimize etme."},"hunyuan-turbo-latest":{"description":"Genel deneyim optimizasyonu, NLP anlama, metin oluşturma, sohbet, bilgi sorgulama, \xe7eviri, alan vb. dahil; insan benzeri \xf6zellikleri artırma, modelin duygusal zekasını optimize etme; niyet belirsiz olduğunda modelin aktif olarak netleştirme yeteneğini artırma; kelime ve terim analizi ile ilgili sorunların işlenme yeteneğini artırma; yaratım kalitesini ve etkileşimliğini artırma; \xe7oklu tur deneyimini geliştirme."},"hunyuan-turbo-vision":{"description":"Hunyuan\'ın yeni nesil g\xf6rsel dil amiral modeli, tamamen yeni bir karışık uzman modeli (MoE) yapısını benimser; metin ve g\xf6r\xfcnt\xfc anlama ile ilgili temel tanıma, i\xe7erik oluşturma, bilgi sorgulama, analiz ve akıl y\xfcr\xfctme gibi yeteneklerde bir \xf6nceki nesil modele g\xf6re kapsamlı bir iyileştirme sağlar."},"hunyuan-turbos-20250313":{"description":"Matematik problem \xe7\xf6zme adımlarının stilini birleştirir, matematikte \xe7ok turlu soru-cevapları g\xfc\xe7lendirir. Metin oluşturma, yanıt stilini optimize eder, yapay zeka izlerini kaldırır, edebi ifadeyi artırır."},"hunyuan-turbos-20250416":{"description":"\xd6n eğitim tabanı y\xfckseltmesi, tabanın komut anlama ve uyum yeteneklerini g\xfc\xe7lendirir; hizalama aşamasında matematik, kodlama, mantık ve bilimsel alanlardaki yetenekleri artırır; yaratıcı yazım kalitesi, metin anlama, \xe7eviri doğruluğu ve bilgi tabanlı soru-cevap gibi beşeri bilimler yeteneklerini geliştirir; \xe7eşitli alanlardaki ajan yeteneklerini g\xfc\xe7lendirir, \xf6zellikle \xe7ok turlu diyalog anlama yeteneğine odaklanır."},"hunyuan-turbos-20250604":{"description":"\xd6n eğitim tabanı y\xfckseltildi; yazma ve okuduğunu anlama yetenekleri geliştirildi; kodlama ve fen bilimleri yeteneklerinde \xf6nemli iyileştirmeler sağlandı; karmaşık talimatlara uyum gibi alanlarda s\xfcrekli gelişme devam ediyor."},"hunyuan-turbos-20250926":{"description":"\xd6n eğitim tabanı veri kalitesi y\xfckseltmesi. Post-train aşaması eğitim stratejisi optimize edilerek Agent, İngilizce dışı k\xfc\xe7\xfck diller, talimat uyumu, kodlama ve fen bilimleri yetenekleri s\xfcrekli geliştirilmiştir."},"hunyuan-turbos-latest":{"description":"hunyuan-TurboS, daha g\xfc\xe7l\xfc d\xfcş\xfcnme yeteneği ve daha iyi deneyim sunan en son s\xfcr\xfcm\xfcd\xfcr."},"hunyuan-turbos-longtext-128k-20250325":{"description":"Uzun metin g\xf6revlerini, \xf6rneğin belge \xf6zetleme ve belge yanıtları gibi, işleme konusunda uzmandır ve genel metin oluşturma g\xf6revlerini de yerine getirebilir. Uzun metinlerin analizi ve oluşturulmasında m\xfckemmel performans g\xf6sterir, karmaşık ve ayrıntılı uzun metin i\xe7erik işleme ihtiya\xe7larını etkili bir şekilde karşılar."},"hunyuan-turbos-role-plus":{"description":"Hunyuan\'ın en son rol yapma modeli, Hunyuan tarafından resmi olarak ince ayar ve eğitimle geliştirilmiş, rol yapma senaryoları veri setiyle artırılmıştır ve rol yapma senaryolarında daha iyi temel performans sunar."},"hunyuan-turbos-vision":{"description":"Bu model, g\xf6rsel ve metin anlama senaryoları i\xe7in uygundur ve Hunyuan\'ın en yeni turbos tabanlı yeni nesil g\xf6rsel dil amiral gemisi b\xfcy\xfck modelidir. G\xf6rsel tabanlı varlık tanıma, bilgi sorgulama, metin oluşturma, fotoğrafla problem \xe7\xf6zme gibi g\xf6revlerde odaklanır ve \xf6nceki nesil modele kıyasla kapsamlı iyileştirmeler i\xe7erir."},"hunyuan-turbos-vision-20250619":{"description":"Hunyuan\'ın en yeni turbos-vision g\xf6rsel dil amiral gemisi b\xfcy\xfck modeli, g\xf6rsel ve metin anlama ile ilgili g\xf6revlerde, g\xf6rsel tabanlı varlık tanıma, bilgi sorgulama, metin oluşturma, fotoğrafla problem \xe7\xf6zme gibi alanlarda \xf6nceki nesil varsayılan modele kıyasla kapsamlı iyileştirmeler sunar."},"hunyuan-vision":{"description":"Hunyuan\'ın en son \xe7ok modlu modeli, resim + metin girişi ile metin i\xe7eriği oluşturmayı destekler."},"image-01":{"description":"Yepyeni g\xf6r\xfcnt\xfc oluşturma modeli, ince detaylı g\xf6rseller sunar; metinden g\xf6r\xfcnt\xfc ve g\xf6r\xfcnt\xfcden g\xf6r\xfcnt\xfc desteği vardır."},"image-01-live":{"description":"G\xf6r\xfcnt\xfc oluşturma modeli, ince detaylı g\xf6rseller sunar; metinden g\xf6r\xfcnt\xfc oluşturmayı ve stil ayarlarını destekler."},"imagen-4.0-fast-generate-001":{"description":"Imagen 4. nesil metinden g\xf6rsele model serisi — Hızlı s\xfcr\xfcm"},"imagen-4.0-generate-001":{"description":"Imagen 4. nesil metinden g\xf6r\xfcnt\xfcye model serisi"},"imagen-4.0-generate-preview-06-06":{"description":"Imagen d\xf6rd\xfcnc\xfc nesil metinden g\xf6rsele model serisi"},"imagen-4.0-ultra-generate-001":{"description":"Imagen 4. nesil metinden-g\xf6r\xfcnt\xfcye model serisi, Ultra s\xfcr\xfcm\xfc"},"imagen-4.0-ultra-generate-preview-06-06":{"description":"Imagen d\xf6rd\xfcnc\xfc nesil metinden g\xf6rsele model serisinin Ultra versiyonu"},"inception/mercury-coder-small":{"description":"Mercury Coder Small, kod \xfcretimi, hata ayıklama ve yeniden yapılandırma g\xf6revleri i\xe7in ideal olup, minimum gecikme sunar."},"inclusionAI/Ling-1T":{"description":"Ling-1T, \\"Ling 2.0\\" serisinin ilk amiral gemisi non-thinking modelidir. Toplamda 1 trilyon parametreye ve her token i\xe7in yaklaşık 50 milyar aktif parametreye sahiptir. Ling 2.0 mimarisi \xfczerine inşa edilen Ling-1T, verimli akıl y\xfcr\xfctme ve \xf6l\xe7eklenebilir bilişsel yeteneklerin sınırlarını zorlamak i\xe7in tasarlanmıştır. Ling-1T-base, 200 trilyondan fazla y\xfcksek kaliteli ve akıl y\xfcr\xfctme yoğun token \xfczerinde eğitilmiştir."},"inclusionAI/Ling-flash-2.0":{"description":"Ling-flash-2.0, Ant Group Bailing ekibi tarafından yayınlanan Ling 2.0 mimari serisinin \xfc\xe7\xfcnc\xfc modelidir. Bu, hibrit uzman (MoE) modeli olup toplam parametre sayısı 100 milyara ulaşırken, her token i\xe7in yalnızca 6.1 milyar parametre aktive eder (embedding dışı 4.8 milyar). Hafif yapılandırmaya sahip bu model, bir\xe7ok otoriter değerlendirmede 40 milyar seviyesindeki yoğun (Dense) modeller ve daha b\xfcy\xfck \xf6l\xe7ekli MoE modelleriyle rekabet eden hatta onları aşan performans sergiler. Model, \\"b\xfcy\xfck model b\xfcy\xfck parametre demektir\\" anlayışı altında y\xfcksek verimlilik yollarını keşfetmek i\xe7in \xfcst\xfcn mimari tasarım ve eğitim stratejileriyle geliştirilmiştir."},"inclusionAI/Ling-mini-2.0":{"description":"Ling-mini-2.0, MoE mimarisi temelinde k\xfc\xe7\xfck boyutlu y\xfcksek performanslı b\xfcy\xfck dil modelidir. Toplam 16 milyar parametreye sahip olup, her token i\xe7in yalnızca 1.4 milyar parametre aktive eder (embedding dışı 789 milyon), b\xf6ylece \xe7ok y\xfcksek \xfcretim hızı sağlar. Verimli MoE tasarımı ve b\xfcy\xfck \xf6l\xe7ekli y\xfcksek kaliteli eğitim verileri sayesinde, aktive edilen parametre sayısı sadece 1.4 milyar olmasına rağmen, Ling-mini-2.0 altındaki 10 milyar yoğun LLM ve daha b\xfcy\xfck \xf6l\xe7ekli MoE modelleriyle kıyaslanabilir \xfcst d\xfczey performans g\xf6sterir."},"inclusionAI/Ring-1T":{"description":"Ring-1T, Bailing ekibi tarafından geliştirilen trilyon parametre \xf6l\xe7eğinde a\xe7ık kaynaklı bir d\xfcş\xfcnce modelidir. Ling 2.0 mimarisi ve Ling-1T-base temel modeli \xfczerine inşa edilmiştir. Toplamda 1 trilyon parametreye ve 50 milyar aktif parametreye sahiptir. 128K\'ya kadar bağlam penceresini destekler. Model, b\xfcy\xfck \xf6l\xe7ekli doğrulanabilir \xf6d\xfcl takviyeli \xf6ğrenme ile optimize edilmiştir."},"inclusionAI/Ring-flash-2.0":{"description":"Ring-flash-2.0, Ling-flash-2.0-base \xfczerine derinlemesine optimize edilmiş y\xfcksek performanslı d\xfcş\xfcnme modelidir. Hibrit uzman (MoE) mimarisi kullanır, toplam parametre sayısı 100 milyardır ancak her \xe7ıkarımda yalnızca 6.1 milyar parametre aktive edilir. Model, \xf6zg\xfcn icepop algoritması ile MoE b\xfcy\xfck modellerin pekiştirmeli \xf6ğrenme (RL) eğitimindeki kararsızlık sorununu \xe7\xf6zerek karmaşık \xe7ıkarım yeteneğini uzun d\xf6nemli eğitimlerde s\xfcrekli artırır. Ring-flash-2.0, matematik yarışmaları, kod \xfcretimi ve mantıksal \xe7ıkarım gibi zorlu kıyaslama testlerinde \xf6nemli atılımlar yapmış, performansı 40 milyar parametre altındaki en iyi yoğun modelleri aşmakla kalmayıp, daha b\xfcy\xfck \xf6l\xe7ekli a\xe7ık kaynak MoE modelleri ve kapalı kaynak y\xfcksek performanslı d\xfcş\xfcnme modelleriyle rekabet edebilir. Model karmaşık \xe7ıkarıma odaklanmasına rağmen yaratıcı yazma gibi g\xf6revlerde de başarılıdır. Ayrıca, y\xfcksek verimli mimari tasarımı sayesinde g\xfc\xe7l\xfc performans sunarken y\xfcksek hızda \xe7ıkarım yapar ve y\xfcksek eşzamanlılık senaryolarında d\xfcş\xfcnme modeli dağıtım maliyetlerini \xf6nemli \xf6l\xe7\xfcde azaltır."},"internlm/internlm2_5-7b-chat":{"description":"InternLM2.5, \xe7oklu senaryolarda akıllı diyalog \xe7\xf6z\xfcmleri sunar."},"internlm2.5-latest":{"description":"En son model serimiz, olağan\xfcst\xfc \xe7ıkarım performansına sahiptir, 1M bağlam uzunluğunu destekler ve daha g\xfc\xe7l\xfc talimat takibi ve ara\xe7 \xe7ağırma yetenekleri sunar."},"internlm3-latest":{"description":"En son model serimiz, olağan\xfcst\xfc \xe7ıkarım performansına sahiptir ve aynı \xf6l\xe7ekli a\xe7ık kaynak modeller arasında liderdir. Varsayılan olarak en son yayımlanan InternLM3 serisi modellerine işaret eder."},"internvl2.5-38b-mpo":{"description":"InternVL2.5 38B MPO, \xe7ok modlu \xf6n eğitimli model, karmaşık g\xf6rsel-metin \xe7ıkarım g\xf6revlerini destekler."},"internvl2.5-latest":{"description":"Hala bakımını yaptığımız InternVL2.5 s\xfcr\xfcm\xfc, m\xfckemmel ve istikrarlı bir performansa sahiptir. Varsayılan olarak en son yayımladığımız InternVL2.5 serisi modele işaret eder, şu anda internvl2.5-78b\'ye işaret ediyor."},"internvl3-14b":{"description":"InternVL3 14B, orta \xf6l\xe7ekli \xe7ok modlu model, performans ve maliyet arasında denge sağlar."},"internvl3-1b":{"description":"InternVL3 1B, hafif \xe7ok modlu model, kaynak kısıtlı ortamlar i\xe7in uygundur."},"internvl3-38b":{"description":"InternVL3 38B, b\xfcy\xfck \xf6l\xe7ekli \xe7ok modlu a\xe7ık kaynak modeli, y\xfcksek hassasiyetli g\xf6rsel-metin anlama g\xf6revleri i\xe7in uygundur."},"internvl3-latest":{"description":"En son yayımladığımız \xe7ok modlu b\xfcy\xfck model, daha g\xfc\xe7l\xfc metin-g\xf6r\xfcnt\xfc anlama yeteneği ve uzun s\xfcreli g\xf6r\xfcnt\xfc anlama yeteneğine sahiptir; performansı en iyi kapalı kaynak modellerle karşılaştırılabilir. Varsayılan olarak en son yayımladığımız InternVL serisi modele işaret eder, şu anda internvl3-78b\'ye işaret ediyor."},"irag-1.0":{"description":"ERNIE iRAG, g\xf6rsel arama destekli \xfcretim modeli, g\xf6rselle arama, g\xf6rsel-metin arama ve i\xe7erik \xfcretimini destekler."},"jamba-large":{"description":"En g\xfc\xe7l\xfc ve en gelişmiş modelimiz, kurumsal d\xfczeyde karmaşık g\xf6revleri işlemek i\xe7in tasarlanmıştır ve olağan\xfcst\xfc performans sunar."},"jamba-mini":{"description":"Sınıfındaki en verimli model, hız ve kaliteyi dengeler, daha k\xfc\xe7\xfck bir boyuta sahiptir."},"jina-deepsearch-v1":{"description":"Derin arama, web araması, okuma ve akıl y\xfcr\xfctmeyi birleştirerek kapsamlı bir araştırma yapar. Bunu, araştırma g\xf6revlerinizi kabul eden bir ajan olarak d\xfcş\xfcnebilirsiniz - geniş bir arama yapar ve birden fazla yineleme ile cevap verir. Bu s\xfcre\xe7, s\xfcrekli araştırma, akıl y\xfcr\xfctme ve sorunları \xe7eşitli a\xe7ılardan \xe7\xf6zmeyi i\xe7erir. Bu, doğrudan \xf6nceden eğitilmiş verilerden cevaplar \xfcreten standart b\xfcy\xfck modellerle ve tek seferlik y\xfczey aramasına dayanan geleneksel RAG sistemleriyle temelde farklıdır."},"kimi-k2":{"description":"Kimi-K2, Moonshot AI tarafından geliştirilen, g\xfc\xe7l\xfc kodlama ve ajan yeteneklerine sahip MoE mimarili temel modeldir; toplam 1 trilyon parametre, 32 milyar aktif parametreye sahiptir. Genel bilgi \xe7ıkarımı, programlama, matematik ve ajan gibi ana kategorilerdeki kıyaslama testlerinde K2 modeli diğer \xf6nde gelen a\xe7ık kaynak modelleri geride bırakır."},"kimi-k2-0711-preview":{"description":"kimi-k2, son derece g\xfc\xe7l\xfc kodlama ve Agent yeteneklerine sahip MoE mimarili temel bir modeldir. Toplam parametre sayısı 1T, aktif parametre sayısı 32B\'dir. Genel bilgi \xe7ıkarımı, programlama, matematik, Agent gibi ana kategorilerde yapılan kıyaslama testlerinde K2 modeli, diğer \xf6nde gelen a\xe7ık kaynak modelleri geride bırakmıştır."},"kimi-k2-0905-preview":{"description":"kimi-k2-0905-preview modelinin bağlam uzunluğu 256k’dır, daha g\xfc\xe7l\xfc Agentic Kodlama yeteneklerine, \xf6n u\xe7 kodlarının estetik ve işlevselliğinde belirgin gelişmelere ve daha iyi bağlam anlama yeteneğine sahiptir."},"kimi-k2-instruct":{"description":"Kimi K2 Instruct, Kimi\'nin resmi \xe7ıkarım modeli, uzun bağlam, kodlama, soru-cevap gibi \xe7oklu senaryoları destekler."},"kimi-k2-turbo-preview":{"description":"kimi-k2, son derece g\xfc\xe7l\xfc kod yazma ve Agent yeteneklerine sahip MoE mimarisine dayanan bir temel modeldir; toplam parametre sayısı 1T, aktif (etkin) parametre sayısı 32B. Genel bilgi \xe7ıkarımı, programlama, matematik ve Agent gibi ana kategorilerde yapılan karşılaştırmalı performans testlerinde K2 modelinin performansı diğer \xf6nde gelen a\xe7ık kaynak modellerinin \xfczerindedir."},"kimi-k2:1t":{"description":"Kimi K2, Ay\'ın Karanlık Y\xfcz\xfc AI tarafından geliştirilen, toplamda 1 trilyon parametreye ve her ileri ge\xe7işte 32 milyar aktif parametreye sahip b\xfcy\xfck \xf6l\xe7ekli bir Karışık Uzman (MoE) dil modelidir. Gelişmiş ara\xe7 kullanımı, muhakeme ve kod sentezi dahil olmak \xfczere ajan yetenekleri i\xe7in optimize edilmiştir."},"kimi-latest":{"description":"Kimi akıllı asistan \xfcr\xfcn\xfc, en son Kimi b\xfcy\xfck modelini kullanır ve hen\xfcz kararlı olmayan \xf6zellikler i\xe7erebilir. G\xf6r\xfcnt\xfc anlayışını desteklerken, isteğin bağlam uzunluğuna g\xf6re 8k/32k/128k modelini faturalama modeli olarak otomatik olarak se\xe7ecektir."},"kimi-thinking-preview":{"description":"kimi-thinking-preview modeli, Ay\'ın karanlık y\xfcz\xfc tarafından sunulan \xe7ok modlu akıl y\xfcr\xfctme ve genel akıl y\xfcr\xfctme yeteneklerine sahip \xe7ok modlu d\xfcş\xfcnme modelidir; derin akıl y\xfcr\xfctmede uzmandır ve daha zor sorunların \xe7\xf6z\xfcm\xfcne yardımcı olur."},"learnlm-1.5-pro-experimental":{"description":"LearnLM, \xf6ğrenme bilimleri ilkelerine uygun olarak eğitilmiş, g\xf6rev odaklı deneysel bir dil modelidir. Eğitim ve \xf6ğrenim senaryolarında sistem talimatlarını takip edebilir ve uzman bir mentor olarak g\xf6rev alabilir."},"learnlm-2.0-flash-experimental":{"description":"LearnLM, \xf6ğrenme bilimleri ilkelerine uygun olarak eğitilmiş, g\xf6rev odaklı deneysel bir dil modelidir; \xf6ğretim ve \xf6ğrenim senaryolarında sistem talimatlarını takip edebilir, uzman bir mentor gibi davranabilir."},"lite":{"description":"Spark Lite, son derece d\xfcş\xfck gecikme s\xfcresi ve y\xfcksek verimlilikle \xe7alışan hafif bir b\xfcy\xfck dil modelidir. Tamamen \xfccretsiz ve a\xe7ık olup, ger\xe7ek zamanlı \xe7evrimi\xe7i arama işlevini desteklemektedir. Hızlı yanıt verme \xf6zelliği, d\xfcş\xfck hesaplama g\xfcc\xfcne sahip cihazlarda \xe7ıkarım uygulamaları ve model ince ayarlarında m\xfckemmel performans sergileyerek, kullanıcılara maliyet etkinliği ve akıllı deneyim sunmakta, \xf6zellikle bilgi sorgulama, i\xe7erik oluşturma ve arama senaryolarında başarılı olmaktadır."},"llama-3.1-70b-versatile":{"description":"Llama 3.1 70B, daha g\xfc\xe7l\xfc AI akıl y\xfcr\xfctme yeteneği sunar, karmaşık uygulamalar i\xe7in uygundur ve y\xfcksek verimlilik ve doğruluk sağlamak i\xe7in \xe7ok sayıda hesaplama işlemini destekler."},"llama-3.1-8b-instant":{"description":"Llama 3.1 8B, hızlı metin \xfcretim yeteneği sunan y\xfcksek performanslı bir modeldir ve b\xfcy\xfck \xf6l\xe7ekli verimlilik ve maliyet etkinliği gerektiren uygulama senaryoları i\xe7in son derece uygundur."},"llama-3.1-instruct":{"description":"Llama 3.1 talimat ince ayarlı modeli, diyalog senaryoları i\xe7in optimize edilmiştir ve yaygın end\xfcstri kıyaslamalarında bir\xe7ok mevcut a\xe7ık kaynaklı sohbet modelini geride bırakmaktadır."},"llama-3.2-11b-vision-instruct":{"description":"Y\xfcksek \xe7\xf6z\xfcn\xfcrl\xfckl\xfc g\xf6r\xfcnt\xfclerde m\xfckemmel g\xf6r\xfcnt\xfc akıl y\xfcr\xfctme yeteneği, g\xf6rsel anlama uygulamaları i\xe7in uygundur."},"llama-3.2-11b-vision-preview":{"description":"Llama 3.2, g\xf6rsel ve metin verilerini birleştiren g\xf6revleri işlemek i\xe7in tasarlanmıştır. G\xf6r\xfcnt\xfc tanımlama ve g\xf6rsel soru-cevap gibi g\xf6revlerde m\xfckemmel performans sergiler, dil \xfcretimi ile g\xf6rsel akıl y\xfcr\xfctme arasındaki u\xe7urumu aşar."},"llama-3.2-90b-vision-instruct":{"description":"G\xf6rsel anlayış ajan uygulamaları i\xe7in ileri d\xfczey g\xf6r\xfcnt\xfc akıl y\xfcr\xfctme yeteneği."},"llama-3.2-90b-vision-preview":{"description":"Llama 3.2, g\xf6rsel ve metin verilerini birleştiren g\xf6revleri işlemek i\xe7in tasarlanmıştır. G\xf6r\xfcnt\xfc tanımlama ve g\xf6rsel soru-cevap gibi g\xf6revlerde m\xfckemmel performans sergiler, dil \xfcretimi ile g\xf6rsel akıl y\xfcr\xfctme arasındaki u\xe7urumu aşar."},"llama-3.2-vision-instruct":{"description":"Llama 3.2-Vision komut ince ayarlı modeli, g\xf6rsel tanıma, g\xf6r\xfcnt\xfc \xe7ıkarımı, g\xf6r\xfcnt\xfc a\xe7ıklama ve g\xf6r\xfcnt\xfclerle ilgili genel soruları yanıtlamak i\xe7in optimize edilmiştir."},"llama-3.3-70b":{"description":"Llama 3.3 70B: Orta-b\xfcy\xfck \xf6l\xe7ekli Llama modeli, akıl y\xfcr\xfctme yeteneği ile y\xfcksek işlem hacmini dengeler."},"llama-3.3-70b-versatile":{"description":"Meta Llama 3.3 \xe7ok dilli b\xfcy\xfck dil modeli (LLM), 70B (metin girişi/metin \xe7ıkışı) i\xe7indeki \xf6nceden eğitilmiş ve talimat ayarlanmış bir \xfcretim modelidir. Llama 3.3 talimat ayarlı saf metin modeli, \xe7ok dilli konuşma kullanım durumları i\xe7in optimize edilmiştir ve yaygın end\xfcstri kıyaslamalarında mevcut bir\xe7ok a\xe7ık kaynak ve kapalı sohbet modelinden daha \xfcst\xfcnd\xfcr."},"llama-3.3-instruct":{"description":"Llama 3.3 komut ince ayarlı modeli, diyalog senaryoları i\xe7in optimize edilmiştir ve yaygın end\xfcstri kıyaslamalarında bir\xe7ok mevcut a\xe7ık kaynaklı sohbet modelini geride bırakmaktadır."},"llama-4-scout-17b-16e-instruct":{"description":"Llama 4 Scout: Y\xfcksek performanslı Llama serisi modeli; y\xfcksek işlem hacmi ve d\xfcş\xfck gecikme gerektiren senaryolar i\xe7in idealdir."},"llama3-70b-8192":{"description":"Meta Llama 3 70B, eşsiz karmaşıklık işleme yeteneği sunar ve y\xfcksek talepli projeler i\xe7in \xf6zel olarak tasarlanmıştır."},"llama3-8b-8192":{"description":"Meta Llama 3 8B, y\xfcksek kaliteli akıl y\xfcr\xfctme performansı sunar ve \xe7ok \xe7eşitli uygulama ihtiya\xe7ları i\xe7in uygundur."},"llama3-groq-70b-8192-tool-use-preview":{"description":"Llama 3 Groq 70B Tool Use, g\xfc\xe7l\xfc ara\xe7 \xe7ağırma yetenekleri sunar ve karmaşık g\xf6revlerin verimli bir şekilde işlenmesini destekler."},"llama3-groq-8b-8192-tool-use-preview":{"description":"Llama 3 Groq 8B Tool Use, verimli ara\xe7 kullanımı i\xe7in optimize edilmiş bir modeldir ve hızlı paralel hesaplamayı destekler."},"llama3.1":{"description":"Llama 3.1, Meta tarafından sunulan \xf6nc\xfc bir modeldir, 405B parametreye kadar destekler ve karmaşık diyaloglar, \xe7ok dilli \xe7eviri ve veri analizi alanlarında kullanılabilir."},"llama3.1-8b":{"description":"Llama 3.1 8B: K\xfc\xe7\xfck boyutlu, d\xfcş\xfck gecikmeli Llama varyantı; hafif \xe7evrimi\xe7i akıl y\xfcr\xfctme ve etkileşimli kullanım senaryoları i\xe7in uygundur."},"llama3.1:405b":{"description":"Llama 3.1, Meta tarafından sunulan \xf6nc\xfc bir modeldir, 405B parametreye kadar destekler ve karmaşık diyaloglar, \xe7ok dilli \xe7eviri ve veri analizi alanlarında kullanılabilir."},"llama3.1:70b":{"description":"Llama 3.1, Meta tarafından sunulan \xf6nc\xfc bir modeldir, 405B parametreye kadar destekler ve karmaşık diyaloglar, \xe7ok dilli \xe7eviri ve veri analizi alanlarında kullanılabilir."},"llava":{"description":"LLaVA, g\xf6rsel kodlayıcı ve Vicuna\'yı birleştiren \xe7ok modlu bir modeldir, g\xfc\xe7l\xfc g\xf6rsel ve dil anlama yetenekleri sunar."},"llava-v1.5-7b-4096-preview":{"description":"LLaVA 1.5 7B, g\xf6rsel işleme yeteneklerini birleştirir ve g\xf6rsel bilgi girişi ile karmaşık \xe7ıktılar \xfcretir."},"llava:13b":{"description":"LLaVA, g\xf6rsel kodlayıcı ve Vicuna\'yı birleştiren \xe7ok modlu bir modeldir, g\xfc\xe7l\xfc g\xf6rsel ve dil anlama yetenekleri sunar."},"llava:34b":{"description":"LLaVA, g\xf6rsel kodlayıcı ve Vicuna\'yı birleştiren \xe7ok modlu bir modeldir, g\xfc\xe7l\xfc g\xf6rsel ve dil anlama yetenekleri sunar."},"magistral-medium-latest":{"description":"Magistral Medium 1.2, Mistral AI tarafından Eyl\xfcl 2025\'te yayınlanan, g\xf6rsel destekli ileri seviye bir \xe7ıkarım modelidir."},"magistral-small-2509":{"description":"Magistral Small 1.2, Mistral AI tarafından Eyl\xfcl 2025\'te yayınlanan, g\xf6rsel destekli a\xe7ık kaynaklı k\xfc\xe7\xfck \xf6l\xe7ekli bir \xe7ıkarım modelidir."},"mathstral":{"description":"MathΣtral, bilimsel araştırma ve matematik akıl y\xfcr\xfctme i\xe7in tasarlanmış, etkili hesaplama yetenekleri ve sonu\xe7 a\xe7ıklamaları sunar."},"max-32k":{"description":"Spark Max 32K, b\xfcy\xfck bağlam işleme yeteneği ile donatılmıştır ve daha g\xfc\xe7l\xfc bağlam anlama ve mantıksal \xe7ıkarım yetenekleri sunmaktadır. 32K token\'lık metin girişi desteklemekte olup, uzun belgelerin okunması, \xf6zel bilgi sorgulama gibi senaryolar i\xe7in uygundur."},"megrez-3b-instruct":{"description":"Megrez 3B Instruct, Wuwen Xinqiong tarafından geliştirilen d\xfcş\xfck parametreli, y\xfcksek verimli bir modeldir."},"meituan/longcat-flash-chat":{"description":"Meituan tarafından a\xe7ık kaynak olarak sunulan, diyalog etkileşimi ve yapay zeka g\xf6revleri i\xe7in optimize edilmiş d\xfcş\xfcnce i\xe7ermeyen temel model; ara\xe7 kullanımı ve karmaşık \xe7ok turlu etkileşim senaryolarında \xfcst\xfcn performans g\xf6sterir."},"meta-llama-3-70b-instruct":{"description":"Akıl y\xfcr\xfctme, kodlama ve geniş dil uygulamalarında m\xfckemmel bir 70 milyar parametreli model."},"meta-llama-3-8b-instruct":{"description":"Diyalog ve metin \xfcretim g\xf6revleri i\xe7in optimize edilmiş \xe7ok y\xf6nl\xfc bir 8 milyar parametreli model."},"meta-llama-3.1-405b-instruct":{"description":"Llama 3.1 talimat ayarlı yalnızca metin modelleri, \xe7ok dilli diyalog kullanım durumları i\xe7in optimize edilmiştir ve mevcut a\xe7ık kaynak ve kapalı sohbet modellerinin \xe7oğunu yaygın end\xfcstri standartlarında geride bırakmaktadır."},"meta-llama-3.1-70b-instruct":{"description":"Llama 3.1 talimat ayarlı yalnızca metin modelleri, \xe7ok dilli diyalog kullanım durumları i\xe7in optimize edilmiştir ve mevcut a\xe7ık kaynak ve kapalı sohbet modellerinin \xe7oğunu yaygın end\xfcstri standartlarında geride bırakmaktadır."},"meta-llama-3.1-8b-instruct":{"description":"Llama 3.1 talimat ayarlı yalnızca metin modelleri, \xe7ok dilli diyalog kullanım durumları i\xe7in optimize edilmiştir ve mevcut a\xe7ık kaynak ve kapalı sohbet modellerinin \xe7oğunu yaygın end\xfcstri standartlarında geride bırakmaktadır."},"meta-llama/Llama-2-13b-chat-hf":{"description":"LLaMA-2 Chat (13B), m\xfckemmel dil işleme yetenekleri ve olağan\xfcst\xfc etkileşim deneyimi sunar."},"meta-llama/Llama-2-70b-hf":{"description":"LLaMA-2, m\xfckemmel dil işleme yeteneği ve \xfcst\xfcn etkileşim deneyimi sunar."},"meta-llama/Llama-3-70b-chat-hf":{"description":"LLaMA-3 Chat (70B), karmaşık diyalog ihtiya\xe7larını destekleyen g\xfc\xe7l\xfc bir sohbet modelidir."},"meta-llama/Llama-3-8b-chat-hf":{"description":"LLaMA-3 Chat (8B), \xe7ok dilli desteği ile zengin alan bilgilerini kapsar."},"meta-llama/Llama-3.2-11B-Vision-Instruct-Turbo":{"description":"LLaMA 3.2, g\xf6rsel ve metin verilerini bir arada işleme amacıyla tasarlanmıştır. G\xf6r\xfcnt\xfc betimleme ve g\xf6rsel soru yanıtlama gibi g\xf6revlerde m\xfckemmel performans sergiler, dil \xfcretimi ve g\xf6rsel akıl y\xfcr\xfctme arasındaki boşluğu kapar."},"meta-llama/Llama-3.2-3B-Instruct-Turbo":{"description":"LLaMA 3.2, g\xf6rsel ve metin verilerini bir arada işleme amacıyla tasarlanmıştır. G\xf6r\xfcnt\xfc betimleme ve g\xf6rsel soru yanıtlama gibi g\xf6revlerde m\xfckemmel performans sergiler, dil \xfcretimi ve g\xf6rsel akıl y\xfcr\xfctme arasındaki boşluğu kapar."},"meta-llama/Llama-3.2-90B-Vision-Instruct-Turbo":{"description":"LLaMA 3.2, g\xf6rsel ve metin verilerini bir arada işleme amacıyla tasarlanmıştır. G\xf6r\xfcnt\xfc betimleme ve g\xf6rsel soru yanıtlama gibi g\xf6revlerde m\xfckemmel performans sergiler, dil \xfcretimi ve g\xf6rsel akıl y\xfcr\xfctme arasındaki boşluğu kapar."},"meta-llama/Llama-3.3-70B-Instruct-Turbo":{"description":"Meta Llama 3.3 \xe7ok dilli b\xfcy\xfck dil modeli (LLM), 70B (metin girişi/metin \xe7ıkışı) i\xe7inde \xf6nceden eğitilmiş ve talimat ayarlı bir \xfcretim modelidir. Llama 3.3 talimat ayarlı saf metin modeli, \xe7ok dilli diyalog kullanım durumları i\xe7in optimize edilmiştir ve yaygın end\xfcstri standartlarında bir\xe7ok mevcut a\xe7ık kaynak ve kapalı sohbet modelinden daha iyi performans g\xf6stermektedir."},"meta-llama/Llama-Vision-Free":{"description":"LLaMA 3.2, g\xf6rsel ve metin verilerini bir arada işleme amacıyla tasarlanmıştır. G\xf6r\xfcnt\xfc betimleme ve g\xf6rsel soru yanıtlama gibi g\xf6revlerde m\xfckemmel performans sergiler, dil \xfcretimi ve g\xf6rsel akıl y\xfcr\xfctme arasındaki boşluğu kapar."},"meta-llama/Meta-Llama-3-70B-Instruct-Lite":{"description":"Llama 3 70B Instruct Lite, y\xfcksek performans ve d\xfcş\xfck gecikme gerektiren ortamlara uygundur."},"meta-llama/Meta-Llama-3-70B-Instruct-Turbo":{"description":"Llama 3 70B Instruct Turbo, en zorlu hesaplama g\xf6revleri i\xe7in m\xfckemmel dil anlama ve \xfcretim yetenekleri sunar."},"meta-llama/Meta-Llama-3-8B-Instruct-Lite":{"description":"Llama 3 8B Instruct Lite, kaynak kısıtlı ortamlara uygun, m\xfckemmel denge performansı sunar."},"meta-llama/Meta-Llama-3-8B-Instruct-Turbo":{"description":"Llama 3 8B Instruct Turbo, geniş uygulama alanlarını destekleyen y\xfcksek performanslı bir b\xfcy\xfck dil modelidir."},"meta-llama/Meta-Llama-3.1-405B-Instruct":{"description":"LLaMA 3.1 405B, \xf6n eğitim ve talimat ayarlaması i\xe7in g\xfc\xe7l\xfc bir modeldir."},"meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo":{"description":"405B Llama 3.1 Turbo modeli, b\xfcy\xfck veri işleme i\xe7in devasa bağlam desteği sunar ve b\xfcy\xfck \xf6l\xe7ekli AI uygulamalarında \xf6ne \xe7ıkar."},"meta-llama/Meta-Llama-3.1-70B":{"description":"Llama 3.1, Meta tarafından sunulan \xf6nc\xfc bir modeldir, 405B parametreye kadar destekler ve karmaşık diyaloglar, \xe7ok dilli \xe7eviri ve veri analizi alanlarında uygulanabilir."},"meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo":{"description":"Llama 3.1 70B modeli, y\xfcksek y\xfck uygulamaları i\xe7in ince ayar yapılmış, FP8\'e kuantize edilerek daha verimli hesaplama g\xfcc\xfc ve doğruluk sağlar, karmaşık senaryolarda m\xfckemmel performans sunar."},"meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo":{"description":"Llama 3.1 8B modeli, FP8 kuantizasyonu ile 131,072\'ye kadar bağlam belirteci destekler, karmaşık g\xf6revler i\xe7in m\xfckemmel bir a\xe7ık kaynak modelidir ve bir\xe7ok end\xfcstri standardını aşar."},"meta-llama/llama-3-70b-instruct":{"description":"Llama 3 70B Instruct, y\xfcksek kaliteli diyalog senaryoları i\xe7in optimize edilmiştir ve \xe7eşitli insan değerlendirmelerinde m\xfckemmel performans g\xf6stermektedir."},"meta-llama/llama-3-8b-instruct":{"description":"Llama 3 8B Instruct, y\xfcksek kaliteli diyalog senaryoları i\xe7in optimize edilmiştir ve bir\xe7ok kapalı kaynak modelden daha iyi performans g\xf6stermektedir."},"meta-llama/llama-3.1-70b-instruct":{"description":"Llama 3.1 70B Instruct, y\xfcksek kaliteli diyalog i\xe7in tasarlanmış olup, insan değerlendirmelerinde \xf6ne \xe7ıkmakta ve \xf6zellikle y\xfcksek etkileşimli senaryolar i\xe7in uygundur."},"meta-llama/llama-3.1-8b-instruct":{"description":"Llama 3.1 8B Instruct, Meta tarafından sunulan en son versiyon olup, y\xfcksek kaliteli diyalog senaryoları i\xe7in optimize edilmiştir ve bir\xe7ok \xf6nde gelen kapalı kaynak modelden daha iyi performans g\xf6stermektedir."},"meta-llama/llama-3.1-8b-instruct:free":{"description":"LLaMA 3.1, \xe7ok dilli destek sunar ve sekt\xf6rdeki en \xf6nde gelen \xfcretim modellerinden biridir."},"meta-llama/llama-3.2-11b-vision-instruct":{"description":"LLaMA 3.2, g\xf6rsel ve metin verilerini birleştiren g\xf6revleri işlemek i\xe7in tasarlanmıştır. G\xf6r\xfcnt\xfc tanımlama ve g\xf6rsel soru yanıtlama gibi g\xf6revlerde m\xfckemmel performans sergileyerek dil \xfcretimi ve g\xf6rsel akıl y\xfcr\xfctme arasındaki boşluğu kapatmaktadır."},"meta-llama/llama-3.2-3b-instruct":{"description":"meta-llama/llama-3.2-3b-instruct"},"meta-llama/llama-3.2-90b-vision-instruct":{"description":"LLaMA 3.2, g\xf6rsel ve metin verilerini birleştiren g\xf6revleri işlemek i\xe7in tasarlanmıştır. G\xf6r\xfcnt\xfc tanımlama ve g\xf6rsel soru yanıtlama gibi g\xf6revlerde m\xfckemmel performans sergileyerek dil \xfcretimi ve g\xf6rsel akıl y\xfcr\xfctme arasındaki boşluğu kapatmaktadır."},"meta-llama/llama-3.3-70b-instruct":{"description":"Llama 3.3, Llama serisinin en gelişmiş \xe7ok dilli a\xe7ık kaynak b\xfcy\xfck dil modelidir ve 405B modelinin performansını \xe7ok d\xfcş\xfck maliyetle deneyimlemenizi sağlar. Transformer yapısına dayanmaktadır ve denetimli ince ayar (SFT) ve insan geri bildirimi ile g\xfc\xe7lendirilmiş \xf6ğrenme (RLHF) ile faydalılığını ve g\xfcvenliğini artırmıştır. Talimat ayarlı versiyonu, \xe7ok dilli diyaloglar i\xe7in optimize edilmiştir ve bir\xe7ok end\xfcstri kıyaslamasında bir\xe7ok a\xe7ık kaynak ve kapalı sohbet modelinden daha iyi performans g\xf6stermektedir. Bilgi kesim tarihi 2023 Aralık\'tır."},"meta-llama/llama-3.3-70b-instruct:free":{"description":"Llama 3.3, Llama serisinin en gelişmiş \xe7ok dilli a\xe7ık kaynak b\xfcy\xfck dil modelidir ve 405B modelinin performansını \xe7ok d\xfcş\xfck maliyetle deneyimlemenizi sağlar. Transformer yapısına dayanmaktadır ve denetimli ince ayar (SFT) ve insan geri bildirimi ile g\xfc\xe7lendirilmiş \xf6ğrenme (RLHF) ile faydalılığını ve g\xfcvenliğini artırmıştır. Talimat ayarlı versiyonu, \xe7ok dilli diyaloglar i\xe7in optimize edilmiştir ve bir\xe7ok end\xfcstri kıyaslamasında bir\xe7ok a\xe7ık kaynak ve kapalı sohbet modelinden daha iyi performans g\xf6stermektedir. Bilgi kesim tarihi 2023 Aralık\'tır."},"meta.llama3-1-405b-instruct-v1:0":{"description":"Meta Llama 3.1 405B Instruct, Llama 3.1 Instruct modelinin en b\xfcy\xfck ve en g\xfc\xe7l\xfc versiyonudur. Bu, son derece gelişmiş bir diyalog akıl y\xfcr\xfctme ve veri sentezleme modelidir ve belirli alanlarda uzmanlaşmış s\xfcrekli \xf6n eğitim veya ince ayar i\xe7in bir temel olarak da kullanılabilir. Llama 3.1, \xe7ok dilli b\xfcy\xfck dil modelleri (LLM\'ler) sunar ve 8B, 70B ve 405B boyutlarında \xf6nceden eğitilmiş, talimat ayarlı \xfcretim modellerinden oluşur (metin girişi/\xe7ıkışı). Llama 3.1\'in talimat ayarlı metin modelleri (8B, 70B, 405B), \xe7ok dilli diyalog kullanım durumları i\xe7in optimize edilmiştir ve yaygın end\xfcstri benchmark testlerinde bir\xe7ok mevcut a\xe7ık kaynaklı sohbet modelini geride bırakmıştır. Llama 3.1, \xe7ok dilli ticari ve araştırma ama\xe7ları i\xe7in tasarlanmıştır. Talimat ayarlı metin modelleri, asistan benzeri sohbetler i\xe7in uygundur, \xf6nceden eğitilmiş modeller ise \xe7eşitli doğal dil \xfcretim g\xf6revlerine uyum sağlayabilir. Llama 3.1 modeli, diğer modellerin \xe7ıktısını iyileştirmek i\xe7in de kullanılabilir, bu da veri sentezleme ve rafine etme işlemlerini i\xe7erir. Llama 3.1, optimize edilmiş bir transformer mimarisi kullanarak oluşturulmuş bir otoregresif dil modelidir. Ayarlanmış versiyon, insan yardımseverliği ve g\xfcvenlik tercihleri ile uyumlu hale getirmek i\xe7in denetimli ince ayar (SFT) ve insan geri bildirimi ile g\xfc\xe7lendirilmiş \xf6ğrenme (RLHF) kullanır."},"meta.llama3-1-70b-instruct-v1:0":{"description":"Meta Llama 3.1 70B Instruct\'un g\xfcncellenmiş versiyonu, genişletilmiş 128K bağlam uzunluğu, \xe7ok dilli yetenek ve geliştirilmiş akıl y\xfcr\xfctme yetenekleri i\xe7erir. Llama 3.1 tarafından sağlanan \xe7ok dilli b\xfcy\xfck dil modelleri (LLM\'ler), 8B, 70B ve 405B boyutlarında \xf6nceden eğitilmiş, talimat ayarlı \xfcretim modelleridir (metin girişi/\xe7ıkışı). Llama 3.1 talimat ayarlı metin modelleri (8B, 70B, 405B), \xe7ok dilli diyalog kullanım durumları i\xe7in optimize edilmiştir ve bir\xe7ok mevcut a\xe7ık kaynaklı sohbet modelini yaygın end\xfcstri benchmark testlerinde ge\xe7miştir. Llama 3.1, \xe7ok dilli ticari ve araştırma ama\xe7ları i\xe7in kullanılmak \xfczere tasarlanmıştır. Talimat ayarlı metin modelleri, asistan benzeri sohbetler i\xe7in uygundur, \xf6nceden eğitilmiş modeller ise \xe7eşitli doğal dil \xfcretim g\xf6revlerine uyum sağlayabilir. Llama 3.1 modeli, diğer modellerin \xe7ıktısını iyileştirmek i\xe7in de kullanılabilir, bu da sentetik veri \xfcretimi ve rafine etme işlemlerini i\xe7erir. Llama 3.1, optimize edilmiş bir d\xf6n\xfcşt\xfcr\xfcc\xfc mimarisi kullanarak oluşturulmuş bir otoregresif dil modelidir. Ayarlanmış versiyonlar, insan yardımseverliği ve g\xfcvenlik tercihlerini karşılamak i\xe7in denetimli ince ayar (SFT) ve insan geri bildirimli pekiştirmeli \xf6ğrenme (RLHF) kullanır."},"meta.llama3-1-8b-instruct-v1:0":{"description":"Meta Llama 3.1 8B Instruct\'un g\xfcncellenmiş versiyonu, genişletilmiş 128K bağlam uzunluğu, \xe7ok dilli yetenek ve geliştirilmiş akıl y\xfcr\xfctme yetenekleri i\xe7erir. Llama 3.1 tarafından sağlanan \xe7ok dilli b\xfcy\xfck dil modelleri (LLM\'ler), 8B, 70B ve 405B boyutlarında \xf6nceden eğitilmiş, talimat ayarlı \xfcretim modelleridir (metin girişi/\xe7ıkışı). Llama 3.1 talimat ayarlı metin modelleri (8B, 70B, 405B), \xe7ok dilli diyalog kullanım durumları i\xe7in optimize edilmiştir ve bir\xe7ok mevcut a\xe7ık kaynaklı sohbet modelini yaygın end\xfcstri benchmark testlerinde ge\xe7miştir. Llama 3.1, \xe7ok dilli ticari ve araştırma ama\xe7ları i\xe7in kullanılmak \xfczere tasarlanmıştır. Talimat ayarlı metin modelleri, asistan benzeri sohbetler i\xe7in uygundur, \xf6nceden eğitilmiş modeller ise \xe7eşitli doğal dil \xfcretim g\xf6revlerine uyum sağlayabilir. Llama 3.1 modeli, diğer modellerin \xe7ıktısını iyileştirmek i\xe7in de kullanılabilir, bu da sentetik veri \xfcretimi ve rafine etme işlemlerini i\xe7erir. Llama 3.1, optimize edilmiş bir d\xf6n\xfcşt\xfcr\xfcc\xfc mimarisi kullanarak oluşturulmuş bir otoregresif dil modelidir. Ayarlanmış versiyonlar, insan yardımseverliği ve g\xfcvenlik tercihlerini karşılamak i\xe7in denetimli ince ayar (SFT) ve insan geri bildirimli pekiştirmeli \xf6ğrenme (RLHF) kullanır."},"meta.llama3-70b-instruct-v1:0":{"description":"Meta Llama 3, geliştiriciler, araştırmacılar ve işletmeler i\xe7in a\xe7ık bir b\xfcy\xfck dil modelidir (LLM) ve onların \xfcretken AI fikirlerini inşa etmelerine, denemelerine ve sorumlu bir şekilde genişletmelerine yardımcı olmak i\xe7in tasarlanmıştır. K\xfcresel topluluk yeniliğinin temel sistemlerinden biri olarak, i\xe7erik oluşturma, diyalog AI, dil anlama, araştırma ve işletme uygulamaları i\xe7in son derece uygundur."},"meta.llama3-8b-instruct-v1:0":{"description":"Meta Llama 3, geliştiriciler, araştırmacılar ve işletmeler i\xe7in a\xe7ık bir b\xfcy\xfck dil modelidir (LLM) ve onların \xfcretken AI fikirlerini inşa etmelerine, denemelerine ve sorumlu bir şekilde genişletmelerine yardımcı olmak i\xe7in tasarlanmıştır. K\xfcresel topluluk yeniliğinin temel sistemlerinden biri olarak, sınırlı hesaplama g\xfcc\xfc ve kaynaklara sahip, kenar cihazları ve daha hızlı eğitim s\xfcreleri i\xe7in son derece uygundur."},"meta/Llama-3.2-11B-Vision-Instruct":{"description":"Y\xfcksek \xe7\xf6z\xfcn\xfcrl\xfckl\xfc g\xf6r\xfcnt\xfclerde \xfcst\xfcn g\xf6rsel \xe7ıkarım yeteneği sunar, g\xf6rsel anlama uygulamaları i\xe7in idealdir."},"meta/Llama-3.2-90B-Vision-Instruct":{"description":"G\xf6rsel anlama ajan uygulamaları i\xe7in gelişmiş g\xf6r\xfcnt\xfc \xe7ıkarım yetenekleri sağlar."},"meta/Llama-3.3-70B-Instruct":{"description":"Llama 3.3, Llama serisinin en gelişmiş \xe7ok dilli a\xe7ık kaynak b\xfcy\xfck dil modeli olup, 405 milyar parametreli modellere kıyasla \xe7ok d\xfcş\xfck maliyetle y\xfcksek performans sunar. Transformer mimarisi temel alınmış, denetimli ince ayar (SFT) ve insan geri bildirimi ile g\xfc\xe7lendirilmiş pekiştirmeli \xf6ğrenme (RLHF) ile faydalılık ve g\xfcvenlik artırılmıştır. \xc7ok dilli diyaloglar i\xe7in optimize edilmiş talimat ayarlı versiyonu, bir\xe7ok end\xfcstri kıyaslamasında a\xe7ık ve kapalı sohbet modellerinden \xfcst\xfcn performans g\xf6sterir. Bilgi kesim tarihi 2023 Aralık\'tır."},"meta/Meta-Llama-3-70B-Instruct":{"description":"\xc7ıkarım, kodlama ve geniş dil uygulamalarında \xfcst\xfcn performans g\xf6steren g\xfc\xe7l\xfc 70 milyar parametreli model."},"meta/Meta-Llama-3-8B-Instruct":{"description":"Diyalog ve metin \xfcretimi g\xf6revleri i\xe7in optimize edilmiş \xe7ok y\xf6nl\xfc 8 milyar parametreli model."},"meta/Meta-Llama-3.1-405B-Instruct":{"description":"Llama 3.1 talimat ayarlı metin modeli, \xe7ok dilli diyalog senaryoları i\xe7in optimize edilmiştir ve bir\xe7ok a\xe7ık ve kapalı sohbet modeli arasında yaygın end\xfcstri kıyaslamalarında \xfcst\xfcn performans sergiler."},"meta/Meta-Llama-3.1-70B-Instruct":{"description":"Llama 3.1 talimat ayarlı metin modeli, \xe7ok dilli diyalog senaryoları i\xe7in optimize edilmiştir ve bir\xe7ok a\xe7ık ve kapalı sohbet modeli arasında yaygın end\xfcstri kıyaslamalarında \xfcst\xfcn performans sergiler."},"meta/Meta-Llama-3.1-8B-Instruct":{"description":"Llama 3.1 talimat ayarlı metin modeli, \xe7ok dilli diyalog senaryoları i\xe7in optimize edilmiştir ve bir\xe7ok a\xe7ık ve kapalı sohbet modeli arasında yaygın end\xfcstri kıyaslamalarında \xfcst\xfcn performans sergiler."},"meta/llama-3-70b":{"description":"Meta tarafından talimat takibi ama\xe7lı \xf6zenle ayarlanmış 70 milyar parametre a\xe7ık kaynak modeli. Groq tarafından \xf6zel Dil İşleme Birimi (LPU) donanımı ile hizmet verilir ve hızlı, verimli \xe7ıkarım sağlar."},"meta/llama-3-8b":{"description":"Meta tarafından talimat takibi ama\xe7lı \xf6zenle ayarlanmış 8 milyar parametre a\xe7ık kaynak modeli. Groq tarafından \xf6zel Dil İşleme Birimi (LPU) donanımı ile hizmet verilir ve hızlı, verimli \xe7ıkarım sağlar."},"meta/llama-3.1-405b-instruct":{"description":"Gelişmiş LLM, sentetik veri \xfcretimi, bilgi damıtma ve akıl y\xfcr\xfctmeyi destekler, sohbet botları, programlama ve belirli alan g\xf6revleri i\xe7in uygundur."},"meta/llama-3.1-70b":{"description":"Meta Llama 3 70B Instruct\'in g\xfcncellenmiş versiyonu olup, genişletilmiş 128K bağlam uzunluğu, \xe7ok dillilik ve geliştirilmiş \xe7ıkarım yetenekleri i\xe7erir."},"meta/llama-3.1-70b-instruct":{"description":"Karmaşık diyalogları g\xfc\xe7lendiren, m\xfckemmel bağlam anlama, akıl y\xfcr\xfctme yeteneği ve metin \xfcretimi yeteneğine sahip."},"meta/llama-3.1-8b":{"description":"Llama 3.1 8B, 128K bağlam penceresini destekler ve ger\xe7ek zamanlı diyalog aray\xfczleri ile veri analizi i\xe7in ideal bir se\xe7imdir; daha b\xfcy\xfck modellere kıyasla \xf6nemli maliyet tasarrufu sağlar. Groq tarafından \xf6zel Dil İşleme Birimi (LPU) donanımı ile hizmet verilir ve hızlı, verimli \xe7ıkarım sağlar."},"meta/llama-3.1-8b-instruct":{"description":"En son teknolojiye sahip model, dil anlama, m\xfckemmel akıl y\xfcr\xfctme yeteneği ve metin \xfcretimi yeteneğine sahiptir."},"meta/llama-3.2-11b":{"description":"Talimat ayarlı g\xf6r\xfcnt\xfc \xe7ıkarım \xfcretim modeli (metin + g\xf6r\xfcnt\xfc girişi / metin \xe7ıktısı) olup, g\xf6rsel tanıma, g\xf6r\xfcnt\xfc \xe7ıkarımı, başlık oluşturma ve g\xf6r\xfcnt\xfc ile ilgili genel soruları yanıtlamada optimize edilmiştir."},"meta/llama-3.2-11b-vision-instruct":{"description":"Gelişmiş g\xf6rsel-dil modeli, g\xf6r\xfcnt\xfclerden y\xfcksek kaliteli akıl y\xfcr\xfctme yapma konusunda uzmandır."},"meta/llama-3.2-1b":{"description":"Sadece metin modeli olup, \xe7ok dilli yerel bilgi arama, \xf6zetleme ve yeniden yazma gibi cihaz \xfczeri kullanım durumlarını destekler."},"meta/llama-3.2-1b-instruct":{"description":"En son teknolojiye sahip k\xfc\xe7\xfck dil modeli, dil anlama, m\xfckemmel akıl y\xfcr\xfctme yeteneği ve metin \xfcretimi yeteneğine sahiptir."},"meta/llama-3.2-3b":{"description":"Sadece metin modeli olup, \xe7ok dilli yerel bilgi arama, \xf6zetleme ve yeniden yazma gibi cihaz \xfczeri kullanım durumlarını desteklemek i\xe7in \xf6zenle ayarlanmıştır."},"meta/llama-3.2-3b-instruct":{"description":"En son teknolojiye sahip k\xfc\xe7\xfck dil modeli, dil anlama, m\xfckemmel akıl y\xfcr\xfctme yeteneği ve metin \xfcretimi yeteneğine sahiptir."},"meta/llama-3.2-90b":{"description":"Talimat ayarlı g\xf6r\xfcnt\xfc \xe7ıkarım \xfcretim modeli (metin + g\xf6r\xfcnt\xfc girişi / metin \xe7ıktısı) olup, g\xf6rsel tanıma, g\xf6r\xfcnt\xfc \xe7ıkarımı, başlık oluşturma ve g\xf6r\xfcnt\xfc ile ilgili genel soruları yanıtlamada optimize edilmiştir."},"meta/llama-3.2-90b-vision-instruct":{"description":"Gelişmiş g\xf6rsel-dil modeli, g\xf6r\xfcnt\xfclerden y\xfcksek kaliteli akıl y\xfcr\xfctme yapma konusunda uzmandır."},"meta/llama-3.3-70b":{"description":"Performans ve verimliliğin m\xfckemmel birleşimi. Model, y\xfcksek performanslı diyalog yapay zekasını destekler, i\xe7erik oluşturma, kurumsal uygulamalar ve araştırma i\xe7in tasarlanmıştır ve metin \xf6zetleme, sınıflandırma, duygu analizi ve kod \xfcretimi dahil gelişmiş dil anlama yetenekleri sunar."},"meta/llama-3.3-70b-instruct":{"description":"Akıllı LLM, akıl y\xfcr\xfctme, matematik, genel bilgi ve fonksiyon \xe7ağrılarında uzmandır."},"meta/llama-4-maverick":{"description":"Llama 4 model ailesi, metin ve \xe7ok modlu deneyimleri destekleyen yerel \xe7ok modlu yapay zeka modelleridir. Bu modeller, karma uzman mimarisi kullanarak metin ve g\xf6r\xfcnt\xfc anlama alanında sekt\xf6r lideri performans sunar. Llama 4 Maverick, 17 milyar parametreli ve 128 uzmanlı bir modeldir. DeepInfra tarafından hizmet verilmektedir."},"meta/llama-4-scout":{"description":"Llama 4 model ailesi, metin ve \xe7ok modlu deneyimleri destekleyen yerel \xe7ok modlu yapay zeka modelleridir. Bu modeller, karma uzman mimarisi kullanarak metin ve g\xf6r\xfcnt\xfc anlama alanında sekt\xf6r lideri performans sunar. Llama 4 Scout, 17 milyar parametreli ve 16 uzmanlı bir modeldir. DeepInfra tarafından hizmet verilmektedir."},"microsoft/Phi-3-medium-128k-instruct":{"description":"Aynı Phi-3-medium modeli, ancak daha b\xfcy\xfck bağlam boyutuna sahip olup RAG veya az sayıda istem i\xe7in uygundur."},"microsoft/Phi-3-medium-4k-instruct":{"description":"140 milyar parametreli model, Phi-3-mini\'den daha y\xfcksek kaliteye sahip olup, y\xfcksek kaliteli ve \xe7ıkarım yoğun veriye odaklanır."},"microsoft/Phi-3-mini-128k-instruct":{"description":"Aynı Phi-3-mini modeli, ancak daha b\xfcy\xfck bağlam boyutuna sahip olup RAG veya az sayıda istem i\xe7in uygundur."},"microsoft/Phi-3-mini-4k-instruct":{"description":"Phi-3 ailesinin en k\xfc\xe7\xfck \xfcyesi olup, kalite ve d\xfcş\xfck gecikme i\xe7in optimize edilmiştir."},"microsoft/Phi-3-small-128k-instruct":{"description":"Aynı Phi-3-small modeli, ancak daha b\xfcy\xfck bağlam boyutuna sahip olup RAG veya az sayıda istem i\xe7in uygundur."},"microsoft/Phi-3-small-8k-instruct":{"description":"70 milyar parametreli model, Phi-3-mini\'den daha y\xfcksek kaliteye sahip olup, y\xfcksek kaliteli ve \xe7ıkarım yoğun veriye odaklanır."},"microsoft/Phi-3.5-mini-instruct":{"description":"Phi-3-mini modelinin g\xfcncellenmiş versiyonu."},"microsoft/Phi-3.5-vision-instruct":{"description":"Phi-3-vision modelinin g\xfcncellenmiş versiyonu."},"microsoft/WizardLM-2-8x22B":{"description":"WizardLM 2, Microsoft AI tarafından sağlanan bir dil modelidir ve karmaşık diyaloglar, \xe7ok dilli destek, akıl y\xfcr\xfctme ve akıllı asistan alanlarında \xf6zellikle başarılıdır."},"microsoft/wizardlm-2-8x22b":{"description":"WizardLM-2 8x22B, Microsoft\'un en gelişmiş AI Wizard modelidir ve son derece rekabet\xe7i bir performans sergiler."},"minicpm-v":{"description":"MiniCPM-V, OpenBMB tarafından sunulan yeni nesil \xe7ok modlu b\xfcy\xfck bir modeldir; olağan\xfcst\xfc OCR tanıma ve \xe7ok modlu anlama yeteneklerine sahiptir ve geniş bir uygulama yelpazesini destekler."},"minimax-m2":{"description":"MiniMax M2, kodlama ve yardımcı iş akışları i\xe7in \xf6zel olarak geliştirilmiş, verimli bir b\xfcy\xfck dil modelidir."},"minimax/minimax-m2":{"description":"Verimli kodlama ve Agent iş akışları i\xe7in \xf6zel olarak tasarlanmıştır."},"minimaxai/minimax-m2":{"description":"MiniMax-M2, 230 milyar toplam parametreye ve 10 milyar etkin parametreye sahip kompakt, hızlı ve ekonomik bir Uzman Karışımı (MoE) modelidir. Kodlama ve yapay zek\xe2 g\xf6revlerinde \xfcst\xfcn performans sunmak \xfczere tasarlanmış olup, g\xfc\xe7l\xfc bir genel zek\xe2 kapasitesini de korur. \xc7oklu dosya d\xfczenleme, kodla-\xe7alıştır-d\xfczelt d\xf6ng\xfcs\xfc, test doğrulama ve d\xfczeltme ile karmaşık uzun zincirli ara\xe7 zincirlerinde \xfcst\xfcn performans g\xf6stererek geliştirici iş akışları i\xe7in ideal bir se\xe7imdir."},"ministral-3b-latest":{"description":"Ministral 3B, Mistral\'ın d\xfcnya \xe7apında en \xfcst d\xfczey kenar modelidir."},"ministral-8b-latest":{"description":"Ministral 8B, Mistral\'ın fiyat-performans oranı olduk\xe7a y\xfcksek kenar modelidir."},"mistral":{"description":"Mistral, Mistral AI tarafından sunulan 7B modelidir, değişken dil işleme ihtiya\xe7ları i\xe7in uygundur."},"mistral-ai/Mistral-Large-2411":{"description":"Mistral\'in amiral gemisi modeli olup, b\xfcy\xfck \xf6l\xe7ekli \xe7ıkarım yetenekleri veya y\xfcksek derecede uzmanlaşmış karmaşık g\xf6revler (metin sentezi, kod \xfcretimi, RAG veya ajanlar) i\xe7in uygundur."},"mistral-ai/Mistral-Nemo":{"description":"Mistral Nemo, boyut kategorisinde en gelişmiş \xe7ıkarım, d\xfcnya bilgisi ve kodlama yeteneklerine sahip ileri d\xfczey bir dil modelidir (LLM)."},"mistral-ai/mistral-small-2503":{"description":"Mistral Small, y\xfcksek verimlilik ve d\xfcş\xfck gecikme gerektiren dil tabanlı g\xf6revler i\xe7in uygundur."},"mistral-large":{"description":"Mixtral Large, Mistral\'ın amiral gemisi modelidir, kod \xfcretimi, matematik ve akıl y\xfcr\xfctme yeteneklerini birleştirir, 128k bağlam penceresini destekler."},"mistral-large-instruct":{"description":"Mistral-Large-Instruct-2407, 123 milyar parametreye sahip, gelişmiş bir yoğun b\xfcy\xfck dil modelidir (LLM) ve en son akıl y\xfcr\xfctme, bilgi ve kodlama yeteneklerine sahiptir."},"mistral-large-latest":{"description":"Mistral Large, \xe7ok dilli g\xf6revler, karmaşık akıl y\xfcr\xfctme ve kod \xfcretimi i\xe7in ideal bir se\xe7imdir ve y\xfcksek u\xe7 uygulamalar i\xe7in tasarlanmıştır."},"mistral-medium-latest":{"description":"Mistral Medium 3, 8 kat daha d\xfcş\xfck maliyetle en ileri d\xfczey performansı sunar ve kurumsal dağıtımları temelden basitleştirir."},"mistral-nemo":{"description":"Mistral Nemo, Mistral AI ve NVIDIA işbirliği ile sunulan, y\xfcksek verimli 12B modelidir."},"mistral-nemo-instruct":{"description":"Mistral-Nemo-Instruct-2407 b\xfcy\xfck dil modeli (LLM), Mistral-Nemo-Base-2407\'nin komut ince ayarlı versiyonudur."},"mistral-small":{"description":"Mistral Small, y\xfcksek verimlilik ve d\xfcş\xfck gecikme gerektiren her dil tabanlı g\xf6revde kullanılabilir."},"mistral-small-latest":{"description":"Mistral Small, \xe7eviri, \xf6zetleme ve duygu analizi gibi kullanım durumları i\xe7in maliyet etkin, hızlı ve g\xfcvenilir bir se\xe7enektir."},"mistral/codestral":{"description":"Mistral Codestral 25.01, d\xfcş\xfck gecikme ve y\xfcksek frekanslı kullanım durumları i\xe7in optimize edilmiş en gelişmiş kodlama modelidir. 80\'den fazla programlama dilinde uzman olup, orta doldurma (FIM), kod d\xfczeltme ve test \xfcretimi gibi g\xf6revlerde \xfcst\xfcn performans g\xf6sterir."},"mistral/codestral-embed":{"description":"Kod veritabanları ve depolarına g\xf6m\xfclebilen, kodlama asistanlarını destekleyen kod g\xf6mme modeli."},"mistral/devstral-small":{"description":"Devstral, yazılım m\xfchendisliği g\xf6revleri i\xe7in bir ajan b\xfcy\xfck dil modeli olup, yazılım m\xfchendisliği ajanları i\xe7in m\xfckemmel bir se\xe7imdir."},"mistral/magistral-medium":{"description":"Derin anlayışa dayanan karmaşık d\xfcş\xfcnce, takip edilebilir ve doğrulanabilir şeffaf \xe7ıkarım sunar. Model, g\xf6rev ortasında dil değiştirse bile bir\xe7ok dilde y\xfcksek sadakatli \xe7ıkarım sağlar."},"mistral/magistral-small":{"description":"Derin anlayışa dayanan karmaşık d\xfcş\xfcnce, takip edilebilir ve doğrulanabilir şeffaf \xe7ıkarım sunar. Model, g\xf6rev ortasında dil değiştirse bile bir\xe7ok dilde y\xfcksek sadakatli \xe7ıkarım sağlar."},"mistral/ministral-3b":{"description":"Akıllı asistanlar ve yerel analiz gibi cihaz \xfczeri g\xf6revler i\xe7in kompakt, verimli model olup, d\xfcş\xfck gecikmeli performans sunar."},"mistral/ministral-8b":{"description":"Daha g\xfc\xe7l\xfc, daha hızlı ve bellek a\xe7ısından verimli \xe7ıkarım sunan model olup, karmaşık iş akışları ve zorlu u\xe7 uygulamalar i\xe7in idealdir."},"mistral/mistral-embed":{"description":"Anlamsal arama, benzerlik, k\xfcmeleme ve RAG iş akışları i\xe7in genel ama\xe7lı metin g\xf6mme modeli."},"mistral/mistral-large":{"description":"Mistral Large, b\xfcy\xfck \xe7ıkarım yetenekleri veya y\xfcksek uzmanlık gerektiren karmaşık g\xf6revler i\xe7in ideal se\xe7imdir—\xf6rneğin sentez metin \xfcretimi, kod \xfcretimi, RAG veya ajanlık."},"mistral/mistral-small":{"description":"Mistral Small, sınıflandırma, m\xfcşteri desteği veya metin \xfcretimi gibi toplu yapılabilen basit g\xf6revler i\xe7in ideal se\xe7imdir. Uygun fiyat noktasında m\xfckemmel performans sunar."},"mistral/mixtral-8x22b-instruct":{"description":"8x22b Instruct modeli. 8x22b, Mistral tarafından hizmet verilen karma uzman a\xe7ık kaynak modelidir."},"mistral/pixtral-12b":{"description":"G\xf6r\xfcnt\xfc anlama yeteneğine sahip 12 milyar parametreli model ve metin."},"mistral/pixtral-large":{"description":"Pixtral Large, \xe7ok modlu ailemizdeki ikinci model olup, ileri d\xfczey g\xf6r\xfcnt\xfc anlama yetenekleri sergiler. \xd6zellikle belge, grafik ve doğal g\xf6r\xfcnt\xfcleri anlayabilir ve Mistral Large 2\'nin lider metin anlama yeteneklerini korur."},"mistralai/Mistral-7B-Instruct-v0.1":{"description":"Mistral (7B) Instruct, y\xfcksek performansıyla tanınır ve \xe7eşitli dil g\xf6revleri i\xe7in uygundur."},"mistralai/Mistral-7B-Instruct-v0.2":{"description":"Mistral 7B, talebe g\xf6re ince ayar yapılmış bir modeldir ve g\xf6revler i\xe7in optimize edilmiş yanıtlar sunar."},"mistralai/Mistral-7B-Instruct-v0.3":{"description":"Mistral (7B) Instruct v0.3, geniş uygulamalar i\xe7in etkili hesaplama g\xfcc\xfc ve doğal dil anlama sunar."},"mistralai/Mistral-7B-v0.1":{"description":"Mistral 7B, kompakt ancak y\xfcksek performanslı bir modeldir, sınıflandırma ve metin \xfcretimi gibi basit g\xf6revlerde iyi bir akıl y\xfcr\xfctme yeteneği ile yoğun işlem yapma konusunda uzmandır."},"mistralai/Mixtral-8x22B-Instruct-v0.1":{"description":"Mixtral-8x22B Instruct (141B), son derece b\xfcy\xfck bir dil modelidir ve \xe7ok y\xfcksek işleme taleplerini destekler."},"mistralai/Mixtral-8x7B-Instruct-v0.1":{"description":"Mixtral 8x7B, genel metin g\xf6revleri i\xe7in kullanılan \xf6nceden eğitilmiş seyrek karışık uzman modelidir."},"mistralai/Mixtral-8x7B-v0.1":{"description":"Mixtral 8x7B, birden fazla parametre kullanarak akıl y\xfcr\xfctme hızını artıran seyrek uzman modelidir, \xe7ok dilli ve kod \xfcretim g\xf6revleri i\xe7in uygundur."},"mistralai/mistral-nemo":{"description":"Mistral Nemo, \xe7ok dilli destek ve y\xfcksek performanslı programlama sunan 7.3B parametreli bir modeldir."},"mixtral":{"description":"Mixtral, Mistral AI\'nın uzman modelidir, a\xe7ık kaynak ağırlıkları ile birlikte gelir ve kod \xfcretimi ve dil anlama konularında destek sunar."},"mixtral-8x7b-32768":{"description":"Mixtral 8x7B, y\xfcksek hata toleransına sahip paralel hesaplama yeteneği sunar ve karmaşık g\xf6revler i\xe7in uygundur."},"mixtral:8x22b":{"description":"Mixtral, Mistral AI\'nın uzman modelidir, a\xe7ık kaynak ağırlıkları ile birlikte gelir ve kod \xfcretimi ve dil anlama konularında destek sunar."},"moonshot-v1-128k":{"description":"Moonshot V1 128K, ultra uzun bağlam işleme yeteneğine sahip bir modeldir, karmaşık \xfcretim g\xf6revlerini karşılamak i\xe7in ultra uzun metinler \xfcretmekte kullanılabilir, 128,000 token\'a kadar i\xe7eriği işleyebilir, araştırma, akademik ve b\xfcy\xfck belgelerin \xfcretilmesi gibi uygulama senaryoları i\xe7in son derece uygundur."},"moonshot-v1-128k-vision-preview":{"description":"Kimi g\xf6rsel modeli (moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-preview gibi) resim i\xe7eriğini anlayabilir, resim metni, resim rengi ve nesne şekilleri gibi i\xe7erikleri kapsar."},"moonshot-v1-32k":{"description":"Moonshot V1 32K, orta uzunlukta bağlam işleme yeteneği sunar, 32,768 token\'ı işleyebilir, \xe7eşitli uzun belgeler ve karmaşık diyaloglar \xfcretmek i\xe7in \xf6zellikle uygundur, i\xe7erik oluşturma, rapor \xfcretimi ve diyalog sistemleri gibi alanlarda kullanılabilir."},"moonshot-v1-32k-vision-preview":{"description":"Kimi g\xf6rsel modeli (moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-preview gibi) resim i\xe7eriğini anlayabilir, resim metni, resim rengi ve nesne şekilleri gibi i\xe7erikleri kapsar."},"moonshot-v1-8k":{"description":"Moonshot V1 8K, kısa metin g\xf6revleri i\xe7in tasarlanmış, y\xfcksek verimlilikte işleme performansı sunar, 8,192 token\'ı işleyebilir, kısa diyaloglar, not alma ve hızlı i\xe7erik \xfcretimi i\xe7in son derece uygundur."},"moonshot-v1-8k-vision-preview":{"description":"Kimi g\xf6rsel modeli (moonshot-v1-8k-vision-preview/moonshot-v1-32k-vision-preview/moonshot-v1-128k-vision-preview gibi) resim i\xe7eriğini anlayabilir, resim metni, resim rengi ve nesne şekilleri gibi i\xe7erikleri kapsar."},"moonshot-v1-auto":{"description":"Moonshot V1 Auto, mevcut bağlamın kullandığı Token sayısına g\xf6re uygun modeli se\xe7ebilir."},"moonshotai/Kimi-Dev-72B":{"description":"Kimi-Dev-72B, b\xfcy\xfck \xf6l\xe7ekli pekiştirmeli \xf6ğrenme ile optimize edilmiş a\xe7ık kaynaklı bir kod modeli olup, sağlam ve doğrudan \xfcretime uygun yamalar \xfcretebilir. Bu model, SWE-bench Verified \xfczerinde %60,4 ile yeni bir rekor kırarak, a\xe7ık kaynak modeller arasında hata d\xfczeltme, kod incelemesi gibi otomatik yazılım m\xfchendisliği g\xf6revlerinde en y\xfcksek puanı elde etmiştir."},"moonshotai/Kimi-K2-Instruct-0905":{"description":"Kimi K2-Instruct-0905, Kimi K2\'nin en yeni ve en g\xfc\xe7l\xfc versiyonudur. Bu, toplamda 1 trilyon parametreye ve 32 milyar aktif parametreye sahip, \xfcst d\xfczey bir Hibrit Uzman (MoE) dil modelidir. Modelin başlıca \xf6zellikleri şunlardır: geliştirilmiş ajan kodlama zekası, a\xe7ık benchmark testlerinde ve ger\xe7ek d\xfcnya ajan kodlama g\xf6revlerinde belirgin performans artışı; \xf6n u\xe7 kodlama deneyiminde iyileştirmeler, \xf6n u\xe7 programlamada estetik ve işlevsellik a\xe7ısından ilerlemeler."},"moonshotai/kimi-k2":{"description":"Kimi K2, Moonshot AI tarafından geliştirilen b\xfcy\xfck \xf6l\xe7ekli karma uzman (MoE) dil modeli olup, toplamda 1 trilyon parametre ve her ileri ge\xe7işte 32 milyar aktif parametreye sahiptir. Ajan yetenekleri i\xe7in optimize edilmiştir; gelişmiş ara\xe7 kullanımı, \xe7ıkarım ve kod sentezi i\xe7erir."},"moonshotai/kimi-k2-0905":{"description":"kimi-k2-0905-preview modelinin bağlam uzunluğu 256k’dır, daha g\xfc\xe7l\xfc Agentic Kodlama yeteneklerine, \xf6n u\xe7 kodlarının estetik ve işlevselliğinde belirgin gelişmelere ve daha iyi bağlam anlama yeteneğine sahiptir."},"moonshotai/kimi-k2-instruct-0905":{"description":"kimi-k2-0905-preview modelinin bağlam uzunluğu 256k’dır, daha g\xfc\xe7l\xfc Agentic Kodlama yeteneklerine, \xf6n u\xe7 kodlarının estetik ve işlevselliğinde belirgin gelişmelere ve daha iyi bağlam anlama yeteneğine sahiptir."},"morph/morph-v3-fast":{"description":"Morph, Claude veya GPT-4o gibi ileri modellerin \xf6nerdiği kod değişikliklerini mevcut kod dosyalarınıza UYGULAR - HIZLI - 4500+ token/saniye. AI kodlama iş akışında son adım olarak g\xf6rev yapar. 16k giriş token ve 16k \xe7ıkış token destekler."},"morph/morph-v3-large":{"description":"Morph, Claude veya GPT-4o gibi ileri modellerin \xf6nerdiği kod değişikliklerini mevcut kod dosyalarınıza UYGULAR - HIZLI - 2500+ token/saniye. AI kodlama iş akışında son adım olarak g\xf6rev yapar. 16k giriş token ve 16k \xe7ıkış token destekler."},"nousresearch/hermes-2-pro-llama-3-8b":{"description":"Hermes 2 Pro Llama 3 8B, Nous Hermes 2\'nin g\xfcncellenmiş versiyonudur ve en son i\xe7 geliştirme veri setlerini i\xe7ermektedir."},"nvidia/Llama-3.1-Nemotron-70B-Instruct-HF":{"description":"Llama 3.1 Nemotron 70B, NVIDIA tarafından \xf6zelleştirilmiş b\xfcy\xfck bir dil modelidir ve LLM tarafından \xfcretilen yanıtların kullanıcı sorgularına yardımcı olma d\xfczeyini artırmayı ama\xe7lamaktadır. Bu model, Arena Hard, AlpacaEval 2 LC ve GPT-4-Turbo MT-Bench gibi standart testlerde m\xfckemmel performans sergilemiştir ve 1 Ekim 2024 itibarıyla t\xfcm \xfc\xe7 otomatik hizalama testinde birinci sıradadır. Model, Llama-3.1-70B-Instruct modelinin temelinde RLHF (\xf6zellikle REINFORCE), Llama-3.1-Nemotron-70B-Reward ve HelpSteer2-Preference ipu\xe7ları kullanılarak eğitilmiştir."},"nvidia/llama-3.1-nemotron-51b-instruct":{"description":"Eşsiz bir dil modeli, benzersiz doğruluk ve verimlilik sunar."},"nvidia/llama-3.1-nemotron-70b-instruct":{"description":"Llama-3.1-Nemotron-70B-Instruct, NVIDIA\'nın \xf6zel olarak geliştirdiği b\xfcy\xfck dil modelidir ve LLM tarafından \xfcretilen yanıtların yardımcı olmasını artırmayı ama\xe7lar."},"o1":{"description":"Gelişmiş \xe7ıkarım ve karmaşık sorunları \xe7\xf6zmeye odaklanır, matematik ve bilim g\xf6revlerini i\xe7erir. Derin bağlam anlayışı ve aracılık iş akışları gerektiren uygulamalar i\xe7in son derece uygundur."},"o1-mini":{"description":"o1-mini, programlama, matematik ve bilim uygulama senaryoları i\xe7in tasarlanmış hızlı ve ekonomik bir akıl y\xfcr\xfctme modelidir. Bu model, 128K bağlam ve Ekim 2023 bilgi kesim tarihi ile donatılmıştır."},"o1-preview":{"description":"İleri d\xfczey muhakeme ve matematik ile fen g\xf6revleri dahil olmak \xfczere karmaşık sorunların \xe7\xf6z\xfcm\xfcne odaklanır. Derin bağlam anlayışı ve \xf6zerk iş akışları gerektiren uygulamalar i\xe7in son derece uygundur."},"o1-pro":{"description":"o1 serisi modeller, yanıtlamadan \xf6nce d\xfcş\xfcnme yapabilen ve karmaşık akıl y\xfcr\xfctme g\xf6revlerini yerine getirebilen pekiştirmeli \xf6ğrenme ile eğitilmiştir. o1-pro modeli, daha derin d\xfcş\xfcnme i\xe7in daha fazla hesaplama kaynağı kullanır ve b\xf6ylece s\xfcrekli olarak daha kaliteli yanıtlar sunar."},"o3":{"description":"o3, \xe7ok \xe7eşitli alanlarda m\xfckemmel performans g\xf6steren \xe7ok y\xf6nl\xfc g\xfc\xe7l\xfc bir modeldir. Matematik, bilim, programlama ve g\xf6rsel \xe7ıkarım g\xf6revlerinde yeni standartlar belirler. Ayrıca teknik yazım ve talimat takibi konusunda da uzmandır. Kullanıcılar, metin, kod ve g\xf6r\xfcnt\xfcleri analiz ederek \xe7ok adımlı karmaşık sorunları \xe7\xf6zebilir."},"o3-2025-04-16":{"description":"o3, OpenAI\'nin yeni akıl y\xfcr\xfctme modeli olup, metin ve g\xf6rsel girişleri destekler ve metin \xe7ıktısı verir; geniş kapsamlı genel bilgi gerektiren karmaşık g\xf6revler i\xe7in uygundur."},"o3-deep-research":{"description":"o3-derin-arama, karmaşık \xe7ok adımlı araştırma g\xf6revlerini işlemek i\xe7in \xf6zel olarak tasarlanmış en gelişmiş derin araştırma modelimizdir. İnternetten bilgi arayıp sentezleyebilir ve MCP bağlayıcısı aracılığıyla kendi verilerinize erişip bunları kullanabilir."},"o3-mini":{"description":"o3-mini, aynı maliyet ve gecikme hedefleriyle y\xfcksek zeka sunan en yeni k\xfc\xe7\xfck \xf6l\xe7ekli \xe7ıkarım modelimizdir."},"o3-pro":{"description":"o3-pro modeli, daha derin d\xfcş\xfcnmek ve her zaman daha iyi yanıtlar sunmak i\xe7in daha fazla hesaplama kullanır, yalnızca Responses API altında kullanılabilir."},"o3-pro-2025-06-10":{"description":"o3 Pro, OpenAI\'nin yeni akıl y\xfcr\xfctme modeli olup, metin ve g\xf6rsel girişleri destekler ve metin \xe7ıktısı verir; geniş kapsamlı genel bilgi gerektiren karmaşık g\xf6revler i\xe7in uygundur."},"o4-mini":{"description":"o4-mini, en yeni k\xfc\xe7\xfck o serisi modelimizdir. Hızlı ve etkili \xe7ıkarım i\xe7in optimize edilmiştir ve kodlama ile g\xf6rsel g\xf6revlerde son derece y\xfcksek verimlilik ve performans sergiler."},"o4-mini-2025-04-16":{"description":"o4-mini, OpenAI\'nin akıl y\xfcr\xfctme modeli olup, metin ve g\xf6rsel girişleri destekler ve metin \xe7ıktısı verir; geniş kapsamlı genel bilgi gerektiren karmaşık g\xf6revler i\xe7in uygundur. Model 200K bağlam uzunluğuna sahiptir."},"o4-mini-deep-research":{"description":"o4-mini-derin-arama, daha hızlı ve uygun maliyetli derin araştırma modelimizdir — karmaşık \xe7ok adımlı araştırma g\xf6revleri i\xe7in idealdir. İnternetten bilgi arayıp sentezleyebilir ve MCP bağlayıcısı aracılığıyla kendi verilerinize erişip bunları kullanabilir."},"open-codestral-mamba":{"description":"Codestral Mamba, kod \xfcretimine odaklanan Mamba 2 dil modelidir ve ileri d\xfczey kod ve akıl y\xfcr\xfctme g\xf6revlerine g\xfc\xe7l\xfc destek sunar."},"open-mistral-7b":{"description":"Mistral 7B, kompakt ama y\xfcksek performanslı bir modeldir, sınıflandırma ve metin \xfcretimi gibi basit g\xf6revlerde iyi bir akıl y\xfcr\xfctme yeteneğine sahiptir."},"open-mistral-nemo":{"description":"Mistral Nemo, Nvidia ile işbirliği i\xe7inde geliştirilmiş 12B modelidir, m\xfckemmel akıl y\xfcr\xfctme ve kodlama performansı sunar, entegrasyonu ve değiştirilmesi kolaydır."},"open-mixtral-8x22b":{"description":"Mixtral 8x22B, karmaşık g\xf6revler i\xe7in odaklanmış daha b\xfcy\xfck bir uzman modelidir, m\xfckemmel akıl y\xfcr\xfctme yeteneği ve daha y\xfcksek bir verim sunar."},"open-mixtral-8x7b":{"description":"Mixtral 8x7B, birden fazla parametre kullanarak akıl y\xfcr\xfctme hızını artıran seyrek uzman modelidir, \xe7ok dilli ve kod \xfcretim g\xf6revlerini işlemek i\xe7in uygundur."},"openai/gpt-3.5-turbo":{"description":"OpenAI\'nin GPT-3.5 serisindeki en yetenekli ve maliyet etkin modeli olup, sohbet ama\xe7lı optimize edilmiştir ancak geleneksel tamamlama g\xf6revlerinde de iyi performans g\xf6sterir."},"openai/gpt-3.5-turbo-instruct":{"description":"GPT-3 d\xf6nemindeki modellere benzer yetenekler sunar. Sohbet tamamlama u\xe7 noktası yerine geleneksel tamamlama u\xe7 noktası ile uyumludur."},"openai/gpt-4-turbo":{"description":"OpenAI\'den gpt-4-turbo, geniş genel bilgi ve alan uzmanlığına sahip olup, karmaşık doğal dil talimatlarını takip edebilir ve zor problemleri doğru şekilde \xe7\xf6zebilir. Bilgi kesim tarihi Nisan 2023\'t\xfcr ve 128.000 token bağlam penceresine sahiptir."},"openai/gpt-4.1":{"description":"GPT 4.1, OpenAI\'nin amiral gemisi modeli olup, karmaşık g\xf6revler i\xe7in uygundur. Alanlar arası problem \xe7\xf6zmede m\xfckemmeldir."},"openai/gpt-4.1-mini":{"description":"GPT 4.1 mini, zeka, hız ve maliyet arasında denge kurar ve bir\xe7ok kullanım durumu i\xe7in \xe7ekici bir modeldir."},"openai/gpt-4.1-nano":{"description":"GPT-4.1 nano, GPT 4.1 modelleri arasında en hızlı ve en maliyet etkin olanıdır."},"openai/gpt-4o":{"description":"OpenAI\'den GPT-4o, geniş genel bilgi ve alan uzmanlığına sahip olup, karmaşık doğal dil talimatlarını takip edebilir ve zor problemleri doğru şekilde \xe7\xf6zebilir. GPT-4 Turbo performansını daha hızlı ve daha uygun maliyetli API ile eşler."},"openai/gpt-4o-mini":{"description":"OpenAI\'nin en gelişmiş ve maliyet etkin k\xfc\xe7\xfck modeli olan GPT-4o mini, \xe7ok modludur (metin veya g\xf6r\xfcnt\xfc girişi alır ve metin \xe7ıktısı verir) ve gpt-3.5-turbo\'dan daha zeki ancak aynı hızdadır."},"openai/gpt-5":{"description":"GPT-5, OpenAI\'nin amiral gemisi dil modeli olup, karmaşık \xe7ıkarım, geniş ger\xe7ek d\xfcnya bilgisi, kod yoğun ve \xe7ok adımlı ajan g\xf6revlerinde \xfcst\xfcn performans g\xf6sterir."},"openai/gpt-5-mini":{"description":"GPT-5 mini, maliyet optimize edilmiş bir model olup, \xe7ıkarım/sohbet g\xf6revlerinde \xfcst\xfcn performans sunar. Hız, maliyet ve yetenek arasında en iyi dengeyi sağlar."},"openai/gpt-5-nano":{"description":"GPT-5 nano, y\xfcksek işlem hacmine sahip model olup, basit talimat veya sınıflandırma g\xf6revlerinde \xfcst\xfcn performans g\xf6sterir."},"openai/gpt-oss-120b":{"description":"Son derece yetenekli genel ama\xe7lı b\xfcy\xfck dil modeli olup, g\xfc\xe7l\xfc ve kontrol edilebilir \xe7ıkarım yeteneklerine sahiptir."},"openai/gpt-oss-20b":{"description":"Kompakt, a\xe7ık kaynak ağırlıklı dil modeli olup, d\xfcş\xfck gecikme ve kaynak kısıtlı ortamlar i\xe7in optimize edilmiştir; yerel ve u\xe7 dağıtımları destekler."},"openai/o1":{"description":"OpenAI\'nin o1 modeli, derin d\xfcş\xfcnme gerektiren karmaşık problemler i\xe7in amiral gemisi \xe7ıkarım modelidir. Karmaşık \xe7ok adımlı g\xf6revlerde g\xfc\xe7l\xfc \xe7ıkarım yeteneği ve y\xfcksek doğruluk sunar."},"openai/o1-mini":{"description":"o1-mini, programlama, matematik ve bilim uygulama senaryoları i\xe7in tasarlanmış hızlı ve ekonomik bir akıl y\xfcr\xfctme modelidir. Bu model, 128K bağlam ve Ekim 2023 bilgi kesim tarihi ile donatılmıştır."},"openai/o1-preview":{"description":"o1, OpenAI\'nin geniş genel bilgiye ihtiya\xe7 duyan karmaşık g\xf6revler i\xe7in uygun yeni bir akıl y\xfcr\xfctme modelidir. Bu model, 128K bağlam ve Ekim 2023 bilgi kesim tarihi ile donatılmıştır."},"openai/o3":{"description":"OpenAI\'nin o3 modeli, kodlama, matematik, bilim ve g\xf6rsel algılamada yeni en ileri seviyeler belirleyen en g\xfc\xe7l\xfc \xe7ıkarım modelidir. \xc7ok y\xf6nl\xfc analiz gerektiren karmaşık sorgularda uzmandır ve g\xf6r\xfcnt\xfc, grafik ve diyagram analizinde \xf6zel avantajlara sahiptir."},"openai/o3-mini":{"description":"o3-mini, OpenAI\'nin en yeni k\xfc\xe7\xfck \xe7ıkarım modeli olup, o1-mini ile aynı maliyet ve gecikme hedeflerinde y\xfcksek zeka sunar."},"openai/o3-mini-high":{"description":"o3-mini y\xfcksek akıl y\xfcr\xfctme seviyesi, o1-mini ile aynı maliyet ve gecikme hedefleri altında y\xfcksek zeka sunar."},"openai/o4-mini":{"description":"OpenAI\'nin o4-mini modeli, hızlı ve maliyet etkin \xe7ıkarım sunar ve boyutuna g\xf6re \xf6zellikle matematik (AIME kıyaslamasında en iyi performans), kodlama ve g\xf6rsel g\xf6revlerde \xfcst\xfcn performans g\xf6sterir."},"openai/o4-mini-high":{"description":"o4-mini y\xfcksek \xe7ıkarım seviyesinde, hızlı ve etkili \xe7ıkarım i\xe7in optimize edilmiştir ve kodlama ile g\xf6rsel g\xf6revlerde son derece y\xfcksek verimlilik ve performans sergiler."},"openai/text-embedding-3-large":{"description":"OpenAI\'nin en yetenekli g\xf6mme modeli olup, İngilizce ve İngilizce dışı g\xf6revlerde kullanılır."},"openai/text-embedding-3-small":{"description":"OpenAI\'nin geliştirilmiş, daha y\xfcksek performanslı ada g\xf6mme modeli versiyonu."},"openai/text-embedding-ada-002":{"description":"OpenAI\'nin klasik metin g\xf6mme modeli."},"openrouter/auto":{"description":"Bağlam uzunluğu, konu ve karmaşıklığa g\xf6re isteğiniz, Llama 3 70B Instruct, Claude 3.5 Sonnet (kendini ayarlama) veya GPT-4o\'ya g\xf6nderilecektir."},"perplexity/sonar":{"description":"Perplexity\'nin hafif \xfcr\xfcn\xfc olup, arama temelli yeteneklere sahiptir ve Sonar Pro\'dan daha hızlı ve daha ucuzdur."},"perplexity/sonar-pro":{"description":"Perplexity\'nin amiral gemisi \xfcr\xfcn\xfc olup, arama temelli yeteneklere sahiptir ve gelişmiş sorgular ile takip işlemlerini destekler."},"perplexity/sonar-reasoning":{"description":"\xc7ıkarıma odaklanan model olup, yanıtlarında d\xfcş\xfcnce zinciri (CoT) sunar ve arama temelli detaylı a\xe7ıklamalar sağlar."},"perplexity/sonar-reasoning-pro":{"description":"Gelişmiş \xe7ıkarım odaklı model olup, yanıtlarında d\xfcş\xfcnce zinciri (CoT) sunar, geliştirilmiş arama yetenekleri ve her istek i\xe7in birden fazla arama sorgusu ile kapsamlı a\xe7ıklamalar sağlar."},"phi3":{"description":"Phi-3, Microsoft tarafından sunulan hafif bir a\xe7ık modeldir, verimli entegrasyon ve b\xfcy\xfck \xf6l\xe7ekli bilgi akıl y\xfcr\xfctme i\xe7in uygundur."},"phi3:14b":{"description":"Phi-3, Microsoft tarafından sunulan hafif bir a\xe7ık modeldir, verimli entegrasyon ve b\xfcy\xfck \xf6l\xe7ekli bilgi akıl y\xfcr\xfctme i\xe7in uygundur."},"pixtral-12b-2409":{"description":"Pixtral modeli, grafik ve g\xf6r\xfcnt\xfc anlama, belge yanıtı, \xe7ok modlu akıl y\xfcr\xfctme ve talimat takibi gibi g\xf6revlerde g\xfc\xe7l\xfc yetenekler sergiler, doğal \xe7\xf6z\xfcn\xfcrl\xfck ve en boy oranında g\xf6r\xfcnt\xfcleri alabilir ve 128K token uzunluğunda bir bağlam penceresinde herhangi bir sayıda g\xf6r\xfcnt\xfcy\xfc işleyebilir."},"pixtral-large-latest":{"description":"Pixtral Large, 1240 milyar parametreye sahip a\xe7ık kaynaklı \xe7ok modlu bir modeldir ve Mistral Large 2 \xfczerine inşa edilmiştir. Bu, \xe7ok modlu ailemizdeki ikinci modeldir ve \xf6nc\xfc d\xfczeyde g\xf6r\xfcnt\xfc anlama yetenekleri sergilemektedir."},"pro-128k":{"description":"Spark Pro 128K, olağan\xfcst\xfc bağlam işleme yeteneği ile donatılmıştır ve 128K\'ya kadar bağlam bilgilerini işleyebilir. \xd6zellikle uzun metinlerin b\xfct\xfcnsel analizi ve uzun vadeli mantıksal ilişkilerin işlenmesi gereken durumlar i\xe7in uygundur ve karmaşık metin iletişiminde akıcı ve tutarlı bir mantık ile \xe7eşitli alıntı desteği sunmaktadır."},"pro-deepseek-r1":{"description":"Kurumsal \xf6zel hizmetler i\xe7in tasarlanmış modeldir ve eşzamanlı hizmetleri i\xe7erir."},"pro-deepseek-v3":{"description":"Kurumsal \xf6zel hizmetler i\xe7in tasarlanmış modeldir ve eşzamanlı hizmetleri i\xe7erir."},"qianfan-70b":{"description":"Qianfan 70B, y\xfcksek parametreli \xc7ince model, y\xfcksek kaliteli i\xe7erik \xfcretimi ve karmaşık akıl y\xfcr\xfctme g\xf6revleri i\xe7in uygundur."},"qianfan-8b":{"description":"Qianfan 8B, orta \xf6l\xe7ekli genel ama\xe7lı model, maliyet ve performans dengesi gerektiren metin \xfcretimi ve soru-cevap senaryoları i\xe7in uygundur."},"qianfan-agent-intent-32k":{"description":"Qianfan Agent Intent 32K, niyet tanıma ve akıllı ajan d\xfczenlemesi i\xe7in tasarlanmış model, uzun bağlam senaryolarını destekler."},"qianfan-agent-lite-8k":{"description":"Qianfan Agent Lite 8K, hafif akıllı ajan modeli, d\xfcş\xfck maliyetli \xe7ok turlu diyaloglar ve iş akışı d\xfczenlemeleri i\xe7in uygundur."},"qianfan-agent-speed-32k":{"description":"Qianfan Agent Speed 32K, y\xfcksek akış kontrol\xfcne sahip akıllı ajan modeli, b\xfcy\xfck \xf6l\xe7ekli ve \xe7ok g\xf6revli ajan uygulamaları i\xe7in uygundur."},"qianfan-agent-speed-8k":{"description":"Qianfan Agent Speed 8K, orta ve kısa diyaloglar ile hızlı yanıt gerektiren y\xfcksek eşzamanlı akıllı ajan modeli."},"qianfan-check-vl":{"description":"Qianfan Check VL, \xe7ok modlu i\xe7erik denetimi ve tespit modeli, g\xf6rsel ve metin uyumluluğu ile tanıma g\xf6revlerini destekler."},"qianfan-composition":{"description":"Qianfan Composition, \xe7ok modlu i\xe7erik \xfcretim modeli, g\xf6rsel ve metinlerin birleşik anlaşılması ve \xfcretimini destekler."},"qianfan-engcard-vl":{"description":"Qianfan EngCard VL, İngilizce odaklı \xe7ok modlu tanıma modeli."},"qianfan-lightning-128b-a19b":{"description":"Qianfan Lightning 128B A19B, y\xfcksek performanslı \xc7ince genel model, karmaşık soru-cevap ve b\xfcy\xfck \xf6l\xe7ekli akıl y\xfcr\xfctme g\xf6revleri i\xe7in uygundur."},"qianfan-llama-vl-8b":{"description":"Qianfan Llama VL 8B, Llama tabanlı \xe7ok modlu model, genel g\xf6rsel-metin anlama g\xf6revlerine y\xf6neliktir."},"qianfan-multipicocr":{"description":"Qianfan MultiPicOCR, \xe7oklu g\xf6rsel OCR modeli, birden fazla g\xf6rseldeki metinleri tespit ve tanıma yeteneğine sahiptir."},"qianfan-qi-vl":{"description":"Qianfan QI VL, \xe7ok modlu soru-cevap modeli, karmaşık g\xf6rsel-metin senaryolarında hassas arama ve cevaplama desteği sunar."},"qianfan-singlepicocr":{"description":"Qianfan SinglePicOCR, tek g\xf6rsel OCR modeli, y\xfcksek doğrulukta karakter tanıma sağlar."},"qianfan-vl-70b":{"description":"Qianfan VL 70B, y\xfcksek parametreli g\xf6rsel-dil modeli, karmaşık g\xf6rsel-metin anlama senaryoları i\xe7in uygundur."},"qianfan-vl-8b":{"description":"Qianfan VL 8B, hafif g\xf6rsel-dil modeli, g\xfcnl\xfck g\xf6rsel-metin soru-cevap ve analiz i\xe7in uygundur."},"qvq-72b-preview":{"description":"QVQ modeli, Qwen ekibi tarafından geliştirilen deneysel bir araştırma modelidir; g\xf6rsel akıl y\xfcr\xfctme yeteneğini artırmaya odaklanır, \xf6zellikle matematik akıl y\xfcr\xfctme alanında."},"qvq-max":{"description":"Tongyi Qianwen QVQ g\xf6rsel akıl y\xfcr\xfctme modeli, g\xf6rsel giriş ve d\xfcş\xfcnce zinciri \xe7ıktısını destekler; matematik, programlama, g\xf6rsel analiz, yaratım ve genel g\xf6revlerde daha g\xfc\xe7l\xfc performans sergiler."},"qvq-plus":{"description":"G\xf6rsel \xe7ıkarım modeli. G\xf6rsel girişleri ve d\xfcş\xfcnce zinciri \xe7ıktısını destekler; qvq-max modelinin ardından gelen plus versiyonudur. qvq-max modeline kıyasla, qvq-plus serisi modeller daha hızlı \xe7ıkarım yapar ve performans ile maliyet arasında daha dengeli bir sonu\xe7 sunar."},"qwen-3-32b":{"description":"Qwen 3 32B: Qwen serisi, \xe7ok dilli ve kodlama g\xf6revlerinde \xfcst\xfcn performans g\xf6sterir; orta \xf6l\xe7ekli \xfcretim kullanımı i\xe7in uygundur."},"qwen-3-coder-480b":{"description":"Qwen 3 Coder 480B: Kod \xfcretimi ve karmaşık programlama g\xf6revleri i\xe7in tasarlanmış uzun bağlamlı bir modeldir."},"qwen-coder-plus":{"description":"Tongyi Qianwen kodlama modeli."},"qwen-coder-turbo":{"description":"Tongyi Qianwen kodlama modeli."},"qwen-coder-turbo-latest":{"description":"Tongyi Qianwen kodlama modeli."},"qwen-flash":{"description":"Tongyi Qianwen serisi, en hızlı ve maliyeti son derece d\xfcş\xfck modeller sunar; basit g\xf6revler i\xe7in uygundur."},"qwen-image":{"description":"Qwen-Image, \xe7eşitli sanat stillerini destekleyen genel ama\xe7lı bir g\xf6rsel oluşturma modelidir; karmaşık metin renderleme konusunda, \xf6zellikle \xc7ince ve İngilizce metinlerin renderlenmesinde uzmandır. Model \xe7ok satırlı d\xfczenleri, paragraf d\xfczeyinde metin \xfcretimini ve ince ayrıntıların işlenmesini destekler; karmaşık g\xf6rsel-metin karışık d\xfczen tasarımlarının oluşturulmasına olanak tanır."},"qwen-image-edit":{"description":"Qwen Image Edit, girdiğiniz g\xf6r\xfcnt\xfc ve metin ipu\xe7larına dayanarak g\xf6r\xfcnt\xfc d\xfczenleme ve değiştirme yapabilen bir g\xf6r\xfcnt\xfcden g\xf6r\xfcnt\xfcye modelidir. Kullanıcı ihtiya\xe7larına g\xf6re orijinal g\xf6r\xfcnt\xfcy\xfc hassas bir şekilde ayarlayabilir ve yaratıcı d\xf6n\xfcş\xfcmler ger\xe7ekleştirebilir."},"qwen-long":{"description":"Tongyi Qianwen, uzun metin bağlamını destekleyen ve uzun belgeler, \xe7oklu belgeler gibi \xe7eşitli senaryolar i\xe7in diyalog işlevselliği sunan b\xfcy\xfck \xf6l\xe7ekli bir dil modelidir."},"qwen-math-plus":{"description":"Tongyi Qianwen matematik modeli, matematik problemlerini \xe7\xf6zmek i\xe7in \xf6zel olarak tasarlanmış dil modelidir."},"qwen-math-plus-latest":{"description":"Tongyi Qianwen matematik modeli, matematik problemlerini \xe7\xf6zmek i\xe7in \xf6zel olarak tasarlanmış bir dil modelidir."},"qwen-math-turbo":{"description":"Tongyi Qianwen matematik modeli, matematik problemlerini \xe7\xf6zmek i\xe7in \xf6zel olarak tasarlanmış dil modelidir."},"qwen-math-turbo-latest":{"description":"Tongyi Qianwen matematik modeli, matematik problemlerini \xe7\xf6zmek i\xe7in \xf6zel olarak tasarlanmış bir dil modelidir."},"qwen-max":{"description":"Tongyi Qianwen, 100 milyar seviyesinde b\xfcy\xfck \xf6l\xe7ekli bir dil modelidir ve \xc7ince, İngilizce gibi farklı dil girişlerini destekler; şu anda Tongyi Qianwen 2.5 \xfcr\xfcn s\xfcr\xfcm\xfcn\xfcn arkasındaki API modelidir."},"qwen-omni-turbo":{"description":"Qwen-Omni serisi modeller, video, ses, resim ve metin dahil \xe7oklu modalite girişlerini destekler ve ses ile metin \xe7ıktısı sağlar."},"qwen-plus":{"description":"Tongyi Qianwen, \xc7ince, İngilizce gibi farklı dil girişlerini destekleyen geliştirilmiş b\xfcy\xfck \xf6l\xe7ekli bir dil modelidir."},"qwen-turbo":{"description":"Tongyi Qianwen Turbo bundan sonra g\xfcncellenmeyecektir; yerine Tongyi Qianwen Flash kullanılması \xf6nerilir. Tongyi Qianwen, \xe7ok b\xfcy\xfck \xf6l\xe7ekli bir dil modelidir ve \xc7ince, İngilizce gibi farklı dillerde girişleri destekler."},"qwen-vl-chat-v1":{"description":"Tongyi Qianwen VL, \xe7oklu g\xf6r\xfcnt\xfc, \xe7ok turlu soru-cevap, yaratım gibi esnek etkileşim y\xf6ntemlerini destekleyen bir modeldir."},"qwen-vl-max":{"description":"Tongyi Qianwen ultra b\xfcy\xfck \xf6l\xe7ekli g\xf6rsel-dil modeli. Geliştirilmiş versiyona kıyasla g\xf6rsel akıl y\xfcr\xfctme ve komut uyum yeteneklerini daha da artırır, daha y\xfcksek g\xf6rsel algı ve bilişsel seviyeler sunar."},"qwen-vl-max-latest":{"description":"Tongyi Qianwen ultra b\xfcy\xfck \xf6l\xe7ekli g\xf6rsel dil modeli. Geliştirilmiş versiyona kıyasla, g\xf6rsel akıl y\xfcr\xfctme yeteneğini ve talimatlara uyum yeteneğini bir kez daha artırır, daha y\xfcksek g\xf6rsel algı ve bilişsel seviyeler sunar."},"qwen-vl-ocr":{"description":"Tongyi Qianwen OCR, belge, tablo, sınav soruları ve el yazısı gibi g\xf6r\xfcnt\xfclerden metin \xe7ıkarma konusunda uzmanlaşmış \xf6zel modeldir. \xc7oklu dil tanıma yeteneğine sahiptir; desteklenen diller arasında \xc7ince, İngilizce, Fransızca, Japonca, Korece, Almanca, Rus\xe7a, İtalyanca, Vietnamca ve Arap\xe7a bulunmaktadır."},"qwen-vl-plus":{"description":"Tongyi Qianwen b\xfcy\xfck \xf6l\xe7ekli g\xf6rsel-dil modeli geliştirilmiş versiyonu. Detay tanıma ve metin tanıma yeteneklerini b\xfcy\xfck \xf6l\xe7\xfcde artırır, milyonlarca piksel \xe7\xf6z\xfcn\xfcrl\xfck ve herhangi bir en-boy oranındaki g\xf6r\xfcnt\xfcleri destekler."},"qwen-vl-plus-latest":{"description":"Tongyi Qianwen b\xfcy\xfck \xf6l\xe7ekli g\xf6rsel dil modelinin geliştirilmiş versiyonu. Detay tanıma ve metin tanıma yeteneklerini b\xfcy\xfck \xf6l\xe7\xfcde artırır, bir milyondan fazla piksel \xe7\xf6z\xfcn\xfcrl\xfcğ\xfc ve herhangi bir en-boy oranındaki g\xf6r\xfcnt\xfcleri destekler."},"qwen-vl-v1":{"description":"Qwen-7B dil modeli ile başlatılan, 448 \xe7\xf6z\xfcn\xfcrl\xfckte g\xf6r\xfcnt\xfc girişi olan \xf6nceden eğitilmiş bir modeldir."},"qwen/qwen-2-7b-instruct":{"description":"Qwen2, tamamen yeni bir Qwen b\xfcy\xfck dil modeli serisidir. Qwen2 7B, dil anlama, \xe7ok dilli yetenek, programlama, matematik ve akıl y\xfcr\xfctme konularında m\xfckemmel performans sergileyen bir transformer tabanlı modeldir."},"qwen/qwen-2-7b-instruct:free":{"description":"Qwen2, daha g\xfc\xe7l\xfc anlama ve \xfcretme yeteneklerine sahip yeni bir b\xfcy\xfck dil modeli serisidir."},"qwen/qwen-2-vl-72b-instruct":{"description":"Qwen2-VL, Qwen-VL modelinin en son yineleme versiyonudur ve MathVista, DocVQA, RealWorldQA ve MTVQA gibi g\xf6rsel anlama benchmark testlerinde en gelişmiş performansa ulaşmıştır. Qwen2-VL, y\xfcksek kaliteli video tabanlı soru-cevap, diyalog ve i\xe7erik oluşturma i\xe7in 20 dakikadan fazla videoyu anlayabilmektedir. Ayrıca, karmaşık akıl y\xfcr\xfctme ve karar verme yeteneklerine sahiptir ve mobil cihazlar, robotlar gibi sistemlerle entegre olarak g\xf6rsel ortam ve metin talimatlarına dayalı otomatik işlemler ger\xe7ekleştirebilmektedir. İngilizce ve \xc7ince\'nin yanı sıra, Qwen2-VL artık \xe7oğu Avrupa dili, Japonca, Korece, Arap\xe7a ve Vietnamca gibi farklı dillerdeki metinleri de anlayabilmektedir."},"qwen/qwen-2.5-72b-instruct":{"description":"Qwen2.5-72B-Instruct, Alibaba Cloud tarafından yayınlanan en son b\xfcy\xfck dil modeli serilerinden biridir. Bu 72B modeli, kodlama ve matematik gibi alanlarda \xf6nemli iyileştirmelere sahiptir. Model ayrıca, \xc7ince, İngilizce gibi 29\'dan fazla dili kapsayan \xe7ok dilli destek sunmaktadır. Model, talimat takibi, yapılandırılmış verileri anlama ve yapılandırılmış \xe7ıktı (\xf6zellikle JSON) \xfcretme konularında \xf6nemli gelişmeler g\xf6stermektedir."},"qwen/qwen2.5-32b-instruct":{"description":"Qwen2.5-32B-Instruct, Alibaba Cloud tarafından yayınlanan en son b\xfcy\xfck dil modeli serilerinden biridir. Bu 32B modeli, kodlama ve matematik gibi alanlarda \xf6nemli iyileştirmelere sahiptir. Model, \xc7ince, İngilizce gibi 29\'dan fazla dili kapsayan \xe7ok dilli destek sunmaktadır. Model, talimat takibi, yapılandırılmış verileri anlama ve yapılandırılmış \xe7ıktı (\xf6zellikle JSON) \xfcretme konularında \xf6nemli gelişmeler g\xf6stermektedir."},"qwen/qwen2.5-7b-instruct":{"description":"\xc7ince ve İngilizce\'ye y\xf6nelik LLM, dil, programlama, matematik, akıl y\xfcr\xfctme gibi alanlara odaklanır."},"qwen/qwen2.5-coder-32b-instruct":{"description":"Gelişmiş LLM, kod \xfcretimi, akıl y\xfcr\xfctme ve d\xfczeltme desteği sunar, ana akım programlama dillerini kapsar."},"qwen/qwen2.5-coder-7b-instruct":{"description":"G\xfc\xe7l\xfc orta \xf6l\xe7ekli kod modeli, 32K bağlam uzunluğunu destekler, \xe7ok dilli programlama konusunda uzmandır."},"qwen/qwen3-14b":{"description":"Qwen3-14B, Qwen3 serisindeki yoğun 14.8 milyar parametreli nedensel dil modelidir ve karmaşık akıl y\xfcr\xfctme ve etkili diyalog i\xe7in tasarlanmıştır. Matematik, programlama ve mantık akıl y\xfcr\xfctme gibi g\xf6revler i\xe7in \'d\xfcş\xfcnme\' modu ile genel diyalog i\xe7in \'d\xfcş\xfcnmeme\' modu arasında sorunsuz ge\xe7iş yapmayı destekler. Bu model, talimat takibi, ajan ara\xe7 kullanımı, yaratıcı yazım ve 100\'den fazla dil ve leh\xe7ede \xe7ok dilli g\xf6revler i\xe7in ince ayar yapılmıştır. 32K token bağlamını yerel olarak işler ve YaRN tabanlı genişletme ile 131K token\'a kadar genişletilebilir."},"qwen/qwen3-14b:free":{"description":"Qwen3-14B, Qwen3 serisindeki yoğun 14.8 milyar parametreli nedensel dil modelidir ve karmaşık akıl y\xfcr\xfctme ve etkili diyalog i\xe7in tasarlanmıştır. Matematik, programlama ve mantık akıl y\xfcr\xfctme gibi g\xf6revler i\xe7in \'d\xfcş\xfcnme\' modu ile genel diyalog i\xe7in \'d\xfcş\xfcnmeme\' modu arasında sorunsuz ge\xe7iş yapmayı destekler. Bu model, talimat takibi, ajan ara\xe7 kullanımı, yaratıcı yazım ve 100\'den fazla dil ve leh\xe7ede \xe7ok dilli g\xf6revler i\xe7in ince ayar yapılmıştır. 32K token bağlamını yerel olarak işler ve YaRN tabanlı genişletme ile 131K token\'a kadar genişletilebilir."},"qwen/qwen3-235b-a22b":{"description":"Qwen3-235B-A22B, Qwen tarafından geliştirilen 235B parametreli uzman karışımı (MoE) modelidir ve her ileri ge\xe7işte 22B parametreyi etkinleştirir. Karmaşık akıl y\xfcr\xfctme, matematik ve kod g\xf6revleri i\xe7in \'d\xfcş\xfcnme\' modu ile genel diyalog verimliliği i\xe7in \'d\xfcş\xfcnmeme\' modu arasında sorunsuz ge\xe7iş yapmayı destekler. Bu model, g\xfc\xe7l\xfc akıl y\xfcr\xfctme yetenekleri, \xe7ok dilli destek (100\'den fazla dil ve leh\xe7e), ileri d\xfczey talimat takibi ve ajan ara\xe7 \xe7ağırma yetenekleri sergiler. 32K token bağlam penceresini yerel olarak işler ve YaRN tabanlı genişletme ile 131K token\'a kadar genişletilebilir."},"qwen/qwen3-235b-a22b:free":{"description":"Qwen3-235B-A22B, Qwen tarafından geliştirilen 235B parametreli uzman karışımı (MoE) modelidir ve her ileri ge\xe7işte 22B parametreyi etkinleştirir. Karmaşık akıl y\xfcr\xfctme, matematik ve kod g\xf6revleri i\xe7in \'d\xfcş\xfcnme\' modu ile genel diyalog verimliliği i\xe7in \'d\xfcş\xfcnmeme\' modu arasında sorunsuz ge\xe7iş yapmayı destekler. Bu model, g\xfc\xe7l\xfc akıl y\xfcr\xfctme yetenekleri, \xe7ok dilli destek (100\'den fazla dil ve leh\xe7e), ileri d\xfczey talimat takibi ve ajan ara\xe7 \xe7ağırma yetenekleri sergiler. 32K token bağlam penceresini yerel olarak işler ve YaRN tabanlı genişletme ile 131K token\'a kadar genişletilebilir."},"qwen/qwen3-30b-a3b":{"description":"Qwen3, Qwen b\xfcy\xfck dil modeli serisinin en son neslidir ve yoğun ve uzman karışımı (MoE) mimarisi ile akıl y\xfcr\xfctme, \xe7ok dilli destek ve ileri d\xfczey g\xf6revlerde m\xfckemmel performans sergilemektedir. Karmaşık akıl y\xfcr\xfctme d\xfcş\xfcnce modu ile etkili diyalog i\xe7in d\xfcş\xfcnmeden ge\xe7iş yapma yeteneği, \xe7ok y\xf6nl\xfc ve y\xfcksek kaliteli performansı garanti eder.\\n\\nQwen3, QwQ ve Qwen2.5 gibi \xf6nceki modellere kıyasla \xf6nemli \xf6l\xe7\xfcde daha \xfcst\xfcnd\xfcr ve matematik, kodlama, genel bilgi akıl y\xfcr\xfctme, yaratıcı yazım ve etkileşimli diyalog yetenekleri sunar. Qwen3-30B-A3B varyantı, 30.5 milyar parametre (3.3 milyar etkin parametre), 48 katman, 128 uzman (her g\xf6revde 8 etkin) i\xe7erir ve 131K token bağlamını destekler (YaRN kullanarak), a\xe7ık kaynaklı modeller i\xe7in yeni bir standart belirler."},"qwen/qwen3-30b-a3b:free":{"description":"Qwen3, Qwen b\xfcy\xfck dil modeli serisinin en son neslidir ve yoğun ve uzman karışımı (MoE) mimarisi ile akıl y\xfcr\xfctme, \xe7ok dilli destek ve ileri d\xfczey g\xf6revlerde m\xfckemmel performans sergilemektedir. Karmaşık akıl y\xfcr\xfctme d\xfcş\xfcnce modu ile etkili diyalog i\xe7in d\xfcş\xfcnmeden ge\xe7iş yapma yeteneği, \xe7ok y\xf6nl\xfc ve y\xfcksek kaliteli performansı garanti eder.\\n\\nQwen3, QwQ ve Qwen2.5 gibi \xf6nceki modellere kıyasla \xf6nemli \xf6l\xe7\xfcde daha \xfcst\xfcnd\xfcr ve matematik, kodlama, genel bilgi akıl y\xfcr\xfctme, yaratıcı yazım ve etkileşimli diyalog yetenekleri sunar. Qwen3-30B-A3B varyantı, 30.5 milyar parametre (3.3 milyar etkin parametre), 48 katman, 128 uzman (her g\xf6revde 8 etkin) i\xe7erir ve 131K token bağlamını destekler (YaRN kullanarak), a\xe7ık kaynaklı modeller i\xe7in yeni bir standart belirler."},"qwen/qwen3-32b":{"description":"Qwen3-32B, Qwen3 serisindeki yoğun 32.8 milyar parametreli nedensel dil modelidir ve karmaşık akıl y\xfcr\xfctme ve etkili diyalog i\xe7in optimize edilmiştir. Matematik, kodlama ve mantık akıl y\xfcr\xfctme gibi g\xf6revler i\xe7in \'d\xfcş\xfcnme\' modu ile daha hızlı, genel diyalog i\xe7in \'d\xfcş\xfcnmeme\' modu arasında sorunsuz ge\xe7iş yapmayı destekler. Bu model, talimat takibi, ajan ara\xe7 kullanımı, yaratıcı yazım ve 100\'den fazla dil ve leh\xe7ede \xe7ok dilli g\xf6revlerde g\xfc\xe7l\xfc performans sergiler. 32K token bağlamını yerel olarak işler ve YaRN tabanlı genişletme ile 131K token\'a kadar genişletilebilir."},"qwen/qwen3-32b:free":{"description":"Qwen3-32B, Qwen3 serisindeki yoğun 32.8 milyar parametreli nedensel dil modelidir ve karmaşık akıl y\xfcr\xfctme ve etkili diyalog i\xe7in optimize edilmiştir. Matematik, kodlama ve mantık akıl y\xfcr\xfctme gibi g\xf6revler i\xe7in \'d\xfcş\xfcnme\' modu ile daha hızlı, genel diyalog i\xe7in \'d\xfcş\xfcnmeme\' modu arasında sorunsuz ge\xe7iş yapmayı destekler. Bu model, talimat takibi, ajan ara\xe7 kullanımı, yaratıcı yazım ve 100\'den fazla dil ve leh\xe7ede \xe7ok dilli g\xf6revlerde g\xfc\xe7l\xfc performans sergiler. 32K token bağlamını yerel olarak işler ve YaRN tabanlı genişletme ile 131K token\'a kadar genişletilebilir."},"qwen/qwen3-8b:free":{"description":"Qwen3-8B, Qwen3 serisindeki yoğun 8.2 milyar parametreli nedensel dil modelidir ve akıl y\xfcr\xfctme yoğun g\xf6revler ve etkili diyalog i\xe7in tasarlanmıştır. Matematik, kodlama ve mantık akıl y\xfcr\xfctme i\xe7in \'d\xfcş\xfcnme\' modu ile genel diyalog i\xe7in \'d\xfcş\xfcnmeme\' modu arasında sorunsuz ge\xe7iş yapmayı destekler. Bu model, talimat takibi, ajan entegrasyonu, yaratıcı yazım ve 100\'den fazla dil ve leh\xe7ede \xe7ok dilli kullanım i\xe7in ince ayar yapılmıştır. 32K token bağlam penceresini yerel olarak destekler ve YaRN aracılığıyla 131K token\'a genişletilebilir."},"qwen2":{"description":"Qwen2, Alibaba\'nın yeni nesil b\xfcy\xfck \xf6l\xe7ekli dil modelidir, m\xfckemmel performans ile \xe7eşitli uygulama ihtiya\xe7larını destekler."},"qwen2.5":{"description":"Qwen2.5, Alibaba\'nın yeni nesil b\xfcy\xfck \xf6l\xe7ekli dil modelidir ve m\xfckemmel performansıyla \xe7eşitli uygulama ihtiya\xe7larını desteklemektedir."},"qwen2.5-14b-instruct":{"description":"Tongyi Qianwen 2.5, halka a\xe7ık 14B \xf6l\xe7eğinde bir modeldir."},"qwen2.5-14b-instruct-1m":{"description":"Tongyi Qianwen 2.5, 72B \xf6l\xe7eğinde a\xe7ık kaynak olarak sunulmuştur."},"qwen2.5-32b-instruct":{"description":"Tongyi Qianwen 2.5, halka a\xe7ık 32B \xf6l\xe7eğinde bir modeldir."},"qwen2.5-72b-instruct":{"description":"Tongyi Qianwen 2.5, halka a\xe7ık 72B \xf6l\xe7eğinde bir modeldir."},"qwen2.5-7b-instruct":{"description":"Qwen2.5 7B Instruct, olgun a\xe7ık kaynaklı talimat modeli, \xe7oklu senaryolarda diyalog ve \xfcretim i\xe7in uygundur."},"qwen2.5-coder-1.5b-instruct":{"description":"Tongyi Qianwen kodlama modelinin a\xe7ık kaynak s\xfcr\xfcm\xfcd\xfcr."},"qwen2.5-coder-14b-instruct":{"description":"Tongyi Qianwen kodlama modeli a\xe7ık kaynak s\xfcr\xfcm\xfc."},"qwen2.5-coder-32b-instruct":{"description":"Tongyi Qianwen kod modeli a\xe7ık kaynak versiyonu."},"qwen2.5-coder-7b-instruct":{"description":"Tongyi Qianwen kodlama modelinin a\xe7ık kaynak versiyonu."},"qwen2.5-coder-instruct":{"description":"Qwen2.5-Coder, Qwen serisinin en yeni kod odaklı b\xfcy\xfck dil modelidir (eski adıyla CodeQwen)."},"qwen2.5-instruct":{"description":"Qwen2.5, Qwen b\xfcy\xfck dil modeli serisinin en son s\xfcr\xfcm\xfcd\xfcr. Qwen2.5 i\xe7in, 500 milyondan 7.2 milyara kadar değişen parametre aralığında birden fazla temel dil modeli ve komut ayarlı dil modeli yayınladık."},"qwen2.5-math-1.5b-instruct":{"description":"Qwen-Math modeli, g\xfc\xe7l\xfc matematiksel problem \xe7\xf6zme yeteneklerine sahiptir."},"qwen2.5-math-72b-instruct":{"description":"Qwen-Math modeli, g\xfc\xe7l\xfc matematik problem \xe7\xf6zme yeteneklerine sahiptir."},"qwen2.5-math-7b-instruct":{"description":"Qwen-Math modeli, g\xfc\xe7l\xfc matematik problem \xe7\xf6zme yeteneklerine sahiptir."},"qwen2.5-omni-7b":{"description":"Qwen-Omni serisi modeller, video, ses, resim ve metin gibi \xe7eşitli modlarda veri girişi destekler ve ses ile metin \xe7ıktısı verir."},"qwen2.5-vl-32b-instruct":{"description":"Qwen2.5 VL 32B Instruct, \xe7ok modlu a\xe7ık kaynak modeli, \xf6zelleştirilmiş kurulum ve \xe7oklu senaryo uygulamaları i\xe7in uygundur."},"qwen2.5-vl-72b-instruct":{"description":"Talimat takibi, matematik, problem \xe7\xf6zme, kodlama genelinde iyileştirme, her t\xfcrl\xfc nesneyi tanıma yeteneği artışı, \xe7eşitli formatları doğrudan hassas bir şekilde g\xf6rsel unsurları konumlandırma desteği, uzun video dosyalarını (en fazla 10 dakika) anlama ve saniye d\xfczeyinde olay anlarını konumlandırma yeteneği, zaman sıralamasını ve hızını anlama, analiz ve konumlandırma yeteneğine dayanarak OS veya Mobil ajanları kontrol etme desteği, anahtar bilgileri \xe7ıkarma yeteneği ve Json formatında \xe7ıktı verme yeteneği g\xfc\xe7l\xfcd\xfcr, bu s\xfcr\xfcm 72B versiyonudur, bu serinin en g\xfc\xe7l\xfc versiyonudur."},"qwen2.5-vl-7b-instruct":{"description":"Qwen2.5 VL 7B Instruct, hafif \xe7ok modlu model, kurulum maliyeti ve tanıma yeteneği arasında denge sağlar."},"qwen2.5-vl-instruct":{"description":"Qwen2.5-VL, Qwen model ailesinin en yeni g\xf6rsel-dil modeli s\xfcr\xfcm\xfcd\xfcr."},"qwen2.5:0.5b":{"description":"Qwen2.5, Alibaba\'nın yeni nesil b\xfcy\xfck \xf6l\xe7ekli dil modelidir ve m\xfckemmel performansıyla \xe7eşitli uygulama ihtiya\xe7larını desteklemektedir."},"qwen2.5:1.5b":{"description":"Qwen2.5, Alibaba\'nın yeni nesil b\xfcy\xfck \xf6l\xe7ekli dil modelidir ve m\xfckemmel performansıyla \xe7eşitli uygulama ihtiya\xe7larını desteklemektedir."},"qwen2.5:72b":{"description":"Qwen2.5, Alibaba\'nın yeni nesil b\xfcy\xfck \xf6l\xe7ekli dil modelidir ve m\xfckemmel performansıyla \xe7eşitli uygulama ihtiya\xe7larını desteklemektedir."},"qwen2:0.5b":{"description":"Qwen2, Alibaba\'nın yeni nesil b\xfcy\xfck \xf6l\xe7ekli dil modelidir, m\xfckemmel performans ile \xe7eşitli uygulama ihtiya\xe7larını destekler."},"qwen2:1.5b":{"description":"Qwen2, Alibaba\'nın yeni nesil b\xfcy\xfck \xf6l\xe7ekli dil modelidir, m\xfckemmel performans ile \xe7eşitli uygulama ihtiya\xe7larını destekler."},"qwen2:72b":{"description":"Qwen2, Alibaba\'nın yeni nesil b\xfcy\xfck \xf6l\xe7ekli dil modelidir, m\xfckemmel performans ile \xe7eşitli uygulama ihtiya\xe7larını destekler."},"qwen3":{"description":"Qwen3, Alibaba\'nın yeni nesil b\xfcy\xfck \xf6l\xe7ekli dil modelidir ve \xe7eşitli uygulama ihtiya\xe7larını m\xfckemmel bir performansla destekler."},"qwen3-0.6b":{"description":"Qwen3 0.6B, giriş seviyesi model, basit akıl y\xfcr\xfctme ve kaynakların son derece sınırlı olduğu ortamlar i\xe7in uygundur."},"qwen3-1.7b":{"description":"Qwen3 1.7B, ultra hafif model, u\xe7 ve yerel cihazlara dağıtım i\xe7in uygundur."},"qwen3-14b":{"description":"Qwen3 14B, orta \xf6l\xe7ekli model, \xe7ok dilli soru-cevap ve metin \xfcretimi i\xe7in uygundur."},"qwen3-235b-a22b":{"description":"Qwen3 235B A22B, genel ama\xe7lı b\xfcy\xfck model, \xe7eşitli karmaşık g\xf6revler i\xe7in uygundur."},"qwen3-235b-a22b-instruct-2507":{"description":"Qwen3 235B A22B Instruct 2507, genel ama\xe7lı amiral gemisi talimat modeli, \xe7oklu \xfcretim ve akıl y\xfcr\xfctme g\xf6revleri i\xe7in uygundur."},"qwen3-235b-a22b-thinking-2507":{"description":"Qwen3 235B A22B Thinking 2507, ultra b\xfcy\xfck \xf6l\xe7ekli d\xfcş\xfcnme modeli, y\xfcksek zorlukta akıl y\xfcr\xfctme i\xe7in uygundur."},"qwen3-30b-a3b":{"description":"Qwen3 30B A3B, orta-b\xfcy\xfck \xf6l\xe7ekli genel model, maliyet ve performans arasında denge sağlar."},"qwen3-30b-a3b-instruct-2507":{"description":"Qwen3 30B A3B Instruct 2507, orta-b\xfcy\xfck \xf6l\xe7ekli talimat modeli, y\xfcksek kaliteli \xfcretim ve soru-cevap i\xe7in uygundur."},"qwen3-30b-a3b-thinking-2507":{"description":"Qwen3 30B A3B Thinking 2507, orta-b\xfcy\xfck \xf6l\xe7ekli d\xfcş\xfcnme modeli, doğruluk ve maliyet arasında denge sağlar."},"qwen3-32b":{"description":"Qwen3 32B, daha g\xfc\xe7l\xfc anlama yeteneği gerektiren genel g\xf6rev senaryoları i\xe7in uygundur."},"qwen3-4b":{"description":"Qwen3 4B, orta-k\xfc\xe7\xfck \xf6l\xe7ekli uygulamalar ve yerel akıl y\xfcr\xfctme senaryoları i\xe7in uygundur."},"qwen3-8b":{"description":"Qwen3 8B, hafif model, esnek dağıtım imkanı sunar ve y\xfcksek eşzamanlı iş y\xfckleri i\xe7in uygundur."},"qwen3-coder-30b-a3b-instruct":{"description":"Qwen3 tabanlı kod \xfcretim modeli olan en yeni a\xe7ık kaynaklı Tongyi Qianwen kod modeli. G\xfc\xe7l\xfc Kodlama Ajanı yeteneklerine sahiptir, ara\xe7 kullanımı ve \xe7evre ile etkileşimde uzmandır. Kendi kendine programlama yapabilir, \xfcst\xfcn kodlama yeteneklerinin yanı sıra genel ama\xe7lı beceriler de sunar."},"qwen3-coder-480b-a35b-instruct":{"description":"Qwen3 Coder 480B A35B Instruct, amiral gemisi kod modeli, \xe7oklu programlama dili ve karmaşık kod anlama desteği sunar."},"qwen3-coder-flash":{"description":"Tongyi Qianwen kod modeli. En yeni Qwen3-Coder serisi modeller, Qwen3 tabanlı kod \xfcretim modelleridir, g\xfc\xe7l\xfc Kodlama Ajanı yeteneklerine sahiptir, ara\xe7 \xe7ağrıları ve ortam etkileşiminde uzmandır, bağımsız programlama yapabilir, \xfcst\xfcn kodlama yeteneklerinin yanı sıra genel yeteneklere de sahiptir."},"qwen3-coder-plus":{"description":"Tongyi Qianwen kod modeli. En yeni Qwen3-Coder serisi modeller, Qwen3 tabanlı kod \xfcretim modelleridir, g\xfc\xe7l\xfc Kodlama Ajanı yeteneklerine sahiptir, ara\xe7 \xe7ağrıları ve ortam etkileşiminde uzmandır, bağımsız programlama yapabilir, \xfcst\xfcn kodlama yeteneklerinin yanı sıra genel yeteneklere de sahiptir."},"qwen3-coder:480b":{"description":"Alibaba tarafından ajan ve kodlama g\xf6revleri i\xe7in optimize edilmiş y\xfcksek performanslı uzun bağlam modelidir."},"qwen3-max":{"description":"Tongyi Qianwen 3 serisi Max modeli, 2.5 serisine kıyasla genel yeteneklerde b\xfcy\xfck gelişme g\xf6stermiştir; hem \xc7ince hem İngilizce metin anlama, karmaşık talimat takibi, \xf6znel a\xe7ık g\xf6revler, \xe7oklu dil yetenekleri ve ara\xe7 \xe7ağrısı yetenekleri belirgin şekilde artmıştır; model bilgi hal\xfcsinasyonları azalmıştır. En yeni qwen3-max modeli, qwen3-max-preview versiyonuna g\xf6re akıllı ajan programlama ve ara\xe7 \xe7ağrısı alanlarında \xf6zel y\xfckseltmeler i\xe7ermektedir. Bu resmi s\xfcr\xfcm modeli, alanında SOTA seviyesine ulaşmış olup, daha karmaşık ajan ihtiya\xe7larına uyarlanmıştır."},"qwen3-max-preview":{"description":"Tongyi Qianwen serisinin en yetenekli modeli; karmaşık ve \xe7ok adımlı g\xf6revler i\xe7in uygundur. \xd6nizleme s\xfcr\xfcm\xfc d\xfcş\xfcnme yeteneğini desteklemektedir."},"qwen3-next-80b-a3b-instruct":{"description":"Qwen3 tabanlı yeni nesil d\xfcş\xfcnmeden \xe7alışan a\xe7ık kaynak modeli, \xf6nceki s\xfcr\xfcme (Tongyi Qianwen 3-235B-A22B-Instruct-2507) kıyasla \xc7ince metin anlama yeteneği daha iyi, mantıksal \xe7ıkarım yeteneği geliştirilmiş ve metin \xfcretimi g\xf6revlerinde daha başarılıdır."},"qwen3-next-80b-a3b-thinking":{"description":"Qwen3 Next 80B A3B Thinking, karmaşık g\xf6revler i\xe7in amiral gemisi akıl y\xfcr\xfctme modeli s\xfcr\xfcm\xfcd\xfcr."},"qwen3-omni-flash":{"description":"Qwen-Omni modeli, metin, g\xf6rsel, ses ve video gibi \xe7oklu modların birleşik girişlerini kabul edebilir ve metin ya da ses bi\xe7iminde yanıtlar \xfcretebilir. \xc7eşitli insansı ses tonları sunar, \xe7ok dilli ve leh\xe7eli ses \xe7ıktısını destekler. Metin \xfcretimi, g\xf6rsel tanıma ve sesli asistan gibi senaryolarda kullanılabilir."},"qwen3-vl-235b-a22b-instruct":{"description":"Qwen3 VL 235B A22B Instruct, amiral gemisi \xe7ok modlu model, y\xfcksek d\xfczeyde anlama ve i\xe7erik \xfcretimi senaryoları i\xe7in uygundur."},"qwen3-vl-235b-a22b-thinking":{"description":"Qwen3 VL 235B A22B Thinking, amiral gemisi d\xfcş\xfcnme s\xfcr\xfcm\xfc, karmaşık \xe7ok modlu akıl y\xfcr\xfctme ve planlama g\xf6revleri i\xe7in uygundur."},"qwen3-vl-30b-a3b-instruct":{"description":"Qwen3 VL 30B A3B Instruct, \xe7ok modlu b\xfcy\xfck model, doğruluk ve akıl y\xfcr\xfctme performansını dengeler."},"qwen3-vl-30b-a3b-thinking":{"description":"Qwen3 VL 30B A3B Thinking, karmaşık \xe7ok modlu g\xf6revler i\xe7in derin d\xfcş\xfcnme s\xfcr\xfcm\xfcd\xfcr."},"qwen3-vl-32b-instruct":{"description":"Qwen3 VL 32B Instruct, \xe7ok modlu talimatla ince ayarlanmış model, y\xfcksek kaliteli g\xf6rsel-metin soru-cevap ve i\xe7erik \xfcretimi i\xe7in uygundur."},"qwen3-vl-32b-thinking":{"description":"Qwen3 VL 32B Thinking, \xe7ok modlu derin d\xfcş\xfcnme s\xfcr\xfcm\xfc, karmaşık akıl y\xfcr\xfctme ve uzun zincirli analizleri g\xfc\xe7lendirir."},"qwen3-vl-8b-instruct":{"description":"Qwen3 VL 8B Instruct, hafif \xe7ok modlu model, g\xfcnl\xfck g\xf6rsel soru-cevap ve uygulama entegrasyonu i\xe7in uygundur."},"qwen3-vl-8b-thinking":{"description":"Qwen3 VL 8B Thinking, \xe7ok modlu d\xfcş\xfcnce zinciri modeli, g\xf6rsel bilgilerin ayrıntılı akıl y\xfcr\xfctmesi i\xe7in uygundur."},"qwen3-vl-flash":{"description":"Qwen3 VL Flash: Gecikmeye duyarlı veya y\xfcksek hacimli istek senaryoları i\xe7in uygun, hafif ve y\xfcksek hızlı akıl y\xfcr\xfctme s\xfcr\xfcm\xfcd\xfcr."},"qwen3-vl-plus":{"description":"Tongyi Qianwen VL, g\xf6rsel (resim) anlama yeteneğine sahip metin \xfcretim modelidir. Sadece OCR (resim metni tanıma) yapmakla kalmaz, aynı zamanda \xfcr\xfcn fotoğraflarından \xf6zellik \xe7ıkarma, alıştırma resimlerinden problem \xe7\xf6zme gibi \xf6zetleme ve \xe7ıkarım yapabilir."},"qwq":{"description":"QwQ, AI akıl y\xfcr\xfctme yeteneklerini artırmaya odaklanan deneysel bir araştırma modelidir."},"qwq-32b":{"description":"Qwen2.5-32B modeli \xfczerine eğitilmiş QwQ \xe7ıkarım modeli, pekiştirmeli \xf6ğrenme ile modelin \xe7ıkarım yeteneğini \xf6nemli \xf6l\xe7\xfcde artırmıştır. Modelin matematiksel kodları ve diğer temel g\xf6stergeleri (AIME 24/25, LiveCodeBench) ile bazı genel g\xf6stergeleri (IFEval, LiveBench vb.) DeepSeek-R1 tam s\xfcr\xfcm seviyesine ulaşmıştır ve t\xfcm g\xf6stergeler, yine Qwen2.5-32B tabanlı olan DeepSeek-R1-Distill-Qwen-32B\'yi \xf6nemli \xf6l\xe7\xfcde aşmaktadır."},"qwq-32b-preview":{"description":"QwQ modeli, Qwen ekibi tarafından geliştirilen deneysel bir araştırma modelidir ve AI akıl y\xfcr\xfctme yeteneklerini artırmaya odaklanmaktadır."},"qwq-plus":{"description":"Qwen2.5 modeli temel alınarak eğitilmiş QwQ akıl y\xfcr\xfctme modeli, pekiştirmeli \xf6ğrenme ile modelin akıl y\xfcr\xfctme yeteneğini b\xfcy\xfck \xf6l\xe7\xfcde artırmıştır. Model, matematik ve kodlama gibi temel g\xf6stergelerde (AIME 24/25, LiveCodeBench) ve bazı genel g\xf6stergelerde (IFEval, LiveBench vb.) DeepSeek-R1 tam s\xfcr\xfcm seviyesine ulaşmıştır."},"qwq_32b":{"description":"Qwen serisinin orta \xf6l\xe7ekli \xe7ıkarım modelidir. Geleneksel talimat ayarlama modellerine kıyasla, d\xfcş\xfcnme ve \xe7ıkarım yeteneğine sahip QwQ, \xf6zellikle zorlu g\xf6revleri \xe7\xf6zme konusunda, alt g\xf6revlerde performansı \xf6nemli \xf6l\xe7\xfcde artırabilir."},"r1-1776":{"description":"R1-1776, DeepSeek R1 modelinin bir versiyonudur ve son eğitimle, sans\xfcrs\xfcz, tarafsız ger\xe7ek bilgileri sunar."},"solar-mini":{"description":"Solar Mini, GPT-3.5\'ten daha iyi performansa sahip kompakt bir LLM\'dir, g\xfc\xe7l\xfc \xe7ok dilli yeteneklere sahiptir, İngilizce ve Korece\'yi destekler ve etkili, kompakt \xe7\xf6z\xfcmler sunar."},"solar-mini-ja":{"description":"Solar Mini (Ja), Solar Mini\'nin yeteneklerini genişletir, Japonca\'ya odaklanır ve İngilizce ile Korece kullanımında y\xfcksek verimlilik ve m\xfckemmel performans sağlar."},"solar-pro":{"description":"Solar Pro, Upstage tarafından sunulan y\xfcksek akıllı LLM\'dir, tek GPU talimat takibi yeteneğine odaklanır, IFEval puanı 80\'in \xfczerindedir. Şu anda İngilizceyi desteklemekte olup, resmi versiyonu 2024 Kasım\'da piyasaya s\xfcr\xfclmesi planlanmaktadır ve dil desteği ile bağlam uzunluğunu genişletecektir."},"sonar":{"description":"Arama bağlamına dayalı hafif bir arama \xfcr\xfcn\xfcd\xfcr, Sonar Pro\'dan daha hızlı ve daha ucuzdur."},"sonar-deep-research":{"description":"Deep Research, kapsamlı uzman d\xfczeyinde araştırmalar yapar ve bunları erişilebilir, uygulanabilir raporlar haline getirir."},"sonar-pro":{"description":"Gelişmiş sorgular ve takip desteği sunan, arama bağlamını destekleyen bir \xfcst d\xfczey arama \xfcr\xfcn\xfcd\xfcr."},"sonar-reasoning":{"description":"DeepSeek akıl y\xfcr\xfctme modeli tarafından desteklenen yeni API \xfcr\xfcn\xfc."},"sonar-reasoning-pro":{"description":"DeepSeek\'in akıl y\xfcr\xfctme modeli tarafından desteklenen yeni API \xfcr\xfcn\xfc."},"stable-diffusion-3-medium":{"description":"Stability AI tarafından geliştirilen en yeni metinden g\xf6r\xfcnt\xfc oluşturma b\xfcy\xfck modelidir. \xd6nceki s\xfcr\xfcmlerin avantajlarını koruyarak, g\xf6r\xfcnt\xfc kalitesi, metin anlama ve stil \xe7eşitliliği alanlarında \xf6nemli iyileştirmeler sunar. Karmaşık doğal dil istemlerini daha doğru yorumlayabilir ve daha kesin, \xe7eşitli g\xf6r\xfcnt\xfcler oluşturabilir."},"stable-diffusion-3.5-large":{"description":"stable-diffusion-3.5-large, 800 milyon parametreli \xe7ok modlu dif\xfczyon d\xf6n\xfcşt\xfcr\xfcc\xfc (MMDiT) metinden g\xf6r\xfcnt\xfc oluşturma modelidir. \xdcst\xfcn g\xf6r\xfcnt\xfc kalitesi ve istem uyumu sağlar, 1 milyon piksel y\xfcksek \xe7\xf6z\xfcn\xfcrl\xfckl\xfc g\xf6r\xfcnt\xfcler oluşturabilir ve sıradan t\xfcketici donanımında verimli \xe7alışabilir."},"stable-diffusion-3.5-large-turbo":{"description":"stable-diffusion-3.5-large-turbo, stable-diffusion-3.5-large temel alınarak adversarial diffusion distillation (ADD) teknolojisi ile hızlandırılmış modeldir."},"stable-diffusion-v1.5":{"description":"stable-diffusion-v1.5, stable-diffusion-v1.2 kontrol noktası ağırlıkları ile başlatılmış ve \\"laion-aesthetics v2 5+\\" \xfczerinde 512x512 \xe7\xf6z\xfcn\xfcrl\xfckte 595k adım ince ayar yapılmıştır. %10 daha az metin koşullandırması ile sınıflandırıcı olmayan rehberli \xf6rnekleme geliştirilmiştir."},"stable-diffusion-xl":{"description":"stable-diffusion-xl, v1.5\'e kıyasla \xf6nemli geliştirmeler i\xe7erir ve mevcut a\xe7ık kaynak metinden g\xf6r\xfcnt\xfc oluşturma SOTA modeli midjourney ile benzer performans g\xf6sterir. Gelişmeler şunlardır: daha b\xfcy\xfck unet omurgası (\xf6ncekinden 3 kat b\xfcy\xfck); g\xf6r\xfcnt\xfc kalitesini artırmak i\xe7in iyileştirme mod\xfcl\xfc eklenmesi; daha verimli eğitim teknikleri."},"stable-diffusion-xl-base-1.0":{"description":"Stability AI tarafından geliştirilen ve a\xe7ık kaynaklı metinden g\xf6r\xfcnt\xfc oluşturma b\xfcy\xfck modelidir. Yaratıcı g\xf6r\xfcnt\xfc oluşturma yetenekleri sekt\xf6rde \xf6nc\xfcd\xfcr. \xdcst\xfcn talimat anlama yeteneğine sahiptir ve ters prompt tanımlamayı destekleyerek i\xe7eriği hassas şekilde oluşturabilir."},"step-1-128k":{"description":"Performans ve maliyet arasında denge sağlar, genel senaryolar i\xe7in uygundur."},"step-1-256k":{"description":"Ultra uzun bağlam işleme yeteneklerine sahiptir, \xf6zellikle uzun belgelerin analizine uygundur."},"step-1-32k":{"description":"Orta uzunlukta diyalogları destekler, \xe7eşitli uygulama senaryoları i\xe7in uygundur."},"step-1-8k":{"description":"K\xfc\xe7\xfck model, hafif g\xf6revler i\xe7in uygundur."},"step-1-flash":{"description":"Y\xfcksek hızlı model, ger\xe7ek zamanlı diyaloglar i\xe7in uygundur."},"step-1.5v-mini":{"description":"Bu model, g\xfc\xe7l\xfc bir video anlama yeteneğine sahiptir."},"step-1o-turbo-vision":{"description":"Bu model, g\xfc\xe7l\xfc bir g\xf6r\xfcnt\xfc anlama yeteneğine sahiptir, matematik ve kod alanında 1o\'dan daha \xfcst\xfcnd\xfcr. Model, 1o\'dan daha k\xfc\xe7\xfckt\xfcr ve \xe7ıktı hızı daha y\xfcksektir."},"step-1o-vision-32k":{"description":"Bu model, g\xfc\xe7l\xfc bir g\xf6r\xfcnt\xfc anlama yeteneğine sahiptir. Step-1v serisi modellere kıyasla daha g\xfc\xe7l\xfc bir g\xf6rsel performansa sahiptir."},"step-1v-32k":{"description":"G\xf6rsel girdi desteği sunar, \xe7ok modlu etkileşim deneyimini artırır."},"step-1v-8k":{"description":"K\xfc\xe7\xfck g\xf6rsel model, temel metin ve g\xf6rsel g\xf6revler i\xe7in uygundur."},"step-1x-edit":{"description":"Bu model, g\xf6r\xfcnt\xfc d\xfczenleme g\xf6revlerine odaklanır ve kullanıcı tarafından sağlanan g\xf6r\xfcnt\xfc ve metin a\xe7ıklamalarına g\xf6re g\xf6r\xfcnt\xfcy\xfc değiştirip iyileştirebilir. Metin a\xe7ıklamaları ve \xf6rnek g\xf6r\xfcnt\xfcler dahil olmak \xfczere \xe7eşitli giriş formatlarını destekler. Model, kullanıcı niyetini anlayarak istenen d\xfczenleme sonu\xe7larını \xfcretir."},"step-1x-medium":{"description":"Bu model g\xfc\xe7l\xfc g\xf6r\xfcnt\xfc oluşturma yeteneklerine sahiptir ve metin a\xe7ıklamalarını giriş olarak destekler. Yerel \xc7ince desteği ile \xc7ince metin a\xe7ıklamalarını daha iyi anlar ve işler, metin anlamını daha doğru yakalayarak g\xf6r\xfcnt\xfc \xf6zelliklerine d\xf6n\xfcşt\xfcr\xfcr ve b\xf6ylece daha hassas g\xf6r\xfcnt\xfc oluşturma sağlar. Model, y\xfcksek \xe7\xf6z\xfcn\xfcrl\xfckl\xfc ve kaliteli g\xf6r\xfcnt\xfcler oluşturabilir ve belirli \xf6l\xe7\xfcde stil transferi yeteneğine sahiptir."},"step-2-16k":{"description":"B\xfcy\xfck \xf6l\xe7ekli bağlam etkileşimlerini destekler, karmaşık diyalog senaryoları i\xe7in uygundur."},"step-2-16k-exp":{"description":"step-2 modelinin deneysel versiyonu, en son \xf6zellikleri i\xe7erir ve s\xfcrekli g\xfcncellenmektedir. Resmi \xfcretim ortamında kullanılması \xf6nerilmez."},"step-2-mini":{"description":"Yeni nesil kendi geliştirdiğimiz MFA Attention mimarisine dayanan hızlı b\xfcy\xfck model, \xe7ok d\xfcş\xfck maliyetle step1 ile benzer sonu\xe7lar elde ederken, daha y\xfcksek bir throughput ve daha hızlı yanıt s\xfcresi sağlıyor. Genel g\xf6revleri işleyebilme yeteneğine sahip olup, kodlama yeteneklerinde uzmanlık g\xf6steriyor."},"step-2x-large":{"description":"Jieyue Xingchen\'in yeni nesil g\xf6r\xfcnt\xfc oluşturma modelidir. Model, kullanıcı tarafından sağlanan metin a\xe7ıklamalarına g\xf6re y\xfcksek kaliteli g\xf6r\xfcnt\xfcler oluşturur. Yeni model, daha ger\xe7ek\xe7i doku ve hem \xc7ince hem İngilizce metin oluşturma yeteneklerinde gelişmiş performans sunar."},"step-3":{"description":"Bu model g\xfc\xe7l\xfc g\xf6rsel algılama ve karmaşık akıl y\xfcr\xfctme yeteneklerine sahiptir. Disiplinlerarası karmaşık bilgi anlayışını, matematiksel ve g\xf6rsel verilerin \xe7apraz analizini ve g\xfcnl\xfck hayattaki \xe7eşitli g\xf6rsel analiz gereksinimlerini doğru ve tutarlı şekilde yerine getirebilir."},"step-r1-v-mini":{"description":"Bu model, g\xfc\xe7l\xfc g\xf6r\xfcnt\xfc anlama yeteneğine sahip bir \xe7ıkarım b\xfcy\xfck modelidir, g\xf6r\xfcnt\xfc ve metin bilgilerini işleyebilir, derin d\xfcş\xfcnme sonrası metin oluşturma \xe7ıktısı verebilir. Bu model, g\xf6rsel \xe7ıkarım alanında \xf6ne \xe7ıkarken, birinci sınıf matematik, kod ve metin \xe7ıkarım yeteneklerine de sahiptir. Bağlam uzunluğu 100k\'dır."},"step3":{"description":"Step3, StepStar tarafından geliştirilen \xe7ok modlu bir modeldir ve g\xfc\xe7l\xfc g\xf6rsel anlama yeteneklerine sahiptir."},"stepfun-ai/step3":{"description":"Step3, StepFun tarafından yayımlanan \xf6nc\xfc \xe7ok modlu \xe7ıkarım modelidir; 321 milyar toplam ve 38 milyar aktif parametreye sahip Uzman Karışımı (MoE) mimarisi \xfczerine inşa edilmiştir. Model u\xe7tan uca bir tasarımla kod \xe7\xf6zme maliyetlerini en aza indirmeyi hedeflerken g\xf6rsel-dilsel \xe7ıkarımda \xfcst d\xfczey performans sunar. \xc7oklu matris faktorizasyonlu dikkat (MFA) ile dikkat-FFN ayrıştırmasının (AFD) uyumlu tasarımı sayesinde Step3, hem \xfcst d\xfczey hem de d\xfcş\xfck kapasiteli hızlandırıcılarda y\xfcksek verimliliğini korur. \xd6n eğitim aşamasında Step3, 20 trilyondan fazla metin tokeni ve 4 trilyon g\xf6rsel-metin tokeni işlemiş olup on\'dan fazla dili kapsar. Model, matematik, kodlama ve \xe7ok modlu g\xf6revler gibi \xe7eşitli kıyaslama testlerinde a\xe7ık kaynak modeller arasında lider d\xfczeye ulaşmıştır."},"taichu_llm":{"description":"Zidong Taichu dil b\xfcy\xfck modeli, g\xfc\xe7l\xfc dil anlama yeteneği ile metin oluşturma, bilgi sorgulama, kod programlama, matematik hesaplama, mantıksal akıl y\xfcr\xfctme, duygu analizi, metin \xf6zeti gibi yeteneklere sahiptir. Yenilik\xe7i bir şekilde b\xfcy\xfck veri \xf6n eğitimi ile \xe7ok kaynaklı zengin bilgiyi birleştirir, algoritma teknolojisini s\xfcrekli olarak geliştirir ve b\xfcy\xfck metin verilerinden kelime, yapı, dil bilgisi, anlam gibi yeni bilgileri s\xfcrekli olarak edinir, modelin performansını s\xfcrekli olarak evrimleştirir. Kullanıcılara daha kolay bilgi ve hizmetler sunar ve daha akıllı bir deneyim sağlar."},"taichu_o1":{"description":"taichu_o1, yeni nesil \xe7ıkarım b\xfcy\xfck modelidir, \xe7ok modlu etkileşim ve pekiştirme \xf6ğrenimi ile insan benzeri d\xfcş\xfcnme zincirleri oluşturur, karmaşık karar verme senaryolarını destekler, y\xfcksek hassasiyetli \xe7ıktılar sunarken model \xe7ıkarım d\xfcş\xfcnce yollarını sergiler, strateji analizi ve derin d\xfcş\xfcnme gibi senaryolar i\xe7in uygundur."},"taichu_vl":{"description":"G\xf6r\xfcnt\xfc anlama, bilgi transferi, mantıksal \xe7ıkarım gibi yetenekleri birleştirir ve g\xf6rsel-işitsel soru-cevap alanında \xf6ne \xe7ıkar."},"tencent/Hunyuan-A13B-Instruct":{"description":"Hunyuan-A13B-Instruct, 80 milyar parametreye sahip olup, 13 milyar parametre etkinleştirilerek daha b\xfcy\xfck modellerle rekabet edebilir; \\"hızlı d\xfcş\xfcnme/yavaş d\xfcş\xfcnme\\" karma akıl y\xfcr\xfctmeyi destekler; uzun metin anlama kararlıdır; BFCL-v3 ve τ-Bench ile doğrulanmış, ajan yeteneklerinde liderdir; GQA ve \xe7oklu kuantizasyon formatlarıyla birleşerek verimli akıl y\xfcr\xfctme sağlar."},"tencent/Hunyuan-MT-7B":{"description":"Hunyuan \xc7eviri Modeli, Hunyuan-MT-7B \xe7eviri modeli ve Hunyuan-MT-Chimera birleşik modelinden oluşur. Hunyuan-MT-7B, 7 milyar parametreye sahip hafif bir \xe7eviri modelidir ve kaynak metni hedef dile \xe7evirmek i\xe7in kullanılır. Model, 33 dili ve 5 \xc7in azınlık dilini destekleyen \xe7ift y\xf6nl\xfc \xe7eviri yeteneğine sahiptir. WMT25 uluslararası makine \xe7evirisi yarışmasında, katıldığı 31 dil kategorisinin 30\'unda birinci olarak \xfcst\xfcn \xe7eviri yeteneğini kanıtlamıştır. \xc7eviri senaryoları i\xe7in Tencent Hunyuan, \xf6n eğitimden denetimli ince ayara, ardından \xe7eviri g\xfc\xe7lendirme ve birleşik g\xfc\xe7lendirmeye kadar eksiksiz bir eğitim paradigması sunmuştur. Bu sayede benzer \xf6l\xe7ekli modeller arasında sekt\xf6r lideri performansa ulaşmıştır. Model y\xfcksek hesaplama verimliliğine sahiptir, kolayca dağıtılabilir ve \xe7eşitli uygulama senaryolarına uygundur."},"text-embedding-3-large":{"description":"En g\xfc\xe7l\xfc vekt\xf6rleştirme modeli, İngilizce ve diğer dillerdeki g\xf6revler i\xe7in uygundur."},"text-embedding-3-small":{"description":"Verimli ve ekonomik yeni nesil Embedding modeli, bilgi arama, RAG uygulamaları gibi senaryolar i\xe7in uygundur."},"thudm/glm-4-32b":{"description":"GLM-4-32B-0414, kod \xfcretimi, fonksiyon \xe7ağrıları ve ajan tabanlı g\xf6revler i\xe7in optimize edilmiş 32B iki dilli (\xc7ince ve İngilizce) a\xe7ık ağırlık dil modelidir. 15T y\xfcksek kaliteli ve yeniden akıl y\xfcr\xfctme verisi \xfczerinde \xf6nceden eğitilmiştir ve insan tercihleri uyumu, reddetme \xf6rnekleme ve pekiştirmeli \xf6ğrenme ile daha da geliştirilmiştir. Bu model, karmaşık akıl y\xfcr\xfctme, nesne \xfcretimi ve yapılandırılmış \xe7ıktı g\xf6revlerinde m\xfckemmel performans sergilemekte ve bir\xe7ok benchmark testinde GPT-4o ve DeepSeek-V3-0324 ile karşılaştırılabilir performans g\xf6stermektedir."},"thudm/glm-4-32b:free":{"description":"GLM-4-32B-0414, kod \xfcretimi, fonksiyon \xe7ağrıları ve ajan tabanlı g\xf6revler i\xe7in optimize edilmiş 32B iki dilli (\xc7ince ve İngilizce) a\xe7ık ağırlık dil modelidir. 15T y\xfcksek kaliteli ve yeniden akıl y\xfcr\xfctme verisi \xfczerinde \xf6nceden eğitilmiştir ve insan tercihleri uyumu, reddetme \xf6rnekleme ve pekiştirmeli \xf6ğrenme ile daha da geliştirilmiştir. Bu model, karmaşık akıl y\xfcr\xfctme, nesne \xfcretimi ve yapılandırılmış \xe7ıktı g\xf6revlerinde m\xfckemmel performans sergilemekte ve bir\xe7ok benchmark testinde GPT-4o ve DeepSeek-V3-0324 ile karşılaştırılabilir performans g\xf6stermektedir."},"thudm/glm-4-9b-chat":{"description":"Zhi Pu AI tarafından yayınlanan GLM-4 serisinin en son nesil \xf6n eğitim modelinin a\xe7ık kaynak versiyonudur."},"thudm/glm-z1-32b":{"description":"GLM-Z1-32B-0414, GLM-4-32B\'nin geliştirilmiş akıl y\xfcr\xfctme varyantıdır ve derin matematik, mantık ve kod odaklı sorun \xe7\xf6zme i\xe7in tasarlanmıştır. Karmaşık \xe7ok adımlı g\xf6revlerin performansını artırmak i\xe7in genişletilmiş pekiştirmeli \xf6ğrenme (g\xf6rev spesifik ve genel \xe7ift tercih tabanlı) uygular. Temel GLM-4-32B modeline kıyasla, Z1 yapılandırılmış akıl y\xfcr\xfctme ve formel alanlardaki yetenekleri \xf6nemli \xf6l\xe7\xfcde artırmıştır.\\n\\nBu model, ipucu m\xfchendisliği ile \'d\xfcş\xfcnme\' adımlarını zorunlu kılmayı destekler ve uzun format \xe7ıktılar i\xe7in geliştirilmiş tutarlılık sağlar. Ajan iş akışları i\xe7in optimize edilmiştir ve uzun bağlamı (YaRN aracılığıyla), JSON ara\xe7 \xe7ağrılarını ve kararlı akıl y\xfcr\xfctme i\xe7in ince ayar \xf6rnekleme yapılandırmalarını destekler. Derin d\xfcş\xfcnme, \xe7ok adımlı akıl y\xfcr\xfctme veya formel \xe7ıkarım gerektiren kullanım durumları i\xe7in idealdir."},"thudm/glm-z1-rumination-32b":{"description":"THUDM: GLM Z1 Rumination 32B, GLM-4-Z1 serisinin 32B parametreli derin akıl y\xfcr\xfctme modelidir ve uzun s\xfcre d\xfcş\xfcnmeyi gerektiren karmaşık, a\xe7ık u\xe7lu g\xf6revler i\xe7in optimize edilmiştir. glm-4-32b-0414 temel alınarak geliştirilmiş ve ek g\xfc\xe7lendirilmiş \xf6ğrenme aşamaları ve \xe7ok aşamalı hizalama stratejileri eklenmiştir; genişletilmiş bilişsel işleme sim\xfcle etmek i\xe7in \'d\xfcş\xfcnme\' yeteneği getirilmiştir. Bu, yinelemeli akıl y\xfcr\xfctme, \xe7ok adımlı analiz ve arama, alma ve alıntı bilincine sahip sentez gibi ara\xe7 artırma iş akışlarını i\xe7erir.\\n\\nBu model, araştırma yazımı, karşılaştırmalı analiz ve karmaşık soru-cevap konularında m\xfckemmel performans sergiler. Arama ve navigasyon ilkelere (`search`, `click`, `open`, `finish`) y\xf6nelik işlev \xe7ağrılarını destekler, b\xf6ylece ajan tabanlı boru hatlarında kullanılabilir. D\xfcş\xfcnme davranışı, kural tabanlı \xf6d\xfcller ve gecikmeli karar verme mekanizması ile \xe7ok turlu d\xf6ng\xfc kontrol\xfc ile şekillendirilir ve OpenAI i\xe7 hizalama yığını gibi derin araştırma \xe7er\xe7evelerine g\xf6re değerlendirilir. Bu varyant, derinlik gerektiren senaryolar i\xe7in uygundur."},"tngtech/deepseek-r1t-chimera:free":{"description":"DeepSeek-R1T-Chimera, DeepSeek-R1 ve DeepSeek-V3 (0324) birleştirilerek oluşturulmuştur ve R1\'in akıl y\xfcr\xfctme yetenekleri ile V3\'\xfcn token verimliliği iyileştirmelerini bir araya getirir. DeepSeek-MoE Transformer mimarisine dayanır ve genel metin \xfcretim g\xf6revleri i\xe7in optimize edilmiştir.\\n\\nBu model, iki kaynak modelin \xf6nceden eğitilmiş ağırlıklarını birleştirerek akıl y\xfcr\xfctme, verimlilik ve talimat takibi g\xf6revlerinin performansını dengelemektedir. MIT lisansı altında yayımlanmış olup, araştırma ve ticari kullanım i\xe7in tasarlanmıştır."},"togethercomputer/StripedHyena-Nous-7B":{"description":"StripedHyena Nous (7B), etkili stratejiler ve model mimarisi ile artırılmış hesaplama yetenekleri sunar."},"tts-1":{"description":"En son metinden sese model, ger\xe7ek zamanlı senaryolar i\xe7in hız optimizasyonu yapılmıştır."},"tts-1-hd":{"description":"En son metinden sese model, kaliteyi optimize etmek i\xe7in tasarlanmıştır."},"upstage/SOLAR-10.7B-Instruct-v1.0":{"description":"Upstage SOLAR Instruct v1 (11B), ince ayar gerektiren talimat g\xf6revleri i\xe7in uygundur ve m\xfckemmel dil işleme yetenekleri sunar."},"us.anthropic.claude-3-5-sonnet-20241022-v2:0":{"description":"Claude 3.5 Sonnet, end\xfcstri standartlarını y\xfckselterek, rakip modelleri ve Claude 3 Opus\'u aşan performans sergilemekte; geniş değerlendirmelerde m\xfckemmel sonu\xe7lar verirken, orta seviye modellerimizin hız ve maliyetine sahiptir."},"us.anthropic.claude-3-7-sonnet-20250219-v1:0":{"description":"Claude 3.7 sonnet, Anthropic\'in en hızlı bir sonraki nesil modelidir. Claude 3 Haiku ile karşılaştırıldığında, Claude 3.7 Sonnet, t\xfcm becerilerde iyileşmeler g\xf6stermiştir ve bir\xe7ok zeka standart testinde bir \xf6nceki neslin en b\xfcy\xfck modeli olan Claude 3 Opus\'u geride bırakmıştır."},"us.anthropic.claude-haiku-4-5-20251001-v1:0":{"description":"Claude Haiku 4.5, Anthropic\'in şimdiye kadarki en hızlı ve en akıllı Haiku modelidir; yıldırım hızında \xe7alışır ve gelişmiş d\xfcş\xfcnme yeteneklerine sahiptir."},"us.anthropic.claude-sonnet-4-5-20250929-v1:0":{"description":"Claude Sonnet 4.5, Anthropic\'in bug\xfcne kadarki en akıllı modelidir."},"v0-1.0-md":{"description":"v0-1.0-md modeli, v0 API aracılığıyla hizmet veren eski bir modeldir"},"v0-1.5-lg":{"description":"v0-1.5-lg modeli, ileri d\xfczey d\xfcş\xfcnme veya muhakeme g\xf6revleri i\xe7in uygundur"},"v0-1.5-md":{"description":"v0-1.5-md modeli, g\xfcnl\xfck g\xf6revler ve kullanıcı aray\xfcz\xfc (UI) oluşturma i\xe7in uygundur"},"vercel/v0-1.0-md":{"description":"Modern web uygulamaları oluşturmak, d\xfczeltmek ve optimize etmek i\xe7in v0 arkasındaki modele erişim; belirli \xe7er\xe7eveler i\xe7in \xe7ıkarım ve g\xfcncel bilgi i\xe7erir."},"vercel/v0-1.5-md":{"description":"Modern web uygulamaları oluşturmak, d\xfczeltmek ve optimize etmek i\xe7in v0 arkasındaki modele erişim; belirli \xe7er\xe7eveler i\xe7in \xe7ıkarım ve g\xfcncel bilgi i\xe7erir."},"wan2.2-t2i-flash":{"description":"Wanxiang 2.2 hızlı s\xfcr\xfcm, mevcut en yeni modeldir. Yaratıcılık, kararlılık ve ger\xe7ek\xe7ilikte kapsamlı y\xfckseltmeler sunar; hızlı \xfcretim hızı ve y\xfcksek maliyet performansı sağlar."},"wan2.2-t2i-plus":{"description":"Wanxiang 2.2 profesyonel s\xfcr\xfcm, mevcut en yeni modeldir. Yaratıcılık, kararlılık ve ger\xe7ek\xe7ilikte kapsamlı y\xfckseltmeler sunar; detaylı ve zengin g\xf6r\xfcnt\xfcler \xfcretir."},"wanx-v1":{"description":"Temel metinden g\xf6r\xfcnt\xfc oluşturma modelidir. Tongyi Wanxiang resmi web sitesindeki 1.0 genel modeline karşılık gelir."},"wanx2.0-t2i-turbo":{"description":"Doku ve portrelerde uzmandır; orta hızda ve d\xfcş\xfck maliyetlidir. Tongyi Wanxiang resmi web sitesindeki 2.0 hızlı modele karşılık gelir."},"wanx2.1-t2i-plus":{"description":"Kapsamlı y\xfckseltilmiş versiyondur. \xdcretilen g\xf6r\xfcnt\xfc detayları daha zengindir, hız biraz daha yavaştır. Tongyi Wanxiang resmi web sitesindeki 2.1 profesyonel modele karşılık gelir."},"wanx2.1-t2i-turbo":{"description":"Kapsamlı y\xfckseltilmiş versiyondur. \xdcretim hızı hızlı, etkisi kapsamlı ve genel maliyet performansı y\xfcksektir. Tongyi Wanxiang resmi web sitesindeki 2.1 hızlı modele karşılık gelir."},"whisper-1":{"description":"Genel ama\xe7lı konuşma tanıma modeli olup, \xe7ok dilli konuşma tanıma, konuşma \xe7evirisi ve dil tanıma destekler."},"wizardlm2":{"description":"WizardLM 2, Microsoft AI tarafından sunulan bir dil modelidir, karmaşık diyaloglar, \xe7ok dilli, akıl y\xfcr\xfctme ve akıllı asistan alanlarında \xf6zellikle başarılıdır."},"wizardlm2:8x22b":{"description":"WizardLM 2, Microsoft AI tarafından sunulan bir dil modelidir, karmaşık diyaloglar, \xe7ok dilli, akıl y\xfcr\xfctme ve akıllı asistan alanlarında \xf6zellikle başarılıdır."},"x-ai/grok-4-fast":{"description":"Grok 4 Fast\'i sunmaktan mutluluk duyuyoruz; bu, maliyet etkin \xe7ıkarım modelleri konusundaki en son ilerlememizdir."},"x-ai/grok-code-fast-1":{"description":"Hızlı ve ekonomik bir \xe7ıkarım modeli olan grok-code-fast-1\'i tanıtmaktan memnuniyet duyuyoruz; \xf6zellikle temsilci tabanlı kodlamada \xfcst\xfcn performans sergiler."},"x1":{"description":"Spark X1 modeli daha da geliştirilecek; \xf6nceki matematik g\xf6revlerinde ulusal liderlik temelinde, akıl y\xfcr\xfctme, metin \xfcretimi, dil anlama gibi genel g\xf6revlerde OpenAI o1 ve DeepSeek R1 ile karşılaştırılabilir sonu\xe7lar elde edilecektir."},"xai/grok-2":{"description":"Grok 2, en ileri \xe7ıkarım yeteneklerine sahip \xf6nc\xfc bir dil modelidir. Sohbet, kodlama ve \xe7ıkarımda gelişmiş yetenekler sunar ve LMSYS sıralamasında Claude 3.5 Sonnet ve GPT-4-Turbo\'nun \xf6n\xfcndedir."},"xai/grok-2-vision":{"description":"Grok 2 g\xf6rsel modeli, g\xf6rsel tabanlı g\xf6revlerde \xfcst\xfcn performans sunar; g\xf6rsel matematik \xe7ıkarımı (MathVista) ve belge tabanlı soru-cevap (DocVQA) alanlarında en ileri performansı sağlar. Belgeler, grafikler, diyagramlar, ekran g\xf6r\xfcnt\xfcleri ve fotoğraflar dahil \xe7eşitli g\xf6rsel bilgileri işleyebilir."},"xai/grok-3":{"description":"xAI\'nin amiral gemisi modeli olup, veri \xe7ıkarımı, kodlama ve metin \xf6zetleme gibi kurumsal kullanım durumlarında \xfcst\xfcn performans g\xf6sterir. Finans, sağlık, hukuk ve bilim alanlarında derin alan bilgisine sahiptir."},"xai/grok-3-fast":{"description":"xAI\'nin amiral gemisi modeli olup, veri \xe7ıkarımı, kodlama ve metin \xf6zetleme gibi kurumsal kullanım durumlarında \xfcst\xfcn performans g\xf6sterir. Hızlı model varyantı, daha hızlı altyapıda hizmet verir ve standart modele g\xf6re \xe7ok daha hızlı yanıt s\xfcreleri sunar. Artan hız, \xe7ıktı başına daha y\xfcksek maliyetle dengelenir."},"xai/grok-3-mini":{"description":"xAI\'nin hafif modeli olup, yanıt \xf6ncesi d\xfcş\xfcnme yapar. Derin alan bilgisi gerektirmeyen basit veya mantığa dayalı g\xf6revler i\xe7in idealdir. Ham d\xfcş\xfcnce izleri erişilebilir durumdadır."},"xai/grok-3-mini-fast":{"description":"xAI\'nin hafif modeli olup, yanıt \xf6ncesi d\xfcş\xfcnme yapar. Derin alan bilgisi gerektirmeyen basit veya mantığa dayalı g\xf6revler i\xe7in idealdir. Ham d\xfcş\xfcnce izleri erişilebilir durumdadır. Hızlı model varyantı, daha hızlı altyapıda hizmet verir ve standart modele g\xf6re \xe7ok daha hızlı yanıt s\xfcreleri sunar. Artan hız, \xe7ıktı başına daha y\xfcksek maliyetle dengelenir."},"xai/grok-4":{"description":"xAI\'nin en yeni ve en b\xfcy\xfck amiral gemisi modeli olup, doğal dil, matematik ve \xe7ıkarımda eşsiz performans sunar—m\xfckemmel \xe7ok y\xf6nl\xfc oyuncu."},"yi-large":{"description":"Yeni nesil y\xfcz milyar parametreli model, g\xfc\xe7l\xfc soru yanıtlama ve metin \xfcretim yetenekleri sunar."},"yi-large-fc":{"description":"yi-large modelinin temelinde, ara\xe7 \xe7ağrısı yeteneklerini destekleyip g\xfc\xe7lendiren bir yapı sunar, \xe7eşitli ajan veya iş akışı kurma gereksinimleri i\xe7in uygundur."},"yi-large-preview":{"description":"Erken s\xfcr\xfcm, yi-large (yeni s\xfcr\xfcm) kullanılması \xf6nerilir."},"yi-large-rag":{"description":"yi-large modelinin g\xfc\xe7l\xfc bir hizmeti, arama ve \xfcretim teknolojilerini birleştirerek doğru yanıtlar sunar, ger\xe7ek zamanlı olarak t\xfcm ağdan bilgi arama hizmeti sağlar."},"yi-large-turbo":{"description":"Son derece y\xfcksek maliyet performansı ve m\xfckemmel performans. Performans ve akıl y\xfcr\xfctme hızı, maliyet a\xe7ısından y\xfcksek hassasiyetli ayarlama yapılır."},"yi-lightning":{"description":"En yeni y\xfcksek performanslı model, y\xfcksek kaliteli \xe7ıktıları garanti ederken akıl y\xfcr\xfctme hızını b\xfcy\xfck \xf6l\xe7\xfcde artırır."},"yi-lightning-lite":{"description":"Hafif versiyon, yi-lightning kullanımını \xf6nerir."},"yi-medium":{"description":"Orta boyutlu model, dengeli yetenekler ve y\xfcksek maliyet performansı sunar. Talimat takibi yetenekleri derinlemesine optimize edilmiştir."},"yi-medium-200k":{"description":"200K ultra uzun bağlam penceresi, uzun metinlerin derinlemesine anlaşılması ve \xfcretilmesi yetenekleri sunar."},"yi-spark":{"description":"K\xfc\xe7\xfck ama etkili, hafif ve hızlı bir modeldir. G\xfc\xe7lendirilmiş matematiksel işlemler ve kod yazma yetenekleri sunar."},"yi-vision":{"description":"Karmaşık g\xf6rsel g\xf6revler i\xe7in model, y\xfcksek performanslı resim anlama ve analiz yetenekleri sunar."},"yi-vision-v2":{"description":"Karmaşık g\xf6rsel g\xf6revler i\xe7in model, birden fazla resme dayalı y\xfcksek performanslı anlama ve analiz yetenekleri sunar."},"z-ai/glm-4.6":{"description":"Zhipu\'nun en yeni amiral gemisi modeli GLM-4.6; ileri d\xfczey kodlama, uzun metin işleme, \xe7ıkarım ve yapay zeka yeteneklerinde seleflerini tamamen geride bırakıyor."},"zai-org/GLM-4.5":{"description":"GLM-4.5, akıllı ajan uygulamaları i\xe7in tasarlanmış temel modeldir ve Mixture-of-Experts (MoE) mimarisi kullanır. Ara\xe7 \xe7ağrısı, web tarama, yazılım m\xfchendisliği ve \xf6n u\xe7 programlama alanlarında derin optimizasyonlar i\xe7erir. Claude Code, Roo Code gibi kod ajanlarına sorunsuz entegrasyon destekler. GLM-4.5, karmaşık \xe7ıkarım ve g\xfcnl\xfck kullanım gibi \xe7eşitli senaryolara uyum sağlayan hibrit \xe7ıkarım moduna sahiptir."},"zai-org/GLM-4.5-Air":{"description":"GLM-4.5-Air, akıllı ajan uygulamaları i\xe7in tasarlanmış temel modeldir ve Mixture-of-Experts (MoE) mimarisi kullanır. Ara\xe7 \xe7ağrısı, web tarama, yazılım m\xfchendisliği ve \xf6n u\xe7 programlama alanlarında derin optimizasyonlar i\xe7erir. Claude Code, Roo Code gibi kod ajanlarına sorunsuz entegrasyon destekler. GLM-4.5, karmaşık \xe7ıkarım ve g\xfcnl\xfck kullanım gibi \xe7eşitli senaryolara uyum sağlayan hibrit \xe7ıkarım moduna sahiptir."},"zai-org/GLM-4.5V":{"description":"GLM-4.5V, Zhipu AI（智谱 AI） tarafından yayımlanan en son nesil g\xf6rsel-dil modeli (VLM)\'dir. Bu model, 106 milyar toplam parametre ve 12 milyar aktivasyon parametresine sahip amiral gemisi metin modeli GLM-4.5-Air \xfczerine inşa edilmiş olup, karma uzman (Mixture-of-Experts, MoE) mimarisini kullanır ve daha d\xfcş\xfck \xe7ıkarım maliyetiyle \xfcst\xfcn performans sağlamayı hedefler. GLM-4.5V teknik olarak GLM-4.1V-Thinking hattını s\xfcrd\xfcr\xfcrken \xfc\xe7 boyutlu d\xf6nd\xfcrmeli pozisyon kodlaması (3D-RoPE) gibi yenilikleri de getirerek \xfc\xe7 boyutlu uzaysal ilişkilerin algılanması ve \xe7ıkarımı yeteneğini \xf6nemli \xf6l\xe7\xfcde g\xfc\xe7lendirir. \xd6n eğitme, denetimli ince ayar ve pekiştirmeli \xf6ğrenme aşamalarında yapılan optimizasyonlar sayesinde model; g\xf6r\xfcnt\xfc, video ve uzun belgeler gibi \xe7eşitli g\xf6rsel i\xe7erikleri işleyebilir ve 41 a\xe7ık \xe7ok modlu kıyaslama testinde aynı seviyedeki a\xe7ık kaynak modeller arasında en \xfcst d\xfczey performansa ulaşmıştır. Ayrıca modele eklenen \\"d\xfcş\xfcnme modu\\" anahtarı, kullanıcıların hızlı yanıt ile derin \xe7ıkarım arasında esnek\xe7e tercih yaparak verim ile etki arasında denge kurmasına olanak tanır."},"zai-org/GLM-4.6":{"description":"GLM-4.5\'e kıyasla GLM-4.6 bir\xe7ok \xf6nemli iyileştirme getirmiştir. Bağlam penceresi 128K\'dan 200K token\'a genişletilerek modelin daha karmaşık ajan g\xf6revlerini işlemesi sağlanmıştır. Model, kod bazlı testlerde daha y\xfcksek puanlar almış ve Claude Code, Cline, Roo Code ve Kilo Code gibi uygulamalarda ger\xe7ek d\xfcnya performansını artırmıştır; \xf6zellikle g\xf6rsel a\xe7ıdan zengin \xf6n y\xfcz sayfaları oluşturma konusunda gelişmeler kaydetmiştir. GLM-4.6 \xe7ıkarım performansında belirgin artış g\xf6stermiş ve \xe7ıkarım sırasında ara\xe7 kullanımını destekleyerek daha g\xfc\xe7l\xfc bir b\xfct\xfcnsel yetenek sunmuştur. Ara\xe7 kullanımı ve arama tabanlı ajanlarda daha iyi performans sergilemiş ve ajan \xe7er\xe7evelerine daha etkili entegrasyon sağlamıştır. Yazımda ise model, stil ve okunabilirlik a\xe7ısından insan tercihleriyle daha uyumlu olup rol yapma senaryolarında daha doğal davranmaktadır."},"zai/glm-4.5":{"description":"GLM-4.5 serisi modeller, ajanlar i\xe7in \xf6zel olarak tasarlanmış temel modellerdir. Amiral gemisi GLM-4.5, 355 milyar toplam parametre (32 milyar aktif) i\xe7erir ve karma \xe7ıkarım, kodlama ve ajan yeteneklerini birleştirerek karmaşık uygulama ihtiya\xe7larını karşılar. Karma \xe7ıkarım sistemi olarak \xe7ift modlu \xe7alışma sunar."},"zai/glm-4.5-air":{"description":"GLM-4.5 ve GLM-4.5-Air, ajan uygulamalarına y\xf6nelik temel modeller olarak tasarlanmış en yeni amiral gemisi modellerimizdir. Her ikisi de karma uzman (MoE) mimarisinden yararlanır. GLM-4.5 toplamda 355 milyar parametreye ve her ileri ge\xe7işte 32 milyar aktif parametreye sahiptir; GLM-4.5-Air ise daha sade bir tasarıma sahip olup toplamda 106 milyar parametre ve 12 milyar aktif parametre i\xe7erir."},"zai/glm-4.5v":{"description":"GLM-4.5V, GLM-4.5-Air temel modeli \xfczerine inşa edilmiştir, GLM-4.1V-Thinking\'in doğrulanmış teknolojisini devralır ve g\xfc\xe7l\xfc 106 milyar parametreli MoE mimarisi ile etkili \xf6l\xe7eklenebilirlik sağlar."}}')}}]);